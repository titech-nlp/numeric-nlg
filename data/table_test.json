[
    {
        "table_id_paper": "D16-1019table_5",
        "caption": "Link prediction results on the test-I, test-II, and test-all sets of FB122 and WN18 (filtered setting).",
        "row_header_level": 2,
        "row_headers": [
            [
                "FB122",
                "TransE"
            ],
            [
                "FB122",
                "TransH"
            ],
            [
                "FB122",
                "TransR"
            ],
            [
                "FB122",
                "KALE-Trip"
            ],
            [
                "FB122",
                "KALE-Pre"
            ],
            [
                "FB122",
                "KALE-Joint"
            ],
            [
                "WN18",
                "TransE"
            ],
            [
                "WN18",
                "TransH"
            ],
            [
                "WN18",
                "TransR"
            ],
            [
                "WN18",
                "KALE-Trip"
            ],
            [
                "WN18",
                "KALE-Pre"
            ],
            [
                "WN18",
                "KALE-Joint"
            ]
        ],
        "column_header_level": 2,
        "column_headers": [
            [
                "Test-I",
                "MRR"
            ],
            [
                "Test-I",
                "MED"
            ],
            [
                "Test-I",
                "HITS@3 (%)"
            ],
            [
                "Test-I",
                "HITS@5 (%)"
            ],
            [
                "Test-I",
                "HITS@10 (%)"
            ],
            [
                "Test-II",
                "MRR"
            ],
            [
                "Test-II",
                "MED"
            ],
            [
                "Test-II",
                "HITS@3 (%)"
            ],
            [
                "Test-II",
                "HITS@5 (%)"
            ],
            [
                "Test-II",
                "HITS@10 (%)"
            ],
            [
                "Test-ALL",
                "MRR"
            ],
            [
                "Test-ALL",
                "MED"
            ],
            [
                "Test-ALL",
                "HITS@3 (%)"
            ],
            [
                "Test-ALL",
                "HITS@5 (%)"
            ],
            [
                "Test-ALL",
                "HITS@10 (%)"
            ]
        ],
        "contents": [
            [
                "0.296",
                "13.0",
                "36.0",
                "41.5",
                "48.1",
                "0.630",
                "2.0",
                "77.5",
                "82.8",
                "88.4",
                "0.480",
                "2.0",
                "58.9",
                "64.2",
                "70.2"
            ],
            [
                "0.280",
                "15.0",
                "33.6",
                "39.1",
                "46.4",
                "0.606",
                "2.0",
                "70.1",
                "75.4",
                "82.0",
                "0.460",
                "3.0",
                "53.7",
                "59.1",
                "66.0"
            ],
            [
                "0.283",
                "16.0",
                "33.4",
                "39.2",
                "46.0",
                "0.499",
                "2.0",
                "57.0",
                "63.2",
                "70.1",
                "0.401",
                "5.0",
                "46.4",
                "52.4",
                "59.3"
            ],
            [
                "0.299",
                "10.0",
                "36.6",
                "42.9",
                "50.2",
                "0.650",
                "2.0",
                "79.0",
                "83.4",
                "88.7",
                "0.492",
                "2.0",
                "59.9",
                "65.2",
                "71.4"
            ],
            [
                "0.291",
                "11.0",
                "35.8",
                "41.9",
                "49.8",
                "0.713",
                "1.0",
                "82.9",
                "86.1",
                "89.9",
                "0.523",
                "2.0",
                "61.7",
                "66.2",
                "71.8"
            ],
            [
                "0.325",
                "9.0",
                "38.4",
                "44.7",
                "52.2",
                "0.684",
                "1.0",
                "79.7",
                "84.1",
                "89.6",
                "0.523",
                "2.0",
                "61.2",
                "66.4",
                "72.8"
            ],
            [
                "0.306",
                "3.0",
                "57.4",
                "72.3",
                "80.1",
                "0.511",
                "2.0",
                "87.5",
                "95.6",
                "98.7",
                "0.453",
                "2.0",
                "79.1",
                "89.1",
                "93.6"
            ],
            [
                "0.318",
                "3.0",
                "61.7",
                "72.4",
                "78.2",
                "0.653",
                "2.0",
                "87.1",
                "91.4",
                "94.6",
                "0.560",
                "2.0",
                "80.0",
                "86.1",
                "90.0"
            ],
            [
                "0.299",
                "3.0",
                "56.1",
                "66.7",
                "74.5",
                "0.597",
                "2.0",
                "75.0",
                "81.7",
                "88.0",
                "0.514",
                "2.0",
                "69.7",
                "77.5",
                "84.3"
            ],
            [
                "0.322",
                "3.0",
                "61.0",
                "73.9",
                "80.8",
                "0.555",
                "2.0",
                "90.6",
                "96.3",
                "98.8",
                "0.490",
                "2.0",
                "82.3",
                "90.1",
                "93.8"
            ],
            [
                "0.322",
                "3.0",
                "60.6",
                "74.5",
                "81.1",
                "0.612",
                "2.0",
                "96.4",
                "98.6",
                "99.6",
                "0.532",
                "2.0",
                "86.4",
                "91.9",
                "94.4"
            ],
            [
                "0.338",
                "3.0",
                "65.5",
                "76.3",
                "82.1",
                "0.787",
                "1.0",
                "93.3",
                "95.4",
                "97.2",
                "0.662",
                "2.0",
                "85.5",
                "90.1",
                "93.0"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "MRR",
            "MED",
            "HITS@3 (%)",
            "HITS@5 (%)",
            "HITS@10 (%)",
            "MRR",
            "MED",
            "HITS@3 (%)",
            "HITS@5 (%)",
            "HITS@10 (%)",
            "MRR",
            "MED",
            "HITS@3 (%)",
            "HITS@5 (%)",
            "HITS@10 (%)"
        ],
        "target_entity": [
            "KALE-Trip",
            "KALE-Pre",
            "KALE-Joint"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Test-I || MRR || 0.296</th>      <th>Test-I || MED || 13.0</th>      <th>Test-I || HITS@3 (%) || 36.0</th>      <th>Test-I || HITS@5 (%) || 41.5</th>      <th>Test-I || HITS@10 (%) || 48.1</th>      <th>Test-II || MRR || 0.630</th>      <th>Test-II || MED || 2.0</th>      <th>Test-II || HITS@3 (%) || 77.5</th>      <th>Test-II || HITS@5 (%) || 82.8</th>      <th>Test-II || HITS@10 (%) || 88.4</th>      <th>Test-ALL || MRR || 0.480</th>      <th>Test-ALL || MED || 2.0</th>      <th>Test-ALL || HITS@3 (%) || 58.9</th>      <th>Test-ALL || HITS@5 (%) || 64.2</th>      <th>Test-ALL || HITS@10 (%) || 70.2</th>    </tr>  </thead>  <tbody>    <tr>      <td>FB122 || TransH</td>      <td>0.280</td>      <td>15.0</td>      <td>33.6</td>      <td>39.1</td>      <td>46.4</td>      <td>0.606</td>      <td>2.0</td>      <td>70.1</td>      <td>75.4</td>      <td>82.0</td>      <td>0.460</td>      <td>3.0</td>      <td>53.7</td>      <td>59.1</td>      <td>66.0</td>    </tr>    <tr>      <td>FB122 || TransR</td>      <td>0.283</td>      <td>16.0</td>      <td>33.4</td>      <td>39.2</td>      <td>46.0</td>      <td>0.499</td>      <td>2.0</td>      <td>57.0</td>      <td>63.2</td>      <td>70.1</td>      <td>0.401</td>      <td>5.0</td>      <td>46.4</td>      <td>52.4</td>      <td>59.3</td>    </tr>    <tr>      <td>FB122 || KALE-Trip</td>      <td>0.299</td>      <td>10.0</td>      <td>36.6</td>      <td>42.9</td>      <td>50.2</td>      <td>0.650</td>      <td>2.0</td>      <td>79.0</td>      <td>83.4</td>      <td>88.7</td>      <td>0.492</td>      <td>2.0</td>      <td>59.9</td>      <td>65.2</td>      <td>71.4</td>    </tr>    <tr>      <td>FB122 || KALE-Pre</td>      <td>0.291</td>      <td>11.0</td>      <td>35.8</td>      <td>41.9</td>      <td>49.8</td>      <td>0.713</td>      <td>1.0</td>      <td>82.9</td>      <td>86.1</td>      <td>89.9</td>      <td>0.523</td>      <td>2.0</td>      <td>61.7</td>      <td>66.2</td>      <td>71.8</td>    </tr>    <tr>      <td>FB122 || KALE-Joint</td>      <td>0.325</td>      <td>9.0</td>      <td>38.4</td>      <td>44.7</td>      <td>52.2</td>      <td>0.684</td>      <td>1.0</td>      <td>79.7</td>      <td>84.1</td>      <td>89.6</td>      <td>0.523</td>      <td>2.0</td>      <td>61.2</td>      <td>66.4</td>      <td>72.8</td>    </tr>    <tr>      <td>WN18 || TransE</td>      <td>0.306</td>      <td>3.0</td>      <td>57.4</td>      <td>72.3</td>      <td>80.1</td>      <td>0.511</td>      <td>2.0</td>      <td>87.5</td>      <td>95.6</td>      <td>98.7</td>      <td>0.453</td>      <td>2.0</td>      <td>79.1</td>      <td>89.1</td>      <td>93.6</td>    </tr>    <tr>      <td>WN18 || TransH</td>      <td>0.318</td>      <td>3.0</td>      <td>61.7</td>      <td>72.4</td>      <td>78.2</td>      <td>0.653</td>      <td>2.0</td>      <td>87.1</td>      <td>91.4</td>      <td>94.6</td>      <td>0.560</td>      <td>2.0</td>      <td>80.0</td>      <td>86.1</td>      <td>90.0</td>    </tr>    <tr>      <td>WN18 || TransR</td>      <td>0.299</td>      <td>3.0</td>      <td>56.1</td>      <td>66.7</td>      <td>74.5</td>      <td>0.597</td>      <td>2.0</td>      <td>75.0</td>      <td>81.7</td>      <td>88.0</td>      <td>0.514</td>      <td>2.0</td>      <td>69.7</td>      <td>77.5</td>      <td>84.3</td>    </tr>    <tr>      <td>WN18 || KALE-Trip</td>      <td>0.322</td>      <td>3.0</td>      <td>61.0</td>      <td>73.9</td>      <td>80.8</td>      <td>0.555</td>      <td>2.0</td>      <td>90.6</td>      <td>96.3</td>      <td>98.8</td>      <td>0.490</td>      <td>2.0</td>      <td>82.3</td>      <td>90.1</td>      <td>93.8</td>    </tr>    <tr>      <td>WN18 || KALE-Pre</td>      <td>0.322</td>      <td>3.0</td>      <td>60.6</td>      <td>74.5</td>      <td>81.1</td>      <td>0.612</td>      <td>2.0</td>      <td>96.4</td>      <td>98.6</td>      <td>99.6</td>      <td>0.532</td>      <td>2.0</td>      <td>86.4</td>      <td>91.9</td>      <td>94.4</td>    </tr>    <tr>      <td>WN18 || KALE-Joint</td>      <td>0.338</td>      <td>3.0</td>      <td>65.5</td>      <td>76.3</td>      <td>82.1</td>      <td>0.787</td>      <td>1.0</td>      <td>93.3</td>      <td>95.4</td>      <td>97.2</td>      <td>0.662</td>      <td>2.0</td>      <td>85.5</td>      <td>90.1</td>      <td>93.0</td>    </tr>  </tbody></table>",
        "table_name": "Table 5",
        "table_id": "table_5",
        "paper_id": "D16-1019",
        "page_no": 8,
        "dir": "emnlp2016",
        "valid": 1
    },
    {
        "table_id_paper": "D16-1031table_3",
        "caption": "Comparison on validation perplexity. BoW, TDNN and NABS are the baseline neural compression models with different encoders in Rush et al. (2015)",
        "row_header_level": 2,
        "row_headers": [
            [
                "Model",
                "Bag-of-Word (BoW)"
            ],
            [
                "Model",
                "Convolutional (TDNN)"
            ],
            [
                "Model",
                "Attention-Based (NABS) (Rush et al.,,2015)"
            ],
            [
                "Model",
                "Forced-Attention (FSC)"
            ],
            [
                "Model",
                "Auto-encoding (ASC+FSC1)"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "Labelled Data"
            ],
            [
                "Perplexity"
            ]
        ],
        "contents": [
            [
                "3.8M",
                "43.6"
            ],
            [
                "3.8M",
                "35.9"
            ],
            [
                "3.8M",
                "27.1"
            ],
            [
                "3.8M",
                "18.6"
            ],
            [
                "3.8M",
                "16.6"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "Labelled Data",
            "Perplexity"
        ],
        "target_entity": [
            "Auto-encoding (ASC+FSC1)"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Labelled Data</th>      <th>Perplexity</th>    </tr>  </thead>  <tbody>    <tr>      <td>Model || Bag-of-Word (BoW)</td>      <td>3.8M</td>      <td>43.6</td>    </tr>    <tr>      <td>Model || Convolutional (TDNN)</td>      <td>3.8M</td>      <td>35.9</td>    </tr>    <tr>      <td>Model || Attention-Based (NABS) (Rush et al.,,2015)</td>      <td>3.8M</td>      <td>27.1</td>    </tr>    <tr>      <td>Model || Forced-Attention (FSC)</td>      <td>3.8M</td>      <td>18.6</td>    </tr>    <tr>      <td>Model || Auto-encoding (ASC+FSC1)</td>      <td>3.8M</td>      <td>16.6</td>    </tr>  </tbody></table>",
        "table_name": "Table 3",
        "table_id": "table_3",
        "paper_id": "D16-1031",
        "page_no": 8,
        "dir": "emnlp2016",
        "valid": 1
    },
    {
        "table_id_paper": "D16-1043table_4",
        "caption": "Performance on maximally covered datasets.",
        "row_header_level": 3,
        "row_headers": [
            [
                "Source",
                "Wikipedia",
                "Text"
            ],
            [
                "Source",
                "Google",
                "Visual"
            ],
            [
                "Source",
                "Google",
                "MM"
            ],
            [
                "Source",
                "Bing",
                "Visual"
            ],
            [
                "Source",
                "Bing",
                "MM"
            ],
            [
                "Source",
                "Flickr",
                "Visual"
            ],
            [
                "Source",
                "Flickr",
                "MM"
            ],
            [
                "Source",
                "ImageNet",
                "Visual"
            ],
            [
                "Source",
                "ImageNet",
                "MM"
            ],
            [
                "Source",
                "ESPGame",
                "Visual"
            ],
            [
                "Source",
                "ESPGame",
                "MM"
            ]
        ],
        "column_header_level": 6,
        "column_headers": [
            [
                "Arch.",
                "AlexNet",
                "Agg.",
                "Mean",
                "Type/Eval",
                "SL"
            ],
            [
                "Arch.",
                "AlexNet",
                "Agg.",
                "Mean",
                "Type/Eval",
                "MEN"
            ],
            [
                "Arch.",
                "AlexNet",
                "Agg.",
                "Max",
                "Type/Eval",
                "SL"
            ],
            [
                "Arch.",
                "AlexNet",
                "Agg.",
                "Max",
                "Type/Eval",
                "MEN"
            ],
            [
                "Arch.",
                "GoogLeNet",
                "Agg.",
                "Mean",
                "Type/Eval",
                "SL"
            ],
            [
                "Arch.",
                "GoogLeNet",
                "Agg.",
                "Mean",
                "Type/Eval",
                "MEN"
            ],
            [
                "Arch.",
                "GoogLeNet",
                "Agg.",
                "Max",
                "Type/Eval",
                "SL"
            ],
            [
                "Arch.",
                "GoogLeNet",
                "Agg.",
                "Max",
                "Type/Eval",
                "MEN"
            ],
            [
                "Arch.",
                "VGGNet",
                "Agg.",
                "Mean",
                "Type/Eval",
                "SL"
            ],
            [
                "Arch.",
                "VGGNet",
                "Agg.",
                "Mean",
                "Type/Eval",
                "MEN"
            ],
            [
                "Arch.",
                "VGGNet",
                "Agg.",
                "Max",
                "Type/Eval",
                "SL"
            ],
            [
                "Arch.",
                "VGGNet",
                "Agg.",
                "Max",
                "Type/Eval",
                "MEN"
            ]
        ],
        "contents": [
            [
                "0.310",
                "0.682",
                "0.310",
                "0.682",
                "0.310",
                "0.682",
                "0.310",
                "0.682",
                "0.310",
                "0.682",
                "0.310",
                "0.682"
            ],
            [
                "0.340",
                "0.503",
                "0.334",
                "0.513",
                "0.358",
                "0.495",
                "0.367",
                "0.501",
                "0.342",
                "0.512",
                "0.332",
                "0.494"
            ],
            [
                "0.380",
                "0.711",
                "0.370",
                "0.719",
                "0.379",
                "0.711",
                "0.365",
                "0.716",
                "0.380",
                "0.714",
                "0.365",
                "0.716"
            ],
            [
                "0.325",
                "0.567",
                "0.316",
                "0.554",
                "0.310",
                "0.526",
                "0.303",
                "0.520",
                "0.304",
                "0.551",
                "0.289",
                "0.507"
            ],
            [
                "0.373",
                "0.727",
                "0.360",
                "0.725",
                "0.364",
                "0.723",
                "0.350",
                "0.724",
                "0.361",
                "0.727",
                "0.349",
                "0.719"
            ],
            [
                "0.234",
                "0.483",
                "0.224",
                "0.441",
                "0.238",
                "0.407",
                "0.236",
                "0.385",
                "0.243",
                "0.460",
                "0.226",
                "0.385"
            ],
            [
                "0.350",
                "0.715",
                "0.343",
                "0.711",
                "0.347",
                "0.689",
                "0.344",
                "0.703",
                "0.354",
                "0.702",
                "0.339",
                "0.696"
            ],
            [
                "0.313",
                "0.561",
                "0.313",
                "0.561",
                "0.341",
                "0.540",
                "0.411",
                "0.603",
                "0.404",
                "0.584",
                "0.401",
                "0.578"
            ],
            [
                "0.362",
                "0.713",
                "0.362",
                "0.713",
                "0.373",
                "0.719",
                "0.401",
                "0.731",
                "0.427",
                "0.727",
                "0.412",
                "0.723"
            ],
            [
                "0.018",
                "0.448",
                "0.026",
                "0.376",
                "0.063",
                "0.487",
                "0.050",
                "0.434",
                "0.125",
                "0.506",
                "0.106",
                "0.451"
            ],
            [
                "0.208",
                "0.686",
                "0.187",
                "0.672",
                "0.243",
                "0.700",
                "0.246",
                "0.696",
                "0.269",
                "0.708",
                "0.260",
                "0.698"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "similarity",
            "similarity",
            "similarity",
            "similarity",
            "similarity",
            "similarity",
            "similarity",
            "similarity",
            "similarity",
            "similarity",
            "similarity",
            "similarity"
        ],
        "target_entity": [
            "VGGNet"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Arch. || AlexNet || Agg. || Mean || Type/Eval || SL</th>      <th>Arch. || AlexNet || Agg. || Mean || Type/Eval || MEN</th>      <th>Arch. || AlexNet || Agg. || Max || Type/Eval || SL</th>      <th>Arch. || AlexNet || Agg. || Max || Type/Eval || MEN</th>      <th>Arch. || GoogLeNet || Agg. || Mean || Type/Eval || SL</th>      <th>Arch. || GoogLeNet || Agg. || Mean || Type/Eval || MEN</th>      <th>Arch. || GoogLeNet || Agg. || Max || Type/Eval || SL</th>      <th>Arch. || GoogLeNet || Agg. || Max || Type/Eval || MEN</th>      <th>Arch. || VGGNet || Agg. || Mean || Type/Eval || SL</th>      <th>Arch. || VGGNet || Agg. || Mean || Type/Eval || MEN</th>      <th>Arch. || VGGNet || Agg. || Max || Type/Eval || SL</th>      <th>Arch. || VGGNet || Agg. || Max || Type/Eval || MEN</th>    </tr>  </thead>  <tbody>    <tr>      <td>Source || Wikipedia || Text</td>      <td>0.310</td>      <td>0.682</td>      <td>0.310</td>      <td>0.682</td>      <td>0.310</td>      <td>0.682</td>      <td>0.310</td>      <td>0.682</td>      <td>0.310</td>      <td>0.682</td>      <td>0.310</td>      <td>0.682</td>    </tr>    <tr>      <td>Source || Google || Visual</td>      <td>0.340</td>      <td>0.503</td>      <td>0.334</td>      <td>0.513</td>      <td>0.358</td>      <td>0.495</td>      <td>0.367</td>      <td>0.501</td>      <td>0.342</td>      <td>0.512</td>      <td>0.332</td>      <td>0.494</td>    </tr>    <tr>      <td>Source || Google || MM</td>      <td>0.380</td>      <td>0.711</td>      <td>0.370</td>      <td>0.719</td>      <td>0.379</td>      <td>0.711</td>      <td>0.365</td>      <td>0.716</td>      <td>0.380</td>      <td>0.714</td>      <td>0.365</td>      <td>0.716</td>    </tr>    <tr>      <td>Source || Bing || Visual</td>      <td>0.325</td>      <td>0.567</td>      <td>0.316</td>      <td>0.554</td>      <td>0.310</td>      <td>0.526</td>      <td>0.303</td>      <td>0.520</td>      <td>0.304</td>      <td>0.551</td>      <td>0.289</td>      <td>0.507</td>    </tr>    <tr>      <td>Source || Bing || MM</td>      <td>0.373</td>      <td>0.727</td>      <td>0.360</td>      <td>0.725</td>      <td>0.364</td>      <td>0.723</td>      <td>0.350</td>      <td>0.724</td>      <td>0.361</td>      <td>0.727</td>      <td>0.349</td>      <td>0.719</td>    </tr>    <tr>      <td>Source || Flickr || Visual</td>      <td>0.234</td>      <td>0.483</td>      <td>0.224</td>      <td>0.441</td>      <td>0.238</td>      <td>0.407</td>      <td>0.236</td>      <td>0.385</td>      <td>0.243</td>      <td>0.460</td>      <td>0.226</td>      <td>0.385</td>    </tr>    <tr>      <td>Source || Flickr || MM</td>      <td>0.350</td>      <td>0.715</td>      <td>0.343</td>      <td>0.711</td>      <td>0.347</td>      <td>0.689</td>      <td>0.344</td>      <td>0.703</td>      <td>0.354</td>      <td>0.702</td>      <td>0.339</td>      <td>0.696</td>    </tr>    <tr>      <td>Source || ImageNet || Visual</td>      <td>0.313</td>      <td>0.561</td>      <td>0.313</td>      <td>0.561</td>      <td>0.341</td>      <td>0.540</td>      <td>0.411</td>      <td>0.603</td>      <td>0.404</td>      <td>0.584</td>      <td>0.401</td>      <td>0.578</td>    </tr>    <tr>      <td>Source || ImageNet || MM</td>      <td>0.362</td>      <td>0.713</td>      <td>0.362</td>      <td>0.713</td>      <td>0.373</td>      <td>0.719</td>      <td>0.401</td>      <td>0.731</td>      <td>0.427</td>      <td>0.727</td>      <td>0.412</td>      <td>0.723</td>    </tr>    <tr>      <td>Source || ESPGame || Visual</td>      <td>0.018</td>      <td>0.448</td>      <td>0.026</td>      <td>0.376</td>      <td>0.063</td>      <td>0.487</td>      <td>0.050</td>      <td>0.434</td>      <td>0.125</td>      <td>0.506</td>      <td>0.106</td>      <td>0.451</td>    </tr>    <tr>      <td>Source || ESPGame || MM</td>      <td>0.208</td>      <td>0.686</td>      <td>0.187</td>      <td>0.672</td>      <td>0.243</td>      <td>0.700</td>      <td>0.246</td>      <td>0.696</td>      <td>0.269</td>      <td>0.708</td>      <td>0.260</td>      <td>0.698</td>    </tr>  </tbody></table>",
        "table_name": "Table 4",
        "table_id": "table_4",
        "paper_id": "D16-1043",
        "page_no": 5,
        "dir": "emnlp2016",
        "valid": 1
    },
    {
        "table_id_paper": "D16-1044table_4",
        "caption": "Open-ended and multiple-choice (MC) results on VQA test set (trained on train+val set) compared with state-of-the-art: accuracy in %. See Sec. 4.4.",
        "row_header_level": 1,
        "row_headers": [
            [
                "MCB"
            ],
            [
                "MCB + Genome"
            ],
            [
                "MCB + Att."
            ],
            [
                "MCB + Att. + GloVe"
            ],
            [
                "MCB + Att. + Genome"
            ],
            [
                "MCB + Att. + GloVe + Genome"
            ],
            [
                "Ensemble of 7 Att. models"
            ],
            [
                "Naver Labs (challenge 2nd)"
            ],
            [
                "HieCoAtt (Lu et al. 2016)"
            ],
            [
                "DMN+ (Xiong et al. 2016)"
            ],
            [
                "FDA (Ilievski et al. 2016)"
            ],
            [
                "D-NMN (Andreas et al. 2016a)"
            ],
            [
                "AMA (Wu et al. 2016)"
            ],
            [
                "SAN (Yang et al. 2015)"
            ],
            [
                "NMN (Andreas et al. 2016b)"
            ],
            [
                "AYN (Malinowski et al. 2016)"
            ],
            [
                "SMem (Xu and Saenko, 2016)"
            ],
            [
                "VQA team (Antol et al. 2015)"
            ],
            [
                "DPPnet (Noh et al. 2015)"
            ],
            [
                "iBOWIMG (Zhou et al. 2015)"
            ]
        ],
        "column_header_level": 3,
        "column_headers": [
            [
                "Test-dev",
                "Open Ended",
                "Y/N"
            ],
            [
                "Test-dev",
                "Open Ended",
                "No."
            ],
            [
                "Test-dev",
                "Open Ended",
                "Other"
            ],
            [
                "Test-dev",
                "Open Ended",
                "All"
            ],
            [
                "Test-dev",
                "MC",
                "All"
            ],
            [
                "Test-standard",
                "Open Ended",
                "Y/N"
            ],
            [
                "Test-standard",
                "Open Ended",
                "No."
            ],
            [
                "Test-standard",
                "Open Ended",
                "Other"
            ],
            [
                "Test-standard",
                "Open Ended",
                "All"
            ],
            [
                "Test-standard",
                "MC",
                "All"
            ]
        ],
        "contents": [
            [
                "81.2",
                "35.1",
                "49.3",
                "60.8",
                "65.4",
                "-",
                "-",
                "-",
                "-",
                "-"
            ],
            [
                "81.7",
                "36.6",
                "51.5",
                "62.3",
                "66.4",
                "-",
                "-",
                "-",
                "-",
                "-"
            ],
            [
                "82.2",
                "37.7",
                "54.8",
                "64.2",
                "68.6",
                "-",
                "-",
                "-",
                "-",
                "-"
            ],
            [
                "82.5",
                "37.6",
                "55.6",
                "64.7",
                "69.1",
                "-",
                "-",
                "-",
                "-",
                "-"
            ],
            [
                "81.7",
                "38.2",
                "57.0",
                "65.1",
                "69.5",
                "-",
                "-",
                "-",
                "-",
                "-"
            ],
            [
                "82.3",
                "37.2",
                "57.4",
                "65.4",
                "69.9",
                "-",
                "-",
                "-",
                "-",
                "-"
            ],
            [
                "83.4",
                "39.8",
                "58.5",
                "66.7",
                "70.2",
                "83.2",
                "39.5",
                "58.0",
                "66.5",
                "70.1"
            ],
            [
                "83.5",
                "39.8",
                "54.8",
                "64.9",
                "69.4",
                "83.3",
                "38.7",
                "54.6",
                "64.8",
                "69.3"
            ],
            [
                "79.7",
                "38.7",
                "51.7",
                "61.8",
                "65.8",
                "-",
                "-",
                "-",
                "62.1",
                "66.1"
            ],
            [
                "80.5",
                "36.8",
                "48.3",
                "60.3",
                "-",
                "-",
                "-",
                "-",
                "60.4",
                "-"
            ],
            [
                "81.1",
                "36.2",
                "45.8",
                "59.2",
                "-",
                "-",
                "-",
                "-",
                "59.5",
                "-"
            ],
            [
                "81.1",
                "38.6",
                "45.5",
                "59.4",
                "-",
                "-",
                "-",
                "-",
                "59.4",
                "-"
            ],
            [
                "81.0",
                "38.4",
                "45.2",
                "59.2",
                "-",
                "81.1",
                "37.1",
                "45.8",
                "59.4",
                "-"
            ],
            [
                "79.3",
                "36.6",
                "46.1",
                "58.7",
                "-",
                "-",
                "-",
                "-",
                "58.9",
                "-"
            ],
            [
                "81.2",
                "38.0",
                "44.0",
                "58.6",
                "-",
                "81.2",
                "37.7",
                "44.0",
                "58.7",
                "-"
            ],
            [
                "78.4",
                "36.4",
                "46.3",
                "58.4",
                "-",
                "78.2",
                "36.3",
                "46.3",
                "58.4",
                "-"
            ],
            [
                "80.9",
                "37.3",
                "43.1",
                "58.0",
                "-",
                "80.9",
                "37.5",
                "43.5",
                "58.2",
                "-"
            ],
            [
                "80.5",
                "36.8",
                "43.1",
                "57.8",
                "62.7",
                "80.6",
                "36.5",
                "43.7",
                "58.2",
                "63.1"
            ],
            [
                "80.7",
                "37.2",
                "41.7",
                "57.2",
                "-",
                "80.3",
                "36.9",
                "42.2",
                "57.4",
                "-"
            ],
            [
                "76.5",
                "35.0",
                "42.6",
                "55.7",
                "-",
                "76.8",
                "35.0",
                "42.6",
                "55.9",
                "62.0"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "accuracy",
            "accuracy",
            "accuracy",
            "accuracy",
            "accuracy",
            "accuracy",
            "accuracy",
            "accuracy",
            "accuracy",
            "accuracy"
        ],
        "target_entity": [
            "MCB",
            "MCB + Genome",
            "MCB + Att.",
            "MCB + Att. + GloVe",
            "MCB + Att. + Genome",
            "MCB + Att. + GloVe + Genome",
            "Ensemble of 7 Att. models"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Test-dev || Open Ended || Y/N</th>      <th>Test-dev || Open Ended || No.</th>      <th>Test-dev || Open Ended || Other</th>      <th>Test-dev || Open Ended || All</th>      <th>Test-dev || MC || All</th>      <th>Test-standard || Open Ended || Y/N</th>      <th>Test-standard || Open Ended || No.</th>      <th>Test-standard || Open Ended || Other</th>      <th>Test-standard || Open Ended || All</th>      <th>Test-standard || MC || All</th>    </tr>  </thead>  <tbody>    <tr>      <td>MCB</td>      <td>81.2</td>      <td>35.1</td>      <td>49.3</td>      <td>60.8</td>      <td>65.4</td>      <td>-</td>      <td>-</td>      <td>-</td>      <td>-</td>      <td>-</td>    </tr>    <tr>      <td>MCB + Genome</td>      <td>81.7</td>      <td>36.6</td>      <td>51.5</td>      <td>62.3</td>      <td>66.4</td>      <td>-</td>      <td>-</td>      <td>-</td>      <td>-</td>      <td>-</td>    </tr>    <tr>      <td>MCB + Att.</td>      <td>82.2</td>      <td>37.7</td>      <td>54.8</td>      <td>64.2</td>      <td>68.6</td>      <td>-</td>      <td>-</td>      <td>-</td>      <td>-</td>      <td>-</td>    </tr>    <tr>      <td>MCB + Att. + GloVe</td>      <td>82.5</td>      <td>37.6</td>      <td>55.6</td>      <td>64.7</td>      <td>69.1</td>      <td>-</td>      <td>-</td>      <td>-</td>      <td>-</td>      <td>-</td>    </tr>    <tr>      <td>MCB + Att. + Genome</td>      <td>81.7</td>      <td>38.2</td>      <td>57.0</td>      <td>65.1</td>      <td>69.5</td>      <td>-</td>      <td>-</td>      <td>-</td>      <td>-</td>      <td>-</td>    </tr>    <tr>      <td>MCB + Att. + GloVe + Genome</td>      <td>82.3</td>      <td>37.2</td>      <td>57.4</td>      <td>65.4</td>      <td>69.9</td>      <td>-</td>      <td>-</td>      <td>-</td>      <td>-</td>      <td>-</td>    </tr>    <tr>      <td>Ensemble of 7 Att. models</td>      <td>83.4</td>      <td>39.8</td>      <td>58.5</td>      <td>66.7</td>      <td>70.2</td>      <td>83.2</td>      <td>39.5</td>      <td>58.0</td>      <td>66.5</td>      <td>70.1</td>    </tr>    <tr>      <td>Naver Labs (challenge 2nd)</td>      <td>83.5</td>      <td>39.8</td>      <td>54.8</td>      <td>64.9</td>      <td>69.4</td>      <td>83.3</td>      <td>38.7</td>      <td>54.6</td>      <td>64.8</td>      <td>69.3</td>    </tr>    <tr>      <td>HieCoAtt (Lu et al. 2016)</td>      <td>79.7</td>      <td>38.7</td>      <td>51.7</td>      <td>61.8</td>      <td>65.8</td>      <td>-</td>      <td>-</td>      <td>-</td>      <td>62.1</td>      <td>66.1</td>    </tr>    <tr>      <td>DMN+ (Xiong et al. 2016)</td>      <td>80.5</td>      <td>36.8</td>      <td>48.3</td>      <td>60.3</td>      <td>-</td>      <td>-</td>      <td>-</td>      <td>-</td>      <td>60.4</td>      <td>-</td>    </tr>    <tr>      <td>FDA (Ilievski et al. 2016)</td>      <td>81.1</td>      <td>36.2</td>      <td>45.8</td>      <td>59.2</td>      <td>-</td>      <td>-</td>      <td>-</td>      <td>-</td>      <td>59.5</td>      <td>-</td>    </tr>    <tr>      <td>D-NMN (Andreas et al. 2016a)</td>      <td>81.1</td>      <td>38.6</td>      <td>45.5</td>      <td>59.4</td>      <td>-</td>      <td>-</td>      <td>-</td>      <td>-</td>      <td>59.4</td>      <td>-</td>    </tr>    <tr>      <td>AMA (Wu et al. 2016)</td>      <td>81.0</td>      <td>38.4</td>      <td>45.2</td>      <td>59.2</td>      <td>-</td>      <td>81.1</td>      <td>37.1</td>      <td>45.8</td>      <td>59.4</td>      <td>-</td>    </tr>    <tr>      <td>SAN (Yang et al. 2015)</td>      <td>79.3</td>      <td>36.6</td>      <td>46.1</td>      <td>58.7</td>      <td>-</td>      <td>-</td>      <td>-</td>      <td>-</td>      <td>58.9</td>      <td>-</td>    </tr>    <tr>      <td>NMN (Andreas et al. 2016b)</td>      <td>81.2</td>      <td>38.0</td>      <td>44.0</td>      <td>58.6</td>      <td>-</td>      <td>81.2</td>      <td>37.7</td>      <td>44.0</td>      <td>58.7</td>      <td>-</td>    </tr>    <tr>      <td>AYN (Malinowski et al. 2016)</td>      <td>78.4</td>      <td>36.4</td>      <td>46.3</td>      <td>58.4</td>      <td>-</td>      <td>78.2</td>      <td>36.3</td>      <td>46.3</td>      <td>58.4</td>      <td>-</td>    </tr>    <tr>      <td>SMem (Xu and Saenko, 2016)</td>      <td>80.9</td>      <td>37.3</td>      <td>43.1</td>      <td>58.0</td>      <td>-</td>      <td>80.9</td>      <td>37.5</td>      <td>43.5</td>      <td>58.2</td>      <td>-</td>    </tr>    <tr>      <td>VQA team (Antol et al. 2015)</td>      <td>80.5</td>      <td>36.8</td>      <td>43.1</td>      <td>57.8</td>      <td>62.7</td>      <td>80.6</td>      <td>36.5</td>      <td>43.7</td>      <td>58.2</td>      <td>63.1</td>    </tr>    <tr>      <td>DPPnet (Noh et al. 2015)</td>      <td>80.7</td>      <td>37.2</td>      <td>41.7</td>      <td>57.2</td>      <td>-</td>      <td>80.3</td>      <td>36.9</td>      <td>42.2</td>      <td>57.4</td>      <td>-</td>    </tr>    <tr>      <td>iBOWIMG (Zhou et al. 2015)</td>      <td>76.5</td>      <td>35.0</td>      <td>42.6</td>      <td>55.7</td>      <td>-</td>      <td>76.8</td>      <td>35.0</td>      <td>42.6</td>      <td>55.9</td>      <td>62.0</td>    </tr>  </tbody></table>",
        "table_name": "Table 4",
        "table_id": "table_4",
        "paper_id": "D16-1044",
        "page_no": 7,
        "dir": "emnlp2016",
        "valid": 1
    },
    {
        "table_id_paper": "D16-1086table_1",
        "caption": "Corpus size (length in token) and system performance by genre. News* used gold trees and is not included in total.",
        "row_header_level": 2,
        "row_headers": [
            [
                "Genre",
                "News*"
            ],
            [
                "Genre",
                "News"
            ],
            [
                "Genre",
                "Wiki"
            ],
            [
                "Genre",
                "Web"
            ],
            [
                "Genre",
                "Total"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "Sentences"
            ],
            [
                "Length"
            ],
            [
                "Yield"
            ],
            [
                "Precision"
            ]
        ],
        "contents": [
            [
                "100",
                "19.3",
                "142",
                "78.9"
            ],
            [
                "100",
                "19.3",
                "144",
                "70.8"
            ],
            [
                "100",
                "21.4",
                "178",
                "61.8"
            ],
            [
                "100",
                "19.2",
                "165",
                "49.1"
            ],
            [
                "300",
                "20.0",
                "487",
                "60.2"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "Sentences",
            "Length",
            "Yield",
            "Precision"
        ],
        "target_entity": [
            "Genre"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Sentences</th>      <th>Length</th>      <th>Yield</th>      <th>Precision</th>    </tr>  </thead>  <tbody>    <tr>      <td>Genre || News*</td>      <td>100</td>      <td>19.3</td>      <td>142</td>      <td>78.9</td>    </tr>    <tr>      <td>Genre || News</td>      <td>100</td>      <td>19.3</td>      <td>144</td>      <td>70.8</td>    </tr>    <tr>      <td>Genre || Wiki</td>      <td>100</td>      <td>21.4</td>      <td>178</td>      <td>61.8</td>    </tr>    <tr>      <td>Genre || Web</td>      <td>100</td>      <td>19.2</td>      <td>165</td>      <td>49.1</td>    </tr>    <tr>      <td>Genre || Total</td>      <td>300</td>      <td>20.0</td>      <td>487</td>      <td>60.2</td>    </tr>  </tbody></table>",
        "table_name": "Table 1",
        "table_id": "table_1",
        "paper_id": "D16-1086",
        "page_no": 5,
        "dir": "emnlp2016",
        "valid": 1
    },
    {
        "table_id_paper": "D16-1132table_3",
        "caption": "Results of instance-wise evaluation for anaphoric and cataphoric sets",
        "row_header_level": 4,
        "row_headers": [
            [
                "Set",
                "Anaphoric",
                "Method",
                "single-column CNN (w/ position vec.)"
            ],
            [
                "Set",
                "Anaphoric",
                "Method",
                "MCNN (BASE)"
            ],
            [
                "Set",
                "Anaphoric",
                "Method",
                "MCNN (BASE+SURFSEQ)"
            ],
            [
                "Set",
                "Anaphoric",
                "Method",
                "MCNN (BASE+DEPTREE)"
            ],
            [
                "Set",
                "Anaphoric",
                "Method",
                "MCNN (BASE+SURFSEQ+DEPTREE)"
            ],
            [
                "Set",
                "Anaphoric",
                "Method",
                "MCNN (BASE+SURFSEQ+PREDCONTEXT)"
            ],
            [
                "Set",
                "Anaphoric",
                "Method",
                "MCNN (BASE+DEPTREE+PREDCONTEXT)"
            ],
            [
                "Set",
                "Anaphoric",
                "Method",
                "MCNN (Proposed)"
            ],
            [
                "Set",
                "Cataphoric",
                "Method",
                "single-column CNN (w/ position vec.)"
            ],
            [
                "Set",
                "Cataphoric",
                "Method",
                "MCNN (BASE)"
            ],
            [
                "Set",
                "Cataphoric",
                "Method",
                "MCNN (BASE+SURFSEQ)"
            ],
            [
                "Set",
                "Cataphoric",
                "Method",
                "MCNN (BASE+DEPTREE)"
            ],
            [
                "Set",
                "Cataphoric",
                "Method",
                "MCNN (BASE+SURFSEQ+DEPTREE)"
            ],
            [
                "Set",
                "Cataphoric",
                "Method",
                "MCNN (BASE+SURFSEQ+PREDCONTEXT)"
            ],
            [
                "Set",
                "Cataphoric",
                "Method",
                "MCNN (BASE+DEPTREE+PREDCONTEXT)"
            ],
            [
                "Set",
                "Cataphoric",
                "Method",
                "MCNN (Proposed)"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "Recall"
            ],
            [
                "Precision"
            ],
            [
                "F-score"
            ],
            [
                "Avg.P"
            ]
        ],
        "contents": [
            [
                "0.445",
                "0.525",
                "0.481",
                "0.341"
            ],
            [
                "0.591",
                "0.33",
                "0.424",
                "0.367"
            ],
            [
                "0.555",
                "0.566",
                "0.56",
                "0.565"
            ],
            [
                "0.389",
                "0.615",
                "0.476",
                "0.518"
            ],
            [
                "0.503",
                "0.66",
                "0.571",
                "0.599"
            ],
            [
                "0.535",
                "0.611",
                "0.57",
                "0.581"
            ],
            [
                "0.33",
                "0.699",
                "0.449",
                "0.528"
            ],
            [
                "0.492",
                "0.673",
                "0.569",
                "0.602"
            ],
            [
                "0.163",
                "0.293",
                "0.209",
                "0.163"
            ],
            [
                "0.171",
                "0.13",
                "0.148",
                "0.099"
            ],
            [
                "0.202",
                "0.417",
                "0.272",
                "0.257"
            ],
            [
                "0.268",
                "0.438",
                "0.332",
                "0.329"
            ],
            [
                "0.195",
                "0.525",
                "0.285",
                "0.33"
            ],
            [
                "0.258",
                "0.406",
                "0.316",
                "0.276"
            ],
            [
                "0.24",
                "0.488",
                "0.322",
                "0.341"
            ],
            [
                "0.251",
                "0.522",
                "0.339",
                "0.337"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "Recall",
            "Precision",
            "F-score",
            "Avg.P"
        ],
        "target_entity": [
            "MCNN (Proposed)"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Recall</th>      <th>Precision</th>      <th>F-score</th>      <th>Avg.P</th>    </tr>  </thead>  <tbody>    <tr>      <td>Set || Anaphoric || Method || single-column CNN (w/ position vec.)</td>      <td>0.445</td>      <td>0.525</td>      <td>0.481</td>      <td>0.341</td>    </tr>    <tr>      <td>Set || Anaphoric || Method || MCNN (BASE)</td>      <td>0.591</td>      <td>0.33</td>      <td>0.424</td>      <td>0.367</td>    </tr>    <tr>      <td>Set || Anaphoric || Method || MCNN (BASE+SURFSEQ)</td>      <td>0.555</td>      <td>0.566</td>      <td>0.56</td>      <td>0.565</td>    </tr>    <tr>      <td>Set || Anaphoric || Method || MCNN (BASE+DEPTREE)</td>      <td>0.389</td>      <td>0.615</td>      <td>0.476</td>      <td>0.518</td>    </tr>    <tr>      <td>Set || Anaphoric || Method || MCNN (BASE+SURFSEQ+DEPTREE)</td>      <td>0.503</td>      <td>0.66</td>      <td>0.571</td>      <td>0.599</td>    </tr>    <tr>      <td>Set || Anaphoric || Method || MCNN (BASE+SURFSEQ+PREDCONTEXT)</td>      <td>0.535</td>      <td>0.611</td>      <td>0.57</td>      <td>0.581</td>    </tr>    <tr>      <td>Set || Anaphoric || Method || MCNN (BASE+DEPTREE+PREDCONTEXT)</td>      <td>0.33</td>      <td>0.699</td>      <td>0.449</td>      <td>0.528</td>    </tr>    <tr>      <td>Set || Anaphoric || Method || MCNN (Proposed)</td>      <td>0.492</td>      <td>0.673</td>      <td>0.569</td>      <td>0.602</td>    </tr>    <tr>      <td>Set || Cataphoric || Method || single-column CNN (w/ position vec.)</td>      <td>0.163</td>      <td>0.293</td>      <td>0.209</td>      <td>0.163</td>    </tr>    <tr>      <td>Set || Cataphoric || Method || MCNN (BASE)</td>      <td>0.171</td>      <td>0.13</td>      <td>0.148</td>      <td>0.099</td>    </tr>    <tr>      <td>Set || Cataphoric || Method || MCNN (BASE+SURFSEQ)</td>      <td>0.202</td>      <td>0.417</td>      <td>0.272</td>      <td>0.257</td>    </tr>    <tr>      <td>Set || Cataphoric || Method || MCNN (BASE+DEPTREE)</td>      <td>0.268</td>      <td>0.438</td>      <td>0.332</td>      <td>0.329</td>    </tr>    <tr>      <td>Set || Cataphoric || Method || MCNN (BASE+SURFSEQ+DEPTREE)</td>      <td>0.195</td>      <td>0.525</td>      <td>0.285</td>      <td>0.33</td>    </tr>    <tr>      <td>Set || Cataphoric || Method || MCNN (BASE+SURFSEQ+PREDCONTEXT)</td>      <td>0.258</td>      <td>0.406</td>      <td>0.316</td>      <td>0.276</td>    </tr>    <tr>      <td>Set || Cataphoric || Method || MCNN (BASE+DEPTREE+PREDCONTEXT)</td>      <td>0.24</td>      <td>0.488</td>      <td>0.322</td>      <td>0.341</td>    </tr>    <tr>      <td>Set || Cataphoric || Method || MCNN (Proposed)</td>      <td>0.251</td>      <td>0.522</td>      <td>0.339</td>      <td>0.337</td>    </tr>  </tbody></table>",
        "table_name": "Table 3",
        "table_id": "table_3",
        "paper_id": "D16-1132",
        "page_no": 9,
        "dir": "emnlp2016",
        "valid": 1
    },
    {
        "table_id_paper": "D16-1136table_3",
        "caption": "Bilingual Lexicon Induction performance from es, it, nl to en. Gouws and S\u00f8gaard (2015) + Panlex/Wikt is our reimplementation using Panlex/Wiktionary dictionary. All our models use Panlex as the dictionary. We reported the recall at 1 and 5. The best performance is bold.",
        "row_header_level": 2,
        "row_headers": [
            [
                "Model",
                "Gouws and S\u00f8gaard (2015) + Panlex"
            ],
            [
                "Model",
                "Gouws and S\u00f8gaard (2015) + Wikt"
            ],
            [
                "Model",
                "BilBOWA: Gouws et al. (2015)"
            ],
            [
                "Model",
                "Vulic and Moens (2015)"
            ],
            [
                "Model",
                "Our model (random selection)"
            ],
            [
                "Model",
                "Our model (EM selection)"
            ],
            [
                "Model",
                "Our model (EM selection) + Joint model"
            ],
            [
                "Model",
                "Our model (EM selection) + combine embeddings (\u03b4 = 0.01)"
            ],
            [
                "Model",
                "Our model (EM selection) + lemmatization"
            ]
        ],
        "column_header_level": 2,
        "column_headers": [
            [
                "es-en",
                "rec1"
            ],
            [
                "es-en",
                "rec5"
            ],
            [
                "it-en",
                "rec1"
            ],
            [
                "it-en",
                "rec5"
            ],
            [
                "nl-en",
                "rec1"
            ],
            [
                "nl-en",
                "rec5"
            ],
            [
                "Average",
                "rec1"
            ],
            [
                "Average",
                "rec5"
            ]
        ],
        "contents": [
            [
                "37.6",
                "63.6",
                "26.6",
                "56.3",
                "49.8",
                "76.0",
                "38.0",
                "65.3"
            ],
            [
                "61.6",
                "78.9",
                "62.6",
                "81.1",
                "65.6",
                "79.7",
                "63.3",
                "79.9"
            ],
            [
                "51.6",
                "-",
                "55.7",
                "-",
                "57.5",
                "-",
                "54.9",
                "-"
            ],
            [
                "68.9",
                "-",
                "68.3",
                "-",
                "39.2",
                "-",
                "58.8",
                "-"
            ],
            [
                "41.1",
                "62.0",
                "57.4",
                "75.4",
                "34.3",
                "55.5",
                "44.3",
                "64.3"
            ],
            [
                "67.3",
                "79.5",
                "66.8",
                "82.3",
                "64.7",
                "82.4",
                "66.3",
                "81.4"
            ],
            [
                "68.0",
                "80.5",
                "70.5",
                "83.3",
                "68.8",
                "84.0",
                "69.1",
                "82.6"
            ],
            [
                "74.7",
                "85.4",
                "80.8",
                "90.4",
                "79.1",
                "90.5",
                "78.2",
                "88.8"
            ],
            [
                "74.9",
                "86.0",
                "81.3",
                "91.3",
                "79.8",
                "91.3",
                "78.7",
                "89.5"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "rec1",
            "rec5",
            "rec1",
            "rec5",
            "rec1",
            "rec5",
            "rec1",
            "rec5"
        ],
        "target_entity": [
            "Our model (random selection)",
            "Our model (EM selection)",
            "Our model (EM selection) + Joint model",
            "Our model (EM selection) + combine embeddings (\u03b4 = 0.01)",
            "Our model (EM selection) + lemmatization"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>es-en || rec1</th>      <th>es-en || rec5</th>      <th>it-en || rec1</th>      <th>it-en || rec5</th>      <th>nl-en || rec1</th>      <th>nl-en || rec5</th>      <th>Average || rec1</th>      <th>Average || rec5</th>    </tr>  </thead>  <tbody>    <tr>      <td>Model || Gouws and S\u00f8gaard (2015) + Panlex</td>      <td>37.6</td>      <td>63.6</td>      <td>26.6</td>      <td>56.3</td>      <td>49.8</td>      <td>76.0</td>      <td>38.0</td>      <td>65.3</td>    </tr>    <tr>      <td>Model || Gouws and S\u00f8gaard (2015) + Wikt</td>      <td>61.6</td>      <td>78.9</td>      <td>62.6</td>      <td>81.1</td>      <td>65.6</td>      <td>79.7</td>      <td>63.3</td>      <td>79.9</td>    </tr>    <tr>      <td>Model || BilBOWA: Gouws et al. (2015)</td>      <td>51.6</td>      <td>-</td>      <td>55.7</td>      <td>-</td>      <td>57.5</td>      <td>-</td>      <td>54.9</td>      <td>-</td>    </tr>    <tr>      <td>Model || Vulic and Moens (2015)</td>      <td>68.9</td>      <td>-</td>      <td>68.3</td>      <td>-</td>      <td>39.2</td>      <td>-</td>      <td>58.8</td>      <td>-</td>    </tr>    <tr>      <td>Model || Our model (random selection)</td>      <td>41.1</td>      <td>62.0</td>      <td>57.4</td>      <td>75.4</td>      <td>34.3</td>      <td>55.5</td>      <td>44.3</td>      <td>64.3</td>    </tr>    <tr>      <td>Model || Our model (EM selection)</td>      <td>67.3</td>      <td>79.5</td>      <td>66.8</td>      <td>82.3</td>      <td>64.7</td>      <td>82.4</td>      <td>66.3</td>      <td>81.4</td>    </tr>    <tr>      <td>Model || Our model (EM selection) + Joint model</td>      <td>68.0</td>      <td>80.5</td>      <td>70.5</td>      <td>83.3</td>      <td>68.8</td>      <td>84.0</td>      <td>69.1</td>      <td>82.6</td>    </tr>    <tr>      <td>Model || Our model (EM selection) + combine embeddings (\u03b4 = 0.01)</td>      <td>74.7</td>      <td>85.4</td>      <td>80.8</td>      <td>90.4</td>      <td>79.1</td>      <td>90.5</td>      <td>78.2</td>      <td>88.8</td>    </tr>    <tr>      <td>Model || Our model (EM selection) + lemmatization</td>      <td>74.9</td>      <td>86.0</td>      <td>81.3</td>      <td>91.3</td>      <td>79.8</td>      <td>91.3</td>      <td>78.7</td>      <td>89.5</td>    </tr>  </tbody></table>",
        "table_name": "Table 3",
        "table_id": "table_3",
        "paper_id": "D16-1136",
        "page_no": 7,
        "dir": "emnlp2016",
        "valid": 1
    },
    {
        "table_id_paper": "D16-1168table_1",
        "caption": "METEOR results for different configuration of our model on STARdev, STARtest and CARTOON datasets.",
        "row_header_level": 3,
        "row_headers": [
            [
                "Model",
                "FULL",
                "-"
            ],
            [
                "Model",
                "FULL",
                "-SEM"
            ],
            [
                "Model",
                "FULL",
                "-SYN"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "STARdev"
            ],
            [
                "STARtest"
            ],
            [
                "CARTOON"
            ]
        ],
        "contents": [
            [
                "31.82",
                "29.16",
                "32.08"
            ],
            [
                "28.72",
                "25.55",
                "27.55"
            ],
            [
                "31.92",
                "29.14",
                "32.04"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "METEOR",
            "METEOR",
            "METEOR"
        ],
        "target_entity": [
            "Model"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>STARdev</th>      <th>STARtest</th>      <th>CARTOON</th>    </tr>  </thead>  <tbody>    <tr>      <td>Model || FULL || -</td>      <td>31.82</td>      <td>29.16</td>      <td>32.08</td>    </tr>    <tr>      <td>Model || FULL || -SEM</td>      <td>28.72</td>      <td>25.55</td>      <td>27.55</td>    </tr>    <tr>      <td>Model || FULL || -SYN</td>      <td>31.92</td>      <td>29.14</td>      <td>32.04</td>    </tr>  </tbody></table>",
        "table_name": "Table 1",
        "table_id": "table_1",
        "paper_id": "D16-1168",
        "page_no": 7,
        "dir": "emnlp2016",
        "valid": 1
    },
    {
        "table_id_paper": "D16-1188table_2",
        "caption": "Accuracy results on the test sets. Bold font marks the best performance for a dataset. * indicates statistical significance of improvement over lasso at p < 0.05 using micro sign test for one of our models LSI, GoW and word2vec (underlined).",
        "row_header_level": 3,
        "row_headers": [
            [
                "20NG",
                "dataset",
                "science"
            ],
            [
                "20NG",
                "dataset",
                "sports"
            ],
            [
                "20NG",
                "dataset",
                "religion"
            ],
            [
                "20NG",
                "dataset",
                "computer"
            ],
            [
                "Sentiment",
                "dataset",
                "vote"
            ],
            [
                "Sentiment",
                "dataset",
                "movie"
            ],
            [
                "Sentiment",
                "dataset",
                "books"
            ],
            [
                "Sentiment",
                "dataset",
                "dvd"
            ],
            [
                "Sentiment",
                "dataset",
                "electr."
            ],
            [
                "Sentiment",
                "dataset",
                "kitch."
            ]
        ],
        "column_header_level": 2,
        "column_headers": [
            [
                "no reg.",
                "-"
            ],
            [
                "lasso",
                "-"
            ],
            [
                "ridge",
                "-"
            ],
            [
                "elastic",
                "-"
            ],
            [
                "group lasso",
                "LDA"
            ],
            [
                "group lasso",
                "LSI"
            ],
            [
                "group lasso",
                "sentence"
            ],
            [
                "group lasso",
                "GoW"
            ],
            [
                "group lasso",
                "word2vec"
            ]
        ],
        "contents": [
            [
                "0.946",
                "0.916",
                "0.954",
                "0.954",
                "0.968",
                "0.968*",
                "0.942",
                "0.967",
                "0.968*"
            ],
            [
                "0.908",
                "0.907",
                "0.925",
                "0.92",
                "0.959",
                "0.964*",
                "0.966",
                "0.959*",
                "0.946*"
            ],
            [
                "0.894",
                "0.876",
                "0.895",
                "0.89",
                "0.918",
                "0.907*",
                "0.934",
                "0.911*",
                "0.916*"
            ],
            [
                "0.846",
                "0.843",
                "0.869",
                "0.856",
                "0.891",
                "0.885*",
                "0.904",
                "0.885*",
                "0.911*"
            ],
            [
                "0.606",
                "0.643",
                "0.616",
                "0.622",
                "0.658",
                "0.653",
                "0.656",
                "0.640",
                "0.651"
            ],
            [
                "0.865",
                "0.86",
                "0.87",
                "0.875",
                "0.900",
                "0.895",
                "0.895",
                "0.895",
                "0.890"
            ],
            [
                "0.75",
                "0.77",
                "0.76",
                "0.78",
                "0.790",
                "0.795",
                "0.785",
                "0.790",
                "0.800"
            ],
            [
                "0.765",
                "0.735",
                "0.77",
                "0.76",
                "0.800",
                "0.805*",
                "0.785",
                "0.795*",
                "0.795*"
            ],
            [
                "0.79",
                "0.8",
                "0.8",
                "0.825",
                "0.800",
                "0.815",
                "0.805",
                "0.820",
                "0.815"
            ],
            [
                "0.76",
                "0.8",
                "0.775",
                "0.8",
                "0.845",
                "0.860*",
                "0.855",
                "0.840",
                "0.855*"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "accuracy",
            "accuracy",
            "accuracy",
            "accuracy",
            "accuracy",
            "accuracy",
            "accuracy",
            "accuracy",
            "accuracy"
        ],
        "target_entity": [
            "group lasso"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>no reg. || -</th>      <th>lasso || -</th>      <th>ridge || -</th>      <th>elastic || -</th>      <th>group lasso || LDA</th>      <th>group lasso || LSI</th>      <th>group lasso || sentence</th>      <th>group lasso || GoW</th>      <th>group lasso || word2vec</th>    </tr>  </thead>  <tbody>    <tr>      <td>20NG || dataset || science</td>      <td>0.946</td>      <td>0.916</td>      <td>0.954</td>      <td>0.954</td>      <td>0.968</td>      <td>0.968*</td>      <td>0.942</td>      <td>0.967</td>      <td>0.968*</td>    </tr>    <tr>      <td>20NG || dataset || sports</td>      <td>0.908</td>      <td>0.907</td>      <td>0.925</td>      <td>0.92</td>      <td>0.959</td>      <td>0.964*</td>      <td>0.966</td>      <td>0.959*</td>      <td>0.946*</td>    </tr>    <tr>      <td>20NG || dataset || religion</td>      <td>0.894</td>      <td>0.876</td>      <td>0.895</td>      <td>0.89</td>      <td>0.918</td>      <td>0.907*</td>      <td>0.934</td>      <td>0.911*</td>      <td>0.916*</td>    </tr>    <tr>      <td>20NG || dataset || computer</td>      <td>0.846</td>      <td>0.843</td>      <td>0.869</td>      <td>0.856</td>      <td>0.891</td>      <td>0.885*</td>      <td>0.904</td>      <td>0.885*</td>      <td>0.911*</td>    </tr>    <tr>      <td>Sentiment || dataset || vote</td>      <td>0.606</td>      <td>0.643</td>      <td>0.616</td>      <td>0.622</td>      <td>0.658</td>      <td>0.653</td>      <td>0.656</td>      <td>0.640</td>      <td>0.651</td>    </tr>    <tr>      <td>Sentiment || dataset || movie</td>      <td>0.865</td>      <td>0.86</td>      <td>0.87</td>      <td>0.875</td>      <td>0.900</td>      <td>0.895</td>      <td>0.895</td>      <td>0.895</td>      <td>0.890</td>    </tr>    <tr>      <td>Sentiment || dataset || books</td>      <td>0.75</td>      <td>0.77</td>      <td>0.76</td>      <td>0.78</td>      <td>0.790</td>      <td>0.795</td>      <td>0.785</td>      <td>0.790</td>      <td>0.800</td>    </tr>    <tr>      <td>Sentiment || dataset || dvd</td>      <td>0.765</td>      <td>0.735</td>      <td>0.77</td>      <td>0.76</td>      <td>0.800</td>      <td>0.805*</td>      <td>0.785</td>      <td>0.795*</td>      <td>0.795*</td>    </tr>    <tr>      <td>Sentiment || dataset || electr.</td>      <td>0.79</td>      <td>0.8</td>      <td>0.8</td>      <td>0.825</td>      <td>0.800</td>      <td>0.815</td>      <td>0.805</td>      <td>0.820</td>      <td>0.815</td>    </tr>    <tr>      <td>Sentiment || dataset || kitch.</td>      <td>0.76</td>      <td>0.8</td>      <td>0.775</td>      <td>0.8</td>      <td>0.845</td>      <td>0.860*</td>      <td>0.855</td>      <td>0.840</td>      <td>0.855*</td>    </tr>  </tbody></table>",
        "table_name": "Table 2",
        "table_id": "table_2",
        "paper_id": "D16-1188",
        "page_no": 7,
        "dir": "emnlp2016",
        "valid": 1
    },
    {
        "table_id_paper": "D16-1216table_1",
        "caption": "Accuracy Results on Wikipedia and Stack Exchange.",
        "row_header_level": 2,
        "row_headers": [
            [
                "Model",
                "Bag-of-Words"
            ],
            [
                "Model",
                "Linguistic Features"
            ],
            [
                "Model",
                "With Discovered Features"
            ],
            [
                "Model",
                "CNN"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "Wiki"
            ],
            [
                "SE"
            ]
        ],
        "contents": [
            [
                "80.9%",
                "64.6%"
            ],
            [
                "82.6%",
                "65.2%"
            ],
            [
                "83.8%",
                "65.7%"
            ],
            [
                "85.8%",
                "66.4%"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "accuracy",
            "accuracy"
        ],
        "target_entity": [
            "CNN"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Wiki</th>      <th>SE</th>    </tr>  </thead>  <tbody>    <tr>      <td>Model || Bag-of-Words</td>      <td>80.9%</td>      <td>64.6%</td>    </tr>    <tr>      <td>Model || Linguistic Features</td>      <td>82.6%</td>      <td>65.2%</td>    </tr>    <tr>      <td>Model || With Discovered Features</td>      <td>83.8%</td>      <td>65.7%</td>    </tr>    <tr>      <td>Model || CNN</td>      <td>85.8%</td>      <td>66.4%</td>    </tr>  </tbody></table>",
        "table_name": "Table 1",
        "table_id": "table_1",
        "paper_id": "D16-1216",
        "page_no": 3,
        "dir": "emnlp2016",
        "valid": 1
    },
    {
        "table_id_paper": "D16-1220table_3",
        "caption": "Cross-validation performance on VUAMC. B is always significantly different from N (p < .001), and B \u222a N is always significantly different from both B and N (p < .001).",
        "row_header_level": 4,
        "row_headers": [
            [
                "Genre",
                "News",
                "Features",
                "B"
            ],
            [
                "Genre",
                "News",
                "Features",
                "N"
            ],
            [
                "Genre",
                "News",
                "Features",
                "B \u222a N"
            ],
            [
                "Genre",
                "Academic",
                "Features",
                "B"
            ],
            [
                "Genre",
                "Academic",
                "Features",
                "N"
            ],
            [
                "Genre",
                "Academic",
                "Features",
                "B \u222a N"
            ],
            [
                "Genre",
                "Conversation",
                "Features",
                "B"
            ],
            [
                "Genre",
                "Conversation",
                "Features",
                "N"
            ],
            [
                "Genre",
                "Conversation",
                "Features",
                "B \u222a N"
            ],
            [
                "Genre",
                "Fiction",
                "Features",
                "B"
            ],
            [
                "Genre",
                "Fiction",
                "Features",
                "N"
            ],
            [
                "Genre",
                "Fiction",
                "Features",
                "B \u222a N"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "C"
            ],
            [
                "P"
            ],
            [
                "R"
            ],
            [
                "F"
            ]
        ],
        "contents": [
            [
                "1.0",
                "0.475",
                "0.742",
                "0.576"
            ],
            [
                "1.0",
                "0.576",
                "0.479",
                "0.522"
            ],
            [
                "1.0",
                "0.615",
                "0.539",
                "0.574"
            ],
            [
                "0.6",
                "0.489",
                "0.733",
                "0.568"
            ],
            [
                "0.6",
                "0.572",
                "0.494",
                "0.511"
            ],
            [
                "1.0",
                "0.539",
                "0.648",
                "0.569"
            ],
            [
                "0.6",
                "0.292",
                "0.799",
                "0.416"
            ],
            [
                "0.6",
                "0.304",
                "0.626",
                "0.393"
            ],
            [
                "1.0",
                "0.299",
                "0.731",
                "0.406"
            ],
            [
                "0.6",
                "0.349",
                "0.695",
                "0.460"
            ],
            [
                "0.6",
                "0.430",
                "0.418",
                "0.421"
            ],
            [
                "0.6",
                "0.409",
                "0.551",
                "0.465"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "C",
            "P",
            "R",
            "F"
        ],
        "target_entity": [
            "Features"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>C</th>      <th>P</th>      <th>R</th>      <th>F</th>    </tr>  </thead>  <tbody>    <tr>      <td>Genre || News || Features || B</td>      <td>1.0</td>      <td>0.475</td>      <td>0.742</td>      <td>0.576</td>    </tr>    <tr>      <td>Genre || News || Features || N</td>      <td>1.0</td>      <td>0.576</td>      <td>0.479</td>      <td>0.522</td>    </tr>    <tr>      <td>Genre || News || Features || B \u222a N</td>      <td>1.0</td>      <td>0.615</td>      <td>0.539</td>      <td>0.574</td>    </tr>    <tr>      <td>Genre || Academic || Features || B</td>      <td>0.6</td>      <td>0.489</td>      <td>0.733</td>      <td>0.568</td>    </tr>    <tr>      <td>Genre || Academic || Features || N</td>      <td>0.6</td>      <td>0.572</td>      <td>0.494</td>      <td>0.511</td>    </tr>    <tr>      <td>Genre || Academic || Features || B \u222a N</td>      <td>1.0</td>      <td>0.539</td>      <td>0.648</td>      <td>0.569</td>    </tr>    <tr>      <td>Genre || Conversation || Features || B</td>      <td>0.6</td>      <td>0.292</td>      <td>0.799</td>      <td>0.416</td>    </tr>    <tr>      <td>Genre || Conversation || Features || N</td>      <td>0.6</td>      <td>0.304</td>      <td>0.626</td>      <td>0.393</td>    </tr>    <tr>      <td>Genre || Conversation || Features || B \u222a N</td>      <td>1.0</td>      <td>0.299</td>      <td>0.731</td>      <td>0.406</td>    </tr>    <tr>      <td>Genre || Fiction || Features || B</td>      <td>0.6</td>      <td>0.349</td>      <td>0.695</td>      <td>0.460</td>    </tr>    <tr>      <td>Genre || Fiction || Features || N</td>      <td>0.6</td>      <td>0.430</td>      <td>0.418</td>      <td>0.421</td>    </tr>    <tr>      <td>Genre || Fiction || Features || B \u222a N</td>      <td>0.6</td>      <td>0.409</td>      <td>0.551</td>      <td>0.465</td>    </tr>  </tbody></table>",
        "table_name": "Table 3",
        "table_id": "table_3",
        "paper_id": "D16-1220",
        "page_no": 4,
        "dir": "emnlp2016",
        "valid": 1
    },
    {
        "table_id_paper": "D16-1262table_5",
        "caption": "Comparison of various decoders using the same model from our full system (Global A\u2217). We report F1 with and without the backoff model, the percentage of sentences that the decoder can parse, and the time spent decoding relative to A\u2217.",
        "row_header_level": 2,
        "row_headers": [
            [
                "Decoder",
                "Global A*"
            ],
            [
                "Decoder",
                "Best-first"
            ],
            [
                "Decoder",
                "10-best reranking"
            ],
            [
                "Decoder",
                "100-best reranking"
            ],
            [
                "Decoder",
                "2-best beam search"
            ],
            [
                "Decoder",
                "4-best beam search"
            ],
            [
                "Decoder",
                "8-best beam search"
            ]
        ],
        "column_header_level": 2,
        "column_headers": [
            [
                "Dev F1",
                "- backoff"
            ],
            [
                "Dev F1",
                "backoff"
            ],
            [
                "Relative Time",
                "-"
            ]
        ],
        "contents": [
            [
                "88.4",
                "88.4 (99.8%)",
                "1X"
            ],
            [
                "87.5",
                "2.8 (6.7%)",
                "293.4X"
            ],
            [
                "87.9",
                "87.9 (99.7%)",
                "8.5X"
            ],
            [
                "88.2",
                "88.0 (99.4%)",
                "72.3X"
            ],
            [
                "88.2",
                "85.7 (94.0%)",
                "2.0X"
            ],
            [
                "88.3",
                "88.1 (99.2%)",
                "6.7X"
            ],
            [
                "88.2",
                "86.8 (98.1%)",
                "26.3X"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "Dev F1",
            "Dev F1",
            "Relative Time"
        ],
        "target_entity": [
            "Global A*"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Dev F1 || - backoff</th>      <th>Dev F1 || backoff</th>      <th>Relative Time || -</th>    </tr>  </thead>  <tbody>    <tr>      <td>Decoder || Global A*</td>      <td>88.4</td>      <td>88.4 (99.8%)</td>      <td>1X</td>    </tr>    <tr>      <td>Decoder || Best-first</td>      <td>87.5</td>      <td>2.8 (6.7%)</td>      <td>293.4X</td>    </tr>    <tr>      <td>Decoder || 10-best reranking</td>      <td>87.9</td>      <td>87.9 (99.7%)</td>      <td>8.5X</td>    </tr>    <tr>      <td>Decoder || 100-best reranking</td>      <td>88.2</td>      <td>88.0 (99.4%)</td>      <td>72.3X</td>    </tr>    <tr>      <td>Decoder || 2-best beam search</td>      <td>88.2</td>      <td>85.7 (94.0%)</td>      <td>2.0X</td>    </tr>    <tr>      <td>Decoder || 4-best beam search</td>      <td>88.3</td>      <td>88.1 (99.2%)</td>      <td>6.7X</td>    </tr>    <tr>      <td>Decoder || 8-best beam search</td>      <td>88.2</td>      <td>86.8 (98.1%)</td>      <td>26.3X</td>    </tr>  </tbody></table>",
        "table_name": "Table 5",
        "table_id": "table_5",
        "paper_id": "D16-1262",
        "page_no": 9,
        "dir": "emnlp2016",
        "valid": 1
    },
    {
        "table_id_paper": "D17-1241table_3",
        "caption": "SPE: Prediction Results",
        "row_header_level": 2,
        "row_headers": [
            [
                "Methods",
                "Unigram"
            ],
            [
                "Methods",
                "LIWC"
            ],
            [
                "Methods",
                "SVD"
            ],
            [
                "Methods",
                "UserLDA"
            ],
            [
                "Methods",
                "PostLDA_Word"
            ],
            [
                "Methods",
                "PostLDA_Doc"
            ],
            [
                "Methods",
                "Post-D-DM"
            ],
            [
                "Methods",
                "User-D-DM"
            ],
            [
                "Methods",
                "Post-D-DBOW"
            ],
            [
                "Methods",
                "User-D-DBOW"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "Tobacco"
            ],
            [
                "Alcohol"
            ],
            [
                "Drug"
            ]
        ],
        "contents": [
            [
                "0.663",
                "0.672",
                "0.644"
            ],
            [
                "0.731",
                "0.689",
                "0.758"
            ],
            [
                "0.779",
                "0.724",
                "0.764"
            ],
            [
                "0.641",
                "0.603",
                "0.599"
            ],
            [
                "0.733",
                "0.617",
                "0.628"
            ],
            [
                "0.768",
                "0.687",
                "0.721"
            ],
            [
                "0.536",
                "0.622",
                "0.52"
            ],
            [
                "0.775",
                "0.73",
                "0.767"
            ],
            [
                "0.531",
                "0.606",
                "0.526"
            ],
            [
                "0.802",
                "0.768",
                "0.819"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "AUC",
            "AUC",
            "AUC"
        ],
        "target_entity": [
            "User-D-DBOW"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Tobacco</th>      <th>Alcohol</th>      <th>Drug</th>    </tr>  </thead>  <tbody>    <tr>      <td>Methods || Unigram</td>      <td>0.663</td>      <td>0.672</td>      <td>0.644</td>    </tr>    <tr>      <td>Methods || LIWC</td>      <td>0.731</td>      <td>0.689</td>      <td>0.758</td>    </tr>    <tr>      <td>Methods || SVD</td>      <td>0.779</td>      <td>0.724</td>      <td>0.764</td>    </tr>    <tr>      <td>Methods || UserLDA</td>      <td>0.641</td>      <td>0.603</td>      <td>0.599</td>    </tr>    <tr>      <td>Methods || PostLDA_Word</td>      <td>0.733</td>      <td>0.617</td>      <td>0.628</td>    </tr>    <tr>      <td>Methods || PostLDA_Doc</td>      <td>0.768</td>      <td>0.687</td>      <td>0.721</td>    </tr>    <tr>      <td>Methods || Post-D-DM</td>      <td>0.536</td>      <td>0.622</td>      <td>0.52</td>    </tr>    <tr>      <td>Methods || User-D-DM</td>      <td>0.775</td>      <td>0.73</td>      <td>0.767</td>    </tr>    <tr>      <td>Methods || Post-D-DBOW</td>      <td>0.531</td>      <td>0.606</td>      <td>0.526</td>    </tr>    <tr>      <td>Methods || User-D-DBOW</td>      <td>0.802</td>      <td>0.768</td>      <td>0.819</td>    </tr>  </tbody></table>",
        "table_name": "Table 3",
        "table_id": "table_3",
        "paper_id": "D17-1241",
        "page_no": 4,
        "dir": "emnlp2017",
        "valid": 1
    },
    {
        "table_id_paper": "D17-1245table_7",
        "caption": "Results obtained by the best model on each category of the test set for the factual vs opinion argument classification task",
        "row_header_level": 2,
        "row_headers": [
            [
                "Category",
                "fact"
            ],
            [
                "Category",
                "opinion"
            ],
            [
                "Category",
                "avg/total"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "P"
            ],
            [
                "R"
            ],
            [
                "F1"
            ],
            [
                "#argument per category"
            ]
        ],
        "contents": [
            [
                "0.49",
                "0.5",
                "0.5",
                "138"
            ],
            [
                "0.88",
                "0.87",
                "0.88",
                "575"
            ],
            [
                "0.81",
                "0.79",
                "0.8",
                "713"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "P",
            "R",
            "F1",
            "#argument per category"
        ],
        "target_entity": [
            "avg/total"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>P</th>      <th>R</th>      <th>F1</th>      <th>#argument per category</th>    </tr>  </thead>  <tbody>    <tr>      <td>Category || fact</td>      <td>0.49</td>      <td>0.5</td>      <td>0.5</td>      <td>138</td>    </tr>    <tr>      <td>Category || opinion</td>      <td>0.88</td>      <td>0.87</td>      <td>0.88</td>      <td>575</td>    </tr>    <tr>      <td>Category || avg/total</td>      <td>0.81</td>      <td>0.79</td>      <td>0.8</td>      <td>713</td>    </tr>  </tbody></table>",
        "table_name": "Table 7",
        "table_id": "table_7",
        "paper_id": "D17-1245",
        "page_no": 4,
        "dir": "emnlp2017",
        "valid": 1
    },
    {
        "table_id_paper": "D17-1254table_4",
        "caption": "Results for image-sentence ranking experiments on the COCO dataset. R@K denotes Recall@K (higher is better) and Med r is the median rank (lower is better). (\u2020) taken from Kiros et al. (2015). (\u2217) taken from Karpathy and Fei-Fei (2015). (\u2021) taken from Mao et al. (2015).",
        "row_header_level": 2,
        "row_headers": [
            [
                "Method",
                "uni-skip"
            ],
            [
                "Method",
                "bi-skip"
            ],
            [
                "Method",
                "combine-skip"
            ],
            [
                "Our Results",
                "hierarchical model+emb."
            ],
            [
                "Our Results",
                "composite model+emb."
            ],
            [
                "Our Results",
                "combine+emb."
            ],
            [
                "Task-dependent methods",
                "DVSA*"
            ],
            [
                "Task-dependent methods",
                "m-RNN"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "R@1"
            ],
            [
                "Med r"
            ],
            [
                "R@2"
            ],
            [
                "Med r"
            ]
        ],
        "contents": [
            [
                "30.6",
                "3",
                "22.7",
                "4"
            ],
            [
                "32.7",
                "3",
                "24.2",
                "4"
            ],
            [
                "33.8",
                "3",
                "25.9",
                "4"
            ],
            [
                "32.7",
                "3",
                "25.3",
                "4"
            ],
            [
                "33.8",
                "3",
                "25.7",
                "4"
            ],
            [
                "34.4",
                "3",
                "26.6",
                "4"
            ],
            [
                "38.4",
                "1",
                "27.4",
                "3"
            ],
            [
                "41",
                "2",
                "29",
                "3"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "R@1",
            "Med r",
            "R@2",
            "Med r"
        ],
        "target_entity": [
            "combine+emb."
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>R@1</th>      <th>Med r</th>      <th>R@2</th>      <th>Med r</th>    </tr>  </thead>  <tbody>    <tr>      <td>Method || uni-skip</td>      <td>30.6</td>      <td>3</td>      <td>22.7</td>      <td>4</td>    </tr>    <tr>      <td>Method || bi-skip</td>      <td>32.7</td>      <td>3</td>      <td>24.2</td>      <td>4</td>    </tr>    <tr>      <td>Method || combine-skip</td>      <td>33.8</td>      <td>3</td>      <td>25.9</td>      <td>4</td>    </tr>    <tr>      <td>Our Results || hierarchical model+emb.</td>      <td>32.7</td>      <td>3</td>      <td>25.3</td>      <td>4</td>    </tr>    <tr>      <td>Our Results || composite model+emb.</td>      <td>33.8</td>      <td>3</td>      <td>25.7</td>      <td>4</td>    </tr>    <tr>      <td>Our Results || combine+emb.</td>      <td>34.4</td>      <td>3</td>      <td>26.6</td>      <td>4</td>    </tr>    <tr>      <td>Task-dependent methods || DVSA*</td>      <td>38.4</td>      <td>1</td>      <td>27.4</td>      <td>3</td>    </tr>    <tr>      <td>Task-dependent methods || m-RNN</td>      <td>41</td>      <td>2</td>      <td>29</td>      <td>3</td>    </tr>  </tbody></table>",
        "table_name": "Table 4",
        "table_id": "table_4",
        "paper_id": "D17-1254",
        "page_no": 8,
        "dir": "emnlp2017",
        "valid": 1
    },
    {
        "table_id_paper": "D17-1267table_4",
        "caption": "Cognate clustering results on the Algonquian dataset (in %) with subsets of features.",
        "row_header_level": 2,
        "row_headers": [
            [
                "Features",
                "Phonetic only"
            ],
            [
                "Features",
                "+ Definitions"
            ],
            [
                "Features",
                "+ WordNet"
            ],
            [
                "Features",
                "+ Word Vectors"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "Found Sets"
            ],
            [
                "Purity"
            ]
        ],
        "contents": [
            [
                "52.0 (36.3)",
                "70.2"
            ],
            [
                "57.4 (41.7)",
                "68.4"
            ],
            [
                "61.9 (46.9)",
                "68.1"
            ],
            [
                "66.2 (51.3)",
                "66.5"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "Found Sets",
            "Purity"
        ],
        "target_entity": [
            "Phonetic only"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Found Sets</th>      <th>Purity</th>    </tr>  </thead>  <tbody>    <tr>      <td>Features || Phonetic only</td>      <td>52.0 (36.3)</td>      <td>70.2</td>    </tr>    <tr>      <td>Features || + Definitions</td>      <td>57.4 (41.7)</td>      <td>68.4</td>    </tr>    <tr>      <td>Features || + WordNet</td>      <td>61.9 (46.9)</td>      <td>68.1</td>    </tr>    <tr>      <td>Features || + Word Vectors</td>      <td>66.2 (51.3)</td>      <td>66.5</td>    </tr>  </tbody></table>",
        "table_name": "Table 4",
        "table_id": "table_4",
        "paper_id": "D17-1267",
        "page_no": 8,
        "dir": "emnlp2017",
        "valid": 1
    },
    {
        "table_id_paper": "D17-1304table_1",
        "caption": "Results on NIST Chinese-to-English Translation Task. \u201c*\u201d indicates statistically significant better than \u201cSennrich-deponly\u201d at p-value < 0.05 and \u201c**\u201d at p-value < 0.01. AVG = average BLEU scores for test sets.",
        "row_header_level": 2,
        "row_headers": [
            [
                "System",
                "PBSMT"
            ],
            [
                "System",
                "AttNMT"
            ],
            [
                "System",
                "Sennrich-deponly"
            ],
            [
                "System",
                "SDRNMT-1"
            ],
            [
                "System",
                "SDRNMT-2"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "Dev (MT02)"
            ],
            [
                "MT03"
            ],
            [
                "MT04"
            ],
            [
                "MT05"
            ],
            [
                "MT06"
            ],
            [
                "MT08"
            ],
            [
                "AVG"
            ]
        ],
        "contents": [
            [
                "33.15",
                "31.02",
                "33.78",
                "30.33",
                "29.62",
                "23.53",
                "29.66"
            ],
            [
                "36.31",
                "34.02",
                "37.11",
                "32.86",
                "32.54",
                "25.44",
                "32.4"
            ],
            [
                "36.68",
                "34.51",
                "38.09",
                "33.37",
                "32.96",
                "26.96",
                "32.98"
            ],
            [
                "36.88",
                "34.98*",
                "38.14",
                "34.61",
                "33.58",
                "27.06",
                "33.32"
            ],
            [
                "37.34",
                "35.91**",
                "38.73*",
                "34.18**",
                "33.76**",
                "27.64*",
                "34.04"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "BLEU",
            "BLEU",
            "BLEU",
            "BLEU",
            "BLEU",
            "BLEU",
            "BLEU"
        ],
        "target_entity": [
            "SDRNMT-2"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Dev (MT02)</th>      <th>MT03</th>      <th>MT04</th>      <th>MT05</th>      <th>MT06</th>      <th>MT08</th>      <th>AVG</th>    </tr>  </thead>  <tbody>    <tr>      <td>System || PBSMT</td>      <td>33.15</td>      <td>31.02</td>      <td>33.78</td>      <td>30.33</td>      <td>29.62</td>      <td>23.53</td>      <td>29.66</td>    </tr>    <tr>      <td>System || AttNMT</td>      <td>36.31</td>      <td>34.02</td>      <td>37.11</td>      <td>32.86</td>      <td>32.54</td>      <td>25.44</td>      <td>32.4</td>    </tr>    <tr>      <td>System || Sennrich-deponly</td>      <td>36.68</td>      <td>34.51</td>      <td>38.09</td>      <td>33.37</td>      <td>32.96</td>      <td>26.96</td>      <td>32.98</td>    </tr>    <tr>      <td>System || SDRNMT-1</td>      <td>36.88</td>      <td>34.98*</td>      <td>38.14</td>      <td>34.61</td>      <td>33.58</td>      <td>27.06</td>      <td>33.32</td>    </tr>    <tr>      <td>System || SDRNMT-2</td>      <td>37.34</td>      <td>35.91**</td>      <td>38.73*</td>      <td>34.18**</td>      <td>33.76**</td>      <td>27.64*</td>      <td>34.04</td>    </tr>  </tbody></table>",
        "table_name": "Table 1",
        "table_id": "table_1",
        "paper_id": "D17-1304",
        "page_no": 5,
        "dir": "emnlp2017",
        "valid": 1
    },
    {
        "table_id_paper": "D17-1309table_4",
        "caption": "Segmentation results. Explicit bigrams are useful.",
        "row_header_level": 2,
        "row_headers": [
            [
                "Model",
                "Zhang et al. (2016)"
            ],
            [
                "Model",
                "Zhang et al. (2016)-combo"
            ],
            [
                "Model",
                "Small FF 64 dim"
            ],
            [
                "Model",
                "Small FF 256 dim"
            ],
            [
                "Model",
                "Small FF 64 dim bigrams"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "Accuracy"
            ],
            [
                "Size"
            ]
        ],
        "contents": [
            [
                "95.01",
                "\u2212"
            ],
            [
                "95.95",
                "\u2212"
            ],
            [
                "94.24",
                "846KB"
            ],
            [
                "94.16",
                "3.2MB"
            ],
            [
                "95.18",
                "2.0MB"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "Accuracy",
            "Size"
        ],
        "target_entity": [
            "Small FF 64 dim bigrams"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Accuracy</th>      <th>Size</th>    </tr>  </thead>  <tbody>    <tr>      <td>Model || Zhang et al. (2016)</td>      <td>95.01</td>      <td>\u2212</td>    </tr>    <tr>      <td>Model || Zhang et al. (2016)-combo</td>      <td>95.95</td>      <td>\u2212</td>    </tr>    <tr>      <td>Model || Small FF 64 dim</td>      <td>94.24</td>      <td>846KB</td>    </tr>    <tr>      <td>Model || Small FF 256 dim</td>      <td>94.16</td>      <td>3.2MB</td>    </tr>    <tr>      <td>Model || Small FF 64 dim bigrams</td>      <td>95.18</td>      <td>2.0MB</td>    </tr>  </tbody></table>",
        "table_name": "Table 4",
        "table_id": "table_4",
        "paper_id": "D17-1309",
        "page_no": 4,
        "dir": "emnlp2017",
        "valid": 1
    },
    {
        "table_id_paper": "D18-1033table_5",
        "caption": "Performance on monolingual word similarity computation with seed lexicon size 6000.",
        "row_header_level": 2,
        "row_headers": [
            [
                "Method",
                "BiLex"
            ],
            [
                "Method",
                "CLSP-WR"
            ],
            [
                "Method",
                "CLSP-SE"
            ]
        ],
        "column_header_level": 2,
        "column_headers": [
            [
                "Chinese (source)",
                "WS-240"
            ],
            [
                "Chinese (source)",
                "WS-297"
            ],
            [
                "English (target)",
                "WS-353"
            ],
            [
                "English (target)",
                "SL-999"
            ]
        ],
        "contents": [
            [
                "60.36",
                "62.17",
                "60.46",
                "27.22"
            ],
            [
                "61.27",
                "65.25",
                "60.46",
                "27.22"
            ],
            [
                "60.84",
                "65.62",
                "62.47",
                "28.79"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "accuracy",
            "accuracy",
            "accuracy",
            "accuracy"
        ],
        "target_entity": [
            "CLSP-WR",
            "CLSP-SE"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Chinese (source) || WS-240</th>      <th>Chinese (source) || WS-297</th>      <th>English (target) || WS-353</th>      <th>English (target) || SL-999</th>    </tr>  </thead>  <tbody>    <tr>      <td>Method || BiLex</td>      <td>60.36</td>      <td>62.17</td>      <td>60.46</td>      <td>27.22</td>    </tr>    <tr>      <td>Method || CLSP-WR</td>      <td>61.27</td>      <td>65.25</td>      <td>60.46</td>      <td>27.22</td>    </tr>    <tr>      <td>Method || CLSP-SE</td>      <td>60.84</td>      <td>65.62</td>      <td>62.47</td>      <td>28.79</td>    </tr>  </tbody></table>",
        "table_name": "Table 5",
        "table_id": "table_5",
        "paper_id": "D18-1033",
        "page_no": 9,
        "dir": "emnlp2018",
        "valid": 1
    },
    {
        "table_id_paper": "D18-1049table_4",
        "caption": "Comparison with Transformer on FrenchEnglish translation task. The evaluation metric is caseinsensitive BLEU score.",
        "row_header_level": 2,
        "row_headers": [
            [
                "Method",
                "Transformer"
            ],
            [
                "Method",
                "this work"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "Dev"
            ],
            [
                "Test"
            ]
        ],
        "contents": [
            [
                "29.42",
                "35.15"
            ],
            [
                "30.40",
                "36.04"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "BLEU",
            "BLEU"
        ],
        "target_entity": [
            "this work"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Dev</th>      <th>Test</th>    </tr>  </thead>  <tbody>    <tr>      <td>Method || Transformer</td>      <td>29.42</td>      <td>35.15</td>    </tr>    <tr>      <td>Method || this work</td>      <td>30.40</td>      <td>36.04</td>    </tr>  </tbody></table>",
        "table_name": "Table 4",
        "table_id": "table_4",
        "paper_id": "D18-1049",
        "page_no": 7,
        "dir": "emnlp2018",
        "valid": 1
    },
    {
        "table_id_paper": "D18-1054table_2",
        "caption": "Performance of various models on NarrativeQA dataset (SS=sample size \u2261 number of relevant sentences)",
        "row_header_level": 2,
        "row_headers": [
            [
                "Model",
                "Seq2Seq"
            ],
            [
                "Model",
                "ASR"
            ],
            [
                "Model",
                "BiDAF"
            ],
            [
                "Model",
                "MRU (Tay et al. 2018)"
            ],
            [
                "Model",
                "Baseline 1 (SS=5)"
            ],
            [
                "Model",
                "Baseline 2 (SS=5)"
            ],
            [
                "Model",
                "ConZNet (SS=1)"
            ],
            [
                "Model",
                "ConZNet (SS=3)"
            ],
            [
                "Model",
                "ConZNet (SS=5)"
            ],
            [
                "Model",
                "ConZNet (SS=7)"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "BLEU-1"
            ],
            [
                "BLEU-4"
            ],
            [
                "ROUGE-L"
            ],
            [
                "METEOR"
            ]
        ],
        "contents": [
            [
                "15.89",
                "1.26",
                "13.15",
                "4.08"
            ],
            [
                "23.20",
                "6.39",
                "22.26",
                "7.77"
            ],
            [
                "33.72",
                "15.53",
                "36.30",
                "15.38"
            ],
            [
                "36.55",
                "19.79",
                "41.44",
                "17.87"
            ],
            [
                "30.22",
                "14.43",
                "34.40",
                "13.36"
            ],
            [
                "39.35",
                "20.17",
                "43.36",
                "18.01"
            ],
            [
                "28.97",
                "16.70",
                "36.02",
                "12.39"
            ],
            [
                "36.21",
                "19.33",
                "41.23",
                "17.77"
            ],
            [
                "42.76",
                "22.49",
                "46.67",
                "19.24"
            ],
            [
                "40.80",
                "21.14",
                "44.01",
                "18.67"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "BLEU-1",
            "BLEU-4",
            "ROUGE-L",
            "METEOR"
        ],
        "target_entity": [
            "ConZNet (SS=1)",
            "ConZNet (SS=3)",
            "ConZNet (SS=5)",
            "ConZNet (SS=7)"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>BLEU-1</th>      <th>BLEU-4</th>      <th>ROUGE-L</th>      <th>METEOR</th>    </tr>  </thead>  <tbody>    <tr>      <td>Model || Seq2Seq</td>      <td>15.89</td>      <td>1.26</td>      <td>13.15</td>      <td>4.08</td>    </tr>    <tr>      <td>Model || ASR</td>      <td>23.20</td>      <td>6.39</td>      <td>22.26</td>      <td>7.77</td>    </tr>    <tr>      <td>Model || BiDAF</td>      <td>33.72</td>      <td>15.53</td>      <td>36.30</td>      <td>15.38</td>    </tr>    <tr>      <td>Model || MRU (Tay et al. 2018)</td>      <td>36.55</td>      <td>19.79</td>      <td>41.44</td>      <td>17.87</td>    </tr>    <tr>      <td>Model || Baseline 1 (SS=5)</td>      <td>30.22</td>      <td>14.43</td>      <td>34.40</td>      <td>13.36</td>    </tr>    <tr>      <td>Model || Baseline 2 (SS=5)</td>      <td>39.35</td>      <td>20.17</td>      <td>43.36</td>      <td>18.01</td>    </tr>    <tr>      <td>Model || ConZNet (SS=1)</td>      <td>28.97</td>      <td>16.70</td>      <td>36.02</td>      <td>12.39</td>    </tr>    <tr>      <td>Model || ConZNet (SS=3)</td>      <td>36.21</td>      <td>19.33</td>      <td>41.23</td>      <td>17.77</td>    </tr>    <tr>      <td>Model || ConZNet (SS=5)</td>      <td>42.76</td>      <td>22.49</td>      <td>46.67</td>      <td>19.24</td>    </tr>    <tr>      <td>Model || ConZNet (SS=7)</td>      <td>40.80</td>      <td>21.14</td>      <td>44.01</td>      <td>18.67</td>    </tr>  </tbody></table>",
        "table_name": "Table 2",
        "table_id": "table_2",
        "paper_id": "D18-1054",
        "page_no": 5,
        "dir": "emnlp2018",
        "valid": 1
    },
    {
        "table_id_paper": "D18-1058table_3",
        "caption": "Published results of other models on the SemEval2012 Task 2 dataset.",
        "row_header_level": 2,
        "row_headers": [
            [
                "Model",
                "Rink and Harabagiu (2012)"
            ],
            [
                "Model",
                "Mikolov et al. (2013b)"
            ],
            [
                "Model",
                "Levy and Goldberg (2014)"
            ],
            [
                "Model",
                "Zhila et al. (2013)"
            ],
            [
                "Model",
                "Iacobacci et al. (2015)"
            ],
            [
                "Model",
                "Turney (2013)"
            ],
            [
                "Model",
                "VecOff"
            ],
            [
                "Model",
                "LRA"
            ],
            [
                "Model",
                "NLRA"
            ],
            [
                "Model",
                "NLRA+VecOff"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                " Accuracy"
            ],
            [
                "Correlation"
            ]
        ],
        "contents": [
            [
                "0.394",
                "0.229"
            ],
            [
                "0.418",
                "0.275"
            ],
            [
                "0.452",
                "-"
            ],
            [
                "0.452",
                "0.353"
            ],
            [
                "0.459",
                "0.358"
            ],
            [
                "0.472",
                "0.408"
            ],
            [
                "0.443",
                "0.321"
            ],
            [
                "0.415",
                "0.264"
            ],
            [
                "0.453",
                "0.36"
            ],
            [
                "0.475",
                "0.391"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "Accuracy",
            "Correlation"
        ],
        "target_entity": [
            "NLRA",
            "NLRA+VecOff"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Accuracy</th>      <th>Correlation</th>    </tr>  </thead>  <tbody>    <tr>      <td>Model || Rink and Harabagiu (2012)</td>      <td>0.394</td>      <td>0.229</td>    </tr>    <tr>      <td>Model || Mikolov et al. (2013b)</td>      <td>0.418</td>      <td>0.275</td>    </tr>    <tr>      <td>Model || Levy and Goldberg (2014)</td>      <td>0.452</td>      <td>-</td>    </tr>    <tr>      <td>Model || Zhila et al. (2013)</td>      <td>0.452</td>      <td>0.353</td>    </tr>    <tr>      <td>Model || Iacobacci et al. (2015)</td>      <td>0.459</td>      <td>0.358</td>    </tr>    <tr>      <td>Model || Turney (2013)</td>      <td>0.472</td>      <td>0.408</td>    </tr>    <tr>      <td>Model || VecOff</td>      <td>0.443</td>      <td>0.321</td>    </tr>    <tr>      <td>Model || LRA</td>      <td>0.415</td>      <td>0.264</td>    </tr>    <tr>      <td>Model || NLRA</td>      <td>0.453</td>      <td>0.36</td>    </tr>    <tr>      <td>Model || NLRA+VecOff</td>      <td>0.475</td>      <td>0.391</td>    </tr>  </tbody></table>",
        "table_name": "Table 3",
        "table_id": "table_3",
        "paper_id": "D18-1058",
        "page_no": 4,
        "dir": "emnlp2018",
        "valid": 1
    },
    {
        "table_id_paper": "D18-1082table_1",
        "caption": "Automatic evaluation",
        "row_header_level": 2,
        "row_headers": [
            [
                "Model",
                "S2SA"
            ],
            [
                "Model",
                "TAS2S"
            ],
            [
                "Model",
                "SPMN500"
            ],
            [
                "Model",
                "SPMN1000"
            ],
            [
                "Model",
                "DPMN100"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "PPL-V"
            ],
            [
                "PPL-T"
            ],
            [
                "distinct-1"
            ],
            [
                "distinct-2"
            ]
        ],
        "contents": [
            [
                "8.41",
                "9.05",
                "0.0809",
                "0.2110"
            ],
            [
                "7.38",
                "7.84",
                "0.04759",
                "0.1087"
            ],
            [
                "7.04",
                "7.93",
                "0.06430",
                "0.1734"
            ],
            [
                "6.28",
                "7.72",
                "0.07347",
                "0.1909"
            ],
            [
                "6.45",
                "7.69",
                "0.04350",
                "0.1048"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "PPL-V",
            "PPL-T",
            "distinct-1",
            "distinct-2"
        ],
        "target_entity": [
            "SPMN500",
            "SPMN1000",
            "DPMN100"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>PPL-V</th>      <th>PPL-T</th>      <th>distinct-1</th>      <th>distinct-2</th>    </tr>  </thead>  <tbody>    <tr>      <td>Model || S2SA</td>      <td>8.41</td>      <td>9.05</td>      <td>0.0809</td>      <td>0.2110</td>    </tr>    <tr>      <td>Model || TAS2S</td>      <td>7.38</td>      <td>7.84</td>      <td>0.04759</td>      <td>0.1087</td>    </tr>    <tr>      <td>Model || SPMN500</td>      <td>7.04</td>      <td>7.93</td>      <td>0.06430</td>      <td>0.1734</td>    </tr>    <tr>      <td>Model || SPMN1000</td>      <td>6.28</td>      <td>7.72</td>      <td>0.07347</td>      <td>0.1909</td>    </tr>    <tr>      <td>Model || DPMN100</td>      <td>6.45</td>      <td>7.69</td>      <td>0.04350</td>      <td>0.1048</td>    </tr>  </tbody></table>",
        "table_name": "Table 1",
        "table_id": "table_1",
        "paper_id": "D18-1082",
        "page_no": 4,
        "dir": "emnlp2018",
        "valid": 1
    },
    {
        "table_id_paper": "D18-1160table_4",
        "caption": "Unsupervised POS tagging results on WSJ, with fastText vectors as the observed embeddings.",
        "row_header_level": 2,
        "row_headers": [
            [
                "System",
                "Gaussian HMM"
            ],
            [
                "System",
                "Ours (4 layers)"
            ],
            [
                "System",
                "Ours (8 layers)"
            ],
            [
                "System",
                "Ours (16 layers)"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "M-1"
            ],
            [
                "VM"
            ]
        ],
        "contents": [
            [
                "72.0",
                "65.0"
            ],
            [
                "76.4",
                "69.3"
            ],
            [
                "76.8",
                "69.4"
            ],
            [
                "67.3",
                "62.0"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "M-1",
            "VM"
        ],
        "target_entity": [
            "Ours (4 layers)",
            "Ours (8 layers)",
            "Ours (16 layers)"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>M-1</th>      <th>VM</th>    </tr>  </thead>  <tbody>    <tr>      <td>System || Gaussian HMM</td>      <td>72.0</td>      <td>65.0</td>    </tr>    <tr>      <td>System || Ours (4 layers)</td>      <td>76.4</td>      <td>69.3</td>    </tr>    <tr>      <td>System || Ours (8 layers)</td>      <td>76.8</td>      <td>69.4</td>    </tr>    <tr>      <td>System || Ours (16 layers)</td>      <td>67.3</td>      <td>62.0</td>    </tr>  </tbody></table>",
        "table_name": "Table 4",
        "table_id": "table_4",
        "paper_id": "D18-1160",
        "page_no": 8,
        "dir": "emnlp2018",
        "valid": 1
    },
    {
        "table_id_paper": "D18-1166table_2",
        "caption": "Results for simple and neural models on the test set of RecipeQA dataset.",
        "row_header_level": 1,
        "row_headers": [
            [
                "Hasty Student"
            ],
            [
                "Impatient Reader (Text only)"
            ],
            [
                "Impatient Reader (Multimodal)"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "Visual Cloze"
            ],
            [
                "Textual Cloze"
            ],
            [
                "Visual Coherence"
            ],
            [
                "Visual Ordering"
            ]
        ],
        "contents": [
            [
                "27.35",
                "26.89",
                "65.80",
                "40.88"
            ],
            [
                "-",
                "28.03",
                "-",
                "-"
            ],
            [
                "27.36",
                "29.07",
                "28.08",
                "26.74"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "accuracy",
            "accuracy",
            "accuracy",
            "accuracy"
        ],
        "target_entity": [
            "Hasty Student",
            "Impatient Reader (Text only)",
            "Impatient Reader (Multimodal)"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Visual Cloze</th>      <th>Textual Cloze</th>      <th>Visual Coherence</th>      <th>Visual Ordering</th>    </tr>  </thead>  <tbody>    <tr>      <td>Hasty Student</td>      <td>27.35</td>      <td>26.89</td>      <td>65.80</td>      <td>40.88</td>    </tr>    <tr>      <td>Impatient Reader (Text only)</td>      <td>-</td>      <td>28.03</td>      <td>-</td>      <td>-</td>    </tr>    <tr>      <td>Impatient Reader (Multimodal)</td>      <td>27.36</td>      <td>29.07</td>      <td>28.08</td>      <td>26.74</td>    </tr>  </tbody></table>",
        "table_name": "Table 2",
        "table_id": "table_2",
        "paper_id": "D18-1166",
        "page_no": 8,
        "dir": "emnlp2018",
        "valid": 1
    },
    {
        "table_id_paper": "D18-1176table_1",
        "caption": "Accuracy scores on the Stanford Natural Language Inference (SNLI) and MultiNLI Mismatched (MNLI) tasks. DME=Dynamic Meta-Embeddings; CDME=Contextualized Dynamic Meta-Embeddings; *=multiple different embedding sets (see Section 4). Number of parameters included in parenthesis. Results averaged over five runs with different random seeds, using a BiLSTM-Max sentence encoder.",
        "row_header_level": 2,
        "row_headers": [
            [
                "Model",
                "InferSent (Conneau et al., 2017)"
            ],
            [
                "Model",
                "NSE (Munkhdalai and Yu, 2017)"
            ],
            [
                "Model",
                "G-TreeLSTM (Choi et al., 2017)"
            ],
            [
                "Model",
                "SSE (Nie and Bansal, 2017)"
            ],
            [
                "Model",
                "ReSan (Shen et al., 2018)"
            ],
            [
                "Model",
                "GloVe BiLSTM-Max (8.6M)"
            ],
            [
                "Model",
                "FastText BiLSTM-Max (8.6M)"
            ],
            [
                "Model",
                "Naive baseline (9.8M)"
            ],
            [
                "Model",
                "Naive baseline (61.3M)"
            ],
            [
                "Model",
                "Unweighted DME (8.6M)"
            ],
            [
                "Model",
                "DME (8.6M)"
            ],
            [
                "Model",
                "CDME (8.6M)"
            ],
            [
                "Model",
                "DME* (9.0M)"
            ],
            [
                "Model",
                "CDME* (9.0M)"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "SNLI"
            ],
            [
                "MNLI"
            ]
        ],
        "contents": [
            [
                "84.5",
                "-"
            ],
            [
                "84.6",
                "-"
            ],
            [
                "86.0",
                "-"
            ],
            [
                "86.1",
                "73.6"
            ],
            [
                "86.3",
                "-"
            ],
            [
                "85.2\u0081}.3",
                "70.0\u0081}.5"
            ],
            [
                "85.2\u0081}.2",
                "70.3\u0081}.3"
            ],
            [
                "85.6\u0081}.3",
                "71.1\u0081}.2"
            ],
            [
                "86.0\u0081}.5",
                "73.0\u0081}.2"
            ],
            [
                "86.3\u0081}.4",
                "74.4\u0081}.2"
            ],
            [
                "86.2\u0081}.2",
                "74.4\u0081}.2"
            ],
            [
                "86.4\u0081}.3",
                "74.1\u0081}.2"
            ],
            [
                "86.7\u0081}.2",
                "74.3\u0081}.4"
            ],
            [
                "86.5\u0081}.2",
                "74.9\u0081}.5"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "Accuracy",
            "Accuracy"
        ],
        "target_entity": [
            "Unweighted DME (8.6M)",
            "DME (8.6M)",
            "CDME (8.6M)",
            "DME* (9.0M)",
            "CDME* (9.0M)"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>SNLI</th>      <th>MNLI</th>    </tr>  </thead>  <tbody>    <tr>      <td>Model || InferSent (Conneau et al., 2017)</td>      <td>84.5</td>      <td>-</td>    </tr>    <tr>      <td>Model || NSE (Munkhdalai and Yu, 2017)</td>      <td>84.6</td>      <td>-</td>    </tr>    <tr>      <td>Model || G-TreeLSTM (Choi et al., 2017)</td>      <td>86.0</td>      <td>-</td>    </tr>    <tr>      <td>Model || SSE (Nie and Bansal, 2017)</td>      <td>86.1</td>      <td>73.6</td>    </tr>    <tr>      <td>Model || ReSan (Shen et al., 2018)</td>      <td>86.3</td>      <td>-</td>    </tr>    <tr>      <td>Model || GloVe BiLSTM-Max (8.6M)</td>      <td>85.2\u0081}.3</td>      <td>70.0\u0081}.5</td>    </tr>    <tr>      <td>Model || FastText BiLSTM-Max (8.6M)</td>      <td>85.2\u0081}.2</td>      <td>70.3\u0081}.3</td>    </tr>    <tr>      <td>Model || Naive baseline (9.8M)</td>      <td>85.6\u0081}.3</td>      <td>71.1\u0081}.2</td>    </tr>    <tr>      <td>Model || Naive baseline (61.3M)</td>      <td>86.0\u0081}.5</td>      <td>73.0\u0081}.2</td>    </tr>    <tr>      <td>Model || Unweighted DME (8.6M)</td>      <td>86.3\u0081}.4</td>      <td>74.4\u0081}.2</td>    </tr>    <tr>      <td>Model || DME (8.6M)</td>      <td>86.2\u0081}.2</td>      <td>74.4\u0081}.2</td>    </tr>    <tr>      <td>Model || CDME (8.6M)</td>      <td>86.4\u0081}.3</td>      <td>74.1\u0081}.2</td>    </tr>    <tr>      <td>Model || DME* (9.0M)</td>      <td>86.7\u0081}.2</td>      <td>74.3\u0081}.4</td>    </tr>    <tr>      <td>Model || CDME* (9.0M)</td>      <td>86.5\u0081}.2</td>      <td>74.9\u0081}.5</td>    </tr>  </tbody></table>",
        "table_name": "Table 1",
        "table_id": "table_1",
        "paper_id": "D18-1176",
        "page_no": 5,
        "dir": "emnlp2018",
        "valid": 1
    },
    {
        "table_id_paper": "D18-1188table_2",
        "caption": "Performance of different approaches on the WikiSQL dataset. The two evaluation metrics are logical form accuracy (Acclf ) and execution accuracy (Accex). The settings of the training data represent the proportion of supervised data we use.",
        "row_header_level": 4,
        "row_headers": [
            [
                "Methods",
                "Attentional Seq2Seq",
                "Training Data",
                "100%"
            ],
            [
                "Methods",
                "Aug.PntNet (Zhong et al. 2017)",
                "Training Data",
                "100%"
            ],
            [
                "Methods",
                "Aug.PntNet (re-implemented by us)",
                "Training Data",
                "100%"
            ],
            [
                "Methods",
                "Seq2SQL (Zhong et al. 2017)",
                "Training Data",
                "100%"
            ],
            [
                "Methods",
                "SQLNet (Xu et al. 2017)",
                "Training Data",
                "100%"
            ],
            [
                "Methods",
                "STAMP",
                "Training Data",
                "30%"
            ],
            [
                "Methods",
                "STAMP + QG",
                "Training Data",
                "30%"
            ],
            [
                "Methods",
                "STAMP",
                "Training Data",
                "100%"
            ],
            [
                "Methods",
                "STAMP + QG",
                "Training Data",
                "100%"
            ]
        ],
        "column_header_level": 2,
        "column_headers": [
            [
                "Dev",
                "Acclf"
            ],
            [
                "Dev",
                "Accex"
            ],
            [
                "Test",
                "Acclf"
            ],
            [
                "Test",
                "Accex"
            ]
        ],
        "contents": [
            [
                "23.3%",
                "37.0%",
                "23.4%",
                "35.9%"
            ],
            [
                "44.1%",
                "53.8%",
                "43.3%",
                "53.3%"
            ],
            [
                "51.5%",
                "58.9%",
                "52.1%",
                "59.2%"
            ],
            [
                "49.5%",
                "60.8%",
                "48.3%",
                "59.4%"
            ],
            [
                "-",
                "69.8%",
                "-",
                "68.0%"
            ],
            [
                "54.6%",
                "69.7%",
                "53.7%",
                "68.9%"
            ],
            [
                "61.6%",
                "74.4%",
                "61.2%",
                "73.9%"
            ],
            [
                "61.5%",
                "74.8%",
                "60.7%",
                "74.4%"
            ],
            [
                "64.3%",
                "76.5%",
                "63.7%",
                "75.5%"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "Acclf",
            "Accex",
            "Acclf",
            "Accex"
        ],
        "target_entity": [
            "STAMP",
            "STAMP + QG"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Dev || Acclf</th>      <th>Dev || Accex</th>      <th>Test || Acclf</th>      <th>Test || Accex</th>    </tr>  </thead>  <tbody>    <tr>      <td>Methods || Attentional Seq2Seq || Training Data || 100%</td>      <td>23.3%</td>      <td>37.0%</td>      <td>23.4%</td>      <td>35.9%</td>    </tr>    <tr>      <td>Methods || Aug.PntNet (Zhong et al. 2017) || Training Data || 100%</td>      <td>44.1%</td>      <td>53.8%</td>      <td>43.3%</td>      <td>53.3%</td>    </tr>    <tr>      <td>Methods || Aug.PntNet (re-implemented by us) || Training Data || 100%</td>      <td>51.5%</td>      <td>58.9%</td>      <td>52.1%</td>      <td>59.2%</td>    </tr>    <tr>      <td>Methods || Seq2SQL (Zhong et al. 2017) || Training Data || 100%</td>      <td>49.5%</td>      <td>60.8%</td>      <td>48.3%</td>      <td>59.4%</td>    </tr>    <tr>      <td>Methods || SQLNet (Xu et al. 2017) || Training Data || 100%</td>      <td>-</td>      <td>69.8%</td>      <td>-</td>      <td>68.0%</td>    </tr>    <tr>      <td>Methods || STAMP || Training Data || 30%</td>      <td>54.6%</td>      <td>69.7%</td>      <td>53.7%</td>      <td>68.9%</td>    </tr>    <tr>      <td>Methods || STAMP + QG || Training Data || 30%</td>      <td>61.6%</td>      <td>74.4%</td>      <td>61.2%</td>      <td>73.9%</td>    </tr>    <tr>      <td>Methods || STAMP || Training Data || 100%</td>      <td>61.5%</td>      <td>74.8%</td>      <td>60.7%</td>      <td>74.4%</td>    </tr>    <tr>      <td>Methods || STAMP + QG || Training Data || 100%</td>      <td>64.3%</td>      <td>76.5%</td>      <td>63.7%</td>      <td>75.5%</td>    </tr>  </tbody></table>",
        "table_name": "Table 2",
        "table_id": "table_2",
        "paper_id": "D18-1188",
        "page_no": 5,
        "dir": "emnlp2018",
        "valid": 1
    },
    {
        "table_id_paper": "D18-1219table_5",
        "caption": "Results of using NP head alone for bridging anaphora resolution based on different word representation resources. Bold indicates statistically significant differences over the baselines (two-sided paired approximate randomization test, p < 0.01).",
        "row_header_level": 1,
        "row_headers": [
            [
                "GloVe GigaWiki14"
            ],
            [
                "GloVe Giga"
            ],
            [
                "embeddings PP"
            ],
            [
                "embeddings bridging"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "acc"
            ]
        ],
        "contents": [
            [
                "21.42"
            ],
            [
                "21.87"
            ],
            [
                "33.03"
            ],
            [
                "34.84"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "acc"
        ],
        "target_entity": [
            "embeddings bridging"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>acc</th>    </tr>  </thead>  <tbody>    <tr>      <td>GloVe GigaWiki14</td>      <td>21.42</td>    </tr>    <tr>      <td>GloVe Giga</td>      <td>21.87</td>    </tr>    <tr>      <td>embeddings PP</td>      <td>33.03</td>    </tr>    <tr>      <td>embeddings bridging</td>      <td>34.84</td>    </tr>  </tbody></table>",
        "table_name": "Table 5",
        "table_id": "table_5",
        "paper_id": "D18-1219",
        "page_no": 7,
        "dir": "emnlp2018",
        "valid": 1
    },
    {
        "table_id_paper": "D18-1262table_5",
        "caption": "Comparison of our Syn-GCN model with (Marcheggiani and Titov, 2017), (He et al., 2018) and (Cai et al., 2018) on the English test set. \u2206 F1 shows the absolute performance gap between syntax-agnostic and syntax-aware settings.",
        "row_header_level": 2,
        "row_headers": [
            [
                "System",
                "M&T (2017)"
            ],
            [
                "System",
                "He et al. (2018)"
            ],
            [
                "System",
                "Cai et al. (2018)"
            ],
            [
                "System",
                "Our model"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "syntax-agnostic"
            ],
            [
                "syntax-aware"
            ],
            [
                "\u0394F1"
            ]
        ],
        "contents": [
            [
                "87.7",
                "88.0",
                "0.3"
            ],
            [
                "88.7",
                "89.5",
                "0.8"
            ],
            [
                "89.6",
                "89.6",
                "\u22480.0"
            ],
            [
                "88.7",
                "89.8",
                "1.1"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "F1",
            "F1",
            "F1"
        ],
        "target_entity": [
            "Our model"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>syntax-agnostic</th>      <th>syntax-aware</th>      <th>\u0394F1</th>    </tr>  </thead>  <tbody>    <tr>      <td>System || M&amp;T (2017)</td>      <td>87.7</td>      <td>88.0</td>      <td>0.3</td>    </tr>    <tr>      <td>System || He et al. (2018)</td>      <td>88.7</td>      <td>89.5</td>      <td>0.8</td>    </tr>    <tr>      <td>System || Cai et al. (2018)</td>      <td>89.6</td>      <td>89.6</td>      <td>\u22480.0</td>    </tr>    <tr>      <td>System || Our model</td>      <td>88.7</td>      <td>89.8</td>      <td>1.1</td>    </tr>  </tbody></table>",
        "table_name": "Table 5",
        "table_id": "table_5",
        "paper_id": "D18-1262",
        "page_no": 7,
        "dir": "emnlp2018",
        "valid": 1
    },
    {
        "table_id_paper": "D18-1273table_6",
        "caption": "Human evaluation results. S-ocr refer to 150 sentences from the D-ocr and E-ocr represents the errors in S-ocr, similar for S-asr and Easr. R denotes the average recall of three students. Numbers in bold denotes the correctly-annotated results by students.",
        "row_header_level": 1,
        "row_headers": [
            [
                "S-ocr"
            ],
            [
                "E-ocr"
            ],
            [
                "S-asr"
            ],
            [
                "E-asr"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "Correctly-annotated Number of Stu1"
            ],
            [
                "Correctly-annotated Number of Stu2"
            ],
            [
                "Correctly-annotated Number of Stu3"
            ],
            [
                "R"
            ]
        ],
        "contents": [
            [
                "84/150",
                "100/150",
                "75/150",
                "57.3"
            ],
            [
                "104/170",
                "121/170",
                "100/170",
                "72.0"
            ],
            [
                "95/150",
                "79/150",
                "106/150",
                "62.0"
            ],
            [
                "341/393",
                "179/393",
                "356/393",
                "74.3"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "Correctly-annotated Number of Stu1",
            "Correctly-annotated Number of Stu2",
            "Correctly-annotated Number of Stu3",
            "R"
        ],
        "target_entity": [
            "S-ocr",
            "E-ocr",
            "S-asr",
            "E-asr"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Stu1</th>      <th>Stu2</th>      <th>Stu3</th>      <th>R</th>    </tr>  </thead>  <tbody>    <tr>      <td>S-ocr</td>      <td>84/150</td>      <td>100/150</td>      <td>75/150</td>      <td>57.3</td>    </tr>    <tr>      <td>E-ocr</td>      <td>104/170</td>      <td>121/170</td>      <td>100/170</td>      <td>72.0</td>    </tr>    <tr>      <td>S-asr</td>      <td>95/150</td>      <td>79/150</td>      <td>106/150</td>      <td>62.0</td>    </tr>    <tr>      <td>E-asr</td>      <td>341/393</td>      <td>179/393</td>      <td>356/393</td>      <td>74.3</td>    </tr>  </tbody></table>",
        "table_name": "Table 6",
        "table_id": "table_6",
        "paper_id": "D18-1273",
        "page_no": 6,
        "dir": "emnlp2018",
        "valid": 1
    },
    {
        "table_id_paper": "D18-1276table_2",
        "caption": "Performance of Clique-EBM with pruned edges in G.",
        "row_header_level": 2,
        "row_headers": [
            [
                "k",
                "5"
            ],
            [
                "k",
                "10"
            ],
            [
                "k",
                "15"
            ],
            [
                "k",
                "20"
            ]
        ],
        "column_header_level": 2,
        "column_headers": [
            [
                "WPT",
                "P"
            ],
            [
                "WPT",
                "R"
            ],
            [
                "WPT",
                "F"
            ],
            [
                "WP3T",
                "P"
            ],
            [
                "WP3T",
                "R"
            ],
            [
                "WP3T",
                "F"
            ]
        ],
        "contents": [
            [
                "90.46",
                "92.27",
                "91.36",
                "83.52",
                "80.48",
                "81.97"
            ],
            [
                "92.92",
                "95.07",
                "93.98",
                "85.32",
                "84.4",
                "84.86"
            ],
            [
                "94.85",
                "96.14",
                "95.49",
                "87.67",
                "86.38",
                "87.02"
            ],
            [
                "95.23",
                "96.49",
                "95.86",
                "89.25",
                "88.62",
                "88.93"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "P",
            "R",
            "F",
            "P",
            "R",
            "F"
        ],
        "target_entity": [
            "k"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>WPT || P</th>      <th>WPT || R</th>      <th>WPT || F</th>      <th>WP3T || P</th>      <th>WP3T || R</th>      <th>WP3T || F</th>    </tr>  </thead>  <tbody>    <tr>      <td>k || 5</td>      <td>90.46</td>      <td>92.27</td>      <td>91.36</td>      <td>83.52</td>      <td>80.48</td>      <td>81.97</td>    </tr>    <tr>      <td>k || 10</td>      <td>92.92</td>      <td>95.07</td>      <td>93.98</td>      <td>85.32</td>      <td>84.4</td>      <td>84.86</td>    </tr>    <tr>      <td>k || 15</td>      <td>94.85</td>      <td>96.14</td>      <td>95.49</td>      <td>87.67</td>      <td>86.38</td>      <td>87.02</td>    </tr>    <tr>      <td>k || 20</td>      <td>95.23</td>      <td>96.49</td>      <td>95.86</td>      <td>89.25</td>      <td>88.62</td>      <td>88.93</td>    </tr>  </tbody></table>",
        "table_name": "Table 2",
        "table_id": "table_2",
        "paper_id": "D18-1276",
        "page_no": 8,
        "dir": "emnlp2018",
        "valid": 1
    },
    {
        "table_id_paper": "D18-1281table_2",
        "caption": "Comparison of various bounding box regressors on Flickr30k Entities for different IoU thresholds. The number of parameters in Gr is also shown.",
        "row_header_level": 2,
        "row_headers": [
            [
                "Architecture",
                "w/o regression"
            ],
            [
                "Architecture",
                "300-16(-4096)"
            ],
            [
                "Architecture",
                "300-64(-4096)"
            ],
            [
                "Architecture",
                "300-256(-4096)"
            ],
            [
                "Architecture",
                "300-1024(-4096)"
            ],
            [
                "Architecture",
                "300(-256-4096)"
            ],
            [
                "Architecture",
                "300-4096"
            ]
        ],
        "column_header_level": 2,
        "column_headers": [
            [
                "Params",
                "-"
            ],
            [
                "IoU",
                "0.5"
            ],
            [
                "IoU",
                "0.6"
            ],
            [
                "IoU",
                "0.7"
            ],
            [
                "IoU",
                "0.8"
            ],
            [
                "IoU",
                "0.9"
            ]
        ],
        "contents": [
            [
                "-",
                "65.21",
                "53.19",
                "35.70",
                "14.32",
                "1.88"
            ],
            [
                "0.3M",
                "64.14",
                "57.66",
                "48.22",
                "33.04",
                "9.29"
            ],
            [
                "1.1M",
                "63.87",
                "57.43",
                "49.05",
                "33.84",
                "10.55"
            ],
            [
                "4.3M",
                "63.84",
                "57.70",
                "48.71",
                "33.87",
                "10.05"
            ],
            [
                "17M",
                "64.29",
                "58.05",
                "48.49",
                "33.94",
                "10.09"
            ],
            [
                "4.5M",
                "62.82",
                "56.28",
                "48.02",
                "32.71",
                "9.89"
            ],
            [
                "1.2M",
                "63.23",
                "56.92",
                "48.17",
                "32.66",
                "9.20"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "# Params",
            "accuracy",
            "accuracy",
            "accuracy",
            "accuracy",
            "accuracy"
        ],
        "target_entity": [
            "300-16(-4096)",
            "300-64(-4096)",
            "300-256(-4096)",
            "300-1024(-4096)",
            "300(-256-4096)",
            "300-4096"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Params || -</th>      <th>IoU || 0.5</th>      <th>IoU || 0.6</th>      <th>IoU || 0.7</th>      <th>IoU || 0.8</th>      <th>IoU || 0.9</th>    </tr>  </thead>  <tbody>    <tr>      <td>Architecture || w/o regression</td>      <td>-</td>      <td>65.21</td>      <td>53.19</td>      <td>35.70</td>      <td>14.32</td>      <td>1.88</td>    </tr>    <tr>      <td>Architecture || 300-16(-4096)</td>      <td>0.3M</td>      <td>64.14</td>      <td>57.66</td>      <td>48.22</td>      <td>33.04</td>      <td>9.29</td>    </tr>    <tr>      <td>Architecture || 300-64(-4096)</td>      <td>1.1M</td>      <td>63.87</td>      <td>57.43</td>      <td>49.05</td>      <td>33.84</td>      <td>10.55</td>    </tr>    <tr>      <td>Architecture || 300-256(-4096)</td>      <td>4.3M</td>      <td>63.84</td>      <td>57.70</td>      <td>48.71</td>      <td>33.87</td>      <td>10.05</td>    </tr>    <tr>      <td>Architecture || 300-1024(-4096)</td>      <td>17M</td>      <td>64.29</td>      <td>58.05</td>      <td>48.49</td>      <td>33.94</td>      <td>10.09</td>    </tr>    <tr>      <td>Architecture || 300(-256-4096)</td>      <td>4.5M</td>      <td>62.82</td>      <td>56.28</td>      <td>48.02</td>      <td>32.71</td>      <td>9.89</td>    </tr>    <tr>      <td>Architecture || 300-4096</td>      <td>1.2M</td>      <td>63.23</td>      <td>56.92</td>      <td>48.17</td>      <td>32.66</td>      <td>9.20</td>    </tr>  </tbody></table>",
        "table_name": "Table 2",
        "table_id": "table_2",
        "paper_id": "D18-1281",
        "page_no": 7,
        "dir": "emnlp2018",
        "valid": 1
    },
    {
        "table_id_paper": "D18-1303table_1",
        "caption": "Single-label classification (accuracy) results.",
        "row_header_level": 2,
        "row_headers": [
            [
                "Model",
                "Linear SVM"
            ],
            [
                "Model",
                "Gaussian NB"
            ],
            [
                "Model",
                "Logistic Reg."
            ],
            [
                "Model",
                "SVM"
            ],
            [
                "Model",
                "CNN"
            ],
            [
                "Model",
                "RNN"
            ],
            [
                "Model",
                "CNN-RNN"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "Commenting"
            ],
            [
                "Ogling"
            ],
            [
                "Groping"
            ]
        ],
        "contents": [
            [
                "42.2",
                "35.0",
                "55.8"
            ],
            [
                "46.8",
                "74.7",
                "66.0"
            ],
            [
                "61.4",
                "78.0",
                "69.1"
            ],
            [
                "65.5",
                "79.0",
                "70.3"
            ],
            [
                "80.9",
                "82.2",
                "86.0"
            ],
            [
                "81.0",
                "82.2",
                "86.2"
            ],
            [
                "81.6",
                "84.1",
                "86.5"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "accuracy",
            "accuracy",
            "accuracy"
        ],
        "target_entity": [
            "CNN-RNN"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Commenting</th>      <th>Ogling</th>      <th>Groping</th>    </tr>  </thead>  <tbody>    <tr>      <td>Model || Linear SVM</td>      <td>42.2</td>      <td>35.0</td>      <td>55.8</td>    </tr>    <tr>      <td>Model || Gaussian NB</td>      <td>46.8</td>      <td>74.7</td>      <td>66.0</td>    </tr>    <tr>      <td>Model || Logistic Reg.</td>      <td>61.4</td>      <td>78.0</td>      <td>69.1</td>    </tr>    <tr>      <td>Model || SVM</td>      <td>65.5</td>      <td>79.0</td>      <td>70.3</td>    </tr>    <tr>      <td>Model || CNN</td>      <td>80.9</td>      <td>82.2</td>      <td>86.0</td>    </tr>    <tr>      <td>Model || RNN</td>      <td>81.0</td>      <td>82.2</td>      <td>86.2</td>    </tr>    <tr>      <td>Model || CNN-RNN</td>      <td>81.6</td>      <td>84.1</td>      <td>86.5</td>    </tr>  </tbody></table>",
        "table_name": "Table 1",
        "table_id": "table_1",
        "paper_id": "D18-1303",
        "page_no": 3,
        "dir": "emnlp2018",
        "valid": 1
    },
    {
        "table_id_paper": "D18-1349table_6",
        "caption": "Results (presented in percentage) in terms of precision (P), recall (R) and F-measure (F1) on the test set for each label obtained by our HSLN-RNN model on the PubMed 20k dataset.",
        "row_header_level": 2,
        "row_headers": [
            [
                "Label",
                "Background"
            ],
            [
                "Label",
                "Objectives"
            ],
            [
                "Label",
                "Methods"
            ],
            [
                "Label",
                "Results"
            ],
            [
                "Label",
                "Conclusions"
            ],
            [
                "Label",
                "Total"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "P"
            ],
            [
                "R"
            ],
            [
                "F1"
            ],
            [
                "Support"
            ]
        ],
        "contents": [
            [
                "78.5",
                "80.0",
                "79.2",
                "3077"
            ],
            [
                "74.2",
                "69.9",
                "72.0",
                "2333"
            ],
            [
                "95.0",
                "97.7",
                "96.3",
                "9884"
            ],
            [
                "96.8",
                "95.3",
                "96.0",
                "9713"
            ],
            [
                "97.6",
                "96.5",
                "97.1",
                "4571"
            ],
            [
                "92.6",
                "92.7",
                "92.6",
                "29578"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "P",
            "R",
            "F1",
            "Support"
        ],
        "target_entity": [
            "Background",
            "Objectives",
            "Methods",
            "Results",
            "Conclusions"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>P</th>      <th>R</th>      <th>F1</th>      <th>Support</th>    </tr>  </thead>  <tbody>    <tr>      <td>Label || Background</td>      <td>78.5</td>      <td>80.0</td>      <td>79.2</td>      <td>3077</td>    </tr>    <tr>      <td>Label || Objectives</td>      <td>74.2</td>      <td>69.9</td>      <td>72.0</td>      <td>2333</td>    </tr>    <tr>      <td>Label || Methods</td>      <td>95.0</td>      <td>97.7</td>      <td>96.3</td>      <td>9884</td>    </tr>    <tr>      <td>Label || Results</td>      <td>96.8</td>      <td>95.3</td>      <td>96.0</td>      <td>9713</td>    </tr>    <tr>      <td>Label || Conclusions</td>      <td>97.6</td>      <td>96.5</td>      <td>97.1</td>      <td>4571</td>    </tr>    <tr>      <td>Label || Total</td>      <td>92.6</td>      <td>92.7</td>      <td>92.6</td>      <td>29578</td>    </tr>  </tbody></table>",
        "table_name": "Table 6",
        "table_id": "table_6",
        "paper_id": "D18-1349",
        "page_no": 7,
        "dir": "emnlp2018",
        "valid": 1
    },
    {
        "table_id_paper": "D18-1351table_4",
        "caption": "CV coherence scores for topics generated by various models. Higher is better. The best result in each column is in bold.",
        "row_header_level": 2,
        "row_headers": [
            [
                "Model",
                "LDA"
            ],
            [
                "Model",
                "BTM"
            ],
            [
                "Model",
                "NTM"
            ],
            [
                "Model",
                "TMN"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "Snippets"
            ],
            [
                "TagMyNews"
            ],
            [
                "Twitter"
            ]
        ],
        "contents": [
            [
                "0.436",
                "0.449",
                "0.436"
            ],
            [
                "0.435",
                "0.463",
                "0.435"
            ],
            [
                "0.463",
                "0.468",
                "0.463"
            ],
            [
                "0.487",
                "0.499",
                "0.468"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "CV",
            "CV",
            "CV"
        ],
        "target_entity": [
            "TMN"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Snippets</th>      <th>TagMyNews</th>      <th>Twitter</th>    </tr>  </thead>  <tbody>    <tr>      <td>Model || LDA</td>      <td>0.436</td>      <td>0.449</td>      <td>0.436</td>    </tr>    <tr>      <td>Model || BTM</td>      <td>0.435</td>      <td>0.463</td>      <td>0.435</td>    </tr>    <tr>      <td>Model || NTM</td>      <td>0.463</td>      <td>0.468</td>      <td>0.463</td>    </tr>    <tr>      <td>Model || TMN</td>      <td>0.487</td>      <td>0.499</td>      <td>0.468</td>    </tr>  </tbody></table>",
        "table_name": "Table 4",
        "table_id": "table_4",
        "paper_id": "D18-1351",
        "page_no": 6,
        "dir": "emnlp2018",
        "valid": 1
    },
    {
        "table_id_paper": "D18-1362table_3",
        "caption": "Comparison of dev set MRR of Ours(ConvE) and models without reward shaping and action dropout.",
        "row_header_level": 2,
        "row_headers": [
            [
                "Model",
                "Ours(ConvE)"
            ],
            [
                "Model",
                "-RS"
            ],
            [
                "Model",
                "-AD"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "UMLS"
            ],
            [
                "Kinship"
            ],
            [
                "FB15k237"
            ],
            [
                "WN18RR"
            ],
            [
                "NELL995"
            ]
        ],
        "contents": [
            [
                "73.0",
                "75.0",
                "38.2",
                "43.8",
                "78.8"
            ],
            [
                "67.7",
                "66.5",
                "35.1",
                "45.7",
                "78.4"
            ],
            [
                "61.3",
                "65.4",
                "31.0",
                "39.1",
                "76.1"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "MRR",
            "MRR",
            "MRR",
            "MRR",
            "MRR"
        ],
        "target_entity": [
            "Ours(ConvE)",
            "-RS",
            "-AD"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>UMLS</th>      <th>Kinship</th>      <th>FB15k237</th>      <th>WN18RR</th>      <th>NELL995</th>    </tr>  </thead>  <tbody>    <tr>      <td>Model || Ours(ConvE)</td>      <td>73.0</td>      <td>75.0</td>      <td>38.2</td>      <td>43.8</td>      <td>78.8</td>    </tr>    <tr>      <td>Model || -RS</td>      <td>67.7</td>      <td>66.5</td>      <td>35.1</td>      <td>45.7</td>      <td>78.4</td>    </tr>    <tr>      <td>Model || -AD</td>      <td>61.3</td>      <td>65.4</td>      <td>31.0</td>      <td>39.1</td>      <td>76.1</td>    </tr>  </tbody></table>",
        "table_name": "Table 3",
        "table_id": "table_3",
        "paper_id": "D18-1362",
        "page_no": 7,
        "dir": "emnlp2018",
        "valid": 1
    },
    {
        "table_id_paper": "D18-1363table_3",
        "caption": "MED accuracy on five randomly selected languages with 1, 2, and 4 sources and combined with paradigm transduction (\u201c+PT\u201d). Best results in bold.",
        "row_header_level": 1,
        "row_headers": [
            [
                "dutch"
            ],
            [
                "german"
            ],
            [
                "icelandic"
            ],
            [
                "spanish"
            ],
            [
                "welsh"
            ]
        ],
        "column_header_level": 2,
        "column_headers": [
            [
                "SET1",
                "1"
            ],
            [
                "SET1",
                "2"
            ],
            [
                "SET1",
                "4"
            ],
            [
                "SET1",
                "+PT"
            ],
            [
                "SET2",
                "1"
            ],
            [
                "SET2",
                "2"
            ],
            [
                "SET2",
                "4"
            ],
            [
                "SET2",
                "+PT"
            ],
            [
                "SET3",
                "1"
            ],
            [
                "SET3",
                "2"
            ],
            [
                "SET3",
                "4"
            ],
            [
                "SET3",
                "+PT"
            ]
        ],
        "contents": [
            [
                ".00",
                ".00",
                ".00",
                ".49",
                ".04",
                ".01",
                ".00",
                ".78",
                ".43",
                ".65",
                ".72",
                ".87"
            ],
            [
                ".00",
                ".00",
                ".00",
                ".65",
                ".00",
                ".00",
                ".01",
                ".75",
                ".44",
                ".42",
                ".59",
                ".88"
            ],
            [
                ".00",
                ".00",
                ".00",
                ".41",
                ".03",
                ".02",
                ".02",
                ".50",
                ".24",
                ".33",
                ".35",
                ".77"
            ],
            [
                ".00",
                ".00",
                ".00",
                ".92",
                ".03",
                ".09",
                ".09",
                ".98",
                ".59",
                ".63",
                ".83",
                ".99"
            ],
            [
                ".00",
                ".00",
                ".00",
                ".91",
                ".05",
                ".14",
                ".15",
                ".97",
                ".35",
                ".53",
                ".70",
                ".99"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "accuracy",
            "accuracy",
            "accuracy",
            "accuracy",
            "accuracy",
            "accuracy",
            "accuracy",
            "accuracy",
            "accuracy",
            "accuracy",
            "accuracy",
            "accuracy"
        ],
        "target_entity": [
            "1",
            "2",
            "4"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>SET1 || 1</th>      <th>SET1 || 2</th>      <th>SET1 || 4</th>      <th>SET1 || +PT</th>      <th>SET2 || 1</th>      <th>SET2 || 2</th>      <th>SET2 || 4</th>      <th>SET2 || +PT</th>      <th>SET3 || 1</th>      <th>SET3 || 2</th>      <th>SET3 || 4</th>      <th>SET3 || +PT</th>    </tr>  </thead>  <tbody>    <tr>      <td>dutch</td>      <td>.00</td>      <td>.00</td>      <td>.00</td>      <td>.49</td>      <td>.04</td>      <td>.01</td>      <td>.00</td>      <td>.78</td>      <td>.43</td>      <td>.65</td>      <td>.72</td>      <td>.87</td>    </tr>    <tr>      <td>german</td>      <td>.00</td>      <td>.00</td>      <td>.00</td>      <td>.65</td>      <td>.00</td>      <td>.00</td>      <td>.01</td>      <td>.75</td>      <td>.44</td>      <td>.42</td>      <td>.59</td>      <td>.88</td>    </tr>    <tr>      <td>icelandic</td>      <td>.00</td>      <td>.00</td>      <td>.00</td>      <td>.41</td>      <td>.03</td>      <td>.02</td>      <td>.02</td>      <td>.50</td>      <td>.24</td>      <td>.33</td>      <td>.35</td>      <td>.77</td>    </tr>    <tr>      <td>spanish</td>      <td>.00</td>      <td>.00</td>      <td>.00</td>      <td>.92</td>      <td>.03</td>      <td>.09</td>      <td>.09</td>      <td>.98</td>      <td>.59</td>      <td>.63</td>      <td>.83</td>      <td>.99</td>    </tr>    <tr>      <td>welsh</td>      <td>.00</td>      <td>.00</td>      <td>.00</td>      <td>.91</td>      <td>.05</td>      <td>.14</td>      <td>.15</td>      <td>.97</td>      <td>.35</td>      <td>.53</td>      <td>.70</td>      <td>.99</td>    </tr>  </tbody></table>",
        "table_name": "Table 3",
        "table_id": "table_3",
        "paper_id": "D18-1363",
        "page_no": 8,
        "dir": "emnlp2018",
        "valid": 1
    },
    {
        "table_id_paper": "D18-1368table_2",
        "caption": "Situation Entity Type Classification Results on the Training Set of MASC+Wiki with 10-Fold Cross-Validation. We report accuracy (Acc), macro-average F1-score (Macro) and class-wise F1 scores for STATE (STA), EVENT (EVE), REPORT (REP), GENERIC (GENI), GENERALIZING (GENA), QUESTION (QUE) and IMPERATIVE (IMP).",
        "row_header_level": 2,
        "row_headers": [
            [
                "Model",
                "Humans"
            ],
            [
                "Model",
                "CRF (Friedrich et al. 2016)"
            ],
            [
                "Model",
                "Clause-level Bi-LSTM"
            ],
            [
                "Model",
                "Paragraph-level Model"
            ],
            [
                "Model",
                "Paragraph-level Model+CRF"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "Macro"
            ],
            [
                "Acc"
            ],
            [
                "F1 STA"
            ],
            [
                "F1 EVE"
            ],
            [
                "F1 REP"
            ],
            [
                "F1 GENI"
            ],
            [
                "F1 GENA"
            ],
            [
                "F1 QUE"
            ],
            [
                "F1 IMP"
            ]
        ],
        "contents": [
            [
                "78.6",
                "79.6",
                "82.8",
                "80.5",
                "81.5",
                "75.1",
                "45.8",
                "90.7",
                "93.6"
            ],
            [
                "71.2",
                "76.4",
                "80.6",
                "78.6",
                "78.9",
                "68.3",
                "29.4",
                "84.4",
                "75.3"
            ],
            [
                "74.4",
                "78.3",
                "82.6",
                "81.3",
                "84.9",
                "66.2",
                "36.1",
                "88.5",
                "80.9"
            ],
            [
                "77.6",
                "81.2",
                "84.3",
                "82.1",
                "85.3",
                "76.4",
                "43.2",
                "90.8",
                "81.2"
            ],
            [
                "77.8",
                "81.3",
                "84.3",
                "82.0",
                "85.7",
                "77.0",
                "43.5",
                "90.4",
                "81.5"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "Macro",
            "Acc",
            "F1 STA",
            "F1 EVE",
            "F1 REP",
            "F1 GENI",
            "F1 GENA",
            "F1 QUE",
            "F1 IMP"
        ],
        "target_entity": [
            "Paragraph-level Model",
            "Paragraph-level Model+CRF"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Macro</th>      <th>Acc</th>      <th>STA</th>      <th>EVE</th>      <th>REP</th>      <th>GENI</th>      <th>GENA</th>      <th>QUE</th>      <th>IMP</th>    </tr>  </thead>  <tbody>    <tr>      <td>Model || Humans</td>      <td>78.6</td>      <td>79.6</td>      <td>82.8</td>      <td>80.5</td>      <td>81.5</td>      <td>75.1</td>      <td>45.8</td>      <td>90.7</td>      <td>93.6</td>    </tr>    <tr>      <td>Model || CRF (Friedrich et al. 2016)</td>      <td>71.2</td>      <td>76.4</td>      <td>80.6</td>      <td>78.6</td>      <td>78.9</td>      <td>68.3</td>      <td>29.4</td>      <td>84.4</td>      <td>75.3</td>    </tr>    <tr>      <td>Model || Clause-level Bi-LSTM</td>      <td>74.4</td>      <td>78.3</td>      <td>82.6</td>      <td>81.3</td>      <td>84.9</td>      <td>66.2</td>      <td>36.1</td>      <td>88.5</td>      <td>80.9</td>    </tr>    <tr>      <td>Model || Paragraph-level Model</td>      <td>77.6</td>      <td>81.2</td>      <td>84.3</td>      <td>82.1</td>      <td>85.3</td>      <td>76.4</td>      <td>43.2</td>      <td>90.8</td>      <td>81.2</td>    </tr>    <tr>      <td>Model || Paragraph-level Model+CRF</td>      <td>77.8</td>      <td>81.3</td>      <td>84.3</td>      <td>82.0</td>      <td>85.7</td>      <td>77.0</td>      <td>43.5</td>      <td>90.4</td>      <td>81.5</td>    </tr>  </tbody></table>",
        "table_name": "Table 2",
        "table_id": "table_2",
        "paper_id": "D18-1368",
        "page_no": 6,
        "dir": "emnlp2018",
        "valid": 1
    },
    {
        "table_id_paper": "D18-1369table_2",
        "caption": "Narrative reconstruction results in NYT dataset and post grouping results in Wikipedia conversation dataset.",
        "row_header_level": 2,
        "row_headers": [
            [
                "NYT",
                "LDA + DBSCAN"
            ],
            [
                "NYT",
                "HDP + DBSCAN"
            ],
            [
                "NYT",
                "HDHP"
            ],
            [
                "NYT",
                "HD-GMHP (100D)"
            ],
            [
                "Wiki",
                "W2V + DBSCAN"
            ],
            [
                "Wiki",
                "HDHP"
            ],
            [
                "Wiki",
                "HD-GMHP (100D)"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "AMI"
            ],
            [
                "ARI"
            ]
        ],
        "contents": [
            [
                "0.0627",
                "0.0117"
            ],
            [
                "0.0260",
                "0.0203"
            ],
            [
                "0.1768",
                "0.0746"
            ],
            [
                "0.2479",
                "0.1416"
            ],
            [
                "0.0055",
                "0.0001"
            ],
            [
                "0.4240",
                "0.3512"
            ],
            [
                "0.5848",
                "0.3834"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "accuracy",
            "accuracy"
        ],
        "target_entity": [
            "HD-GMHP (100D)"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>AMI</th>      <th>ARI</th>    </tr>  </thead>  <tbody>    <tr>      <td>NYT || LDA + DBSCAN</td>      <td>0.0627</td>      <td>0.0117</td>    </tr>    <tr>      <td>NYT || HDP + DBSCAN</td>      <td>0.0260</td>      <td>0.0203</td>    </tr>    <tr>      <td>NYT || HDHP</td>      <td>0.1768</td>      <td>0.0746</td>    </tr>    <tr>      <td>NYT || HD-GMHP (100D)</td>      <td>0.2479</td>      <td>0.1416</td>    </tr>    <tr>      <td>Wiki || W2V + DBSCAN</td>      <td>0.0055</td>      <td>0.0001</td>    </tr>    <tr>      <td>Wiki || HDHP</td>      <td>0.4240</td>      <td>0.3512</td>    </tr>    <tr>      <td>Wiki || HD-GMHP (100D)</td>      <td>0.5848</td>      <td>0.3834</td>    </tr>  </tbody></table>",
        "table_name": "Table 2",
        "table_id": "table_2",
        "paper_id": "D18-1369",
        "page_no": 8,
        "dir": "emnlp2018",
        "valid": 1
    },
    {
        "table_id_paper": "D18-1381table_2",
        "caption": "Experimental results on Sem2016 with two training settings TRAIN and TRAIN-ALL.",
        "row_header_level": 1,
        "row_headers": [
            [
                "NBOW-MLP"
            ],
            [
                "CNN"
            ],
            [
                "BiLSTM"
            ],
            [
                "AT-BiLSTM"
            ],
            [
                "Lexicon RNN"
            ],
            [
                "AGLR"
            ]
        ],
        "column_header_level": 3,
        "column_headers": [
            [
                "Sem2016 (TRAIN)",
                "3-way",
                "Acc"
            ],
            [
                "Sem2016 (TRAIN)",
                "3-way",
                "F1"
            ],
            [
                "Sem2016 (TRAIN)",
                "Binary",
                "Acc"
            ],
            [
                "Sem2016 (TRAIN)",
                "Binary",
                "F1"
            ],
            [
                "Sem2016 (TRAIN-ALL)",
                "3-way",
                "Acc"
            ],
            [
                "Sem2016 (TRAIN-ALL)",
                "3-way",
                "F1"
            ],
            [
                "Sem2016 (TRAIN-ALL)",
                "Binary",
                "Acc"
            ],
            [
                "Sem2016 (TRAIN-ALL)",
                "Binary",
                "F1"
            ],
            [
                "-",
                "AVG",
                "Acc"
            ],
            [
                "-",
                "AVG",
                "F1"
            ]
        ],
        "contents": [
            [
                "54.31",
                "52.90",
                "79.69",
                "77.33",
                "61.09",
                "55.91",
                "84.90",
                "82.01",
                "70.00",
                "67.04"
            ],
            [
                "54.67",
                "52.17",
                "79.79",
                "75.28",
                "62.68",
                "57.71",
                "84.10",
                "81.31",
                "70.31",
                "66.62"
            ],
            [
                "55.57",
                "52.33",
                "81.90",
                "77.12",
                "63.26",
                "60.31",
                "85.89",
                "84.14",
                "71.66",
                "68.50"
            ],
            [
                "56.95",
                "54.53",
                "80.09",
                "73.93",
                "64.20",
                "61.64",
                "86.77",
                "83.67",
                "72.00",
                "68.44"
            ],
            [
                "51.02",
                "50.45",
                "81.72",
                "79.00",
                "61.41",
                "60.50",
                "86.68",
                "83.82",
                "70.21",
                "68.44"
            ],
            [
                "59.01",
                "56.67",
                "82.79",
                "80.10",
                "66.62",
                "64.36",
                "87.16",
                "84.98",
                "73.90",
                "71.53"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "Acc",
            "F1",
            "Acc",
            "F1",
            "Acc",
            "F1",
            "Acc",
            "F1",
            "Acc",
            "F1"
        ],
        "target_entity": [
            "AGLR"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Sem2016 (TRAIN) || 3-way || Acc</th>      <th>Sem2016 (TRAIN) || 3-way || F1</th>      <th>Sem2016 (TRAIN) || Binary || Acc</th>      <th>Sem2016 (TRAIN) || Binary || F1</th>      <th>Sem2016 (TRAIN-ALL) || 3-way || Acc</th>      <th>Sem2016 (TRAIN-ALL) || 3-way || F1</th>      <th>Sem2016 (TRAIN-ALL) || Binary || Acc</th>      <th>Sem2016 (TRAIN-ALL) || Binary || F1</th>      <th>- || AVG || Acc</th>      <th>- || AVG || F1</th>    </tr>  </thead>  <tbody>    <tr>      <td>NBOW-MLP</td>      <td>54.31</td>      <td>52.90</td>      <td>79.69</td>      <td>77.33</td>      <td>61.09</td>      <td>55.91</td>      <td>84.90</td>      <td>82.01</td>      <td>70.00</td>      <td>67.04</td>    </tr>    <tr>      <td>CNN</td>      <td>54.67</td>      <td>52.17</td>      <td>79.79</td>      <td>75.28</td>      <td>62.68</td>      <td>57.71</td>      <td>84.10</td>      <td>81.31</td>      <td>70.31</td>      <td>66.62</td>    </tr>    <tr>      <td>BiLSTM</td>      <td>55.57</td>      <td>52.33</td>      <td>81.90</td>      <td>77.12</td>      <td>63.26</td>      <td>60.31</td>      <td>85.89</td>      <td>84.14</td>      <td>71.66</td>      <td>68.50</td>    </tr>    <tr>      <td>AT-BiLSTM</td>      <td>56.95</td>      <td>54.53</td>      <td>80.09</td>      <td>73.93</td>      <td>64.20</td>      <td>61.64</td>      <td>86.77</td>      <td>83.67</td>      <td>72.00</td>      <td>68.44</td>    </tr>    <tr>      <td>Lexicon RNN</td>      <td>51.02</td>      <td>50.45</td>      <td>81.72</td>      <td>79.00</td>      <td>61.41</td>      <td>60.50</td>      <td>86.68</td>      <td>83.82</td>      <td>70.21</td>      <td>68.44</td>    </tr>    <tr>      <td>AGLR</td>      <td>59.01</td>      <td>56.67</td>      <td>82.79</td>      <td>80.10</td>      <td>66.62</td>      <td>64.36</td>      <td>87.16</td>      <td>84.98</td>      <td>73.90</td>      <td>71.53</td>    </tr>  </tbody></table>",
        "table_name": "Table 2",
        "table_id": "table_2",
        "paper_id": "D18-1381",
        "page_no": 7,
        "dir": "emnlp2018",
        "valid": 1
    },
    {
        "table_id_paper": "D18-1396table_4",
        "caption": "BLEU scores on En-Jp test set. \u201d0\u201d represents the normal translation results, and \u201d1\u201d represents the teacher-forcing translation results.",
        "row_header_level": 1,
        "row_headers": [
            [
                "left"
            ],
            [
                "right"
            ]
        ],
        "column_header_level": 2,
        "column_headers": [
            [
                "left-to-right",
                "0"
            ],
            [
                "left-to-right",
                "1"
            ],
            [
                "right-to-left",
                "0"
            ],
            [
                "right-to-left",
                "1"
            ]
        ],
        "contents": [
            [
                "7.90",
                "9.91",
                "7.45",
                "8.95"
            ],
            [
                "8.70",
                "11.52",
                "9.24",
                "10.59"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "BLEU",
            "BLEU",
            "BLEU",
            "BLEU"
        ],
        "target_entity": [
            "1"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>left-to-right || 0</th>      <th>left-to-right || 1</th>      <th>right-to-left || 0</th>      <th>right-to-left || 1</th>    </tr>  </thead>  <tbody>    <tr>      <td>left</td>      <td>7.90</td>      <td>9.91</td>      <td>7.45</td>      <td>8.95</td>    </tr>    <tr>      <td>right</td>      <td>8.70</td>      <td>11.52</td>      <td>9.24</td>      <td>10.59</td>    </tr>  </tbody></table>",
        "table_name": "Table 4",
        "table_id": "table_4",
        "paper_id": "D18-1396",
        "page_no": 6,
        "dir": "emnlp2018",
        "valid": 1
    },
    {
        "table_id_paper": "D18-1400table_3",
        "caption": "Translation results on the IKEA dataset",
        "row_header_level": 2,
        "row_headers": [
            [
                "Method",
                "LIUMCVC-Multi"
            ],
            [
                "Method",
                "Text-Only NMT"
            ],
            [
                "Method",
                "VAG-NMT"
            ]
        ],
        "column_header_level": 2,
        "column_headers": [
            [
                "English \u2192 German",
                "BLEU"
            ],
            [
                "English \u2192 German",
                "METEOR"
            ],
            [
                "English \u2192 French",
                "BLEU"
            ],
            [
                "English \u2192 French",
                "METEOR"
            ]
        ],
        "contents": [
            [
                "59.9 \u00b1 1.9",
                "63.8 \u00b1 0.4",
                "58.4 \u00b1 1.6",
                "64.6 \u00b1 1.8"
            ],
            [
                "61.9 \u00b1 0.9",
                "65.6 \u00b1 0.9",
                "65.2 \u00b1 0.7",
                "69.0 \u00b1 0.2"
            ],
            [
                "63.5 \u00b1 1.2",
                "65.7 \u00b1 0.1",
                "65.8 \u00b1 1.2",
                "68.9 \u00b1 1.4"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "BLEU",
            "METEOR",
            "BLEU",
            "METEOR"
        ],
        "target_entity": [
            "VAG-NMT"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>English \u2192 German || BLEU</th>      <th>English \u2192 German || METEOR</th>      <th>English \u2192 French || BLEU</th>      <th>English \u2192 French || METEOR</th>    </tr>  </thead>  <tbody>    <tr>      <td>Method || LIUMCVC-Multi</td>      <td>59.9 \u00b1 1.9</td>      <td>63.8 \u00b1 0.4</td>      <td>58.4 \u00b1 1.6</td>      <td>64.6 \u00b1 1.8</td>    </tr>    <tr>      <td>Method || Text-Only NMT</td>      <td>61.9 \u00b1 0.9</td>      <td>65.6 \u00b1 0.9</td>      <td>65.2 \u00b1 0.7</td>      <td>69.0 \u00b1 0.2</td>    </tr>    <tr>      <td>Method || VAG-NMT</td>      <td>63.5 \u00b1 1.2</td>      <td>65.7 \u00b1 0.1</td>      <td>65.8 \u00b1 1.2</td>      <td>68.9 \u00b1 1.4</td>    </tr>  </tbody></table>",
        "table_name": "Table 3",
        "table_id": "table_3",
        "paper_id": "D18-1400",
        "page_no": 6,
        "dir": "emnlp2018",
        "valid": 1
    },
    {
        "table_id_paper": "D18-1401table_2",
        "caption": "Performance of our approaches to QA-style sentiment classification in all domains.",
        "row_header_level": 1,
        "row_headers": [
            [
                "SVM"
            ],
            [
                "LSTM"
            ],
            [
                "Bi-LSTM"
            ],
            [
                "Bidirectional-Match"
            ],
            [
                "AtoQ-Match"
            ],
            [
                "QtoA-Match"
            ],
            [
                "Bidirectional-Match QA"
            ],
            [
                "HMN"
            ]
        ],
        "column_header_level": 2,
        "column_headers": [
            [
                "Beauty",
                "Macro-F1"
            ],
            [
                "Beauty",
                "Accuracy"
            ],
            [
                "Shoe",
                "Macro-F1"
            ],
            [
                "Shoe",
                "Accuracy"
            ],
            [
                "Electronic",
                "Macro-F1"
            ],
            [
                "Electronic",
                "Accuracy"
            ]
        ],
        "contents": [
            [
                "0.362",
                "0.684",
                "0.381",
                "0.718",
                "0.435",
                "0.691"
            ],
            [
                "0.499",
                "0.712",
                "0.520",
                "0.754",
                "0.562",
                "0.715"
            ],
            [
                "0.527",
                "0.719",
                "0.531",
                "0.759",
                "0.574",
                "0.723"
            ],
            [
                "0.526",
                "0.747",
                "0.557",
                "0.796",
                "0.582",
                "0.741"
            ],
            [
                "0.543",
                "0.745",
                "0.602",
                "0.792",
                "0.567",
                "0.754"
            ],
            [
                "0.573",
                "0.751",
                "0.647",
                "0.807",
                "0.608",
                "0.752"
            ],
            [
                "0.583",
                "0.760",
                "0.666",
                "0.815",
                "0.617",
                "0.764"
            ],
            [
                "0.598",
                "0.776",
                "0.683",
                "0.827",
                "0.640",
                "0.779"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "Macro-F1",
            "Accuracy",
            "Macro-F1",
            "Accuracy",
            "Macro-F1",
            "Accuracy"
        ],
        "target_entity": [
            "HMN"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Beauty || Macro-F1</th>      <th>Beauty || Accuracy</th>      <th>Shoe || Macro-F1</th>      <th>Shoe || Accuracy</th>      <th>Electronic || Macro-F1</th>      <th>Electronic || Accuracy</th>    </tr>  </thead>  <tbody>    <tr>      <td>SVM</td>      <td>0.362</td>      <td>0.684</td>      <td>0.381</td>      <td>0.718</td>      <td>0.435</td>      <td>0.691</td>    </tr>    <tr>      <td>LSTM</td>      <td>0.499</td>      <td>0.712</td>      <td>0.520</td>      <td>0.754</td>      <td>0.562</td>      <td>0.715</td>    </tr>    <tr>      <td>Bi-LSTM</td>      <td>0.527</td>      <td>0.719</td>      <td>0.531</td>      <td>0.759</td>      <td>0.574</td>      <td>0.723</td>    </tr>    <tr>      <td>Bidirectional-Match</td>      <td>0.526</td>      <td>0.747</td>      <td>0.557</td>      <td>0.796</td>      <td>0.582</td>      <td>0.741</td>    </tr>    <tr>      <td>AtoQ-Match</td>      <td>0.543</td>      <td>0.745</td>      <td>0.602</td>      <td>0.792</td>      <td>0.567</td>      <td>0.754</td>    </tr>    <tr>      <td>QtoA-Match</td>      <td>0.573</td>      <td>0.751</td>      <td>0.647</td>      <td>0.807</td>      <td>0.608</td>      <td>0.752</td>    </tr>    <tr>      <td>Bidirectional-Match QA</td>      <td>0.583</td>      <td>0.760</td>      <td>0.666</td>      <td>0.815</td>      <td>0.617</td>      <td>0.764</td>    </tr>    <tr>      <td>HMN</td>      <td>0.598</td>      <td>0.776</td>      <td>0.683</td>      <td>0.827</td>      <td>0.640</td>      <td>0.779</td>    </tr>  </tbody></table>",
        "table_name": "Table 2",
        "table_id": "table_2",
        "paper_id": "D18-1401",
        "page_no": 7,
        "dir": "emnlp2018",
        "valid": 1
    },
    {
        "table_id_paper": "D18-1408table_2",
        "caption": "Performance on SNLI and transfer tasks of various sentence encoders. Test accuracies on SNLI, micro and macro averages of accuracies of dev set on transfer tasks are chosen as evaluation metrics.",
        "row_header_level": 2,
        "row_headers": [
            [
                "Model",
                "BiLSTM-Max"
            ],
            [
                "Model",
                "AdaSent"
            ],
            [
                "Model",
                "TBCNN"
            ],
            [
                "Model",
                "DiSAN"
            ],
            [
                "Model",
                "PSAN"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "SNLI"
            ],
            [
                "Micro"
            ],
            [
                "Macro"
            ]
        ],
        "contents": [
            [
                "84.5",
                "85.2",
                "83.7"
            ],
            [
                "83.4",
                "82.0",
                "80.9"
            ],
            [
                "82.1",
                "81.1",
                "79.3"
            ],
            [
                "85.6",
                "84.7",
                "83.4"
            ],
            [
                "86.1",
                "85.7",
                "84.5"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "accuracy",
            "accuracy",
            "accuracy"
        ],
        "target_entity": [
            "PSAN"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>SNLI</th>      <th>Micro</th>      <th>Macro</th>      </tr>  </thead>  <tbody>    <tr>      <td>Model || BiLSTM-max</td>      <td>84.5</td>      <td>85.2</td>      <td>83.7</td>      </tr>    <tr>      <td>Model || AdaSent</td>      <td>83.4</td>      <td>82.0</td>      <td>80.9</td>      </tr>    <tr>      <td>Model || TBCNN</td>      <td>82.1</td>      <td>81.1</td>      <td>79.3</td>      </tr>    <tr>      <td>Model || DiSAN</td>       <td>85.6</td>      <td>84.7</td>      <td>83.4</td>      </tr>    <tr>      <td>Model || PSAN</td>      <td>86.1</td>      <td>85.7</td>      <td>84.5</td>      </tr>  </tbody></table>",
        "table_name": "Table 2",
        "table_id": "table_2",
        "paper_id": "D18-1408",
        "page_no": 5,
        "dir": "emnlp2018",
        "valid": 1
    },
    {
        "table_id_paper": "D18-1408table_3",
        "caption": "Transfer test results for our model and various baselines. Classification accuracy is chosen as evaluation metric for datasets including MR, CR, SUBJ, MPQA, SST, TREC and SICK-E.",
        "row_header_level": 2,
        "row_headers": [
            [
                "Model",
                "BiLSTM-max"
            ],
            [
                "Model",
                "AdaSent"
            ],
            [
                "Model",
                "TBCNN"
            ],
            [
                "Model",
                "DiSAN"
            ],
            [
                "Model",
                "PSAN"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "MR"
            ],
            [
                "CR"
            ],
            [
                "SUBJ"
            ],
            [
                "MPQA"
            ],
            [
                "SST"
            ],
            [
                "TREC"
            ]
        ],
        "contents": [
            [
                "79.9",
                "84.6",
                "92.1",
                "89.8",
                "83.3",
                "88.7"
            ],
            [
                "77.0",
                "82.0",
                "89.9",
                "87.2",
                "82.3",
                "85.6"
            ],
            [
                "75.4",
                "81.6",
                "89.1",
                "85.9",
                "79.4",
                "83.7"
            ],
            [
                "79.7",
                "84.1",
                "92.2",
                "89.5",
                "82.9",
                "88.3"
            ],
            [
                "80.0",
                "84.2",
                "91.9",
                "89.9",
                "83.8",
                "89.1"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "Accuracy",
            "Accuracy",
            "Accuracy",
            "Accuracy",
            "Accuracy",
            "Accuracy"
        ],
        "target_entity": [
            "PSAN"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>MR</th>      <th>CR</th>      <th>SUBJ</th>      <th>MPQA</th>      <th>SST</th>      <th>TREC</th>    </tr>  </thead>  <tbody>    <tr>      <td>Model || BiLSTM-max</td>      <td>79.9</td>      <td>84.6</td>      <td>92.1</td>      <td>89.8</td>      <td>83.3</td>      <td>88.7</td>    </tr>    <tr>      <td>Model || AdaSent</td>      <td>77.0</td>      <td>82.0</td>      <td>89.9</td>      <td>87.2</td>      <td>82.3</td>      <td>85.6</td>    </tr>    <tr>      <td>Model || TBCNN</td>      <td>75.4</td>      <td>81.6</td>      <td>89.1</td>      <td>85.9</td>      <td>79.4</td>      <td>83.7</td>    </tr>    <tr>      <td>Model || DiSAN</td>       <td>79.7</td>      <td>84.1</td>      <td>92.2</td>      <td>89.5</td>      <td>82.9</td>      <td>88.3</td>    </tr>    <tr>      <td>Model || PSAN</td>      <td>80.0</td>      <td>84.2</td>      <td>91.9</td>      <td>89.9</td>      <td>83.8</td>      <td>89.1</td>    </tr>  </tbody></table>",
        "table_name": "Table 3",
        "table_id": "table_3",
        "paper_id": "D18-1408",
        "page_no": 6,
        "dir": "emnlp2018",
        "valid": 1
    },
    {
        "table_id_paper": "D18-1417table_2",
        "caption": "Results of independent training for intent detection in terms of error rate.",
        "row_header_level": 2,
        "row_headers": [
            [
                "Methods",
                "Recursive NN (Guo et al. 2014)"
            ],
            [
                "Methods",
                "Boosting (Tur et al. 2010)"
            ],
            [
                "Methods",
                "Boosting + Simplified sentences(Tur et al. 2011)"
            ],
            [
                "Methods",
                "Attention Enc-Dec (Liu and Lane 2016a)"
            ],
            [
                "Methods",
                "Our Model"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "Error(%)"
            ]
        ],
        "contents": [
            [
                "4.60"
            ],
            [
                "4.38"
            ],
            [
                "3.02"
            ],
            [
                "2.02"
            ],
            [
                "2.69"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "Error(%)"
        ],
        "target_entity": [
            "Our Model"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Error(%)</th>    </tr>  </thead>  <tbody>    <tr>      <td>Methods || Recursive NN (Guo et al. 2014)</td>      <td>4.60</td>    </tr>    <tr>      <td>Methods || Boosting (Tur et al. 2010)</td>      <td>4.38</td>    </tr>    <tr>      <td>Methods || Boosting + Simplified sentences(Tur et al. 2011)</td>      <td>3.02</td>    </tr>    <tr>      <td>Methods || Attention Enc-Dec (Liu and Lane 2016a)</td>      <td>2.02</td>    </tr>    <tr>      <td>Methods || Our Model</td>      <td>2.69</td>    </tr>  </tbody></table>",
        "table_name": "Table 2",
        "table_id": "table_2",
        "paper_id": "D18-1417",
        "page_no": 7,
        "dir": "emnlp2018",
        "valid": 1
    },
    {
        "table_id_paper": "D18-1417table_3",
        "caption": "Results of joint training for slot filling and intent detection.",
        "row_header_level": 2,
        "row_headers": [
            [
                "Methods",
                "Recursive NN (Guo et al.2014)"
            ],
            [
                "Methods",
                "Recursive NN+Viterbi(Guo et al. 2014)"
            ],
            [
                "Methods",
                "Attention Enc-Dec (Liu and Lane 2016a)"
            ],
            [
                "Methods",
                "Attention BiRNN (Liu and Lane 2016a)"
            ],
            [
                "Methods",
                "Our Model"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "F1"
            ],
            [
                "Error(%)"
            ]
        ],
        "contents": [
            [
                "93.22",
                "4.60"
            ],
            [
                "93.96",
                "4.60"
            ],
            [
                "95.87",
                "1.57"
            ],
            [
                "95.98",
                "1.79"
            ],
            [
                "96.52",
                "1.23"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "F1",
            "Error(%)"
        ],
        "target_entity": [
            "Our Model"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>F1</th>      <th>Error(%)</th>    </tr>  </thead>  <tbody>    <tr>      <td>Methods || Recursive NN (Guo et al.2014)</td>      <td>93.22</td>      <td>4.60</td>    </tr>    <tr>      <td>Methods || Recursive NN+Viterbi(Guo et al. 2014)</td>      <td>93.96</td>      <td>4.60</td>    </tr>    <tr>      <td>Methods || Attention Enc-Dec (Liu and Lane 2016a)</td>      <td>95.87</td>      <td>1.57</td>    </tr>    <tr>      <td>Methods || Attention BiRNN (Liu and Lane 2016a)</td>      <td>95.98</td>      <td>1.79</td>    </tr>    <tr>      <td>Methods || Our Model</td>      <td>96.52</td>      <td>1.23</td>    </tr>  </tbody></table>",
        "table_name": "Table 3",
        "table_id": "table_3",
        "paper_id": "D18-1417",
        "page_no": 7,
        "dir": "emnlp2018",
        "valid": 1
    },
    {
        "table_id_paper": "D18-1421table_3",
        "caption": "Performances on Twitter corpus.",
        "row_header_level": 2,
        "row_headers": [
            [
                "Models",
                "Seq2Seq"
            ],
            [
                "Models",
                "Residual LSTM"
            ],
            [
                "Models",
                "Pointer-generator"
            ],
            [
                "Models",
                "RL-ROUGE"
            ],
            [
                "Models",
                "RbM-SL (ours)"
            ],
            [
                "Models",
                "RbM-IRL (ours)"
            ]
        ],
        "column_header_level": 2,
        "column_headers": [
            [
                "Twitter",
                "ROUGE-1"
            ],
            [
                "Twitter",
                "ROUGE-2"
            ],
            [
                "Twitter",
                "BLEU"
            ],
            [
                "Twitter",
                "METEOR"
            ]
        ],
        "contents": [
            [
                "30.43",
                "14.61",
                "30.54",
                "12.80"
            ],
            [
                "32.50",
                "16.86",
                "33.90",
                "13.65"
            ],
            [
                "38.31",
                "21.22",
                "40.37",
                "17.62"
            ],
            [
                "40.16",
                "22.99",
                "42.73",
                "18.89"
            ],
            [
                "41.87",
                "24.23",
                "44.67",
                "19.97"
            ],
            [
                "42.15",
                "24.73",
                "45.74",
                "20.18"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "ROUGE-1",
            "ROUGE-2",
            "BLEU",
            "METEOR"
        ],
        "target_entity": [
            "RbM-SL (ours)",
            "RbM-IRL (ours)"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Twitter || ROUGE-1</th>      <th>Twitter ||  ROUGE-2</th>      <th>Twitter || BLEU</th>      <th>Twitter || METEOR</th>    </tr>  </thead>  <tbody>    <tr>      <td>Models || Seq2Seq</td>      <td>30.43</td>      <td>14.61</td>      <td>30.54</td>      <td>12.80</td>    </tr>    <tr>      <td>Models || Residual LSTM</td>      <td>32.50</td>      <td>16.86</td>      <td>33.90</td>      <td>13.65</td>    </tr>    <tr>      <td>Models || Pointer-generator</td>      <td>38.31</td>      <td>21.22</td>      <td>40.37</td>      <td>17.62</td>    </tr>    <tr>      <td>Models || RL-ROUGE</td>      <td>40.16</td>      <td>22.99</td>      <td>42.73</td>      <td>18.89</td>    </tr>    <tr>      <td>Models || RbM-SL (ours)</td>      <td>41.87</td>      <td>24.23</td>      <td>44.67</td>      <td>19.97</td>    </tr>    <tr>      <td>Models || RbM-IRL (ours)</td>      <td>42.15</td>      <td>24.73</td>      <td>45.74</td>      <td>20.18</td>    </tr>  </tbody></table>",
        "table_name": "Table 3",
        "table_id": "table_3",
        "paper_id": "D18-1421",
        "page_no": 7,
        "dir": "emnlp2018",
        "valid": 1
    },
    {
        "table_id_paper": "D18-1448table_2",
        "caption": "User satisfaction test results. In total, we use the strategy mentioned in Section 4.2 to evaluate 400 randomly selected source news pages. Overall denotes the average score on these 400 samples.",
        "row_header_level": 2,
        "row_headers": [
            [
                "Format",
                "Text"
            ],
            [
                "Format",
                "Pictorial"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "AnnotatorA"
            ],
            [
                "AnnotatorB"
            ],
            [
                "Overall"
            ]
        ],
        "contents": [
            [
                "3.67",
                "3.75",
                "3.71"
            ],
            [
                "4.14",
                "4.20",
                "4.17"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "satisfaction",
            "satisfaction",
            "satisfaction"
        ],
        "target_entity": [
            "Pictorial"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>AnnotatorA</th>      <th>AnnotatorB</th>      <th>Overall</th>    </tr>  </thead>  <tbody>    <tr>      <td>Format || Text</td>      <td>3.67</td>      <td>3.75</td>      <td>3.71</td>    </tr>    <tr>      <td>Format || Pictorial</td>      <td>4.14</td>      <td>4.20</td>      <td>4.17</td>    </tr>  </tbody></table>",
        "table_name": "Table 2",
        "table_id": "table_2",
        "paper_id": "D18-1448",
        "page_no": 6,
        "dir": "emnlp2018",
        "valid": 1
    },
    {
        "table_id_paper": "D18-1486table_3",
        "caption": "Multi-task results of MCapsNet. In column Avg.\u25b3, we use BiLSTM as baseline and calculate the average improvements over it.",
        "row_header_level": 1,
        "row_headers": [
            [
                "BiLSTM"
            ],
            [
                "MT-GRNN"
            ],
            [
                "MT-RNN"
            ],
            [
                "MT-DNN"
            ],
            [
                "MT-CNN"
            ],
            [
                "CapsNet-1"
            ],
            [
                "CapsNet-2"
            ],
            [
                "MCapsNet"
            ]
        ],
        "column_header_level": 2,
        "column_headers": [
            [
                "Dataset",
                "MR"
            ],
            [
                "Dataset",
                "SST-1"
            ],
            [
                "Dataset",
                "SST-2"
            ],
            [
                "Dataset",
                "Subj"
            ],
            [
                "Dataset",
                "TREC"
            ],
            [
                "Dataset",
                "AG\u2019s"
            ],
            [
                "Dataset",
                "Avg.\u25b3"
            ]
        ],
        "contents": [
            [
                "79.3",
                "46.2",
                "83.2",
                "90.5",
                "89.6",
                "88.2",
                "+0"
            ],
            [
                "-",
                "49.2",
                "87.7",
                "89.3",
                "93.8",
                "-",
                "+2.6"
            ],
            [
                "-",
                "49.6",
                "87.9",
                "94.1",
                "91.8",
                "-",
                "+3.5"
            ],
            [
                "82.1",
                "48.1",
                "87.3",
                "93.9",
                "92.2",
                "91.8",
                "+2.9"
            ],
            [
                "81.6",
                "49.0",
                "86.9",
                "93.6",
                "91.8",
                "91.9",
                "+3.0"
            ],
            [
                "81.5",
                "48.1",
                "86.4",
                "93.3",
                "91.8",
                "91.1",
                "+2.5"
            ],
            [
                "82.4",
                "48.7",
                "87.8",
                "93.6",
                "92.9",
                "92.3",
                "+3.3"
            ],
            [
                "83.5",
                "49.7",
                "88.6",
                "94.5",
                "94.2",
                "93.8",
                "+4.6"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "accuracy",
            "accuracy",
            "accuracy",
            "accuracy",
            "accuracy",
            "accuracy",
            "accuracy"
        ],
        "target_entity": [
            "MCapsNet"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Dataset || MR</th>      <th>Dataset || SST-1</th>      <th>Dataset || SST-2</th>      <th>Dataset || Subj</th>      <th>Dataset || TREC</th>      <th>Dataset || AG\u2019s</th>      <th>Dataset || Avg.\u25b3</th>    </tr>  </thead>  <tbody>    <tr>      <td>BiLSTM</td>      <td>79.3</td>      <td>46.2</td>      <td>83.2</td>      <td>90.5</td>      <td>89.6</td>      <td>88.2</td>      <td>+0</td>    </tr>    <tr>      <td>MT-GRNN</td>      <td>-</td>      <td>49.2</td>      <td>87.7</td>      <td>89.3</td>      <td>93.8</td>      <td>-</td>      <td>+2.6</td>    </tr>    <tr>      <td>MT-RNN</td>      <td>-</td>      <td>49.6</td>      <td>87.9</td>      <td>94.1</td>      <td>91.8</td>      <td>-</td>      <td>+3.5</td>    </tr>    <tr>      <td>MT-DNN</td>      <td>82.1</td>      <td>48.1</td>      <td>87.3</td>      <td>93.9</td>      <td>92.2</td>      <td>91.8</td>      <td>+2.9</td>    </tr>    <tr>      <td>MT-CNN</td>      <td>81.6</td>      <td>49.0</td>      <td>86.9</td>      <td>93.6</td>      <td>91.8</td>      <td>91.9</td>      <td>+3.0</td>    </tr>    <tr>      <td>CapsNet-1</td>      <td>81.5</td>      <td>48.1</td>      <td>86.4</td>      <td>93.3</td>      <td>91.8</td>      <td>91.1</td>      <td>+2.5</td>    </tr>    <tr>      <td>CapsNet-2</td>      <td>82.4</td>      <td>48.7</td>      <td>87.8</td>      <td>93.6</td>      <td>92.9</td>      <td>92.3</td>      <td>+3.3</td>    </tr>    <tr>      <td>MCapsNet</td>      <td>83.5</td>      <td>49.7</td>      <td>88.6</td>      <td>94.5</td>      <td>94.2</td>      <td>93.8</td>      <td>+4.6</td>    </tr>  </tbody></table>",
        "table_name": "Table 3",
        "table_id": "table_3",
        "paper_id": "D18-1486",
        "page_no": 7,
        "dir": "emnlp2018",
        "valid": 1
    },
    {
        "table_id_paper": "D18-1533table_1",
        "caption": "Performance (%CERR). Slash-separated pairs denote FSTs incapable/capable of inserting word boundaries, respectively; see Section 4. The -KN suffix denotes Kneser-Ney smoothing. The data from Section 3.2 is used for evaluating the modern-orthography language model perplexity, and \u201cCorpus\u201d evaluates test-set transliteration performance from the synthetic missionary text back to the original modern text.",
        "row_header_level": 2,
        "row_headers": [
            [
                "Transliteration model",
                "FST-(C/Cwb)-7GRAM-KN"
            ],
            [
                "Transliteration model",
                "FST-(C/Cwb)-9GRAM-KN"
            ],
            [
                "Transliteration model",
                "FST-(C/Cwb)-11GRAM-KN"
            ],
            [
                "Transliteration model",
                "FST-RNNLM-(C/Cwb)"
            ]
        ],
        "column_header_level": 2,
        "column_headers": [
            [
                "LM perplexity",
                "Valid."
            ],
            [
                "LM perplexity",
                "Test"
            ],
            [
                "Transliteration performance (%CERR)",
                "Corpus"
            ],
            [
                "Transliteration performance (%CERR)",
                "Newspaper 1"
            ],
            [
                "Transliteration performance (%CERR)",
                "Newspaper 2"
            ]
        ],
        "contents": [
            [
                "3.07",
                "3.13",
                "27.3%",
                "50.1% / 38.7%",
                "52.0% / 47.5%"
            ],
            [
                "2.95",
                "3.02",
                "26.6%",
                "50.7% / 39.3%",
                "52.5% / 47.2%"
            ],
            [
                "2.94",
                "3.02",
                "27.8%",
                "53.9% / 41.3%",
                "54.1% / 48.7%"
            ],
            [
                "2.65",
                "2.69",
                "16.3%",
                "47.2% / 34.3%",
                "49.8% / 41.2%"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "LM perplexity",
            "LM perplexity",
            "Transliteration performance (%CERR)",
            "Transliteration performance (%CERR)",
            "Transliteration performance (%CERR)"
        ],
        "target_entity": [
            "FST-(C/Cwb)-7GRAM-KN",
            "FST-(C/Cwb)-9GRAM-KN",
            "FST-(C/Cwb)-11GRAM-KN",
            "FST-RNNLM-(C/Cwb)"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>LM perplexity || Valid.</th>      <th>LM perplexity || Test</th>      <th>Transliteration performance (%CERR) || Corpus</th>      <th>Transliteration performance (%CERR) || Newspaper 1</th>      <th>Transliteration performance (%CERR) || Newspaper 2</th>    </tr>  </thead>  <tbody>    <tr>      <td>Transliteration model || FST-(C/Cwb)-7GRAM-KN</td>      <td>3.07</td>      <td>3.13</td>      <td>27.3%</td>      <td>50.1% / 38.7%</td>      <td>52.0% / 47.5%</td>    </tr>    <tr>      <td>Transliteration model || FST-(C/Cwb)-9GRAM-KN</td>      <td>2.95</td>      <td>3.02</td>      <td>26.6%</td>      <td>50.7% / 39.3%</td>      <td>52.5% / 47.2%</td>    </tr>    <tr>      <td>Transliteration model || FST-(C/Cwb)-11GRAM-KN</td>      <td>2.94</td>      <td>3.02</td>      <td>27.8%</td>      <td>53.9% / 41.3%</td>      <td>54.1% / 48.7%</td>    </tr>    <tr>      <td>Transliteration model || FST-RNNLM-(C/Cwb)</td>      <td>2.65</td>      <td>2.69</td>      <td>16.3%</td>      <td>47.2% / 34.3%</td>      <td>49.8% / 41.2%</td>    </tr>  </tbody></table>",
        "table_name": "Table 1",
        "table_id": "table_1",
        "paper_id": "D18-1533",
        "page_no": 5,
        "dir": "emnlp2018",
        "valid": 1
    },
    {
        "table_id_paper": "D19-1037table_4",
        "caption": "Comparison of AUC Results",
        "row_header_level": 2,
        "row_headers": [
            [
                "Model",
                "PCNN+ATT"
            ],
            [
                "Model",
                "PCNN+ONE"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "-"
            ],
            [
                "+SelfAtt"
            ],
            [
                "CCL-CT"
            ]
        ],
        "contents": [
            [
                "0.341",
                "0.368",
                "0.381"
            ],
            [
                "0.325",
                "0.352",
                "0.38"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "accuracy",
            "accuracy",
            "accuracy"
        ],
        "target_entity": [
            "+SelfAtt",
            "CCL-CT"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>-</th>      <th>+SelfAtt</th>      <th>CCL-CT</th>    </tr>  </thead>  <tbody>    <tr>      <td>Model || PCNN+ATT</td>      <td>0.341</td>      <td>0.368</td>      <td>0.381</td>    </tr>    <tr>      <td>Model || PCNN+ONE</td>      <td>0.325</td>      <td>0.352</td>      <td>0.38</td>    </tr>  </tbody></table>",
        "table_name": "Table 4",
        "table_id": "table_4",
        "paper_id": "D19-1037",
        "page_no": 8,
        "dir": "emnlp2019",
        "valid": 1
    },
    {
        "table_id_paper": "D19-1068table_3",
        "caption": "Experimental results in exploring the shared syntactic order event detector.",
        "row_header_level": 2,
        "row_headers": [
            [
                "Model",
                "CL_Trans_MLP"
            ],
            [
                "Model",
                "CL_Trans_CNN"
            ],
            [
                "Model",
                "CL_Trans_Hbrid"
            ],
            [
                "Model",
                "CL_Trans_Self."
            ],
            [
                "Model",
                "CL_Trans_GCN (ours)"
            ],
            [
                "Model",
                "CL_Trans_GCN_Self"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "Pre."
            ],
            [
                "Rec."
            ],
            [
                "F1"
            ]
        ],
        "contents": [
            [
                "20.3",
                "16.3",
                "18.1"
            ],
            [
                "32.5",
                "16.3",
                "21.7"
            ],
            [
                "30.4",
                "17.6",
                "22.3"
            ],
            [
                "34.9",
                "18.3",
                "24"
            ],
            [
                "32",
                "23.4",
                "27"
            ],
            [
                "32.1",
                "23",
                "26.8"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "Pre.",
            "Rec.",
            "F1"
        ],
        "target_entity": [
            "CL_Trans_GCN (ours)"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Pre.</th>      <th>Rec.</th>      <th>F1</th>    </tr>  </thead>  <tbody>    <tr>      <td>Model || CL_Trans_MLP</td>      <td>20.3</td>      <td>16.3</td>      <td>18.1</td>    </tr>    <tr>      <td>Model || CL_Trans_CNN</td>      <td>32.5</td>      <td>16.3</td>      <td>21.7</td>    </tr>    <tr>      <td>Model || CL_Trans_Hbrid</td>      <td>30.4</td>      <td>17.6</td>      <td>22.3</td>    </tr>    <tr>      <td>Model || CL_Trans_Self.</td>      <td>34.9</td>      <td>18.3</td>      <td>24</td>    </tr>    <tr>      <td>Model || CL_Trans_GCN (ours)</td>      <td>32</td>      <td>23.4</td>      <td>27</td>    </tr>    <tr>      <td>Model || CL_Trans_GCN_Self</td>      <td>32.1</td>      <td>23</td>      <td>26.8</td>    </tr>  </tbody></table>",
        "table_name": "Table 3",
        "table_id": "table_3",
        "paper_id": "D19-1068",
        "page_no": 8,
        "dir": "emnlp2019",
        "valid": 1
    },
    {
        "table_id_paper": "D19-1070table_8",
        "caption": "Results for each state change type. Performance on predicting creation and destruction are highest, partially due to the model\u2019s ability to use verb semantics for these tasks.",
        "row_header_level": 2,
        "row_headers": [
            [
                "Model",
                "ETBERT"
            ],
            [
                "Model",
                "ETGPT"
            ]
        ],
        "column_header_level": 2,
        "column_headers": [
            [
                "Cat-1",
                "C"
            ],
            [
                "Cat-2",
                "M"
            ],
            [
                "Cat-3",
                "D"
            ],
            [
                "Cat-2",
                "C"
            ],
            [
                "Cat-3",
                "M"
            ],
            [
                "Cat-4",
                "D"
            ]
        ],
        "contents": [
            [
                "78.51",
                "61.6",
                "71.5",
                "76.68",
                "54.12",
                "58.62"
            ],
            [
                "79.82",
                "56.27",
                "73.83",
                "77.24",
                "50.82",
                "56.27"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "accuracy",
            "accuracy",
            "accuracy",
            "accuracy",
            "accuracy",
            "accuracy"
        ],
        "target_entity": [
            "C",
            "M",
            "D"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Cat-1 || C</th>      <th>Cat-2 || M</th>      <th>Cat-3 || D</th>      <th>Cat-2 || C</th>      <th>Cat-3 || M</th>      <th>Cat-4 || D</th>    </tr>  </thead>  <tbody>    <tr>      <td>Model || ETBERT</td>      <td>78.51</td>      <td>61.6</td>      <td>71.5</td>      <td>76.68</td>      <td>54.12</td>      <td>58.62</td>    </tr>    <tr>      <td>Model || ETGPT</td>      <td>79.82</td>      <td>56.27</td>      <td>73.83</td>      <td>77.24</td>      <td>50.82</td>      <td>56.27</td>    </tr>  </tbody></table>",
        "table_name": "Table 8",
        "table_id": "table_8",
        "paper_id": "D19-1070",
        "page_no": 8,
        "dir": "emnlp2019",
        "valid": 1
    },
    {
        "table_id_paper": "D19-1154table_1",
        "caption": "Comparison of multilingual sentence-image retrieval/matching (German-Image) and (English-Image) results on Multi30K. (Visual encoders:VGG\u2020 otherwise ResNet or Faster-RCNN(ResNet).) (Monolingual models*.)",
        "row_header_level": 2,
        "row_headers": [
            [
                "Method",
                "VSE\u2020* (Kiros et al., 2014)"
            ],
            [
                "Method",
                "OE\u2020* (Vendrov et al., 2015)"
            ],
            [
                "Method",
                "DAN* (Nam et al., 2017)"
            ],
            [
                "Method",
                "VSE++* (Faghri et al., 2018)"
            ],
            [
                "Method",
                "SCAN* (Lee et al., 2018)"
            ],
            [
                "Method",
                "Pivot\u2020 (Gella et al., 2017)"
            ],
            [
                "Method",
                "Ours\u2020 (Random, VGG19)"
            ],
            [
                "Method",
                "Ours (Random, No diversity)"
            ],
            [
                "Method",
                "Ours (Random)"
            ],
            [
                "Method",
                "Ours (w/ FastText)"
            ],
            [
                "Method",
                "Ours (w/ BERT)"
            ]
        ],
        "column_header_level": 2,
        "column_headers": [
            [
                "German to Image",
                "R@1"
            ],
            [
                "German to Image",
                "R@5"
            ],
            [
                "German to Image",
                "R10"
            ],
            [
                "Image to German",
                "R@1"
            ],
            [
                "Image to German",
                "R@5"
            ],
            [
                "Image to German",
                "R10"
            ],
            [
                "English to Image",
                "R@1"
            ],
            [
                "English to Image",
                "R@5"
            ],
            [
                "English to Image",
                "R10"
            ],
            [
                "Image to English",
                "R@1"
            ],
            [
                "Image to English",
                "R@5"
            ],
            [
                "Image to English",
                "R10"
            ]
        ],
        "contents": [
            [
                "20.3",
                "47.2",
                "60.1",
                "29.3",
                "58.1",
                "71.8",
                "23.3",
                "53.6",
                "65.8",
                "31.6",
                "60.4",
                "72.7"
            ],
            [
                "21.0",
                "48.5",
                "60.4",
                "26.8",
                "57.5",
                "70.9",
                "25.8",
                "56.5",
                "67.8",
                "34.8",
                "63.7",
                "74.8"
            ],
            [
                "31.0",
                "60.9",
                "71.0",
                "46.5",
                "77.5",
                "83.0",
                "39.4",
                "69.2",
                "69.1",
                "55.0",
                "81.8",
                "89.0"
            ],
            [
                "31.3",
                "62.2",
                "70.9",
                "47.5",
                "78.5",
                "84.5",
                "39.6",
                "69.1",
                "79.8",
                "53.1",
                "82.1",
                "87.5"
            ],
            [
                "35.7",
                "64.9",
                "74.6",
                "52.3",
                "81.8",
                "88.5",
                "45.8",
                "74.4",
                "83.0",
                "61.8",
                "87.5",
                "93.7"
            ],
            [
                "22.5",
                "49.3",
                "61.7",
                "28.2",
                "61.9",
                "73.4",
                "26.2",
                "56.4",
                "68.4",
                "33.8",
                "62.8",
                "75.2"
            ],
            [
                "25.8",
                "54.9",
                "65.1",
                "34.1",
                "65.5",
                "76.5",
                "30.1",
                "62.5",
                "71.6",
                "36.4",
                "68.0",
                "80.9"
            ],
            [
                "36.3",
                "65.3",
                "74.7",
                "53.1",
                "82.3",
                "88.8",
                "46.2",
                "74.7",
                "82.9",
                "63.3",
                "87.0",
                "93.3"
            ],
            [
                "39.2",
                "67.5",
                "76.7",
                "55.0",
                "84.7",
                "91.2",
                "48.7",
                "77.2",
                "85.0",
                "66.4",
                "88.3",
                "93.4"
            ],
            [
                "40.3",
                "70.1",
                "79.0",
                "60.4",
                "85.4",
                "92.0",
                "50.1",
                "78.1",
                "85.7",
                "68.0",
                "88.8",
                "94.0"
            ],
            [
                "40.7",
                "70.5",
                "78.8",
                "56.5",
                "84.6",
                "91.3",
                "48.9",
                "78.3",
                "85.8",
                "66.5",
                "89.1",
                "94.1"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "R@1",
            "R@5",
            "R10",
            "R@1",
            "R@5",
            "R10",
            "R@1",
            "R@5",
            "R10",
            "R@1",
            "R@5",
            "R10"
        ],
        "target_entity": [
            "Ours (w/ FastText)",
            "Ours (w/ BERT)"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>German to Image || R@1</th>      <th>German to Image || R@5</th>      <th>German to Image || R10</th>      <th>Image to German || R@1</th>      <th>Image to German || R@5</th>      <th>Image to German || R10</th>      <th>English to Image || R@1</th>      <th>English to Image || R@5</th>      <th>English to Image || R10</th>      <th>Image to English || R@1</th>      <th>Image to English || R@5</th>      <th>Image to English || R10</th>    </tr>  </thead>  <tbody>    <tr>      <td>Method || VSE\u2020* (Kiros et al., 2014)</td>      <td>20.3</td>      <td>47.2</td>      <td>60.1</td>      <td>29.3</td>      <td>58.1</td>      <td>71.8</td>      <td>23.3</td>      <td>53.6</td>      <td>65.8</td>      <td>31.6</td>      <td>60.4</td>      <td>72.7</td>    </tr>    <tr>      <td>Method || OE\u2020* (Vendrov et al., 2015)</td>      <td>21.0</td>      <td>48.5</td>      <td>60.4</td>      <td>26.8</td>      <td>57.5</td>      <td>70.9</td>      <td>25.8</td>      <td>56.5</td>      <td>67.8</td>      <td>34.8</td>      <td>63.7</td>      <td>74.8</td>    </tr>    <tr>      <td>Method || DAN* (Nam et al., 2017)</td>      <td>31.0</td>      <td>60.9</td>      <td>71.0</td>      <td>46.5</td>      <td>77.5</td>      <td>83.0</td>      <td>39.4</td>      <td>69.2</td>      <td>69.1</td>      <td>55.0</td>      <td>81.8</td>      <td>89.0</td>    </tr>    <tr>      <td>Method || VSE++* (Faghri et al., 2018)</td>      <td>31.3</td>      <td>62.2</td>      <td>70.9</td>      <td>47.5</td>      <td>78.5</td>      <td>84.5</td>      <td>39.6</td>      <td>69.1</td>      <td>79.8</td>      <td>53.1</td>      <td>82.1</td>      <td>87.5</td>    </tr>    <tr>      <td>Method || SCAN* (Lee et al., 2018)</td>      <td>35.7</td>      <td>64.9</td>      <td>74.6</td>      <td>52.3</td>      <td>81.8</td>      <td>88.5</td>      <td>45.8</td>      <td>74.4</td>      <td>83.0</td>      <td>61.8</td>      <td>87.5</td>      <td>93.7</td>    </tr>    <tr>      <td>Method || Pivot\u2020 (Gella et al., 2017)</td>      <td>22.5</td>      <td>49.3</td>      <td>61.7</td>      <td>28.2</td>      <td>61.9</td>      <td>73.4</td>      <td>26.2</td>      <td>56.4</td>      <td>68.4</td>      <td>33.8</td>      <td>62.8</td>      <td>75.2</td>    </tr>    <tr>      <td>Method || Ours\u2020 (Random, VGG19)</td>      <td>25.8</td>      <td>54.9</td>      <td>65.1</td>      <td>34.1</td>      <td>65.5</td>      <td>76.5</td>      <td>30.1</td>      <td>62.5</td>      <td>71.6</td>      <td>36.4</td>      <td>68.0</td>      <td>80.9</td>    </tr>    <tr>      <td>Method || Ours (Random, No diversity)</td>      <td>36.3</td>      <td>65.3</td>      <td>74.7</td>      <td>53.1</td>      <td>82.3</td>      <td>88.8</td>      <td>46.2</td>      <td>74.7</td>      <td>82.9</td>      <td>63.3</td>      <td>87.0</td>      <td>93.3</td>    </tr>    <tr>      <td>Method || Ours (Random)</td>      <td>39.2</td>      <td>67.5</td>      <td>76.7</td>      <td>55.0</td>      <td>84.7</td>      <td>91.2</td>      <td>48.7</td>      <td>77.2</td>      <td>85.0</td>      <td>66.4</td>      <td>88.3</td>      <td>93.4</td>    </tr>    <tr>      <td>Method || Ours (w/ FastText)</td>      <td>40.3</td>      <td>70.1</td>      <td>79.0</td>      <td>60.4</td>      <td>85.4</td>      <td>92.0</td>      <td>50.1</td>      <td>78.1</td>      <td>85.7</td>      <td>68.0</td>      <td>88.8</td>      <td>94.0</td>    </tr>    <tr>      <td>Method || Ours (w/ BERT)</td>      <td>40.7</td>      <td>70.5</td>      <td>78.8</td>      <td>56.5</td>      <td>84.6</td>      <td>91.3</td>      <td>48.9</td>      <td>78.3</td>      <td>85.8</td>      <td>66.5</td>      <td>89.1</td>      <td>94.1</td>    </tr>  </tbody></table>",
        "table_name": "Table 1",
        "table_id": "table_1",
        "paper_id": "D19-1154",
        "page_no": 4,
        "dir": "emnlp2019",
        "valid": 1
    },
    {
        "table_id_paper": "D19-1166table_8",
        "caption": "Evaluation on auxiliary tasks: Multitask models trained on both the translation and simplification dataset improves the performance for the task of English Simplification.",
        "row_header_level": 3,
        "row_headers": [
            [
                "Task",
                "English Simplification",
                "Simplify"
            ],
            [
                "Task",
                "English Simplification",
                "Translate and Simplify"
            ],
            [
                "Task",
                "English Simplification",
                "All Tasks"
            ],
            [
                "Task",
                "Machine Translation",
                "Translate"
            ],
            [
                "Task",
                "Machine Translation",
                "Translate and Simplify"
            ],
            [
                "Task",
                "Machine Translation",
                "All Tasks"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "BLEU"
            ],
            [
                "SARI"
            ],
            [
                "PCC"
            ]
        ],
        "contents": [
            [
                "55.76",
                "41.7",
                "0.736"
            ],
            [
                "56.47",
                "41.3",
                "0.730"
            ],
            [
                "56.05",
                "42.1",
                "0.736"
            ],
            [
                "29.09",
                "-",
                "0.769"
            ],
            [
                "27.33",
                "-",
                "0.647"
            ],
            [
                "27.63",
                "-",
                "0.658"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "BLEU",
            "SARI",
            "PCC"
        ],
        "target_entity": [
            "Machine Translation"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>BLEU</th>      <th>SARI</th>      <th>PCC</th>    </tr>  </thead>  <tbody>    <tr>      <td>Task || English Simplification || Simplify</td>      <td>55.76</td>      <td>41.7</td>      <td>0.736</td>    </tr>    <tr>      <td>Task || English Simplification || Translate and Simplify</td>      <td>56.47</td>      <td>41.3</td>      <td>0.730</td>    </tr>    <tr>      <td>Task || English Simplification || All Tasks</td>      <td>56.05</td>      <td>42.1</td>      <td>0.736</td>    </tr>    <tr>      <td>Task || Machine Translation || Translate</td>      <td>29.09</td>      <td>-</td>      <td>0.769</td>    </tr>    <tr>      <td>Task || Machine Translation || Translate and Simplify</td>      <td>27.33</td>      <td>-</td>      <td>0.647</td>    </tr>    <tr>      <td>Task || Machine Translation || All Tasks</td>      <td>27.63</td>      <td>-</td>      <td>0.658</td>    </tr>  </tbody></table>",
        "table_name": "Table 8",
        "table_id": "table_8",
        "paper_id": "D19-1166",
        "page_no": 9,
        "dir": "emnlp2019",
        "valid": 1
    },
    {
        "table_id_paper": "D19-1174table_2",
        "caption": "Results with traditional machine learning (Label Powerset)",
        "row_header_level": 2,
        "row_headers": [
            [
                "Classifier",
                "SVM"
            ],
            [
                "Classifier",
                "LR"
            ],
            [
                "Classifier",
                "RF"
            ]
        ],
        "column_header_level": 3,
        "column_headers": [
            [
                "Features",
                "Word n-grams",
                "FI"
            ],
            [
                "Features",
                "Word n-grams",
                "Fmacro"
            ],
            [
                "Features",
                "Word n-grams",
                "AccI"
            ],
            [
                "Features",
                "Word n-grams",
                "Fmicro"
            ],
            [
                "Features",
                "Character n-grams",
                "FI"
            ],
            [
                "Features",
                "Character n-grams",
                "Fmacro"
            ],
            [
                "Features",
                "Character n-grams",
                "AccI"
            ],
            [
                "Features",
                "Character n-grams",
                "Fmicro"
            ],
            [
                "Features",
                "Averaged ELMo vectors",
                "FI"
            ],
            [
                "Features",
                "Averaged ELMo vectors",
                "Fmacro"
            ],
            [
                "Features",
                "Averaged ELMo vectors",
                "AccI"
            ],
            [
                "Features",
                "Averaged ELMo vectors",
                "Fmicro"
            ],
            [
                "Features",
                "Composite features",
                "FI"
            ],
            [
                "Features",
                "Composite features",
                "Fmacro"
            ],
            [
                "Features",
                "Composite features",
                "AccI"
            ],
            [
                "Features",
                "Composite features",
                "Fmicro"
            ]
        ],
        "contents": [
            [
                "0.448",
                "0.373",
                "0.324",
                "0.410",
                "0.449",
                "0.374",
                "0.331",
                "0.416",
                "0.546",
                "0.430",
                "0.431",
                "0.500",
                "0.178",
                "0.094",
                "0.116",
                "0.174"
            ],
            [
                "0.357",
                "0.315",
                "0.236",
                "0.349",
                "0.357",
                "0.311",
                "0.230",
                "0.352",
                "0.595",
                "0.479",
                "0.478",
                "0.549",
                "0.438",
                "0.370",
                "0.311",
                "0.421"
            ],
            [
                "0.531",
                "0.398",
                "0.438",
                "0.476",
                "0.395",
                "0.205",
                "0.325",
                "0.349",
                "0.375",
                "0.164",
                "0.305",
                "0.331",
                "0.460",
                "0.311",
                "0.380",
                "0.415"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "FI",
            "Fmacro",
            "AccI",
            "Fmicro",
            "FI",
            "Fmacro",
            "AccI",
            "Fmicro",
            "FI",
            "Fmacro",
            "AccI",
            "Fmicro",
            "FI",
            "Fmacro",
            "AccI",
            "Fmicro"
        ],
        "target_entity": [
            "Classifier"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Features || Word n-grams || FI</th>      <th>Features || Word n-grams || Fmacro</th>      <th>Features || Word n-grams || AccI</th>      <th>Features || Word n-grams || Fmicro</th>      <th>Features || Character n-grams || FI</th>      <th>Features || Character n-grams || Fmacro</th>      <th>Features || Character n-grams || AccI</th>      <th>Features || Character n-grams || Fmicro</th>      <th>Features || Averaged ELMo vectors || FI</th>      <th>Features || Averaged ELMo vectors || Fmacro</th>      <th>Features || Averaged ELMo vectors || AccI</th>      <th>Features || Averaged ELMo vectors || Fmicro</th>      <th>Features || Composite features || FI</th>      <th>Features || Composite features || Fmacro</th>      <th>Features || Composite features || AccI</th>      <th>Features || Composite features || Fmicro</th>    </tr>  </thead>  <tbody>    <tr>      <td>Classifier || SVM</td>      <td>0.448</td>      <td>0.373</td>      <td>0.324</td>      <td>0.410</td>      <td>0.449</td>      <td>0.374</td>      <td>0.331</td>      <td>0.416</td>      <td>0.546</td>      <td>0.430</td>      <td>0.431</td>      <td>0.500</td>      <td>0.178</td>      <td>0.094</td>      <td>0.116</td>      <td>0.174</td>    </tr>    <tr>      <td>Classifier || LR</td>      <td>0.357</td>      <td>0.315</td>      <td>0.236</td>      <td>0.349</td>      <td>0.357</td>      <td>0.311</td>      <td>0.230</td>      <td>0.352</td>      <td>0.595</td>      <td>0.479</td>      <td>0.478</td>      <td>0.549</td>      <td>0.438</td>      <td>0.370</td>      <td>0.311</td>      <td>0.421</td>    </tr>    <tr>      <td>Classifier || RF</td>      <td>0.531</td>      <td>0.398</td>      <td>0.438</td>      <td>0.476</td>      <td>0.395</td>      <td>0.205</td>      <td>0.325</td>      <td>0.349</td>      <td>0.375</td>      <td>0.164</td>      <td>0.305</td>      <td>0.331</td>      <td>0.460</td>      <td>0.311</td>      <td>0.380</td>      <td>0.415</td>    </tr>  </tbody></table>",
        "table_name": "Table 2",
        "table_id": "table_2",
        "paper_id": "D19-1174",
        "page_no": 8,
        "dir": "emnlp2019",
        "valid": 1
    },
    {
        "table_id_paper": "D19-1177table_3",
        "caption": "Results of performance (AUROC) of up-to-date methods on identifying helpful reviews evaluated by the test sets of Amazon. (italic f onts\u2217: the best performance among the baseline approaches; bold fonts: the state-of-the-art performance of all the approaches)",
        "row_header_level": 2,
        "row_headers": [
            [
                "Category (Amazon)",
                "Clothing, Shoes & Jewelry"
            ],
            [
                "Category (Amazon)",
                "Electronics"
            ],
            [
                "Category (Amazon)",
                "Grocery & Gourmet Food"
            ],
            [
                "Category (Amazon)",
                "Health & Personal Care"
            ],
            [
                "Category (Amazon)",
                "Home & Kitchen"
            ],
            [
                "Category (Amazon)",
                "Movies & TV"
            ],
            [
                "Category (Amazon)",
                "Pet Supplies"
            ],
            [
                "Category (Amazon)",
                "Tools & Home Improvement"
            ],
            [
                "Category (Amazon)",
                "MACRO AVERAGE"
            ],
            [
                "Category (Amazon)",
                "MICRO AVERAGE (Primary)"
            ]
        ],
        "column_header_level": 2,
        "column_headers": [
            [
                "Area under Receiver Operating Characteristic (AUROC)",
                "STR"
            ],
            [
                "Area under Receiver Operating Characteristic (AUROC)",
                "LEX"
            ],
            [
                "Area under Receiver Operating Characteristic (AUROC)",
                "GALC"
            ],
            [
                "Area under Receiver Operating Characteristic (AUROC)",
                "INQUIRER"
            ],
            [
                "Area under Receiver Operating Characteristic (AUROC)",
                "FUSION (SVM)"
            ],
            [
                "Area under Receiver Operating Characteristic (AUROC)",
                "FUSION (R.F.)"
            ],
            [
                "Area under Receiver Operating Characteristic (AUROC)",
                "EG-CNN"
            ],
            [
                "Area under Receiver Operating Characteristic (AUROC)",
                "MTNL"
            ],
            [
                "Area under Receiver Operating Characteristic (AUROC)",
                "R2HP"
            ]
        ],
        "contents": [
            [
                "0.548",
                "0.536",
                "0.562",
                "0.601*",
                "0.579",
                "0.55",
                "0.583",
                "0.589",
                "0.623 (+0.022)"
            ],
            [
                "0.583",
                "0.549",
                "0.588",
                "0.616*",
                "0.577",
                "0.58",
                "0.611",
                "0.613",
                "0.661 (+0.045)"
            ],
            [
                "0.536",
                "0.526",
                "0.553",
                "0.602",
                "0.532",
                "0.546",
                "0.611",
                "0.626*",
                "0.657 (+0.031)"
            ],
            [
                "0.558",
                "0.523",
                "0.559",
                "0.61",
                "0.591",
                "0.562",
                "0.613",
                "0.620*",
                "0.683 (+0.063)"
            ],
            [
                "0.568",
                "0.537",
                "0.565",
                "0.597",
                "0.569",
                "0.573",
                "0.603",
                "0.610*",
                "0.646 (+0.036)"
            ],
            [
                "0.603",
                "0.558",
                "0.621",
                "0.634",
                "0.603",
                "0.607",
                "0.648",
                "0.652*",
                "0.713 (+0.061)"
            ],
            [
                "0.56",
                "0.542",
                "0.585",
                "0.603",
                "0.548",
                "0.558",
                "0.58",
                "0.629*",
                "0.692 (+0.063)"
            ],
            [
                "0.584",
                "0.558",
                "0.58",
                "0.592",
                "0.575",
                "0.586",
                "0.617",
                "0.624*",
                "0.672 (+0.048)"
            ],
            [
                "0.568",
                "0.541",
                "0.577",
                "0.607",
                "0.572",
                "0.57",
                "0.608",
                "0.620*",
                "0.668 (+0.048)"
            ],
            [
                "0.571",
                "0.543",
                "0.58",
                "0.609",
                "0.573",
                "0.574",
                "0.614",
                "0.625*",
                "0.675 (+0.049)"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "Area under Receiver Operating Characteristic (AUROC)",
            "Area under Receiver Operating Characteristic (AUROC)",
            "Area under Receiver Operating Characteristic (AUROC)",
            "Area under Receiver Operating Characteristic (AUROC)",
            "Area under Receiver Operating Characteristic (AUROC)",
            "Area under Receiver Operating Characteristic (AUROC)",
            "Area under Receiver Operating Characteristic (AUROC)",
            "Area under Receiver Operating Characteristic (AUROC)",
            "Area under Receiver Operating Characteristic (AUROC)"
        ],
        "target_entity": [
            "R2HP"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Area under Receiver Operating Characteristic (AUROC) || STR</th>      <th>Area under Receiver Operating Characteristic (AUROC) || LEX</th>      <th>Area under Receiver Operating Characteristic (AUROC) || GALC</th>      <th>Area under Receiver Operating Characteristic (AUROC) || INQUIRER</th>      <th>Area under Receiver Operating Characteristic (AUROC) || FUSION (SVM)</th>      <th>Area under Receiver Operating Characteristic (AUROC) || FUSION (R.F.)</th>      <th>Area under Receiver Operating Characteristic (AUROC) || EG-CNN</th>      <th>Area under Receiver Operating Characteristic (AUROC) || MTNL</th>      <th>Area under Receiver Operating Characteristic (AUROC) || R2HP</th>    </tr>  </thead>  <tbody>    <tr>      <td>Category (Amazon) || Clothing, Shoes &amp; Jewelry</td>      <td>0.548</td>      <td>0.536</td>      <td>0.562</td>      <td>0.601*</td>      <td>0.579</td>      <td>0.55</td>      <td>0.583</td>      <td>0.589</td>      <td>0.623 (+0.022)</td>    </tr>    <tr>      <td>Category (Amazon) || Electronics</td>      <td>0.583</td>      <td>0.549</td>      <td>0.588</td>      <td>0.616*</td>      <td>0.577</td>      <td>0.58</td>      <td>0.611</td>      <td>0.613</td>      <td>0.661 (+0.045)</td>    </tr>    <tr>      <td>Category (Amazon) || Grocery &amp; Gourmet Food</td>      <td>0.536</td>      <td>0.526</td>      <td>0.553</td>      <td>0.602</td>      <td>0.532</td>      <td>0.546</td>      <td>0.611</td>      <td>0.626*</td>      <td>0.657 (+0.031)</td>    </tr>    <tr>      <td>Category (Amazon) || Health &amp; Personal Care</td>      <td>0.558</td>      <td>0.523</td>      <td>0.559</td>      <td>0.61</td>      <td>0.591</td>      <td>0.562</td>      <td>0.613</td>      <td>0.620*</td>      <td>0.683 (+0.063)</td>    </tr>    <tr>      <td>Category (Amazon) || Home &amp; Kitchen</td>      <td>0.568</td>      <td>0.537</td>      <td>0.565</td>      <td>0.597</td>      <td>0.569</td>      <td>0.573</td>      <td>0.603</td>      <td>0.610*</td>      <td>0.646 (+0.036)</td>    </tr>    <tr>      <td>Category (Amazon) || Movies &amp; TV</td>      <td>0.603</td>      <td>0.558</td>      <td>0.621</td>      <td>0.634</td>      <td>0.603</td>      <td>0.607</td>      <td>0.648</td>      <td>0.652*</td>      <td>0.713 (+0.061)</td>    </tr>    <tr>      <td>Category (Amazon) || Pet Supplies</td>      <td>0.56</td>      <td>0.542</td>      <td>0.585</td>      <td>0.603</td>      <td>0.548</td>      <td>0.558</td>      <td>0.58</td>      <td>0.629*</td>      <td>0.692 (+0.063)</td>    </tr>    <tr>      <td>Category (Amazon) || Tools &amp; Home Improvement</td>      <td>0.584</td>      <td>0.558</td>      <td>0.58</td>      <td>0.592</td>      <td>0.575</td>      <td>0.586</td>      <td>0.617</td>      <td>0.624*</td>      <td>0.672 (+0.048)</td>    </tr>    <tr>      <td>Category (Amazon) || MACRO AVERAGE</td>      <td>0.568</td>      <td>0.541</td>      <td>0.577</td>      <td>0.607</td>      <td>0.572</td>      <td>0.57</td>      <td>0.608</td>      <td>0.620*</td>      <td>0.668 (+0.048)</td>    </tr>    <tr>      <td>Category (Amazon) || MICRO AVERAGE (Primary)</td>      <td>0.571</td>      <td>0.543</td>      <td>0.58</td>      <td>0.609</td>      <td>0.573</td>      <td>0.574</td>      <td>0.614</td>      <td>0.625*</td>      <td>0.675 (+0.049)</td>    </tr>  </tbody></table>",
        "table_name": "Table 3",
        "table_id": "table_3",
        "paper_id": "D19-1177",
        "page_no": 8,
        "dir": "emnlp2019",
        "valid": 1
    },
    {
        "table_id_paper": "D19-1184table_3",
        "caption": "Results for next utterance retrieval on the Ubuntu dialog corpus. This table shows previous work, and experimental results with two underlying architectures: a dual encoder model and Deep Attention Matching networks. The results shown in the DAM experiments section are performed with the open-sourced implementation of Zhou et al. (2018), which obtains slightly worse performance than they report. All bold-face results are statistically significant to p < 0.01.",
        "row_header_level": 3,
        "row_headers": [
            [
                "Model Name",
                "Previous Research",
                "Dual Encoder (Lowe et al., 2015)"
            ],
            [
                "Model Name",
                "Previous Research",
                "MV-LSTM (Pang et al., 2016)"
            ],
            [
                "Model Name",
                "Previous Research",
                "Match-LSTM (Wang and Jiang, 2016)"
            ],
            [
                "Model Name",
                "Previous Research",
                "Multiview (Zhou et al., 2016)"
            ],
            [
                "Model Name",
                "Previous Research",
                "DL2R (Yan et al., 2016)"
            ],
            [
                "Model Name",
                "Previous Research",
                "SMN (Wu et al., 2016)"
            ],
            [
                "Model Name",
                "Previous Research",
                "DAM (Zhou et al., 2018)"
            ],
            [
                "Model Name",
                "Dual Encoder Experiments",
                "Dual Encoder (Lowe et al., 2015)"
            ],
            [
                "Model Name",
                "Dual Encoder Experiments",
                "Ensemble (5)"
            ],
            [
                "Model Name",
                "Dual Encoder Experiments",
                "Multi-Granularity (5)"
            ],
            [
                "Model Name",
                "Deep Attention Matching Experiments",
                "DAM (Zhou et al., 2018) (re-trained)"
            ],
            [
                "Model Name",
                "Deep Attention Matching Experiments",
                "Ensemble (5)"
            ],
            [
                "Model Name",
                "Deep Attention Matching Experiments",
                "Multi-Granularity (5)"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "MRR"
            ],
            [
                "R10@1"
            ],
            [
                "R2@1"
            ]
        ],
        "contents": [
            [
                "-",
                "63.8",
                "90.1"
            ],
            [
                "-",
                "65.3",
                "90.6"
            ],
            [
                "",
                "65.3",
                "90.4"
            ],
            [
                "-",
                "66.2",
                "90.8"
            ],
            [
                "-",
                "62.6",
                "89.9"
            ],
            [
                "-",
                "72.6",
                "92.6"
            ],
            [
                "-",
                "76.7",
                "93.8"
            ],
            [
                "76.84",
                "63.6",
                "90.9"
            ],
            [
                "78.91",
                "66.9",
                "91.7"
            ],
            [
                "80.10",
                "68.7",
                "91.9"
            ],
            [
                "83.74",
                "74.54",
                "93.08"
            ],
            [
                "84.03",
                "74.95",
                "93.27"
            ],
            [
                "84.26",
                "75.3",
                "93.45"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "MRR",
            "R10@1",
            "R2@1"
        ],
        "target_entity": [
            "Multi-Granularity (5)"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>MRR</th>      <th>R10@1</th>      <th>R2@1</th>    </tr>  </thead>  <tbody>    <tr>      <td>Model Name || Previous Research || Dual Encoder (Lowe et al., 2015)</td>      <td>-</td>      <td>63.8</td>      <td>90.1</td>    </tr>    <tr>      <td>Model Name || Previous Research || MV-LSTM (Pang et al., 2016)</td>      <td>-</td>      <td>65.3</td>      <td>90.6</td>    </tr>    <tr>      <td>Model Name || Previous Research || Match-LSTM (Wang and Jiang, 2016)</td>      <td></td>      <td>65.3</td>      <td>90.4</td>    </tr>    <tr>      <td>Model Name || Previous Research || Multiview (Zhou et al., 2016)</td>      <td>-</td>      <td>66.2</td>      <td>90.8</td>    </tr>    <tr>      <td>Model Name || Previous Research || DL2R (Yan et al., 2016)</td>      <td>-</td>      <td>62.6</td>      <td>89.9</td>    </tr>    <tr>      <td>Model Name || Previous Research || SMN (Wu et al., 2016)</td>      <td>-</td>      <td>72.6</td>      <td>92.6</td>    </tr>    <tr>      <td>Model Name || Previous Research || DAM (Zhou et al., 2018)</td>      <td>-</td>      <td>76.7</td>      <td>93.8</td>    </tr>    <tr>      <td>Model Name || Dual Encoder Experiments || Dual Encoder (Lowe et al., 2015)</td>      <td>76.84</td>      <td>63.6</td>      <td>90.9</td>    </tr>    <tr>      <td>Model Name || Dual Encoder Experiments || Ensemble (5)</td>      <td>78.91</td>      <td>66.9</td>      <td>91.7</td>    </tr>    <tr>      <td>Model Name || Dual Encoder Experiments || Multi-Granularity (5)</td>      <td>80.10</td>      <td>68.7</td>      <td>91.9</td>    </tr>    <tr>      <td>Model Name || Deep Attention Matching Experiments || DAM (Zhou et al., 2018) (re-trained)</td>      <td>83.74</td>      <td>74.54</td>      <td>93.08</td>    </tr>    <tr>      <td>Model Name || Deep Attention Matching Experiments || Ensemble (5)</td>      <td>84.03</td>      <td>74.95</td>      <td>93.27</td>    </tr>    <tr>      <td>Model Name || Deep Attention Matching Experiments || Multi-Granularity (5)</td>      <td>84.26</td>      <td>75.3</td>      <td>93.45</td>    </tr>  </tbody></table>",
        "table_name": "Table 3",
        "table_id": "table_3",
        "paper_id": "D19-1184",
        "page_no": 7,
        "dir": "emnlp2019",
        "valid": 1
    },
    {
        "table_id_paper": "D19-1315table_6",
        "caption": "Comparison of the decoder information sharing methods and encoder sharing methods for the job advertisement dataset. The metrics are the same as in Table 3. The proposed method (adopting HCL) achieved the best scores (bold) compared to the other sharing methods.",
        "row_header_level": 1,
        "row_headers": [
            [
                "Baseline (Pointer-Generator Network)"
            ],
            [
                "Proposed (MTL + SD + HCL)"
            ],
            [
                "Comparison of Decoder Information Sharing Method MTL + SD"
            ],
            [
                "Comparison of Decoder Information Sharing Method MTL + SD + Cascade Model"
            ],
            [
                "Comparison of Decoder Information Sharing Method MTL + SD + Cascade Model (Gold)"
            ],
            [
                "Comparison of Decoder Information Sharing Method MTL + SD + Soft-Parameter Sharing"
            ],
            [
                "Comparison of Decoder Information Sharing Method MTL + SD + Non-Hierarchical Consistency Loss"
            ],
            [
                "Comparison of Decoder Information Sharing Method MTL + SD + HCL with Normalized Attention Weights"
            ],
            [
                "Comparison of Encoder Information Sharing Method HCL (SD and MTL are not applied)"
            ],
            [
                "Comparison of Encoder Information Sharing Method SD + HCL (MTL is not applied)"
            ]
        ],
        "column_header_level": 2,
        "column_headers": [
            [
                "Headline Generation",
                "R-1"
            ],
            [
                " Headline Generation",
                "R-2"
            ],
            [
                "Headline Generation",
                "R-L"
            ],
            [
                "Key Phrase Generation",
                "R-1"
            ],
            [
                "Key Phrase Generation",
                "R-2"
            ],
            [
                "Key Phrase Generation",
                "R-L"
            ],
            [
                " Classification",
                "Accuracy"
            ]
        ],
        "contents": [
            [
                "25.1",
                "5.3",
                "21.1",
                "30.9",
                "10.6",
                "28.7",
                "62.8"
            ],
            [
                "26.9",
                "6.1",
                "22.4",
                "32.8",
                "11.2",
                "30.5",
                "64.4"
            ],
            [
                "26.3",
                "6",
                "21.8",
                "32.3",
                "10.4",
                "29.9",
                "63.9"
            ],
            [
                "26.3",
                "5.6",
                "21.6",
                "31.8",
                "10.6",
                "29.5",
                "64.4"
            ],
            [
                "26.5",
                "5.8",
                "21.9",
                "32.8",
                "10.4",
                "30.3",
                "64.5"
            ],
            [
                "25.8",
                "5.9",
                "21.4",
                "32.1",
                "10",
                "29.6",
                "64"
            ],
            [
                "25.9",
                "6",
                "21.4",
                "32.6",
                "10.9",
                "30.2",
                "64"
            ],
            [
                "26.2",
                "6",
                "21.7",
                "31.9",
                "10.5",
                "29.5",
                "63.9"
            ],
            [
                "25.8",
                "5.6",
                "21.2",
                "31",
                "10.1",
                "28.7",
                "63.1"
            ],
            [
                "25.6",
                "5.6",
                "21.5",
                "31.2",
                "10.2",
                "28.9",
                "62.6"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "R-1",
            "R-2",
            "R-L",
            "R-1",
            "R-2",
            "R-L",
            "Accuracy"
        ],
        "target_entity": [
            "Proposed (MTL + SD + HCL)"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Headline Generation || R-1</th>      <th>Headline Generation || R-2</th>      <th>Headline Generation || R-L</th>      <th>Key Phrase Generation || R-1</th>      <th>Key Phrase Generation || R-2</th>      <th>Key Phrase Generation || R-L</th>      <th>Classification || Accuracy</th>    </tr>  </thead>  <tbody>    <tr>      <td>Baseline (Pointer-Generator Network)</td>      <td>25.1</td>      <td>5.3</td>      <td>21.1</td>      <td>30.9</td>      <td>10.6</td>      <td>28.7</td>      <td>62.8</td>    </tr>    <tr>      <td>Proposed (MTL + SD + HCL)</td>      <td>26.9</td>      <td>6.1</td>      <td>22.4</td>      <td>32.8</td>      <td>11.2</td>      <td>30.5</td>      <td>64.4</td>    </tr>    <tr>      <td>Comparison of Decoder Information Sharing Method MTL + SD</td>      <td>26.3</td>      <td>6</td>      <td>21.8</td>      <td>32.3</td>      <td>10.4</td>      <td>29.9</td>      <td>63.9</td>    </tr>    <tr>      <td>Comparison of Decoder Information Sharing Method MTL + SD + Cascade Model</td>      <td>26.3</td>      <td>5.6</td>      <td>21.6</td>      <td>31.8</td>      <td>10.6</td>      <td>29.5</td>      <td>64.4</td>    </tr>    <tr>      <td>Comparison of Decoder Information Sharing Method MTL + SD + Cascade Model (Gold)</td>      <td>26.5</td>      <td>5.8</td>      <td>21.9</td>      <td>32.8</td>      <td>10.4</td>      <td>30.3</td>      <td>64.5</td>    </tr>    <tr>      <td>Comparison of Decoder Information Sharing Method MTL + SD + Soft-Parameter Sharing</td>      <td>25.8</td>      <td>5.9</td>      <td>21.4</td>      <td>32.1</td>      <td>10</td>      <td>29.6</td>      <td>64</td>    </tr>    <tr>      <td>Comparison of Decoder Information Sharing Method MTL + SD + Non-Hierarchical Consistency Loss</td>      <td>25.9</td>      <td>6</td>      <td>21.4</td>      <td>32.6</td>      <td>10.9</td>      <td>30.2</td>      <td>64</td>    </tr>    <tr>      <td>Comparison of Decoder Information Sharing Method MTL + SD + HCL with Normalized Attention Weights</td>      <td>26.2</td>      <td>6</td>      <td>21.7</td>      <td>31.9</td>      <td>10.5</td>      <td>29.5</td>      <td>63.9</td>    </tr>    <tr>      <td>Comparison of Encoder Information Sharing Method HCL (SD and MTL are not applied)</td>      <td>25.8</td>      <td>5.6</td>      <td>21.2</td>      <td>31</td>      <td>10.1</td>      <td>28.7</td>      <td>63.1</td>    </tr>    <tr>      <td>Comparison of Encoder Information Sharing Method SD + HCL (MTL is not applied)</td>      <td>25.6</td>      <td>5.6</td>      <td>21.5</td>      <td>31.2</td>      <td>10.2</td>      <td>28.9</td>      <td>62.6</td>    </tr>  </tbody></table>",
        "table_name": "Table 6",
        "table_id": "table_6",
        "paper_id": "D19-1315",
        "page_no": 8,
        "dir": "emnlp2019",
        "valid": 1
    },
    {
        "table_id_paper": "D19-1381table_4",
        "caption": "Nested and overlapping event detection F1 (%) score performance on the CG task 2013 development set.",
        "row_header_level": 2,
        "row_headers": [
            [
                "Model",
                "TEES"
            ],
            [
                "Model",
                "SBNN k = 8"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "Nested"
            ],
            [
                "Overlapping"
            ],
            [
                "Flat"
            ],
            [
                "Overall F1 (%)"
            ]
        ],
        "contents": [
            [
                "42.7",
                "34.49",
                "56.81",
                "52.16"
            ],
            [
                "45.24",
                "36.92",
                "60.5",
                "54.36"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "F1",
            "F1",
            "F1",
            "F1"
        ],
        "target_entity": [
            "SBNN k = 8"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Nested</th>      <th>Overlapping</th>      <th>Flat</th>      <th>Overall F1 (%)</th>    </tr>  </thead>  <tbody>    <tr>      <td>Model || TEES</td>      <td>42.7</td>      <td>34.49</td>      <td>56.81</td>      <td>52.16</td>    </tr>    <tr>      <td>Model || SBNN k = 8</td>      <td>45.24</td>      <td>36.92</td>      <td>60.5</td>      <td>54.36</td>    </tr>  </tbody></table>",
        "table_name": "Table 4",
        "table_id": "table_4",
        "paper_id": "D19-1381",
        "page_no": 5,
        "dir": "emnlp2019",
        "valid": 1
    },
    {
        "table_id_paper": "D19-1399table_4",
        "caption": "Performance comparison on the OntoNotes 5.0 Chinese Dataset.",
        "row_header_level": 3,
        "row_headers": [
            [
                "Model",
                "Model",
                "Pradhan et al. (2013)"
            ],
            [
                "Model",
                "Model",
                "Lattice LSTM (Z&Y, 2018)"
            ],
            [
                "Model",
                "Model",
                "BiLSTM-CRF (L = 0)"
            ],
            [
                "Model",
                "Model",
                "BiLSTM-CRF (L = 1)"
            ],
            [
                "Model",
                "Model",
                "BiLSTM-CRF (L = 2)"
            ],
            [
                "Model",
                "Model",
                "BiLSTM-CRF (L = 3)"
            ],
            [
                "Model",
                "Model",
                "BiLSTM-GCN-CRF"
            ],
            [
                "Model",
                "Model",
                "DGLSTM-CRF (L = 0)"
            ],
            [
                "Model",
                "Model",
                "DGLSTM-CRF (L = 1)"
            ],
            [
                "Model",
                "Model",
                "DGLSTM-CRF (L = 2)"
            ],
            [
                "Model",
                "Model",
                "DGLSTM-CRF (L = 3)"
            ],
            [
                "Model",
                "Contextualized Word Representation",
                "BiLSTM-CRF (L = 0) + ELMo"
            ],
            [
                "Model",
                "Contextualized Word Representation",
                "BiLSTM-CRF (L = 1) + ELMo"
            ],
            [
                "Model",
                "Contextualized Word Representation",
                "BiLSTM-CRF(L = 2) + ELMo"
            ],
            [
                "Model",
                "Contextualized Word Representation",
                "BiLSTM-CRF (L = 3) + ELMo"
            ],
            [
                "Model",
                "Contextualized Word Representation",
                "BiLSTM-GCN-CRF + ELMo"
            ],
            [
                "Model",
                "Contextualized Word Representation",
                "DGLSTM-CRF (L = 0) + ELMo"
            ],
            [
                "Model",
                "Contextualized Word Representation",
                "DGLSTM-CRF (L = 1) + ELMo"
            ],
            [
                "Model",
                "Contextualized Word Representation",
                "DGLSTM-CRF (L = 2) + ELMo"
            ],
            [
                "Model",
                "Contextualized Word Representation",
                "DGLSTM-CRF (L = 3) + ELMo"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "Prec."
            ],
            [
                "Rec."
            ],
            [
                "F1"
            ]
        ],
        "contents": [
            [
                "78.2",
                "66.45",
                "71.85"
            ],
            [
                "76.34",
                "77.01",
                "76.67"
            ],
            [
                "76.67",
                "67.79",
                "71.95"
            ],
            [
                "78.45",
                "74.59",
                "76.47"
            ],
            [
                "77.94",
                "75.33",
                "76.61"
            ],
            [
                "76.17",
                "75.23",
                "75.7"
            ],
            [
                "76.35",
                "75.89",
                "76.12"
            ],
            [
                "76.91",
                "70.65",
                "73.65"
            ],
            [
                "77.79",
                "75.29",
                "76.52"
            ],
            [
                "77.4",
                "77.41",
                "77.4"
            ],
            [
                "77.01",
                "74.9",
                "75.94"
            ],
            [
                "75.2",
                "73.39",
                "74.28"
            ],
            [
                "79.2",
                "79.21",
                "79.2"
            ],
            [
                "78.49",
                "79.44",
                "78.96"
            ],
            [
                "78.54",
                "79.76",
                "79.14"
            ],
            [
                "78.71",
                "79.29",
                "79"
            ],
            [
                "76.27",
                "74.61",
                "75.43"
            ],
            [
                "78.91",
                "80.22",
                "79.56"
            ],
            [
                "78.86",
                "81",
                "79.92"
            ],
            [
                "79.3",
                "79.86",
                "79.58"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "Prec.",
            "Rec.",
            "F1"
        ],
        "target_entity": [
            "BiLSTM-CRF (L = 0)",
            "BiLSTM-CRF (L = 1)",
            "BiLSTM-CRF (L = 2)",
            "BiLSTM-CRF (L = 3)",
            "BiLSTM-CRF (L = 0) + ELMo",
            "BiLSTM-CRF (L = 1) + ELMo",
            "BiLSTM-CRF(L = 2) + ELMo",
            "BiLSTM-CRF (L = 3) + ELMo",
            "DGLSTM-CRF (L = 0)",
            "DGLSTM-CRF (L = 1)",
            "DGLSTM-CRF (L = 2)",
            "DGLSTM-CRF (L = 3)",
            "DGLSTM-CRF (L = 0) + ELMo",
            "DGLSTM-CRF (L = 1) + ELMo",
            "DGLSTM-CRF (L = 2) + ELMo",
            "DGLSTM-CRF (L = 3) + ELMo"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Prec.</th>      <th>Rec.</th>      <th>F1</th>    </tr>  </thead>  <tbody>    <tr>      <td>Model || Model || Pradhan et al. (2013)</td>      <td>78.2</td>      <td>66.45</td>      <td>71.85</td>    </tr>    <tr>      <td>Model || Model || Lattice LSTM (Z&amp;Y, 2018)</td>      <td>76.34</td>      <td>77.01</td>      <td>76.67</td>    </tr>    <tr>      <td>Model || Model || BiLSTM-CRF (L = 0)</td>      <td>76.67</td>      <td>67.79</td>      <td>71.95</td>    </tr>    <tr>      <td>Model || Model || BiLSTM-CRF (L = 1)</td>      <td>78.45</td>      <td>74.59</td>      <td>76.47</td>    </tr>    <tr>      <td>Model || Model || BiLSTM-CRF (L = 2)</td>      <td>77.94</td>      <td>75.33</td>      <td>76.61</td>    </tr>    <tr>      <td>Model || Model || BiLSTM-CRF (L = 3)</td>      <td>76.17</td>      <td>75.23</td>      <td>75.7</td>    </tr>    <tr>      <td>Model || Model || BiLSTM-GCN-CRF</td>      <td>76.35</td>      <td>75.89</td>      <td>76.12</td>    </tr>    <tr>      <td>Model || Model || DGLSTM-CRF (L = 0)</td>      <td>76.91</td>      <td>70.65</td>      <td>73.65</td>    </tr>    <tr>      <td>Model || Model || DGLSTM-CRF (L = 1)</td>      <td>77.79</td>      <td>75.29</td>      <td>76.52</td>    </tr>    <tr>      <td>Model || Model || DGLSTM-CRF (L = 2)</td>      <td>77.4</td>      <td>77.41</td>      <td>77.4</td>    </tr>    <tr>      <td>Model || Model || DGLSTM-CRF (L = 3)</td>      <td>77.01</td>      <td>74.9</td>      <td>75.94</td>    </tr>    <tr>      <td>Model || Contextualized Word Representation || BiLSTM-CRF (L = 0) + ELMo</td>      <td>75.2</td>      <td>73.39</td>      <td>74.28</td>    </tr>    <tr>      <td>Model || Contextualized Word Representation || BiLSTM-CRF (L = 1) + ELMo</td>      <td>79.2</td>      <td>79.21</td>      <td>79.2</td>    </tr>    <tr>      <td>Model || Contextualized Word Representation || BiLSTM-CRF(L = 2) + ELMo</td>      <td>78.49</td>      <td>79.44</td>      <td>78.96</td>    </tr>    <tr>      <td>Model || Contextualized Word Representation || BiLSTM-CRF (L = 3) + ELMo</td>      <td>78.54</td>      <td>79.76</td>      <td>79.14</td>    </tr>    <tr>      <td>Model || Contextualized Word Representation || BiLSTM-GCN-CRF + ELMo</td>      <td>78.71</td>      <td>79.29</td>      <td>79</td>    </tr>    <tr>      <td>Model || Contextualized Word Representation || DGLSTM-CRF (L = 0) + ELMo</td>      <td>76.27</td>      <td>74.61</td>      <td>75.43</td>    </tr>    <tr>      <td>Model || Contextualized Word Representation || DGLSTM-CRF (L = 1) + ELMo</td>      <td>78.91</td>      <td>80.22</td>      <td>79.56</td>    </tr>    <tr>      <td>Model || Contextualized Word Representation || DGLSTM-CRF (L = 2) + ELMo</td>      <td>78.86</td>      <td>81</td>      <td>79.92</td>    </tr>    <tr>      <td>Model || Contextualized Word Representation || DGLSTM-CRF (L = 3) + ELMo</td>      <td>79.3</td>      <td>79.86</td>      <td>79.58</td>    </tr>  </tbody></table>",
        "table_name": "Table 4",
        "table_id": "table_4",
        "paper_id": "D19-1399",
        "page_no": 6,
        "dir": "emnlp2019",
        "valid": 1
    },
    {
        "table_id_paper": "D19-1403table_2",
        "caption": "Comparison of mean accuracy (%) on ARSC",
        "row_header_level": 2,
        "row_headers": [
            [
                "Model",
                "Matching Networks (Vinyals et al., 2016)"
            ],
            [
                "Model",
                "Prototypical Networks (Snell et al., 2017)"
            ],
            [
                "Model",
                "Graph Network (Garcia and Bruna, 2017)"
            ],
            [
                "Model",
                "Relation Network (Sung et al., 2018)"
            ],
            [
                "Model",
                "SNAIL (Mishra et al., 2018)"
            ],
            [
                "Model",
                "ROBUSTTC-FSL (Yu et al., 2018)"
            ],
            [
                "Model",
                "Induction Networks (ours)"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "Mean Acc"
            ]
        ],
        "contents": [
            [
                "65.73"
            ],
            [
                "68.17"
            ],
            [
                "82.61"
            ],
            [
                "83.07"
            ],
            [
                "82.57"
            ],
            [
                "83.12"
            ],
            [
                "85.63"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "Mean Acc"
        ],
        "target_entity": [
            "Induction Networks (ours)"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Mean Acc</th>    </tr>  </thead>  <tbody>    <tr>      <td>Model || Matching Networks (Vinyals et al., 2016)</td>      <td>65.73</td>    </tr>    <tr>      <td>Model || Prototypical Networks (Snell et al., 2017)</td>      <td>68.17</td>    </tr>    <tr>      <td>Model || Graph Network (Garcia and Bruna, 2017)</td>      <td>82.61</td>    </tr>    <tr>      <td>Model || Relation Network (Sung et al., 2018)</td>      <td>83.07</td>    </tr>    <tr>      <td>Model || SNAIL (Mishra et al., 2018)</td>      <td>82.57</td>    </tr>    <tr>      <td>Model || ROBUSTTC-FSL (Yu et al., 2018)</td>      <td>83.12</td>    </tr>    <tr>      <td>Model || Induction Networks (ours)</td>      <td>85.63</td>    </tr>  </tbody></table>",
        "table_name": "Table 2",
        "table_id": "table_2",
        "paper_id": "D19-1403",
        "page_no": 6,
        "dir": "emnlp2019",
        "valid": 1
    },
    {
        "table_id_paper": "D19-1450table_2",
        "caption": "Results of bilingual lexicon induction (accuracy % P@1) for similar and distant language pairs on the dataset BLI-1. Procrustes and MUSE represent the supervised and unsupervised model of Lample et al. (2018), VecMap is the supervised model of Artetxe et al. (2017). Word translations are retrieved by using CSLS. Bold face indicates the best result overall and italics indicate the best result between the two columns without refinement.",
        "row_header_level": 2,
        "row_headers": [
            [
                "Similar language pairs",
                "de-en"
            ],
            [
                "Similar language pairs",
                "en-de"
            ],
            [
                "Similar language pairs",
                "es-en"
            ],
            [
                "Similar language pairs",
                "en-es"
            ],
            [
                "Similar language pairs",
                "fr-en"
            ],
            [
                "Similar language pairs",
                "en-fr"
            ],
            [
                "Similar language pairs",
                "it-en"
            ],
            [
                "Similar language pairs",
                "en-it"
            ],
            [
                "Metric",
                "avg."
            ],
            [
                "Distant language pairs",
                "fi-en"
            ],
            [
                "Distant language pairs",
                "en-fi"
            ],
            [
                "Distant language pairs",
                "ru-en"
            ],
            [
                "Distant language pairs",
                "en-ru"
            ],
            [
                "Distant language pairs",
                "tr-en"
            ],
            [
                "Distant language pairs",
                "en-tr"
            ],
            [
                "Distant language pairs",
                "zh-en"
            ],
            [
                "Distant language pairs",
                "en-zh"
            ],
            [
                "Metric",
                "avg."
            ]
        ],
        "column_header_level": 2,
        "column_headers": [
            [
                "Supervised",
                "VecMap"
            ],
            [
                "Supervised",
                "Procrustes"
            ],
            [
                "Without refinement",
                "MUSE"
            ],
            [
                "Without refinement",
                "MUSEMethod"
            ],
            [
                "With refinement",
                "Our"
            ],
            [
                "With refinement",
                "Method"
            ]
        ],
        "contents": [
            [
                "72.5",
                "72",
                "55.3",
                "66.3",
                "72.2",
                "72.4"
            ],
            [
                "72.5",
                "72.1",
                "59.2",
                "68.2",
                "72.5",
                "73.4"
            ],
            [
                "83.4",
                "82.9",
                "78.1",
                "78",
                "83.1",
                "83.6"
            ],
            [
                "81.9",
                "81.5",
                "75.5",
                "74.9",
                "81.1",
                "80.9"
            ],
            [
                "81.5",
                "82.2",
                "72.2",
                "75.6",
                "81.2",
                "83.3"
            ],
            [
                "81.3",
                "81.3",
                "77.8",
                "78.3",
                "82.2",
                "82.2"
            ],
            [
                "77.7",
                "79.1",
                "61",
                "63.3",
                "76.4",
                "76.2"
            ],
            [
                "77.2",
                "77.5",
                "63.3",
                "64.3",
                "77.4",
                "78.2"
            ],
            [
                "78.5",
                "78.6",
                "67.8",
                "71.1",
                "78.3",
                "78.8"
            ],
            [
                "55.9",
                "56.2",
                "0",
                "42.8",
                "28.6",
                "53.5"
            ],
            [
                "39.5",
                "39.3",
                "0",
                "35.2",
                "21",
                "43"
            ],
            [
                "60.5",
                "61.3",
                "43.8",
                "54.3",
                "49.9",
                "58.9"
            ],
            [
                "48",
                "50.9",
                "28.7",
                "43.2",
                "37.6",
                "51.1"
            ],
            [
                "55.7",
                "58",
                "12.2",
                "42.1",
                "25.5",
                "54.7"
            ],
            [
                "37.3",
                "37.1",
                "26.2",
                "33.1",
                "39.4",
                "41.4"
            ],
            [
                "45",
                "41.2",
                "26.9",
                "32.1",
                "30.8",
                "42"
            ],
            [
                "45.4",
                "52.1",
                "29.4",
                "37.7",
                "33",
                "48"
            ],
            [
                "48.4",
                "49.5",
                "20.9",
                "40.1",
                "33.2",
                "49.1"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "P@1",
            "P@1",
            "P@1",
            "P@1",
            "P@1",
            "P@1"
        ],
        "target_entity": [
            "Without refinement",
            "With refinement"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Supervised || VecMap</th>      <th>Supervised || Procrustes</th>      <th>Without refinement || MUSE</th>      <th>Without refinement || MUSEMethod</th>      <th>With refinement || Our</th>      <th>With refinement || Method</th>    </tr>  </thead>  <tbody>    <tr>      <td>Similar language pairs || de-en</td>      <td>72.5</td>      <td>72</td>      <td>55.3</td>      <td>66.3</td>      <td>72.2</td>      <td>72.4</td>    </tr>    <tr>      <td>Similar language pairs || en-de</td>      <td>72.5</td>      <td>72.1</td>      <td>59.2</td>      <td>68.2</td>      <td>72.5</td>      <td>73.4</td>    </tr>    <tr>      <td>Similar language pairs || es-en</td>      <td>83.4</td>      <td>82.9</td>      <td>78.1</td>      <td>78</td>      <td>83.1</td>      <td>83.6</td>    </tr>    <tr>      <td>Similar language pairs || en-es</td>      <td>81.9</td>      <td>81.5</td>      <td>75.5</td>      <td>74.9</td>      <td>81.1</td>      <td>80.9</td>    </tr>    <tr>      <td>Similar language pairs || fr-en</td>      <td>81.5</td>      <td>82.2</td>      <td>72.2</td>      <td>75.6</td>      <td>81.2</td>      <td>83.3</td>    </tr>    <tr>      <td>Similar language pairs || en-fr</td>      <td>81.3</td>      <td>81.3</td>      <td>77.8</td>      <td>78.3</td>      <td>82.2</td>      <td>82.2</td>    </tr>    <tr>      <td>Similar language pairs || it-en</td>      <td>77.7</td>      <td>79.1</td>      <td>61</td>      <td>63.3</td>      <td>76.4</td>      <td>76.2</td>    </tr>    <tr>      <td>Similar language pairs || en-it</td>      <td>77.2</td>      <td>77.5</td>      <td>63.3</td>      <td>64.3</td>      <td>77.4</td>      <td>78.2</td>    </tr>    <tr>      <td>Metric || avg.</td>      <td>78.5</td>      <td>78.6</td>      <td>67.8</td>      <td>71.1</td>      <td>78.3</td>      <td>78.8</td>    </tr>    <tr>      <td>Distant language pairs || fi-en</td>      <td>55.9</td>      <td>56.2</td>      <td>0</td>      <td>42.8</td>      <td>28.6</td>      <td>53.5</td>    </tr>    <tr>      <td>Distant language pairs || en-fi</td>      <td>39.5</td>      <td>39.3</td>      <td>0</td>      <td>35.2</td>      <td>21</td>      <td>43</td>    </tr>    <tr>      <td>Distant language pairs || ru-en</td>      <td>60.5</td>      <td>61.3</td>      <td>43.8</td>      <td>54.3</td>      <td>49.9</td>      <td>58.9</td>    </tr>    <tr>      <td>Distant language pairs || en-ru</td>      <td>48</td>      <td>50.9</td>      <td>28.7</td>      <td>43.2</td>      <td>37.6</td>      <td>51.1</td>    </tr>    <tr>      <td>Distant language pairs || tr-en</td>      <td>55.7</td>      <td>58</td>      <td>12.2</td>      <td>42.1</td>      <td>25.5</td>      <td>54.7</td>    </tr>    <tr>      <td>Distant language pairs || en-tr</td>      <td>37.3</td>      <td>37.1</td>      <td>26.2</td>      <td>33.1</td>      <td>39.4</td>      <td>41.4</td>    </tr>    <tr>      <td>Distant language pairs || zh-en</td>      <td>45</td>      <td>41.2</td>      <td>26.9</td>      <td>32.1</td>      <td>30.8</td>      <td>42</td>    </tr>    <tr>      <td>Distant language pairs || en-zh</td>      <td>45.4</td>      <td>52.1</td>      <td>29.4</td>      <td>37.7</td>      <td>33</td>      <td>48</td>    </tr>    <tr>      <td>Metric || avg.</td>      <td>48.4</td>      <td>49.5</td>      <td>20.9</td>      <td>40.1</td>      <td>33.2</td>      <td>49.1</td>    </tr>  </tbody></table>",
        "table_name": "Table 2",
        "table_id": "table_2",
        "paper_id": "D19-1450",
        "page_no": 6,
        "dir": "emnlp2019",
        "valid": 1
    },
    {
        "table_id_paper": "D19-1491table_1",
        "caption": "SEQ vs. CAMB system results on CWI",
        "row_header_level": 2,
        "row_headers": [
            [
                "Test Set",
                "NEWS"
            ],
            [
                "Test Set",
                "WIKINEWS"
            ],
            [
                "Test Set",
                "WIKIPEDIA"
            ]
        ],
        "column_header_level": 2,
        "column_headers": [
            [
                "Macro",
                "CAMB"
            ],
            [
                "F-Score",
                "SEQ"
            ]
        ],
        "contents": [
            [
                "0.8633",
                "0.8763"
            ],
            [
                "0.8317",
                "0.854"
            ],
            [
                "0.778",
                "0.814"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "Macro",
            "F-Score"
        ],
        "target_entity": [
            "SEQ"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Macro || CAMB</th>      <th>F-Score || SEQ</th>    </tr>  </thead>  <tbody>    <tr>      <td>Test Set || NEWS</td>      <td>0.8633</td>      <td>0.8763</td>    </tr>    <tr>      <td>Test Set || WIKINEWS</td>      <td>0.8317</td>      <td>0.854</td>    </tr>    <tr>      <td>Test Set || WIKIPEDIA</td>      <td>0.778</td>      <td>0.814</td>    </tr>  </tbody></table>",
        "table_name": "Table 1",
        "table_id": "table_1",
        "paper_id": "D19-1491",
        "page_no": 4,
        "dir": "emnlp2019",
        "valid": 1
    },
    {
        "table_id_paper": "D19-1497table_3",
        "caption": "Performance comparisons of different methods for citation count prediction using two datasets. \u201c\u2191\" ( \u201c\u2193\") indicates that a larger (smaller) value corresponds to a better performance.",
        "row_header_level": 3,
        "row_headers": [
            [
                "Datasets",
                "NIPS",
                "LR"
            ],
            [
                "Datasets",
                "NIPS",
                "KNN"
            ],
            [
                "Datasets",
                "NIPS",
                "SVR"
            ],
            [
                "Datasets",
                "NIPS",
                "GBRT"
            ],
            [
                "Datasets",
                "NIPS",
                "Wide&Deep"
            ],
            [
                "Datasets",
                "NIPS",
                "MILAM"
            ],
            [
                "Datasets",
                "NIPS",
                "Our model"
            ],
            [
                "Datasets",
                "ICLR",
                "LR"
            ],
            [
                "Datasets",
                "ICLR",
                "KNN"
            ],
            [
                "Datasets",
                "ICLR",
                "SVR"
            ],
            [
                "Datasets",
                "ICLR",
                "GBRT"
            ],
            [
                "Datasets",
                "ICLR",
                "Wide&Deep"
            ],
            [
                "Datasets",
                "ICLR",
                "MILAM"
            ],
            [
                "Datasets",
                "ICLR",
                "Our model"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "MAE"
            ],
            [
                "RMSE"
            ],
            [
                "OR(@30)"
            ],
            [
                "OR(@50)"
            ],
            [
                "Spearman Rank"
            ]
        ],
        "contents": [
            [
                "0.1776",
                "0.1903",
                "0.27",
                "0.33",
                "0.4776"
            ],
            [
                "0.1701",
                "0.19",
                "0.33",
                "0.36",
                "0.4848"
            ],
            [
                "0.1677",
                "0.1856",
                "0.33",
                "0.4",
                "0.5279"
            ],
            [
                "0.1863",
                "0.1974",
                "0.23",
                "0.34",
                "0.531"
            ],
            [
                "0.147",
                "0.1848",
                "0.3",
                "0.38",
                "0.5351"
            ],
            [
                "0.1426",
                "0.1792",
                "0.37",
                "0.38",
                "0.5458"
            ],
            [
                "0.1349",
                "0.1726",
                "0.4",
                "0.42",
                "0.5561"
            ],
            [
                "0.2395",
                "0.2723",
                "0.4",
                "0.7",
                "0.1475"
            ],
            [
                "0.2293",
                "0.2674",
                "0.4",
                "0.72",
                "0.1874"
            ],
            [
                "0.2226",
                "0.2578",
                "0.4",
                "0.7",
                "0.1328"
            ],
            [
                "0.2223",
                "0.2607",
                "0.43",
                "0.7",
                "0.1469"
            ],
            [
                "0.2182",
                "0.2607",
                "0.47",
                "0.72",
                "0.244"
            ],
            [
                "0.2093",
                "0.251",
                "0.47",
                "0.72",
                "0.251"
            ],
            [
                "0.1866",
                "0.2279",
                "0.5",
                "0.76",
                "0.3026"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "MAE",
            "RMSE",
            "OR(@30)",
            "OR(@50)",
            "Spearman Rank"
        ],
        "target_entity": [
            "Our model"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>MAE</th>      <th>RMSE</th>      <th>OR(@30)</th>      <th>OR(@50)</th>      <th>Spearman Rank</th>    </tr>  </thead>  <tbody>    <tr>      <td>Datasets || NIPS || LR</td>      <td>0.1776</td>      <td>0.1903</td>      <td>0.27</td>      <td>0.33</td>      <td>0.4776</td>    </tr>    <tr>      <td>Datasets || NIPS || KNN</td>      <td>0.1701</td>      <td>0.19</td>      <td>0.33</td>      <td>0.36</td>      <td>0.4848</td>    </tr>    <tr>      <td>Datasets || NIPS || SVR</td>      <td>0.1677</td>      <td>0.1856</td>      <td>0.33</td>      <td>0.4</td>      <td>0.5279</td>    </tr>    <tr>      <td>Datasets || NIPS || GBRT</td>      <td>0.1863</td>      <td>0.1974</td>      <td>0.23</td>      <td>0.34</td>      <td>0.531</td>    </tr>    <tr>      <td>Datasets || NIPS || Wide&amp;Deep</td>      <td>0.147</td>      <td>0.1848</td>      <td>0.3</td>      <td>0.38</td>      <td>0.5351</td>    </tr>    <tr>      <td>Datasets || NIPS || MILAM</td>      <td>0.1426</td>      <td>0.1792</td>      <td>0.37</td>      <td>0.38</td>      <td>0.5458</td>    </tr>    <tr>      <td>Datasets || NIPS || Our model</td>      <td>0.1349</td>      <td>0.1726</td>      <td>0.4</td>      <td>0.42</td>      <td>0.5561</td>    </tr>    <tr>      <td>Datasets || ICLR || LR</td>      <td>0.2395</td>      <td>0.2723</td>      <td>0.4</td>      <td>0.7</td>      <td>0.1475</td>    </tr>    <tr>      <td>Datasets || ICLR || KNN</td>      <td>0.2293</td>      <td>0.2674</td>      <td>0.4</td>      <td>0.72</td>      <td>0.1874</td>    </tr>    <tr>      <td>Datasets || ICLR || SVR</td>      <td>0.2226</td>      <td>0.2578</td>      <td>0.4</td>      <td>0.7</td>      <td>0.1328</td>    </tr>    <tr>      <td>Datasets || ICLR || GBRT</td>      <td>0.2223</td>      <td>0.2607</td>      <td>0.43</td>      <td>0.7</td>      <td>0.1469</td>    </tr>    <tr>      <td>Datasets || ICLR || Wide&amp;Deep</td>      <td>0.2182</td>      <td>0.2607</td>      <td>0.47</td>      <td>0.72</td>      <td>0.244</td>    </tr>    <tr>      <td>Datasets || ICLR || MILAM</td>      <td>0.2093</td>      <td>0.251</td>      <td>0.47</td>      <td>0.72</td>      <td>0.251</td>    </tr>    <tr>      <td>Datasets || ICLR || Our model</td>      <td>0.1866</td>      <td>0.2279</td>      <td>0.5</td>      <td>0.76</td>      <td>0.3026</td>    </tr>  </tbody></table>",
        "table_name": "Table 3",
        "table_id": "table_3",
        "paper_id": "D19-1497",
        "page_no": 7,
        "dir": "emnlp2019",
        "valid": 1
    },
    {
        "table_id_paper": "D19-1507table_1",
        "caption": "Results of completion generation. We group MPC, character language model baseline, and two subword language models separately. +R implies the retrace algorithm. +M implies reranking with approximate marginalization. QPS stands for query per seconds. The higher the QPS, the better. The best results for each column related to accuracy are shown in bold for each segmentation algorithm (BPE and SR). SR model shows higher unseen PMRR scores (underlined). Our models are faster than the character baseline.",
        "row_header_level": 2,
        "row_headers": [
            [
                "Model",
                "MPC"
            ],
            [
                "Model",
                "Char"
            ],
            [
                "Model",
                "BPE"
            ],
            [
                "Model",
                "BPE+R1"
            ],
            [
                "Model",
                "BPE+R2"
            ],
            [
                "Model",
                "BPE+R\u221e"
            ],
            [
                "Model",
                "SR"
            ],
            [
                "Model",
                "SR+M"
            ],
            [
                "Model",
                "SR+R\u221e"
            ],
            [
                "Model",
                "SR+R\u221e+M"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "MRR Seen"
            ],
            [
                "MRR Unseen"
            ],
            [
                "MRR All"
            ],
            [
                "PMRR Seen"
            ],
            [
                "PMRR Unseen"
            ],
            [
                "PMRR All"
            ],
            [
                "MRL Seen"
            ],
            [
                "MRL Unseen"
            ],
            [
                "MRL All"
            ],
            [
                "Execution Speed (QPS) CPU"
            ],
            [
                "Execution Speed (QPS) GPU"
            ],
            [
                "Decode Length"
            ]
        ],
        "contents": [
            [
                ".570",
                ".000",
                ".290",
                ".616",
                ".095",
                ".360",
                "8.06",
                "0.00",
                "4.10",
                ">100",
                ">100",
                "N/A"
            ],
            [
                ".458",
                ".160",
                ".311",
                ".552",
                ".372",
                ".464",
                "5.77",
                "4.24",
                "5.02",
                "11.0 (1.0x)",
                "16.5 (1.0x)",
                "14.5"
            ],
            [
                ".242",
                ".085",
                ".164",
                ".305",
                ".232",
                ".269",
                "0.49",
                "0.54",
                "0.51",
                "24.2 (2.2x)",
                "37.4 (2.3x)",
                "7.1"
            ],
            [
                ".427",
                ".156",
                ".294",
                ".517",
                ".368",
                ".444",
                "5.28",
                "3.98",
                "4.64",
                "15.8 (1.4x)",
                "27.3 (1.7x)",
                "11.8"
            ],
            [
                ".430",
                ".157",
                ".296",
                ".520",
                ".369",
                ".446",
                "5.44",
                "4.01",
                "4.74",
                "15.5 (1.4x)",
                "27.2 (1.6x)",
                "12.2"
            ],
            [
                ".431",
                ".157",
                ".296",
                ".520",
                ".369",
                ".446",
                "5.50",
                "4.01",
                "4.76",
                "15.3 (1.4x)",
                "26.9 (1.6x)",
                "12.2"
            ],
            [
                ".422",
                ".148",
                ".288",
                ".541",
                ".379",
                ".461",
                "5.11",
                "3.82",
                "4.48",
                "20.8 (1.9x)",
                "40.1 (2.4x)",
                "6.8"
            ],
            [
                ".424",
                ".149",
                ".289",
                ".535",
                ".373",
                ".455",
                "5.14",
                "3.85",
                "4.50",
                "19.6 (1.8x)",
                "40.0 (2.4x)",
                "6.8"
            ],
            [
                ".423",
                ".148",
                ".289",
                ".541",
                ".378",
                ".461",
                "5.14",
                "3.83",
                "4.50",
                "16.3 (1.5x)",
                "29.6 (1.8x)",
                "7.4"
            ],
            [
                ".427",
                ".150",
                ".291",
                ".538",
                ".375",
                ".458",
                "5.19",
                "3.88",
                "4.54",
                "16.2 (1.5x)",
                "28.7 (1.7x)",
                "7.4"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "MRR Seen",
            "MRR Unseen",
            "MRR All",
            "PMRR Seen",
            "PMRR Unseen",
            "PMRR All",
            "MRL Seen",
            "MRL Unseen",
            "MRL All",
            "Execution Speed (QPS) CPU",
            "Execution Speed (QPS) GPU",
            "Decode Length"
        ],
        "target_entity": [
            "BPE",
            "SR",
            "BPE+R1",
            "BPE+R2",
            "BPE+R\u221e",
            "SR+M",
            "SR+R\u221e",
            "SR+R\u221e+M"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>MRR Seen</th>      <th>MRR Unseen</th>      <th>MRR All</th>      <th>PMRR Seen</th>      <th>PMRR Unseen</th>      <th>PMRR All</th>      <th>MRL Seen</th>      <th>MRL Unseen</th>      <th>MRL All</th>      <th>Execution Speed (QPS) CPU</th>      <th>Execution Speed (QPS) GPU</th>      <th>Decode Length</th>    </tr>  </thead>  <tbody>    <tr>      <td>Model || MPC</td>      <td>.570</td>      <td>.000</td>      <td>.290</td>      <td>.616</td>      <td>.095</td>      <td>.360</td>      <td>8.06</td>      <td>0.00</td>      <td>4.10</td>      <td>&gt;100</td>      <td>&gt;100</td>      <td>N/A</td>    </tr>    <tr>      <td>Model || Char</td>      <td>.458</td>      <td>.160</td>      <td>.311</td>      <td>.552</td>      <td>.372</td>      <td>.464</td>      <td>5.77</td>      <td>4.24</td>      <td>5.02</td>      <td>11.0 (1.0x)</td>      <td>16.5 (1.0x)</td>      <td>14.5</td>    </tr>    <tr>      <td>Model || BPE</td>      <td>.242</td>      <td>.085</td>      <td>.164</td>      <td>.305</td>      <td>.232</td>      <td>.269</td>      <td>0.49</td>      <td>0.54</td>      <td>0.51</td>      <td>24.2 (2.2x)</td>      <td>37.4 (2.3x)</td>      <td>7.1</td>    </tr>    <tr>      <td>Model || BPE+R1</td>      <td>.427</td>      <td>.156</td>      <td>.294</td>      <td>.517</td>      <td>.368</td>      <td>.444</td>      <td>5.28</td>      <td>3.98</td>      <td>4.64</td>      <td>15.8 (1.4x)</td>      <td>27.3 (1.7x)</td>      <td>11.8</td>    </tr>    <tr>      <td>Model || BPE+R2</td>      <td>.430</td>      <td>.157</td>      <td>.296</td>      <td>.520</td>      <td>.369</td>      <td>.446</td>      <td>5.44</td>      <td>4.01</td>      <td>4.74</td>      <td>15.5 (1.4x)</td>      <td>27.2 (1.6x)</td>      <td>12.2</td>    </tr>    <tr>      <td>Model || BPE+R\u221e</td>      <td>.431</td>      <td>.157</td>      <td>.296</td>      <td>.520</td>      <td>.369</td>      <td>.446</td>      <td>5.50</td>      <td>4.01</td>      <td>4.76</td>      <td>15.3 (1.4x)</td>      <td>26.9 (1.6x)</td>      <td>12.2</td>    </tr>    <tr>      <td>Model || SR</td>      <td>.422</td>      <td>.148</td>      <td>.288</td>      <td>.541</td>      <td>.379</td>      <td>.461</td>      <td>5.11</td>      <td>3.82</td>      <td>4.48</td>      <td>20.8 (1.9x)</td>      <td>40.1 (2.4x)</td>      <td>6.8</td>    </tr>    <tr>      <td>Model || SR+M</td>      <td>.424</td>      <td>.149</td>      <td>.289</td>      <td>.535</td>      <td>.373</td>      <td>.455</td>      <td>5.14</td>      <td>3.85</td>      <td>4.50</td>      <td>19.6 (1.8x)</td>      <td>40.0 (2.4x)</td>      <td>6.8</td>    </tr>    <tr>      <td>Model || SR+R\u221e</td>      <td>.423</td>      <td>.148</td>      <td>.289</td>      <td>.541</td>      <td>.378</td>      <td>.461</td>      <td>5.14</td>      <td>3.83</td>      <td>4.50</td>      <td>16.3 (1.5x)</td>      <td>29.6 (1.8x)</td>      <td>7.4</td>    </tr>    <tr>      <td>Model || SR+R\u221e+M</td>      <td>.427</td>      <td>.150</td>      <td>.291</td>      <td>.538</td>      <td>.375</td>      <td>.458</td>      <td>5.19</td>      <td>3.88</td>      <td>4.54</td>      <td>16.2 (1.5x)</td>      <td>28.7 (1.7x)</td>      <td>7.4</td>    </tr>  </tbody></table>",
        "table_name": "Table 1",
        "table_id": "table_1",
        "paper_id": "D19-1507",
        "page_no": 6,
        "dir": "emnlp2019",
        "valid": 1
    },
    {
        "table_id_paper": "D19-1512table_4",
        "caption": "Evaluation results on automatic metrics and human judgment. Human evaluation results are calculated by combining labels from the three judges. \u201cKappa\u201d means Fleiss\u2019 kappa. Numbers in bold mean that improvement over the best baseline is statistically significant.",
        "row_header_level": 4,
        "row_headers": [
            [
                "Dataset",
                "Tencent",
                "Models",
                "IR-T"
            ],
            [
                "Dataset",
                "Tencent",
                "Models",
                "IR-TC"
            ],
            [
                "Dataset",
                "Tencent",
                "Models",
                "Seq2seq"
            ],
            [
                "Dataset",
                "Tencent",
                "Models",
                "Att"
            ],
            [
                "Dataset",
                "Tencent",
                "Models",
                "Att-TC"
            ],
            [
                "Dataset",
                "Tencent",
                "Models",
                "GANN"
            ],
            [
                "Dataset",
                "Tencent",
                "Models",
                "DeepCom"
            ],
            [
                "Dataset",
                "Yahoo",
                "Models",
                "IR-T"
            ],
            [
                "Dataset",
                "Yahoo",
                "Models",
                "IR-TC"
            ],
            [
                "Dataset",
                "Yahoo",
                "Models",
                "Seq2seq"
            ],
            [
                "Dataset",
                "Yahoo",
                "Models",
                "Att"
            ],
            [
                "Dataset",
                "Yahoo",
                "Models",
                "Att-TC"
            ],
            [
                "Dataset",
                "Yahoo",
                "Models",
                "GANN"
            ],
            [
                "Dataset",
                "Yahoo",
                "Models",
                "DeepCom"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "METEOR"
            ],
            [
                "W-METEOR"
            ],
            [
                "Rouge_L"
            ],
            [
                "W-Rouge_L"
            ],
            [
                "CIDEr"
            ],
            [
                "W-CIDEr"
            ],
            [
                "BLEU-1"
            ],
            [
                "W-BLEU-1"
            ],
            [
                "Human"
            ],
            [
                "Kappa"
            ]
        ],
        "contents": [
            [
                "0.107",
                "0.086",
                "0.254",
                "0.217",
                "0.018",
                "0.014",
                "0.495",
                "0.470",
                "2.43",
                "0.64"
            ],
            [
                "0.127",
                "0.101",
                "0.266",
                "0.225",
                "0.056",
                "0.044",
                "0.474",
                "0.436",
                "2.57",
                "0.71"
            ],
            [
                "0.064",
                "0.047",
                "0.196",
                "0.150",
                "0.011",
                "0.008",
                "0.374",
                "0.320",
                "1.68",
                "0.83"
            ],
            [
                "0.080",
                "0.058",
                "0.246",
                "0.186",
                "0.010",
                "0.007",
                "0.481",
                "0.453",
                "1.81",
                "0.79"
            ],
            [
                "0.114",
                "0.082",
                "0.299",
                "0.223",
                "0.023",
                "0.017",
                "0.602",
                "0.551",
                "2.26",
                "0.69"
            ],
            [
                "0.097",
                "0.075",
                "0.282",
                "0.222",
                "0.010",
                "0.008",
                "0.312",
                "0.278",
                "2.06",
                "0.73"
            ],
            [
                "0.181",
                "0.138",
                "0.317",
                "0.250",
                "0.029",
                "0.023",
                "0.721",
                "0.656",
                "3.58",
                "0.65"
            ],
            [
                "0.114",
                "-",
                "0.214",
                "-",
                "0.014",
                "-",
                "0.472",
                "-",
                "2.71",
                "0.67"
            ],
            [
                "0.117",
                "-",
                "0.219",
                "-",
                "0.017",
                "-",
                "0.483",
                "-",
                "2.86",
                "0.61"
            ],
            [
                "0.061",
                "-",
                "0.203",
                "-",
                "0.011",
                "-",
                "0.365",
                "-",
                "2.26",
                "0.68"
            ],
            [
                "0.075",
                "-",
                "0.217",
                "-",
                "0.017",
                "-",
                "0.462",
                "-",
                "2.29",
                "0.78"
            ],
            [
                "0.089",
                "-",
                "0.246",
                "-",
                "0.022",
                "-",
                "0.515",
                "-",
                "2.74",
                "0.63"
            ],
            [
                "0.079",
                "-",
                "0.228",
                "-",
                "0.019",
                "-",
                "0.496",
                "-",
                "2.52",
                "0.64"
            ],
            [
                "0.107",
                "-",
                "0.263",
                "-",
                "0.024",
                "-",
                "0.665",
                "-",
                "3.35",
                "0.68"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "METEOR",
            "W-METEOR",
            "Rouge_L",
            "W-Rouge_L",
            "CIDEr",
            "W-CIDEr",
            "BLEU-1",
            "W-BLEU-1",
            "Human",
            "Kappa"
        ],
        "target_entity": [
            "DeepCom"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>METEOR</th>      <th>W-METEOR</th>      <th>Rouge_L</th>      <th>W-Rouge_L</th>      <th>CIDEr</th>      <th>W-CIDEr</th>      <th>BLEU-1</th>      <th>W-BLEU-1</th>      <th>Human</th>      <th>Kappa</th>    </tr>  </thead>  <tbody>    <tr>      <td>Dataset || Tencent || Models || IR-T</td>      <td>0.107</td>      <td>0.086</td>      <td>0.254</td>      <td>0.217</td>      <td>0.018</td>      <td>0.014</td>      <td>0.495</td>      <td>0.470</td>      <td>2.43</td>      <td>0.64</td>    </tr>    <tr>      <td>Dataset || Tencent || Models || IR-TC</td>      <td>0.127</td>      <td>0.101</td>      <td>0.266</td>      <td>0.225</td>      <td>0.056</td>      <td>0.044</td>      <td>0.474</td>      <td>0.436</td>      <td>2.57</td>      <td>0.71</td>    </tr>    <tr>      <td>Dataset || Tencent || Models || Seq2seq</td>      <td>0.064</td>      <td>0.047</td>      <td>0.196</td>      <td>0.150</td>      <td>0.011</td>      <td>0.008</td>      <td>0.374</td>      <td>0.320</td>      <td>1.68</td>      <td>0.83</td>    </tr>    <tr>      <td>Dataset || Tencent || Models || Att</td>      <td>0.080</td>      <td>0.058</td>      <td>0.246</td>      <td>0.186</td>      <td>0.010</td>      <td>0.007</td>      <td>0.481</td>      <td>0.453</td>      <td>1.81</td>      <td>0.79</td>    </tr>    <tr>      <td>Dataset || Tencent || Models || Att-TC</td>      <td>0.114</td>      <td>0.082</td>      <td>0.299</td>      <td>0.223</td>      <td>0.023</td>      <td>0.017</td>      <td>0.602</td>      <td>0.551</td>      <td>2.26</td>      <td>0.69</td>    </tr>    <tr>      <td>Dataset || Tencent || Models || GANN</td>      <td>0.097</td>      <td>0.075</td>      <td>0.282</td>      <td>0.222</td>      <td>0.010</td>      <td>0.008</td>      <td>0.312</td>      <td>0.278</td>      <td>2.06</td>      <td>0.73</td>    </tr>    <tr>      <td>Dataset || Tencent || Models || DeepCom</td>      <td>0.181</td>      <td>0.138</td>      <td>0.317</td>      <td>0.250</td>      <td>0.029</td>      <td>0.023</td>      <td>0.721</td>      <td>0.656</td>      <td>3.58</td>      <td>0.65</td>    </tr>    <tr>      <td>Dataset || Yahoo || Models || IR-T</td>      <td>0.114</td>      <td>-</td>      <td>0.214</td>      <td>-</td>      <td>0.014</td>      <td>-</td>      <td>0.472</td>      <td>-</td>      <td>2.71</td>      <td>0.67</td>    </tr>    <tr>      <td>Dataset || Yahoo || Models || IR-TC</td>      <td>0.117</td>      <td>-</td>      <td>0.219</td>      <td>-</td>      <td>0.017</td>      <td>-</td>      <td>0.483</td>      <td>-</td>      <td>2.86</td>      <td>0.61</td>    </tr>    <tr>      <td>Dataset || Yahoo || Models || Seq2seq</td>      <td>0.061</td>      <td>-</td>      <td>0.203</td>      <td>-</td>      <td>0.011</td>      <td>-</td>      <td>0.365</td>      <td>-</td>      <td>2.26</td>      <td>0.68</td>    </tr>    <tr>      <td>Dataset || Yahoo || Models || Att</td>      <td>0.075</td>      <td>-</td>      <td>0.217</td>      <td>-</td>      <td>0.017</td>      <td>-</td>      <td>0.462</td>      <td>-</td>      <td>2.29</td>      <td>0.78</td>    </tr>    <tr>      <td>Dataset || Yahoo || Models || Att-TC</td>      <td>0.089</td>      <td>-</td>      <td>0.246</td>      <td>-</td>      <td>0.022</td>      <td>-</td>      <td>0.515</td>      <td>-</td>      <td>2.74</td>      <td>0.63</td>    </tr>    <tr>      <td>Dataset || Yahoo || Models || GANN</td>      <td>0.079</td>      <td>-</td>      <td>0.228</td>      <td>-</td>      <td>0.019</td>      <td>-</td>      <td>0.496</td>      <td>-</td>      <td>2.52</td>      <td>0.64</td>    </tr>    <tr>      <td>Dataset || Yahoo || Models || DeepCom</td>      <td>0.107</td>      <td>-</td>      <td>0.263</td>      <td>-</td>      <td>0.024</td>      <td>-</td>      <td>0.665</td>      <td>-</td>      <td>3.35</td>      <td>0.68</td>    </tr>  </tbody></table>",
        "table_name": "Table 4",
        "table_id": "table_4",
        "paper_id": "D19-1512",
        "page_no": 8,
        "dir": "emnlp2019",
        "valid": 1
    },
    {
        "table_id_paper": "D19-1581table_4",
        "caption": "Results for small labeled training data. Given the performance with the full dataset, we show BERT trained only with the AL data.",
        "row_header_level": 4,
        "row_headers": [
            [
                "Training dataset",
                "ACP (6K)",
                "Encoder",
                "BERT"
            ],
            [
                "Training dataset",
                " +AL",
                "Encoder",
                "BERT"
            ],
            [
                "Training dataset",
                "ACP (6K)",
                "Encoder",
                "BiGRU"
            ],
            [
                "Training dataset",
                " +AL+CA+CO",
                "Encoder",
                "BiGRU"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "Acc"
            ]
        ],
        "contents": [
            [
                "0.876"
            ],
            [
                "0.886"
            ],
            [
                "0.83"
            ],
            [
                "0.879"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "Acc"
        ],
        "target_entity": [
            "ACP (6K)"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Acc</th>    </tr>  </thead>  <tbody>    <tr>      <td>Training dataset || ACP (6K) || Encoder || BERT</td>      <td>0.876</td>    </tr>    <tr>      <td>Training dataset ||  +AL || Encoder || BERT</td>      <td>0.886</td>    </tr>    <tr>      <td>Training dataset || ACP (6K) || Encoder || BiGRU</td>      <td>0.83</td>    </tr>    <tr>      <td>Training dataset ||  +AL+CA+CO || Encoder || BiGRU</td>      <td>0.879</td>    </tr>  </tbody></table>",
        "table_name": "Table 4",
        "table_id": "table_4",
        "paper_id": "D19-1581",
        "page_no": 6,
        "dir": "emnlp2019",
        "valid": 1
    },
    {
        "table_id_paper": "D19-1633table_4",
        "caption": "The performance (BLEU) of base CMLM with different amounts of mask-predict iterations (T ) on WMT\u201914 EN-DE, bucketed by target sequence length (N). Decoding with (cid:96) = 1 length candidates.",
        "row_header_level": 1,
        "row_headers": [
            [
                "1 ? N < 10"
            ],
            [
                "10 ? N < 20"
            ],
            [
                "20 ? N < 30"
            ],
            [
                "30 ? N < 40"
            ],
            [
                "40 ? N"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "T = 4"
            ],
            [
                "T = 10"
            ],
            [
                "T = N"
            ]
        ],
        "contents": [
            [
                "21.8",
                "22.4",
                "22.4"
            ],
            [
                "24.6",
                "25.9",
                "26"
            ],
            [
                "24.9",
                "26.7",
                "27.1"
            ],
            [
                "24.9",
                "26.7",
                "27.6"
            ],
            [
                "25",
                "27.5",
                "28.1"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "BLEU",
            "BLEU",
            "BLEU"
        ],
        "target_entity": [
            "T = N"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>T = 4</th>      <th>T = 10</th>      <th>T = N</th>    </tr>  </thead>  <tbody>    <tr>      <td>1 ? N &lt; 10</td>      <td>21.8</td>      <td>22.4</td>      <td>22.4</td>    </tr>    <tr>      <td>10 ? N &lt; 20</td>      <td>24.6</td>      <td>25.9</td>      <td>26</td>    </tr>    <tr>      <td>20 ? N &lt; 30</td>      <td>24.9</td>      <td>26.7</td>      <td>27.1</td>    </tr>    <tr>      <td>30 ? N &lt; 40</td>      <td>24.9</td>      <td>26.7</td>      <td>27.6</td>    </tr>    <tr>      <td>40 ? N</td>      <td>25</td>      <td>27.5</td>      <td>28.1</td>    </tr>  </tbody></table>",
        "table_name": "Table 4",
        "table_id": "table_4",
        "paper_id": "D19-1633",
        "page_no": 7,
        "dir": "emnlp2019",
        "valid": 1
    },
    {
        "table_id_paper": "D19-1674table_2",
        "caption": "Human evaluation results. The values in parentheses are standard deviations.",
        "row_header_level": 2,
        "row_headers": [
            [
                "Method",
                "Proposed"
            ],
            [
                "Method",
                "Baseline"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "Average"
            ],
            [
                "Score"
            ]
        ],
        "contents": [
            [
                "4.11",
                "(0.99)"
            ],
            [
                "2.18",
                "(1.17)"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "Average",
            "Score"
        ],
        "target_entity": [
            "Proposed"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Average</th>      <th>Score</th>    </tr>  </thead>  <tbody>    <tr>      <td>Method || Proposed</td>      <td>4.11</td>      <td>(0.99)</td>    </tr>    <tr>      <td>Method || Baseline</td>      <td>2.18</td>      <td>(1.17)</td>    </tr>  </tbody></table>",
        "table_name": "Table 2",
        "table_id": "table_2",
        "paper_id": "D19-1674",
        "page_no": 4,
        "dir": "emnlp2019",
        "valid": 1
    },
    {
        "table_id_paper": "P16-1165table_9",
        "caption": "Results of CRFs on CON dataset.",
        "row_header_level": 1,
        "row_headers": [
            [
                "MEb"
            ],
            [
                "B-LSTMp"
            ],
            [
                "MEe"
            ],
            [
                "CRF (LC-NO)"
            ],
            [
                "CRF (LC-LC)"
            ],
            [
                "CRF (LC-LC1)"
            ],
            [
                "CRF (LC-FC1)"
            ],
            [
                "CRF (FC-FC)"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "QC3"
            ],
            [
                "TA"
            ]
        ],
        "contents": [
            [
                "56.67",
                "63.29"
            ],
            [
                "65.15",
                "66.93"
            ],
            [
                "59.94",
                "59.55"
            ],
            [
                "62.20",
                "60.30"
            ],
            [
                "62.35",
                "60.30"
            ],
            [
                "65.94",
                "61.58"
            ],
            [
                "61.18",
                "60.00"
            ],
            [
                "64.54",
                "61.64"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "accuracy",
            "accuracy"
        ],
        "target_entity": [
            "CRF (LC-NO)",
            "CRF (LC-LC)",
            "CRF (LC-LC1)",
            "CRF (LC-FC1)",
            "CRF (FC-FC)"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>QC3</th>      <th>TA</th>    </tr>  </thead>  <tbody>    <tr>      <td>MEb</td>      <td>56.67</td>      <td>63.29</td>    </tr>    <tr>      <td>B-LSTMp</td>      <td>65.15</td>      <td>66.93</td>    </tr>    <tr>      <td>MEe</td>      <td>59.94</td>      <td>59.55</td>    </tr>    <tr>      <td>CRF (LC-NO)</td>      <td>62.20</td>      <td>60.30</td>    </tr>    <tr>      <td>CRF (LC-LC)</td>      <td>62.35</td>      <td>60.30</td>    </tr>    <tr>      <td>CRF (LC-LC1)</td>      <td>65.94</td>      <td>61.58</td>    </tr>    <tr>      <td>CRF (LC-FC1)</td>      <td>61.18</td>      <td>60.00</td>    </tr>    <tr>      <td>CRF (FC-FC)</td>      <td>64.54</td>      <td>61.64</td>    </tr>  </tbody></table>",
        "table_name": "Table 9",
        "table_id": "table_9",
        "paper_id": "P16-1165",
        "page_no": 8,
        "dir": "acl2016",
        "valid": 1
    },
    {
        "table_id_paper": "P16-1181table_4",
        "caption": "Parsing results (LAS) on test sets for different sentence boundaries.",
        "row_header_level": 1,
        "row_headers": [
            [
                "GOLD"
            ],
            [
                "MARMOT"
            ],
            [
                "NOSYNTAX"
            ],
            [
                "JOINT"
            ],
            [
                "JOINT-REPARSED"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "WSJ"
            ],
            [
                "Switchboard"
            ],
            [
                "WSJ*"
            ]
        ],
        "contents": [
            [
                "90.22",
                "84.99",
                "88.71"
            ],
            [
                "89.81",
                "78.93",
                "83.37"
            ],
            [
                "89.95",
                "80.30\u2020",
                "83.61"
            ],
            [
                "89.71",
                "79.97\u2020",
                "85.66\u2020\u2021"
            ],
            [
                "89.93",
                "80.61\u2020\u2021\u2217",
                "85.38\u2020\u2021"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "LAS",
            "LAS",
            "LAS"
        ],
        "target_entity": [
            "GOLD",
            "JOINT",
            "JOINT-REPARSED"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>WSJ</th>      <th>Switchboard</th>      <th>WSJ*</th>    </tr>  </thead>  <tbody>    <tr>      <td>GOLD</td>      <td>90.22</td>      <td>84.99</td>      <td>88.71</td>    </tr>    <tr>      <td>MARMOT</td>      <td>89.81</td>      <td>78.93</td>      <td>83.37</td>    </tr>    <tr>      <td>NOSYNTAX</td>      <td>89.95</td>      <td>80.30\u2020</td>      <td>83.61</td>    </tr>    <tr>      <td>JOINT</td>      <td>89.71</td>      <td>79.97\u2020</td>      <td>85.66\u2020\u2021</td>    </tr>    <tr>      <td>JOINT-REPARSED</td>      <td>89.93</td>      <td>80.61\u2020\u2021\u2217</td>      <td>85.38\u2020\u2021</td>    </tr>  </tbody></table>",
        "table_name": "Table 4",
        "table_id": "table_4",
        "paper_id": "P16-1181",
        "page_no": 8,
        "dir": "acl2016",
        "valid": 1
    },
    {
        "table_id_paper": "P16-1189table_4",
        "caption": "Best F1 measures on the Accurat evaluation sets",
        "row_header_level": 4,
        "row_headers": [
            [
                "SYSTEM",
                "LEXACC",
                "TEST SETS",
                "1:1"
            ],
            [
                "SYSTEM",
                "STACC",
                "TEST SETS",
                "1:1"
            ],
            [
                "SYSTEM",
                "LEXACC",
                "TEST SETS",
                "2:1"
            ],
            [
                "SYSTEM",
                "STACC",
                "TEST SETS",
                "2:1"
            ],
            [
                "SYSTEM",
                "LEXACC",
                "TEST SETS",
                "100:1"
            ],
            [
                "SYSTEM",
                "STACC",
                "TEST SETS",
                "100:1"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "EN-DE"
            ],
            [
                "EN-EL"
            ],
            [
                "EN-ET"
            ],
            [
                "EN-LT"
            ],
            [
                "EN-LV"
            ],
            [
                "EN-RO"
            ],
            [
                "EN-SL"
            ]
        ],
        "contents": [
            [
                "96.0",
                "89.5",
                "88.9",
                "93.1",
                "95.0",
                "99.4",
                "88.5"
            ],
            [
                "96.7",
                "88.0",
                "92.0",
                "96.1",
                "96.6",
                "98.8",
                "89.5"
            ],
            [
                "83.4",
                "83.2",
                "73.9",
                "81.2",
                "83.8",
                "95.3",
                "81.6"
            ],
            [
                "89.2",
                "83.2",
                "79.9",
                "86.9",
                "88.2",
                "95.3",
                "82.3"
            ],
            [
                "16.6",
                "22.7",
                "34.2",
                "45.1",
                "45.1",
                "70.4",
                "24.9"
            ],
            [
                "33.7",
                "37.3",
                "42.5",
                "56.0",
                "56.2",
                "75.7",
                "35.3"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "F1",
            "F1",
            "F1",
            "F1",
            "F1",
            "F1",
            "F1"
        ],
        "target_entity": [
            "LEXACC",
            "STACC"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>EN-DE</th>      <th>EN-EL</th>      <th>EN-ET</th>      <th>EN-LT</th>      <th>EN-LV</th>      <th>EN-RO</th>      <th>EN-SL</th>    </tr>  </thead>  <tbody>    <tr>      <td>SYSTEM || LEXACC || TEST SETS || 1:1</td>      <td>96.0</td>      <td>89.5</td>      <td>88.9</td>      <td>93.1</td>      <td>95.0</td>      <td>99.4</td>      <td>88.5</td>    </tr>    <tr>      <td>SYSTEM || STACC || TEST SETS || 1:1</td>      <td>96.7</td>      <td>88.0</td>      <td>92.0</td>      <td>96.1</td>      <td>96.6</td>      <td>98.8</td>      <td>89.5</td>    </tr>    <tr>      <td>SYSTEM || LEXACC || TEST SETS || 2:1</td>      <td>83.4</td>      <td>83.2</td>      <td>73.9</td>      <td>81.2</td>      <td>83.8</td>      <td>95.3</td>      <td>81.6</td>    </tr>    <tr>      <td>SYSTEM || STACC || TEST SETS || 2:1</td>      <td>89.2</td>      <td>83.2</td>      <td>79.9</td>      <td>86.9</td>      <td>88.2</td>      <td>95.3</td>      <td>82.3</td>    </tr>    <tr>      <td>SYSTEM || LEXACC || TEST SETS || 100:1</td>      <td>16.6</td>      <td>22.7</td>      <td>34.2</td>      <td>45.1</td>      <td>45.1</td>      <td>70.4</td>      <td>24.9</td>    </tr>    <tr>      <td>SYSTEM || STACC || TEST SETS || 100:1</td>      <td>33.7</td>      <td>37.3</td>      <td>42.5</td>      <td>56.0</td>      <td>56.2</td>      <td>75.7</td>      <td>35.3</td>    </tr>  </tbody></table>",
        "table_name": "Table 4",
        "table_id": "table_4",
        "paper_id": "P16-1189",
        "page_no": 7,
        "dir": "acl2016",
        "valid": 1
    },
    {
        "table_id_paper": "P16-1201table_4",
        "caption": "Performance of the basic ED model. ANN uses pre-trained word embeddings while ANNRandom uses randomly initialized embeddings.",
        "row_header_level": 2,
        "row_headers": [
            [
                "Methods",
                "Nguyen\u2019s CNN (2015)"
            ],
            [
                "Methods",
                "Chen\u2019s DMCNN (2015)"
            ],
            [
                "Methods",
                "Liu\u2019s Approach (2016)"
            ],
            [
                "Methods",
                "ANN (ours)"
            ],
            [
                "Methods",
                "ANN-Random (ours)"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "Pre"
            ],
            [
                "Rec"
            ],
            [
                "F1"
            ]
        ],
        "contents": [
            [
                "71.8",
                "66.4",
                "69.0"
            ],
            [
                "75.6",
                "63.6",
                "69.1"
            ],
            [
                "75.3",
                "64.4",
                "69.4"
            ],
            [
                "79.5",
                "60.7",
                "68.8"
            ],
            [
                "81.0",
                "49.5",
                "61.5"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "Pre",
            "Rec",
            "F1"
        ],
        "target_entity": [
            "ANN (ours)",
            "ANN-Random (ours)"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Pre</th>      <th>Rec</th>      <th>F1</th>    </tr>  </thead>  <tbody>    <tr>      <td>Methods || Nguyen\u2019s CNN (2015)</td>      <td>71.8</td>      <td>66.4</td>      <td>69.0</td>    </tr>    <tr>      <td>Methods || Chen\u2019s DMCNN (2015)</td>      <td>75.6</td>      <td>63.6</td>      <td>69.1</td>    </tr>    <tr>      <td>Methods || Liu\u2019s Approach (2016)</td>      <td>75.3</td>      <td>64.4</td>      <td>69.4</td>    </tr>    <tr>      <td>Methods || ANN (ours)</td>      <td>79.5</td>      <td>60.7</td>      <td>68.8</td>    </tr>    <tr>      <td>Methods || ANN-Random (ours)</td>      <td>81.0</td>      <td>49.5</td>      <td>61.5</td>    </tr>  </tbody></table>",
        "table_name": "Table 4",
        "table_id": "table_4",
        "paper_id": "P16-1201",
        "page_no": 6,
        "dir": "acl2016",
        "valid": 1
    },
    {
        "table_id_paper": "P16-1201table_5",
        "caption": "Results of manual evaluations.",
        "row_header_level": 3,
        "row_headers": [
            [
                "Baselines",
                "Methods",
                "ANN"
            ],
            [
                "Baselines",
                "Methods",
                "SF"
            ],
            [
                "Baselines",
                "Methods",
                "RF"
            ],
            [
                "Baselines",
                "Methods",
                "SL"
            ],
            [
                "-",
                "Methods",
                "PSL-based Approach"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "Precision (%)"
            ]
        ],
        "contents": [
            [
                "77.5"
            ],
            [
                "72.0"
            ],
            [
                "71.0"
            ],
            [
                "79.5"
            ],
            [
                "81.0"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "Precision (%)"
        ],
        "target_entity": [
            "PSL-based Approach"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Precision (%)</th>    </tr>  </thead>  <tbody>    <tr>      <td>Baselines || Methods || ANN</td>      <td>77.5</td>    </tr>    <tr>      <td>Baselines || Methods || SF</td>      <td>72.0</td>    </tr>    <tr>      <td>Baselines || Methods || RF</td>      <td>71.0</td>    </tr>    <tr>      <td>Baselines || Methods || SL</td>      <td>79.5</td>    </tr>    <tr>      <td>- || Methods || PSL-based Approach</td>      <td>81.0</td>    </tr>  </tbody></table>",
        "table_name": "Table 5",
        "table_id": "table_5",
        "paper_id": "P16-1201",
        "page_no": 7,
        "dir": "acl2016",
        "valid": 1
    },
    {
        "table_id_paper": "P16-2011table_2",
        "caption": "Comparison of different methods on English event detection.",
        "row_header_level": 2,
        "row_headers": [
            [
                "Model",
                "MaxEnt"
            ],
            [
                "Model",
                "Cross-Event"
            ],
            [
                "Model",
                "Cross-Entity"
            ],
            [
                "Model",
                "Joint Model"
            ],
            [
                "Model",
                "PR"
            ],
            [
                "Model",
                "CNN"
            ],
            [
                "Model",
                "RNN"
            ],
            [
                "Model",
                "LSTM"
            ],
            [
                "Model",
                "Bi-LSTM"
            ],
            [
                "Model",
                "HNN"
            ]
        ],
        "column_header_level": 2,
        "column_headers": [
            [
                "Trigger Identification",
                "P"
            ],
            [
                "Trigger Identification",
                "R"
            ],
            [
                "Trigger Identification",
                "F"
            ],
            [
                "Trigger Classification",
                "P"
            ],
            [
                "Trigger Classification",
                "R"
            ],
            [
                "Trigger Classification",
                "F"
            ]
        ],
        "contents": [
            [
                "76.2",
                "60.5",
                "67.4",
                "74.5",
                "59.1",
                "65.9"
            ],
            [
                "N/A",
                "N/A",
                "N/A",
                "68.7",
                "68.9",
                "68.8"
            ],
            [
                "N/A",
                "N/A",
                "N/A",
                "72.9",
                "64.3",
                "68.3"
            ],
            [
                "76.9",
                "65.0",
                "70.4",
                "73.7",
                "62.3",
                "67.5"
            ],
            [
                "N/A",
                "N/A",
                "N/A",
                "68.9",
                "72.0",
                "70.4"
            ],
            [
                "80.4",
                "67.7",
                "73.5",
                "75.6",
                "63.6",
                "69.1"
            ],
            [
                "73.2",
                "63.5",
                "67.4",
                "67.3",
                "59.9",
                "64.2"
            ],
            [
                "78.6",
                "67.4",
                "72.6",
                "74.5",
                "60.7",
                "66.9"
            ],
            [
                "80.1",
                "69.4",
                "74.3",
                "81.6",
                "62.3",
                "70.6"
            ],
            [
                "80.8",
                "71.5",
                "75.9",
                "84.6",
                "64.9",
                "73.4"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "P",
            "R",
            "F",
            "P",
            "R",
            "F"
        ],
        "target_entity": [
            "HNN"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Trigger Identification || P</th>      <th>Trigger Identification || R</th>      <th>Trigger Identification || F</th>      <th>Trigger Classification || P</th>      <th>Trigger Classification || R</th>      <th>Trigger Classification || F</th>    </tr>  </thead>  <tbody>    <tr>      <td>Model || MaxEnt</td>      <td>76.2</td>      <td>60.5</td>      <td>67.4</td>      <td>74.5</td>      <td>59.1</td>      <td>65.9</td>    </tr>    <tr>      <td>Model || Cross-Event</td>      <td>N/A</td>      <td>N/A</td>      <td>N/A</td>      <td>68.7</td>      <td>68.9</td>      <td>68.8</td>    </tr>    <tr>      <td>Model || Cross-Entity</td>      <td>N/A</td>      <td>N/A</td>      <td>N/A</td>      <td>72.9</td>      <td>64.3</td>      <td>68.3</td>    </tr>    <tr>      <td>Model || Joint Model</td>      <td>76.9</td>      <td>65.0</td>      <td>70.4</td>      <td>73.7</td>      <td>62.3</td>      <td>67.5</td>    </tr>    <tr>      <td>Model || PR</td>      <td>N/A</td>      <td>N/A</td>      <td>N/A</td>      <td>68.9</td>      <td>72.0</td>      <td>70.4</td>    </tr>    <tr>      <td>Model || CNN</td>      <td>80.4</td>      <td>67.7</td>      <td>73.5</td>      <td>75.6</td>      <td>63.6</td>      <td>69.1</td>    </tr>    <tr>      <td>Model || RNN</td>      <td>73.2</td>      <td>63.5</td>      <td>67.4</td>      <td>67.3</td>      <td>59.9</td>      <td>64.2</td>    </tr>    <tr>      <td>Model || LSTM</td>      <td>78.6</td>      <td>67.4</td>      <td>72.6</td>      <td>74.5</td>      <td>60.7</td>      <td>66.9</td>    </tr>    <tr>      <td>Model || Bi-LSTM</td>      <td>80.1</td>      <td>69.4</td>      <td>74.3</td>      <td>81.6</td>      <td>62.3</td>      <td>70.6</td>    </tr>    <tr>      <td>Model || HNN</td>      <td>80.8</td>      <td>71.5</td>      <td>75.9</td>      <td>84.6</td>      <td>64.9</td>      <td>73.4</td>    </tr>  </tbody></table>",
        "table_name": "Table 2",
        "table_id": "table_2",
        "paper_id": "P16-2011",
        "page_no": 4,
        "dir": "acl2016",
        "valid": 1
    },
    {
        "table_id_paper": "P16-2011table_4",
        "caption": "Results on Spanish event detection.",
        "row_header_level": 2,
        "row_headers": [
            [
                "Model",
                "LSTM"
            ],
            [
                "Model",
                "Bi-LSTM"
            ],
            [
                "Model",
                "HNN"
            ]
        ],
        "column_header_level": 2,
        "column_headers": [
            [
                "Trigger Identification",
                "P"
            ],
            [
                "Trigger Identification",
                "R"
            ],
            [
                "Trigger Identification",
                "F"
            ],
            [
                "Trigger Classification",
                "P"
            ],
            [
                "Trigger Classification",
                "R"
            ],
            [
                "Trigger Classification",
                "F"
            ]
        ],
        "contents": [
            [
                "62.2",
                "52.9",
                "57.2",
                "56.9",
                "32.6",
                "41.6"
            ],
            [
                "76.2",
                "63.1",
                "68.7",
                "61.5",
                "42.2",
                "50.1"
            ],
            [
                "81.4",
                "65.2",
                "71.6",
                "66.3",
                "47.8",
                "55.5"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "P",
            "R",
            "F",
            "P",
            "R",
            "F"
        ],
        "target_entity": [
            "HNN"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Trigger Identification || P</th>      <th>Trigger Identification || R</th>      <th>Trigger Identification || F</th>      <th>Trigger Classification || P</th>      <th>Trigger Classification || R</th>      <th>Trigger Classification || F</th>    </tr>  </thead>  <tbody>    <tr>      <td>Model || LSTM</td>      <td>62.2</td>      <td>52.9</td>      <td>57.2</td>      <td>56.9</td>      <td>32.6</td>      <td>41.6</td>    </tr>    <tr>      <td>Model || Bi-LSTM</td>      <td>76.2</td>      <td>63.1</td>      <td>68.7</td>      <td>61.5</td>      <td>42.2</td>      <td>50.1</td>    </tr>    <tr>      <td>Model || HNN</td>      <td>81.4</td>      <td>65.2</td>      <td>71.6</td>      <td>66.3</td>      <td>47.8</td>      <td>55.5</td>    </tr>  </tbody></table>",
        "table_name": "Table 4",
        "table_id": "table_4",
        "paper_id": "P16-2011",
        "page_no": 5,
        "dir": "acl2016",
        "valid": 1
    },
    {
        "table_id_paper": "P17-1034table_5",
        "caption": "SVM classification results across linguistic features (LF, bigrams here (Mukherjee et al., 2013b)), behavioral features (BF: RL, RD, MCS (Mukherjee et al., 2013b)); the SVM classification results by the intuitive method that finding the most similar existing review by edit distance ratio and take the found reviewers\u2019 behavioral features as approximation (BF EditSim+LF), and results by the intuitive method that finding the most similar existing review by averaged pre-trained word embeddings (using Word2Vec) (BF W2Vsim+W2V); and the SVM classification results across the learnt review embeddings (RE), the learnt review\u2019s rating embeddings (RRE), the learnt product\u2019s average rating embeddings (PRE) by our model. Improvements of our model are statistically significant with p<0.005 based on paired t-test.",
        "row_header_level": 2,
        "row_headers": [
            [
                "Features",
                "LF"
            ],
            [
                "Features",
                "LF+BF"
            ],
            [
                "Features",
                "BF EditSim+LF"
            ],
            [
                "Features",
                "BF W2Vsim+W2V"
            ],
            [
                "Features",
                "Ours RE"
            ],
            [
                "Features",
                "Ours RE+RRE+PRE"
            ]
        ],
        "column_header_level": 2,
        "column_headers": [
            [
                "P",
                "Hotel"
            ],
            [
                "P",
                "Restaurant"
            ],
            [
                "R",
                "Hotel"
            ],
            [
                "R",
                "Restaurant"
            ],
            [
                "F1",
                "Hotel"
            ],
            [
                "F1",
                "Restaurant"
            ],
            [
                "A",
                "Hotel"
            ],
            [
                "A",
                "Restaurant"
            ]
        ],
        "contents": [
            [
                "54.5",
                "53.8",
                "71.1",
                "80.8",
                "61.7",
                "64.6",
                "55.9",
                "55.8"
            ],
            [
                "63.4",
                "58.1",
                "52.6",
                "61.2",
                "57.5",
                "59.6",
                "61.1",
                "58.5"
            ],
            [
                "55.3",
                "53.9",
                "69.7",
                "82.82",
                "61.6",
                "65.1",
                "56.6",
                "56.0"
            ],
            [
                "58.4",
                "56.3",
                "65.9",
                "73.4",
                "61.9",
                "63.7",
                "59.5",
                "58.2"
            ],
            [
                "62.1",
                "58.4",
                "68.3",
                "75.1",
                "65.1",
                "65.7",
                "63.3",
                "60.8"
            ],
            [
                "63.6",
                "59.0",
                "71.2",
                "78.8",
                "67.2",
                "67.5",
                "65.3",
                "62.0"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "P",
            "P",
            "R",
            "R",
            "F1",
            "F1",
            "A",
            "A"
        ],
        "target_entity": [
            "Ours RE",
            "Ours RE+RRE+PRE"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>P || Hotel</th>      <th>P || Restaurant</th>      <th>R || Hotel</th>      <th>R || Restaurant</th>      <th>F1 || Hotel</th>      <th>F1 || Restaurant</th>      <th>A || Hotel</th>      <th>A || Restaurant</th>    </tr>  </thead>  <tbody>    <tr>      <td>Features || LF</td>      <td>54.5</td>      <td>53.8</td>      <td>71.1</td>      <td>80.8</td>      <td>61.7</td>      <td>64.6</td>      <td>55.9</td>      <td>55.8</td>    </tr>    <tr>      <td>Features || LF+BF</td>      <td>63.4</td>      <td>58.1</td>      <td>52.6</td>      <td>61.2</td>      <td>57.5</td>      <td>59.6</td>      <td>61.1</td>      <td>58.5</td>    </tr>    <tr>      <td>Features || BF EditSim+LF</td>      <td>55.3</td>      <td>53.9</td>      <td>69.7</td>      <td>82.82</td>      <td>61.6</td>      <td>65.1</td>      <td>56.6</td>      <td>56.0</td>    </tr>    <tr>      <td>Features || BF W2Vsim+W2V</td>      <td>58.4</td>      <td>56.3</td>      <td>65.9</td>      <td>73.4</td>      <td>61.9</td>      <td>63.7</td>      <td>59.5</td>      <td>58.2</td>    </tr>    <tr>      <td>Features || Ours RE</td>      <td>62.1</td>      <td>58.4</td>      <td>68.3</td>      <td>75.1</td>      <td>65.1</td>      <td>65.7</td>      <td>63.3</td>      <td>60.8</td>    </tr>    <tr>      <td>Features || Ours RE+RRE+PRE</td>      <td>63.6</td>      <td>59.0</td>      <td>71.2</td>      <td>78.8</td>      <td>67.2</td>      <td>67.5</td>      <td>65.3</td>      <td>62.0</td>    </tr>  </tbody></table>",
        "table_name": "Table 5",
        "table_id": "table_5",
        "paper_id": "P17-1034",
        "page_no": 7,
        "dir": "acl2017",
        "valid": 1
    },
    {
        "table_id_paper": "P17-1054table_2",
        "caption": "The performance of predicting present keyphrases of various models on five benchmark datasets",
        "row_header_level": 2,
        "row_headers": [
            [
                "Method",
                "Tf-Idf"
            ],
            [
                "Method",
                "TextRank"
            ],
            [
                "Method",
                "SingleRank"
            ],
            [
                "Method",
                "ExpandRank"
            ],
            [
                "Method",
                "Maui"
            ],
            [
                "Method",
                "KEA"
            ],
            [
                "Method",
                "RNN"
            ],
            [
                "Method",
                "CopyRNN"
            ]
        ],
        "column_header_level": 2,
        "column_headers": [
            [
                "Inspec",
                "F1@5"
            ],
            [
                "Inspec",
                "F1@10"
            ],
            [
                "Krapivin",
                "F1@5"
            ],
            [
                "Krapivin",
                "F1@10"
            ],
            [
                "NUS",
                "F1@5"
            ],
            [
                "NUS",
                "F1@10"
            ],
            [
                "SemEval",
                "F1@5"
            ],
            [
                "SemEval",
                "F1@10"
            ],
            [
                "KP20k",
                "F1@5"
            ],
            [
                "KP20k",
                "F1@10"
            ]
        ],
        "contents": [
            [
                "0.221",
                "0.313",
                "0.129",
                "0.160",
                "0.136",
                "0.184",
                "0.128",
                "0.194",
                "0.102",
                "0.126"
            ],
            [
                "0.223",
                "0.281",
                "0.189",
                "0.162",
                "0.195",
                "0.196",
                "0.176",
                "0.187",
                "0.175",
                "0.147"
            ],
            [
                "0.214",
                "0.306",
                "0.189",
                "0.162",
                "0.140",
                "0.173",
                "0.135",
                "0.176",
                "0.096",
                "0.119"
            ],
            [
                "0.210",
                "0.304",
                "0.081",
                "0.126",
                "0.132",
                "0.164",
                "0.139",
                "0.170",
                "N/A",
                "N/A"
            ],
            [
                "0.040",
                "0.042",
                "0.249",
                "0.216",
                "0.249",
                "0.268",
                "0.044",
                "0.039",
                "0.270",
                "0.230"
            ],
            [
                "0.098",
                "0.126",
                "0.110",
                "0.152",
                "0.069",
                "0.084",
                "0.025",
                "0.026",
                "0.171",
                "0.154"
            ],
            [
                "0.085",
                "0.064",
                "0.135",
                "0.088",
                "0.169",
                "0.127",
                "0.157",
                "0.124",
                "0.179",
                "0.189"
            ],
            [
                "0.278",
                "0.342",
                "0.311",
                "0.266",
                "0.334",
                "0.326",
                "0.293",
                "0.304",
                "0.333",
                "0.262"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "F1@5",
            "F1@10",
            "F1@5",
            "F1@10",
            "F1@5",
            "F1@10",
            "F1@5",
            "F1@10",
            "F1@5",
            "F1@10"
        ],
        "target_entity": [
            "RNN",
            "CopyRNN"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Inspec || F1@5</th>      <th>Inspec || F1@10</th>      <th>Krapivin || F1@5</th>      <th>Krapivin || F1@10</th>      <th>NUS || F1@5</th>      <th>NUS || F1@10</th>      <th>SemEval || F1@5</th>      <th>SemEval || F1@10</th>      <th>KP20k || F1@5</th>      <th>KP20k || F1@10</th>    </tr>  </thead>  <tbody>    <tr>      <td>Method || Tf-Idf</td>      <td>0.221</td>      <td>0.313</td>      <td>0.129</td>      <td>0.160</td>      <td>0.136</td>      <td>0.184</td>      <td>0.128</td>      <td>0.194</td>      <td>0.102</td>      <td>0.126</td>    </tr>    <tr>      <td>Method || TextRank</td>      <td>0.223</td>      <td>0.281</td>      <td>0.189</td>      <td>0.162</td>      <td>0.195</td>      <td>0.196</td>      <td>0.176</td>      <td>0.187</td>      <td>0.175</td>      <td>0.147</td>    </tr>    <tr>      <td>Method || SingleRank</td>      <td>0.214</td>      <td>0.306</td>      <td>0.189</td>      <td>0.162</td>      <td>0.140</td>      <td>0.173</td>      <td>0.135</td>      <td>0.176</td>      <td>0.096</td>      <td>0.119</td>    </tr>    <tr>      <td>Method || ExpandRank</td>      <td>0.210</td>      <td>0.304</td>      <td>0.081</td>      <td>0.126</td>      <td>0.132</td>      <td>0.164</td>      <td>0.139</td>      <td>0.170</td>      <td>N/A</td>      <td>N/A</td>    </tr>    <tr>      <td>Method || Maui</td>      <td>0.040</td>      <td>0.042</td>      <td>0.249</td>      <td>0.216</td>      <td>0.249</td>      <td>0.268</td>      <td>0.044</td>      <td>0.039</td>      <td>0.270</td>      <td>0.230</td>    </tr>    <tr>      <td>Method || KEA</td>      <td>0.098</td>      <td>0.126</td>      <td>0.110</td>      <td>0.152</td>      <td>0.069</td>      <td>0.084</td>      <td>0.025</td>      <td>0.026</td>      <td>0.171</td>      <td>0.154</td>    </tr>    <tr>      <td>Method || RNN</td>      <td>0.085</td>      <td>0.064</td>      <td>0.135</td>      <td>0.088</td>      <td>0.169</td>      <td>0.127</td>      <td>0.157</td>      <td>0.124</td>      <td>0.179</td>      <td>0.189</td>    </tr>    <tr>      <td>Method || CopyRNN</td>      <td>0.278</td>      <td>0.342</td>      <td>0.311</td>      <td>0.266</td>      <td>0.334</td>      <td>0.326</td>      <td>0.293</td>      <td>0.304</td>      <td>0.333</td>      <td>0.262</td>    </tr>  </tbody></table>",
        "table_name": "Table 2",
        "table_id": "table_2",
        "paper_id": "P17-1054",
        "page_no": 7,
        "dir": "acl2017",
        "valid": 1
    },
    {
        "table_id_paper": "P17-1176table_4",
        "caption": "Comparison of our proposed methods on Spanish-French and German-French translation tasks from the Europarl corpus. English is treated as the pivot language.",
        "row_header_level": 2,
        "row_headers": [
            [
                "Method",
                "sent-greedy"
            ],
            [
                "Method",
                "sent-beam"
            ],
            [
                "Method",
                "word-greedy"
            ],
            [
                "Method",
                "word-beam"
            ],
            [
                "Method",
                "word-sampling"
            ]
        ],
        "column_header_level": 2,
        "column_headers": [
            [
                "Es\u2192 Fr",
                "dev"
            ],
            [
                "Es\u2192 Fr",
                "test"
            ],
            [
                "De\u2192 Fr",
                "dev"
            ],
            [
                "De\u2192 Fr",
                "test"
            ]
        ],
        "contents": [
            [
                "31.00",
                "31.05",
                "22.34",
                "21.88"
            ],
            [
                "31.57",
                "31.64",
                "24.95",
                "24.39"
            ],
            [
                "31.37",
                "31.92",
                "24.72",
                "25.15"
            ],
            [
                "30.81",
                "31.21",
                "24.64",
                "24.19"
            ],
            [
                "33.65",
                "33.86",
                "26.99",
                "27.03"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "BLEU",
            "BLEU",
            "BLEU",
            "BLEU"
        ],
        "target_entity": [
            "Method"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Es\u2192 Fr || dev</th>      <th>Es\u2192 Fr || test</th>      <th>De\u2192 Fr || dev</th>      <th>De\u2192 Fr || test</th>    </tr>  </thead>  <tbody>    <tr>      <td>Method || sent-greedy</td>      <td>31.00</td>      <td>31.05</td>      <td>22.34</td>      <td>21.88</td>    </tr>    <tr>      <td>Method || sent-beam</td>      <td>31.57</td>      <td>31.64</td>      <td>24.95</td>      <td>24.39</td>    </tr>    <tr>      <td>Method || word-greedy</td>      <td>31.37</td>      <td>31.92</td>      <td>24.72</td>      <td>25.15</td>    </tr>    <tr>      <td>Method || word-beam</td>      <td>30.81</td>      <td>31.21</td>      <td>24.64</td>      <td>24.19</td>    </tr>    <tr>      <td>Method || word-sampling</td>      <td>33.65</td>      <td>33.86</td>      <td>26.99</td>      <td>27.03</td>    </tr>  </tbody></table>",
        "table_name": "Table 4",
        "table_id": "table_4",
        "paper_id": "P17-1176",
        "page_no": 6,
        "dir": "acl2017",
        "valid": 1
    },
    {
        "table_id_paper": "P17-1183table_1",
        "caption": "Results on the CELEX dataset",
        "row_header_level": 1,
        "row_headers": [
            [
                "MED (Kann and Schutze 2016a)"
            ],
            [
                "NWFST (Rastogi et al. 2016)"
            ],
            [
                "LAT (Dreyer et al. 2008)"
            ],
            [
                "Soft"
            ],
            [
                "Hard"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "13SIA"
            ],
            [
                "2PIE"
            ],
            [
                "2PKE"
            ],
            [
                "rP"
            ],
            [
                "Avg."
            ]
        ],
        "contents": [
            [
                "83.9",
                "95",
                "87.6",
                "84",
                "87.62"
            ],
            [
                "86.8",
                "94.8",
                "87.9",
                "81.1",
                "87.65"
            ],
            [
                "87.5",
                "93.4",
                "87.4",
                "84.9",
                "88.3"
            ],
            [
                "83.1",
                "93.8",
                "88",
                "83.2",
                "87"
            ],
            [
                "85.8",
                "95.1",
                "89.5",
                "87.2",
                "89.44"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "accuracy",
            "accuracy",
            "accuracy",
            "accuracy",
            "avg accuracy"
        ],
        "target_entity": [
            "Hard",
            "Soft"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>13SIA</th>      <th>2PIE</th>      <th>2PKE</th>      <th>rP</th>      <th>Avg.</th>    </tr>  </thead>  <tbody>    <tr>      <td>MED (Kann and Schutze 2016a)</td>      <td>83.9</td>      <td>95</td>      <td>87.6</td>      <td>84</td>      <td>87.62</td>    </tr>    <tr>      <td>NWFST (Rastogi et al. 2016)</td>      <td>86.8</td>      <td>94.8</td>      <td>87.9</td>      <td>81.1</td>      <td>87.65</td>    </tr>    <tr>      <td>LAT (Dreyer et al. 2008)</td>      <td>87.5</td>      <td>93.4</td>      <td>87.4</td>      <td>84.9</td>      <td>88.3</td>    </tr>    <tr>      <td>Soft</td>      <td>83.1</td>      <td>93.8</td>      <td>88</td>      <td>83.2</td>      <td>87</td>    </tr>    <tr>      <td>Hard</td>      <td>85.8</td>      <td>95.1</td>      <td>89.5</td>      <td>87.2</td>      <td>89.44</td>    </tr>  </tbody></table>",
        "table_name": "Table 1",
        "table_id": "table_1",
        "paper_id": "P17-1183",
        "page_no": 6,
        "dir": "acl2017",
        "valid": 1
    },
    {
        "table_id_paper": "P17-1195table_1",
        "caption": "Performance of the reasoning module on manually formalized pre-university problems",
        "row_header_level": 2,
        "row_headers": [
            [
                "Dataset",
                "DEV"
            ],
            [
                "Dataset",
                "TEST"
            ]
        ],
        "column_header_level": 2,
        "column_headers": [
            [
                "Succeeded",
                "Success %"
            ],
            [
                "Succeeded",
                "Avg. Time"
            ],
            [
                "Failed",
                "Timeout"
            ],
            [
                "Failed",
                "Other"
            ]
        ],
        "contents": [
            [
                "75.3% (131/174)",
                "10.5s",
                "16.70%",
                "8.10%"
            ],
            [
                "78.2% (172/220)",
                "16.2s",
                "15.00%",
                "6.80%"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "Success %",
            "Avg. Time",
            "Timeout",
            "Other"
        ],
        "target_entity": [
            "Succeeded"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Succeeded || Success %</th>      <th>Succeeded || Avg. Time</th>      <th>Failed || Timeout</th>      <th>Failed || Other</th>    </tr>  </thead>  <tbody>    <tr>      <td>Dataset || DEV</td>      <td>75.3% (131/174)</td>      <td>10.5s</td>      <td>16.70%</td>      <td>8.10%</td>    </tr>    <tr>      <td>Dataset || TEST</td>      <td>78.2% (172/220)</td>      <td>16.2s</td>      <td>15.00%</td>      <td>6.80%</td>    </tr>  </tbody></table>",
        "table_name": "Table 1",
        "table_id": "table_1",
        "paper_id": "P17-1195",
        "page_no": 3,
        "dir": "acl2017",
        "valid": 1
    },
    {
        "table_id_paper": "P17-2030table_1",
        "caption": "Unlabeled dependency accuracy results with the 5x5 models and test sets. \u2207 shows the slope of deterioration in parser performance.",
        "row_header_level": 1,
        "row_headers": [
            [
                "0%"
            ],
            [
                "5%"
            ],
            [
                "10%"
            ],
            [
                "15%"
            ],
            [
                "20%"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "Baseline"
            ],
            [
                "E05"
            ],
            [
                "E10"
            ],
            [
                "E15"
            ],
            [
                "E20"
            ]
        ],
        "contents": [
            [
                "91.43",
                "91.12",
                "90.87",
                "90.61",
                "90.29"
            ],
            [
                "89.99",
                "90",
                "89.87",
                "89.72",
                "89.48"
            ],
            [
                "87.84",
                "87.99",
                "88.07",
                "88.14",
                "88.04"
            ],
            [
                "85.64",
                "86.18",
                "86.54",
                "86.75",
                "86.82"
            ],
            [
                "84.12",
                "84.78",
                "85.28",
                "85.5",
                "85.76"
            ]
        ],
        "metrics_loc": "row",
        "metrics_type": [
            "UAS",
            "UAS",
            "UAS",
            "UAS",
            "UAS"
        ],
        "target_entity": [
            "0%",
            "5%",
            "10%",
            "15%",
            "20%"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Baseline</th>      <th>E05</th>      <th>E10</th>      <th>E15</th>      <th>E20</th>    </tr>  </thead>  <tbody>    <tr>      <td>0%</td>      <td>91.43</td>      <td>91.12</td>      <td>90.87</td>      <td>90.61</td>      <td>90.29</td>    </tr>    <tr>      <td>5%</td>      <td>89.99</td>      <td>90</td>      <td>89.87</td>      <td>89.72</td>      <td>89.48</td>    </tr>    <tr>      <td>10%</td>      <td>87.84</td>      <td>87.99</td>      <td>88.07</td>      <td>88.14</td>      <td>88.04</td>    </tr>    <tr>      <td>15%</td>      <td>85.64</td>      <td>86.18</td>      <td>86.54</td>      <td>86.75</td>      <td>86.82</td>    </tr>    <tr>      <td>20%</td>      <td>84.12</td>      <td>84.78</td>      <td>85.28</td>      <td>85.5</td>      <td>85.76</td>    </tr>  </tbody></table>",
        "table_name": "Table 1",
        "table_id": "table_1",
        "paper_id": "P17-2030",
        "page_no": 4,
        "dir": "acl2017",
        "valid": 1
    },
    {
        "table_id_paper": "P18-1008table_3",
        "caption": "Performance comparison. Examples/s are normalized by the number of GPUs used in the training job. FLOPs are computed assuming that source and target sequence length are both 50.",
        "row_header_level": 2,
        "row_headers": [
            [
                "Model",
                "ConvS2S"
            ],
            [
                "Model",
                "Trans. Base"
            ],
            [
                "Model",
                "Trans. Big"
            ],
            [
                "Model",
                "RNMT+"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "Examples/s"
            ],
            [
                "FLOPs"
            ],
            [
                "Params"
            ]
        ],
        "contents": [
            [
                "80",
                "15.7B",
                "263.4M"
            ],
            [
                "160",
                "6.2B",
                "93.3M"
            ],
            [
                "50",
                "31.2B",
                "375.4M"
            ],
            [
                "30",
                "28.1B",
                "378.9M"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "Example/s",
            "FLOPs",
            "Params"
        ],
        "target_entity": [
            "RNMT+"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Examples/s</th>      <th>FLOPs</th>      <th>Params</th>    </tr>  </thead>  <tbody>    <tr>      <td>Model || ConvS2S</td>      <td>80</td>      <td>15.7B</td>      <td>263.4M</td>    </tr>    <tr>      <td>Model || Trans. Base</td>      <td>160</td>      <td>6.2B</td>      <td>93.3M</td>    </tr>    <tr>      <td>Model || Trans. Big</td>      <td>50</td>      <td>31.2B</td>      <td>375.4M</td>    </tr>    <tr>      <td>Model || RNMT+</td>      <td>30</td>      <td>28.1B</td>      <td>378.9M</td>    </tr>  </tbody></table>",
        "table_name": "Table 3",
        "table_id": "table_3",
        "paper_id": "P18-1008",
        "page_no": 6,
        "dir": "acl2018",
        "valid": 1
    },
    {
        "table_id_paper": "P18-1021table_5",
        "caption": "Human evaluation results on grammaticality (Gram), informativeness (Info), and relevance (Rel) of arguments. Our model with separate decoder and attention over keyphrases receives significantly better ratings in informativeness and relevance than seq2seq (one-way ANOVA, p < 0.005).",
        "row_header_level": 2,
        "row_headers": [
            [
                "System",
                "RETRIEVAL"
            ],
            [
                "System",
                "SEQ2SEQ"
            ],
            [
                "System",
                "OUR MODEL"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "Gram"
            ],
            [
                " Info"
            ],
            [
                "Rel"
            ]
        ],
        "contents": [
            [
                "4.5 \u0081} 0.6",
                "3.7 \u0081} 0.9",
                "3.3 \u0081} 1.1"
            ],
            [
                "3.3 \u0081} 1.1",
                "1.2 \u0081} 0.5",
                "1.4 \u0081} 0.7"
            ],
            [
                "2.5 \u0081} 0.8",
                "1.6 \u0081} 0.8",
                "1.8 \u0081} 0.8"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "Gram",
            "Info",
            "Rel"
        ],
        "target_entity": [
            "OUR MODEL"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Gram</th>      <th>Info</th>      <th>Rel</th>    </tr>  </thead>  <tbody>    <tr>      <td>System || RETRIEVAL</td>      <td>4.5 \u0081} 0.6</td>      <td>3.7 \u0081} 0.9</td>      <td>3.3 \u0081} 1.1</td>    </tr>    <tr>      <td>System || SEQ2SEQ</td>      <td>3.3 \u0081} 1.1</td>      <td>1.2 \u0081} 0.5</td>      <td>1.4 \u0081} 0.7</td>    </tr>    <tr>      <td>System || OUR MODEL</td>      <td>2.5 \u0081} 0.8</td>      <td>1.6 \u0081} 0.8</td>      <td>1.8 \u0081} 0.8</td>    </tr>  </tbody></table>",
        "table_name": "Table 5",
        "table_id": "table_5",
        "paper_id": "P18-1021",
        "page_no": 8,
        "dir": "acl2018",
        "valid": 1
    },
    {
        "table_id_paper": "P18-1038table_1",
        "caption": "Parsing accuracy of the best existing grammar-free and -based models as well as our SHRG-based model. Results are copied from (Oepen et al., 2015; Peng et al., 2017a; Buys and Blunsom, 2017).",
        "row_header_level": 4,
        "row_headers": [
            [
                "Model",
                "Data-driven",
                "Grammar",
                "NO"
            ],
            [
                "Model",
                "ERG-based",
                "Grammar",
                "Unification"
            ],
            [
                "Model",
                "SHRG-based",
                "Grammar",
                "Rewriting"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "SDG"
            ],
            [
                "EDS"
            ],
            [
                "DMRS"
            ]
        ],
        "contents": [
            [
                "89.4",
                "85.48",
                "84.16"
            ],
            [
                "92.8",
                "89.58",
                "89.64"
            ],
            [
                "-",
                "90.39",
                "89.51"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "accuracy",
            "accuracy",
            "accuracy"
        ],
        "target_entity": [
            "SHRG-based"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>SDG</th>      <th>EDS</th>      <th>DMRS</th>    </tr>  </thead>  <tbody>    <tr>      <td>Model || Data-driven || Grammar || NO</td>      <td>89.4</td>      <td>85.48</td>      <td>84.16</td>    </tr>    <tr>      <td>Model || ERG-based || Grammar || Unification</td>      <td>92.8</td>      <td>89.58</td>      <td>89.64</td>    </tr>    <tr>      <td>Model || SHRG-based || Grammar || Rewriting</td>      <td>-</td>      <td>90.39</td>      <td>89.51</td>    </tr>  </tbody></table>",
        "table_name": "Table 1",
        "table_id": "table_1",
        "paper_id": "P18-1038",
        "page_no": 3,
        "dir": "acl2018",
        "valid": 1
    },
    {
        "table_id_paper": "P18-1048table_2",
        "caption": "Detection performance (trigger identification plus multi-class classification)",
        "row_header_level": 2,
        "row_headers": [
            [
                "Methods",
                "MSEP-EMD"
            ],
            [
                "Methods",
                "Cross-Event"
            ],
            [
                "Methods",
                "Cross-Entity"
            ],
            [
                "Methods",
                "Joint (Local+Global)"
            ],
            [
                "Methods",
                "CNN"
            ],
            [
                "Methods",
                "DM-CNN"
            ],
            [
                "Methods",
                "NC-CNN"
            ],
            [
                "Methods",
                "FB-RNN (GRU)"
            ],
            [
                "Methods",
                "Bi-RNN (GRU)"
            ],
            [
                "Methods",
                "ANNs (ACE+FN)"
            ],
            [
                "Methods",
                "DM-CNN?(ACE+Wiki)"
            ],
            [
                "Methods",
                "ANN-S2 (ACE+FN)"
            ],
            [
                "Methods",
                "Hybrid: Bi-LSTM+CNN"
            ],
            [
                "Methods",
                "SELF: Bi-LSTM+GAN"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "P (%)"
            ],
            [
                "R (%)"
            ],
            [
                "F (%)"
            ]
        ],
        "contents": [
            [
                "70.4",
                "65",
                "67.6"
            ],
            [
                "68.8",
                "68.9",
                "68.8"
            ],
            [
                "72.9",
                "64.3",
                "68.3"
            ],
            [
                "73.7",
                "62.3",
                "67.5"
            ],
            [
                "71.8",
                "66.4",
                "69"
            ],
            [
                "75.6",
                "63.6",
                "69.1"
            ],
            [
                "-",
                "-",
                "71.3"
            ],
            [
                "66.8",
                "68",
                "67.4"
            ],
            [
                "66",
                "73",
                "69.3"
            ],
            [
                "77.6",
                "65.2",
                "70.7"
            ],
            [
                "75.7",
                "66",
                "70.5"
            ],
            [
                "76.8",
                "67.5",
                "71.9"
            ],
            [
                "84.6",
                "64.9",
                "73.4"
            ],
            [
                "71.3",
                "74.7",
                "73"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "P (%)",
            "R (%)",
            "F (%)"
        ],
        "target_entity": [
            "SELF: Bi-LSTM+GAN"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>P (%)</th>      <th>R (%)</th>      <th>F (%)</th>    </tr>  </thead>  <tbody>    <tr>      <td>Methods || MSEP-EMD</td>      <td>70.4</td>      <td>65</td>      <td>67.6</td>    </tr>    <tr>      <td>Methods || Cross-Event</td>      <td>68.8</td>      <td>68.9</td>      <td>68.8</td>    </tr>    <tr>      <td>Methods || Cross-Entity</td>      <td>72.9</td>      <td>64.3</td>      <td>68.3</td>    </tr>    <tr>      <td>Methods || Joint (Local+Global)</td>      <td>73.7</td>      <td>62.3</td>      <td>67.5</td>    </tr>    <tr>      <td>Methods || CNN</td>      <td>71.8</td>      <td>66.4</td>      <td>69</td>    </tr>    <tr>      <td>Methods || DM-CNN</td>      <td>75.6</td>      <td>63.6</td>      <td>69.1</td>    </tr>    <tr>      <td>Methods || NC-CNN</td>      <td>-</td>      <td>-</td>      <td>71.3</td>    </tr>    <tr>      <td>Methods || FB-RNN (GRU)</td>      <td>66.8</td>      <td>68</td>      <td>67.4</td>    </tr>    <tr>      <td>Methods || Bi-RNN (GRU)</td>      <td>66</td>      <td>73</td>      <td>69.3</td>    </tr>    <tr>      <td>Methods || ANNs (ACE+FN)</td>      <td>77.6</td>      <td>65.2</td>      <td>70.7</td>    </tr>    <tr>      <td>Methods || DM-CNN?(ACE+Wiki)</td>      <td>75.7</td>      <td>66</td>      <td>70.5</td>    </tr>    <tr>      <td>Methods || ANN-S2 (ACE+FN)</td>      <td>76.8</td>      <td>67.5</td>      <td>71.9</td>    </tr>    <tr>      <td>Methods || Hybrid: Bi-LSTM+CNN</td>      <td>84.6</td>      <td>64.9</td>      <td>73.4</td>    </tr>    <tr>      <td>Methods || SELF: Bi-LSTM+GAN</td>      <td>71.3</td>      <td>74.7</td>      <td>73</td>    </tr>  </tbody></table>",
        "table_name": "Table 2",
        "table_id": "table_2",
        "paper_id": "P18-1048",
        "page_no": 6,
        "dir": "acl2018",
        "valid": 1
    },
    {
        "table_id_paper": "P18-1050table_6",
        "caption": "Results on MCNC task",
        "row_header_level": 2,
        "row_headers": [
            [
                "Models",
                "(Chambers and Jurafsky 2008)"
            ],
            [
                "Models",
                "(Granroth-Wilding and Clark 2016)"
            ],
            [
                "Models",
                "(Pichotta and Mooney 2016)"
            ],
            [
                "Models",
                "(Wang et al. 2017)"
            ],
            [
                "Models",
                "Our Results"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "Acc.(%)"
            ]
        ],
        "contents": [
            [
                "30.92"
            ],
            [
                "43.28"
            ],
            [
                "43.17"
            ],
            [
                "46.67"
            ],
            [
                "48.83"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "Acc.(%)"
        ],
        "target_entity": [
            "Our Results"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Acc.(%)</th>    </tr>  </thead>  <tbody>    <tr>      <td>Models || (Chambers and Jurafsky 2008)</td>      <td>30.92</td>    </tr>    <tr>      <td>Models || (Granroth-Wilding and Clark 2016)</td>      <td>43.28</td>    </tr>    <tr>      <td>Models || (Pichotta and Mooney 2016)</td>      <td>43.17</td>    </tr>    <tr>      <td>Models || (Wang et al. 2017)</td>      <td>46.67</td>    </tr>    <tr>      <td>Models || Our Results</td>      <td>48.83</td>    </tr>  </tbody></table>",
        "table_name": "Table 6",
        "table_id": "table_6",
        "paper_id": "P18-1050",
        "page_no": 8,
        "dir": "acl2018",
        "valid": 1
    },
    {
        "table_id_paper": "P18-1076table_5",
        "caption": "Results for key-value knowledge retrieval (CN5Sel, 50 facts). Subj/Obj and integration. means: we attend over the fact subject (Key) and take the weighted fact object as value (Value). CN",
        "row_header_level": 2,
        "row_headers": [
            [
                "Key/Value",
                "Subj/Obj"
            ],
            [
                "Key/Value",
                "Obj/Obj"
            ]
        ],
        "column_header_level": 2,
        "column_headers": [
            [
                "NE",
                "Dev"
            ],
            [
                "NE",
                "Test"
            ],
            [
                "CN",
                "Dev"
            ],
            [
                "CN",
                "Test"
            ]
        ],
        "contents": [
            [
                "76.65",
                "71.52",
                "71.85",
                "67.64"
            ],
            [
                "76.7",
                "71.28",
                "71.25",
                "67.48"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "accurary",
            "accurary",
            "accurary",
            "accurary"
        ],
        "target_entity": [
            "Subj/Obj"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>NE || Dev</th>      <th>NE || Test</th>      <th>CN || Dev</th>      <th>CN || Test</th>    </tr>  </thead>  <tbody>    <tr>      <td>Key/Value || Subj/Obj</td>      <td>76.65</td>      <td>71.52</td>      <td>71.85</td>      <td>67.64</td>    </tr>    <tr>      <td>Key/Value || Obj/Obj</td>      <td>76.7</td>      <td>71.28</td>      <td>71.25</td>      <td>67.48</td>    </tr>  </tbody></table>",
        "table_name": "Table 5",
        "table_id": "table_5",
        "paper_id": "P18-1076",
        "page_no": 7,
        "dir": "acl2018",
        "valid": 1
    },
    {
        "table_id_paper": "P18-1101table_4",
        "caption": "Human evaluation results on judging the homogeneity of latent actions in SMD.",
        "row_header_level": 2,
        "row_headers": [
            [
                "Model",
                "DI-VAE"
            ],
            [
                "Model",
                "DI-VST"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "Exp Agree"
            ],
            [
                "Worker \u03ba"
            ],
            [
                "Match Rate"
            ]
        ],
        "contents": [
            [
                "85.60%",
                "0.52",
                "71.30%"
            ],
            [
                "93.30%",
                "0.48",
                "74.90%"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "Exp Agree",
            "Worker \u03ba",
            "Match Rate"
        ],
        "target_entity": [
            "DI-VST"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Exp Agree</th>      <th>Worker \u03ba</th>      <th>Match Rate</th>    </tr>  </thead>  <tbody>    <tr>      <td>Model || DI-VAE</td>      <td>85.60%</td>      <td>0.52</td>      <td>71.30%</td>    </tr>    <tr>      <td>Model || DI-VST</td>      <td>93.30%</td>      <td>0.48</td>      <td>74.90%</td>    </tr>  </tbody></table>",
        "table_name": "Table 4",
        "table_id": "table_4",
        "paper_id": "P18-1101",
        "page_no": 7,
        "dir": "acl2018",
        "valid": 1
    },
    {
        "table_id_paper": "P18-1102table_4",
        "caption": "Results on the human evaluation.",
        "row_header_level": 1,
        "row_headers": [
            [
                "Seq2Seq-att"
            ],
            [
                "MMI-bidi"
            ],
            [
                "MARM"
            ],
            [
                "Seq2Seq+IDF"
            ],
            [
                "SC-Seq2SeqNIWF s=1"
            ],
            [
                "SC-Seq2SeqNIWF s=0.5"
            ],
            [
                "SC-Seq2SeqNIWF s=0"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "+2"
            ],
            [
                "+1"
            ],
            [
                "+0"
            ],
            [
                "kappa"
            ]
        ],
        "contents": [
            [
                "29.32%",
                "25.27%",
                "45.41%",
                "0.448"
            ],
            [
                "30.40%",
                "24.85%",
                "44.75%",
                "0.471"
            ],
            [
                "20.11%",
                "27.96%",
                "51.93%",
                "0.404"
            ],
            [
                "28.81%",
                "23.87%",
                "47.33%",
                "0.418"
            ],
            [
                "42.47%",
                "14.29%",
                "43.24%",
                "0.507"
            ],
            [
                "20.62%",
                "40.16%",
                "39.22%",
                "0.451"
            ],
            [
                "14.34%",
                "46.38%",
                "39.28%",
                "0.526"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "+2",
            "+1",
            "+0",
            "kappa"
        ],
        "target_entity": [
            "SC-Seq2SeqNIWF s=1",
            "SC-Seq2SeqNIWF s=0.5",
            "SC-Seq2SeqNIWF s=0"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>+2</th>      <th>+1</th>      <th>+0</th>      <th>kappa</th>    </tr>  </thead>  <tbody>    <tr>      <td>Seq2Seq-att</td>      <td>29.32%</td>      <td>25.27%</td>      <td>45.41%</td>      <td>0.448</td>    </tr>    <tr>      <td>MMI-bidi</td>      <td>30.40%</td>      <td>24.85%</td>      <td>44.75%</td>      <td>0.471</td>    </tr>    <tr>      <td>MARM</td>      <td>20.11%</td>      <td>27.96%</td>      <td>51.93%</td>      <td>0.404</td>    </tr>    <tr>      <td>Seq2Seq+IDF</td>      <td>28.81%</td>      <td>23.87%</td>      <td>47.33%</td>      <td>0.418</td>    </tr>    <tr>      <td>SC-Seq2SeqNIWF s=1</td>      <td>42.47%</td>      <td>14.29%</td>      <td>43.24%</td>      <td>0.507</td>    </tr>    <tr>      <td>SC-Seq2SeqNIWF s=0.5</td>      <td>20.62%</td>      <td>40.16%</td>      <td>39.22%</td>      <td>0.451</td>    </tr>    <tr>      <td>SC-Seq2SeqNIWF s=0</td>      <td>14.34%</td>      <td>46.38%</td>      <td>39.28%</td>      <td>0.526</td>    </tr>  </tbody></table>",
        "table_name": "Table 4",
        "table_id": "table_4",
        "paper_id": "P18-1102",
        "page_no": 8,
        "dir": "acl2018",
        "valid": 1
    },
    {
        "table_id_paper": "P18-1145table_2",
        "caption": "Experiment results on ACE2005 and KBPEval2017. * indicates the result adapted from the original paper. For KBPEval2017, \u201cTrigger Identification\u201d corresponds to the \u201cSpan\u201d metric and \u201cTrigger Classification\u201d corresponds to the \u201cType\u201d metric reported in official evaluation.",
        "row_header_level": 2,
        "row_headers": [
            [
                "Model",
                "FBRNN(Char)"
            ],
            [
                "Model",
                "DMCNN(Char)"
            ],
            [
                "Model",
                "C-BiLSTM*"
            ],
            [
                "Model",
                "FBRNN(Word)"
            ],
            [
                "Model",
                "DMCNN(Word)"
            ],
            [
                "Model",
                "HNN*"
            ],
            [
                "Model",
                "Rich-C*"
            ],
            [
                "Model",
                "KBP2017 Best*"
            ],
            [
                "Model",
                "NPN(Concat)"
            ],
            [
                "Model",
                "NPN(General)"
            ],
            [
                "Model",
                "NPN(Task-specific)"
            ]
        ],
        "column_header_level": 3,
        "column_headers": [
            [
                "ACE2005",
                "Trigger Identification",
                "P"
            ],
            [
                "ACE2005",
                "Trigger Identification",
                "R"
            ],
            [
                "ACE2005",
                "Trigger Identification",
                "F1"
            ],
            [
                "ACE2005",
                "Trigger Classification",
                "P"
            ],
            [
                "ACE2005",
                "Trigger Classification",
                "R"
            ],
            [
                "ACE2005",
                "Trigger Classification",
                "F1"
            ],
            [
                "KBPEval2017",
                "Trigger Identification",
                "P"
            ],
            [
                "KBPEval2017",
                "Trigger Identification",
                "R"
            ],
            [
                "KBPEval2017",
                "Trigger Identification",
                "F1"
            ],
            [
                "KBPEval2017",
                "Trigger Classification",
                "P"
            ],
            [
                "KBPEval2017",
                "Trigger Classification",
                "R"
            ],
            [
                "KBPEval2017",
                "Trigger Classification",
                "F1"
            ]
        ],
        "contents": [
            [
                "61.3",
                "45.6",
                "52.3",
                "57.5",
                "42.8",
                "49.1",
                "57.97",
                "36.92",
                "45.11",
                "51.71",
                "32.94",
                "40.24"
            ],
            [
                "60.1",
                "61.6",
                "60.9",
                "57.1",
                "58.5",
                "57.8",
                "53.67",
                "49.92",
                "51.73",
                "50.03",
                "46.53",
                "48.22"
            ],
            [
                "65.6",
                "66.7",
                "66.1",
                "60.0",
                "60.9",
                "60.4",
                "-",
                "-",
                "-",
                "-",
                "-",
                "-"
            ],
            [
                "64.1",
                "63.7",
                "63.9",
                "59.9",
                "59.6",
                "59.7",
                "65.10",
                "46.86",
                "54.50",
                "60.05",
                "43.22",
                "50.27"
            ],
            [
                "66.6",
                "63.6",
                "65.1",
                "61.6",
                "58.8",
                "60.2",
                "60.43",
                "51.64",
                "55.69",
                "54.81",
                "46.84",
                "50.51"
            ],
            [
                "74.2",
                "63.1",
                "68.2",
                "77.1",
                "53.1",
                "63.0",
                "-",
                "-",
                "-",
                "-",
                "-",
                "-"
            ],
            [
                "62.2",
                "71.9",
                "66.7",
                "58.9",
                "68.1",
                "63.2",
                "-",
                "-",
                "-",
                "-",
                "-",
                "-"
            ],
            [
                "-",
                "-",
                "-",
                "-",
                "-",
                "-",
                "67.76",
                "45.92",
                "54.74",
                "62.69",
                "42.48",
                "50.64"
            ],
            [
                "76.5",
                "59.8",
                "67.1",
                "72.8",
                "56.9",
                "63.9",
                "64.58",
                "50.31",
                "56.56",
                "59.14",
                "46.07",
                "51.80"
            ],
            [
                "71.5",
                "63.2",
                "67.1",
                "67.3",
                "59.6",
                "63.2",
                "63.67",
                "51.32",
                "56.83",
                "57.78",
                "46.58",
                "51.57"
            ],
            [
                "64.8",
                "73.8",
                "69.0",
                "60.9",
                "69.3",
                "64.8",
                "64.32",
                "53.16",
                "58.21",
                "57.63",
                "47.63",
                "52.15"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "P",
            "R",
            "F1",
            "P",
            "R",
            "F1",
            "P",
            "R",
            "F1",
            "P",
            "R",
            "F1"
        ],
        "target_entity": [
            "NPN(Task-specific)"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>ACE2005 || Trigger Identification || P</th>      <th>ACE2005 || Trigger Identification || R</th>      <th>ACE2005 || Trigger Identification || F1</th>      <th>ACE2005 || Trigger Classification || P</th>      <th>ACE2005 || Trigger Classification || R</th>      <th>ACE2005 || Trigger Classification || F1</th>      <th>KBPEval2017 || Trigger Identification || P</th>      <th>KBPEval2017 || Trigger Identification || R</th>      <th>KBPEval2017 || Trigger Identification || F1</th>      <th>KBPEval2017 || Trigger Classification || P</th>      <th>KBPEval2017 || Trigger Classification || R</th>      <th>KBPEval2017 || Trigger Classification || F1</th>    </tr>  </thead>  <tbody>    <tr>      <td>Model || FBRNN(Char)</td>      <td>61.3</td>      <td>45.6</td>      <td>52.3</td>      <td>57.5</td>      <td>42.8</td>      <td>49.1</td>      <td>57.97</td>      <td>36.92</td>      <td>45.11</td>      <td>51.71</td>      <td>32.94</td>      <td>40.24</td>    </tr>    <tr>      <td>Model || DMCNN(Char)</td>      <td>60.1</td>      <td>61.6</td>      <td>60.9</td>      <td>57.1</td>      <td>58.5</td>      <td>57.8</td>      <td>53.67</td>      <td>49.92</td>      <td>51.73</td>      <td>50.03</td>      <td>46.53</td>      <td>48.22</td>    </tr>    <tr>      <td>Model || C-BiLSTM*</td>      <td>65.6</td>      <td>66.7</td>      <td>66.1</td>      <td>60.0</td>      <td>60.9</td>      <td>60.4</td>      <td>-</td>      <td>-</td>      <td>-</td>      <td>-</td>      <td>-</td>      <td>-</td>    </tr>    <tr>      <td>Model || FBRNN(Word)</td>      <td>64.1</td>      <td>63.7</td>      <td>63.9</td>      <td>59.9</td>      <td>59.6</td>      <td>59.7</td>      <td>65.10</td>      <td>46.86</td>      <td>54.50</td>      <td>60.05</td>      <td>43.22</td>      <td>50.27</td>    </tr>    <tr>      <td>Model || DMCNN(Word)</td>      <td>66.6</td>      <td>63.6</td>      <td>65.1</td>      <td>61.6</td>      <td>58.8</td>      <td>60.2</td>      <td>60.43</td>      <td>51.64</td>      <td>55.69</td>      <td>54.81</td>      <td>46.84</td>      <td>50.51</td>    </tr>    <tr>      <td>Model || HNN*</td>      <td>74.2</td>      <td>63.1</td>      <td>68.2</td>      <td>77.1</td>      <td>53.1</td>      <td>63.0</td>      <td>-</td>      <td>-</td>      <td>-</td>      <td>-</td>      <td>-</td>      <td>-</td>    </tr>    <tr>      <td>Model || Rich-C*</td>      <td>62.2</td>      <td>71.9</td>      <td>66.7</td>      <td>58.9</td>      <td>68.1</td>      <td>63.2</td>      <td>-</td>      <td>-</td>      <td>-</td>      <td>-</td>      <td>-</td>      <td>-</td>    </tr>    <tr>      <td>Model || KBP2017 Best*</td>      <td>-</td>      <td>-</td>      <td>-</td>      <td>-</td>      <td>-</td>      <td>-</td>      <td>67.76</td>      <td>45.92</td>      <td>54.74</td>      <td>62.69</td>      <td>42.48</td>      <td>50.64</td>    </tr>    <tr>      <td>Model || NPN(Concat)</td>      <td>76.5</td>      <td>59.8</td>      <td>67.1</td>      <td>72.8</td>      <td>56.9</td>      <td>63.9</td>      <td>64.58</td>      <td>50.31</td>      <td>56.56</td>      <td>59.14</td>      <td>46.07</td>      <td>51.80</td>    </tr>    <tr>      <td>Model || NPN(General)</td>      <td>71.5</td>      <td>63.2</td>      <td>67.1</td>      <td>67.3</td>      <td>59.6</td>      <td>63.2</td>      <td>63.67</td>      <td>51.32</td>      <td>56.83</td>      <td>57.78</td>      <td>46.58</td>      <td>51.57</td>    </tr>    <tr>      <td>Model || NPN(Task-specific)</td>      <td>64.8</td>      <td>73.8</td>      <td>69.0</td>      <td>60.9</td>      <td>69.3</td>      <td>64.8</td>      <td>64.32</td>      <td>53.16</td>      <td>58.21</td>      <td>57.63</td>      <td>47.63</td>      <td>52.15</td>    </tr>  </tbody></table>",
        "table_name": "Table 2",
        "table_id": "table_2",
        "paper_id": "P18-1145",
        "page_no": 6,
        "dir": "acl2018",
        "valid": 1
    },
    {
        "table_id_paper": "P18-1168table_4",
        "caption": "Results on the development, public test (Test-P) and hidden test (Test-H) sets. For each model, we report both accuracy and consistency.",
        "row_header_level": 2,
        "row_headers": [
            [
                "Model",
                "MAJORITY"
            ],
            [
                "Model",
                "MAXENT"
            ],
            [
                "Model",
                "RULE"
            ],
            [
                "Model",
                "SUP."
            ],
            [
                "Model",
                "SUP.+DISC"
            ],
            [
                "Model",
                "WEAKSUP."
            ],
            [
                "Model",
                "W.+DISC"
            ]
        ],
        "column_header_level": 2,
        "column_headers": [
            [
                "Dev.",
                "Acc."
            ],
            [
                "Dev.",
                "Con."
            ],
            [
                "Test-P",
                "Acc."
            ],
            [
                "Test-P",
                "Con."
            ],
            [
                "Test-H",
                "Acc."
            ],
            [
                "Test-H",
                "Con."
            ]
        ],
        "contents": [
            [
                "55.3",
                "-",
                "56.2",
                "-",
                "55.4",
                "-"
            ],
            [
                "68.0",
                "-",
                "67.7",
                "-",
                "67.8",
                "-"
            ],
            [
                "66.0",
                "29.2",
                "66.3",
                "32.7",
                "-",
                "-"
            ],
            [
                "67.7",
                "36.7",
                "66.9",
                "38.3",
                "-",
                "-"
            ],
            [
                "77.7",
                "52.4",
                "76.6",
                "51.8",
                "-",
                "-"
            ],
            [
                "84.3",
                "66.3",
                "81.7",
                "60.1",
                "-",
                "-"
            ],
            [
                "85.7",
                "67.4",
                "84.0",
                "65.0",
                "82.5",
                "63.9"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "Acc.",
            "Con.",
            "Acc.",
            "Con.",
            "Acc.",
            "Con."
        ],
        "target_entity": [
            "W.+DISC"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Dev. || Acc.</th>      <th>Dev. || Con.</th>      <th>Test-P || Acc.</th>      <th>Test-P || Con.</th>      <th>Test-H || Acc.</th>      <th>Test-H || Con.</th>    </tr>  </thead>  <tbody>    <tr>      <td>Model || MAJORITY</td>      <td>55.3</td>      <td>-</td>      <td>56.2</td>      <td>-</td>      <td>55.4</td>      <td>-</td>    </tr>    <tr>      <td>Model || MAXENT</td>      <td>68.0</td>      <td>-</td>      <td>67.7</td>      <td>-</td>      <td>67.8</td>      <td>-</td>    </tr>    <tr>      <td>Model || RULE</td>      <td>66.0</td>      <td>29.2</td>      <td>66.3</td>      <td>32.7</td>      <td>-</td>      <td>-</td>    </tr>    <tr>      <td>Model || SUP.</td>      <td>67.7</td>      <td>36.7</td>      <td>66.9</td>      <td>38.3</td>      <td>-</td>      <td>-</td>    </tr>    <tr>      <td>Model || SUP.+DISC</td>      <td>77.7</td>      <td>52.4</td>      <td>76.6</td>      <td>51.8</td>      <td>-</td>      <td>-</td>    </tr>    <tr>      <td>Model || WEAKSUP.</td>      <td>84.3</td>      <td>66.3</td>      <td>81.7</td>      <td>60.1</td>      <td>-</td>      <td>-</td>    </tr>    <tr>      <td>Model || W.+DISC</td>      <td>85.7</td>      <td>67.4</td>      <td>84.0</td>      <td>65.0</td>      <td>82.5</td>      <td>63.9</td>    </tr>  </tbody></table>",
        "table_name": "Table 4",
        "table_id": "table_4",
        "paper_id": "P18-1168",
        "page_no": 8,
        "dir": "acl2018",
        "valid": 1
    },
    {
        "table_id_paper": "P18-1177table_5",
        "caption": "Human evaluation results for question generation. \u201cGrammaticality\u201d, \u201cMaking Sense\u201d and \u201cAnswerability\u201d are rated on a 1\u20135 scale (5 for the best, see the supplementary materials for a detailed rating scheme), \u201cAverage rank\u201d is rated on a 1\u20133 scale (1 for the most preferred, ties are allowed.) Two-tailed t-test results are shown for our method compared to ContextNQG (stat. significance is indicated with \u2217(p < 0.05), \u2217\u2217(p < 0.01).)",
        "row_header_level": 1,
        "row_headers": [
            [
                "ContextNQG"
            ],
            [
                "CorefNQG"
            ],
            [
                "Human"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "Grammaticality"
            ],
            [
                "Making Sense"
            ],
            [
                "Answerability"
            ],
            [
                "Avg. rank"
            ]
        ],
        "contents": [
            [
                "3.793",
                "3.836",
                "3.892",
                "1.768"
            ],
            [
                "3.804*",
                "3.847**",
                "3.895*",
                "1.762"
            ],
            [
                "3.807",
                "3.850",
                "3.902",
                "1.758"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "Grammaticality",
            "Making Sense",
            "Answerability",
            "Avg. rank"
        ],
        "target_entity": [
            "CorefNQG"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Grammaticality</th>      <th>Making Sense</th>      <th>Answerability</th>      <th>Avg. rank</th>    </tr>  </thead>  <tbody>    <tr>      <td>ContextNQG</td>      <td>3.793</td>      <td>3.836</td>      <td>3.892</td>      <td>1.768</td>    </tr>    <tr>      <td>CorefNQG</td>      <td>3.804*</td>      <td>3.847**</td>      <td>3.895*</td>      <td>1.762</td>    </tr>    <tr>      <td>Human</td>      <td>3.807</td>      <td>3.850</td>      <td>3.902</td>      <td>1.758</td>    </tr>  </tbody></table>",
        "table_name": "Table 5",
        "table_id": "table_5",
        "paper_id": "P18-1177",
        "page_no": 8,
        "dir": "acl2018",
        "valid": 1
    },
    {
        "table_id_paper": "P18-1188table_3",
        "caption": "Human evaluations: Ranking of various systems. Rank 1st is best and rank 4th, worst. Numbers show the percentage of times a system gets ranked at a certain position.",
        "row_header_level": 2,
        "row_headers": [
            [
                "Models",
                "LEAD"
            ],
            [
                "Models",
                "POINTERNET"
            ],
            [
                "Models",
                "XNET"
            ],
            [
                "Models",
                "HUMAN"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "1st"
            ],
            [
                "2nd"
            ],
            [
                "3rd"
            ],
            [
                "4th"
            ]
        ],
        "contents": [
            [
                "0.15",
                "0.17",
                "0.47",
                "0.21"
            ],
            [
                "0.16",
                "0.05",
                "0.31",
                "0.48"
            ],
            [
                "0.28",
                "0.53",
                "0.15",
                "0.04"
            ],
            [
                "0.41",
                "0.25",
                "0.07",
                "0.27"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "percentage",
            "percentage",
            "percentage",
            "percentage"
        ],
        "target_entity": [
            "XNET"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>1st</th>      <th>2nd</th>      <th>3rd</th>      <th>4th</th>    </tr>  </thead>  <tbody>    <tr>      <td>Models || LEAD</td>      <td>0.15</td>      <td>0.17</td>      <td>0.47</td>      <td>0.21</td>    </tr>    <tr>      <td>Models || POINTERNET</td>      <td>0.16</td>      <td>0.05</td>      <td>0.31</td>      <td>0.48</td>    </tr>    <tr>      <td>Models || XNET</td>      <td>0.28</td>      <td>0.53</td>      <td>0.15</td>      <td>0.04</td>    </tr>    <tr>      <td>Models || HUMAN</td>      <td>0.41</td>      <td>0.25</td>      <td>0.07</td>      <td>0.27</td>    </tr>  </tbody></table>",
        "table_name": "Table 3",
        "table_id": "table_3",
        "paper_id": "P18-1188",
        "page_no": 6,
        "dir": "acl2018",
        "valid": 1
    },
    {
        "table_id_paper": "P18-1191table_6",
        "caption": "Joint span detection and question generation results on the dense development set, using exact-match for both spans and questions.",
        "row_header_level": 1,
        "row_headers": [
            [
                "Span + Local"
            ],
            [
                "Span + Seq. (tau = 0.5)"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "P"
            ],
            [
                "R"
            ],
            [
                "F"
            ]
        ],
        "contents": [
            [
                "37.8",
                "43.7",
                "40.6"
            ],
            [
                "39.6",
                "45.8",
                "42.4"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "P",
            "R",
            "F"
        ],
        "target_entity": [
            "Span + Seq. (tau = 0.5)"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>P</th>      <th>R</th>      <th>F</th>    </tr>  </thead>  <tbody>    <tr>      <td>Span + Local</td>      <td>37.8</td>      <td>43.7</td>      <td>40.6</td>    </tr>    <tr>      <td>Span + Seq. (tau = 0.5)</td>      <td>39.6</td>      <td>45.8</td>      <td>42.4</td>    </tr>  </tbody></table>",
        "table_name": "Table 6",
        "table_id": "table_6",
        "paper_id": "P18-1191",
        "page_no": 6,
        "dir": "acl2018",
        "valid": 1
    },
    {
        "table_id_paper": "P18-1211table_2",
        "caption": "Performance of our approach on sentence ordering dataset from Barzilay and Lapata (2008).",
        "row_header_level": 2,
        "row_headers": [
            [
                "-",
                "Sequential CG"
            ],
            [
                "-",
                "VLV-GM (2017)"
            ],
            [
                "-",
                "HMM (2012)"
            ],
            [
                "-",
                "HMM+Entity (2012)"
            ],
            [
                "-",
                "HMM+Content (2012)"
            ],
            [
                "Discriminative approaches",
                "DM (2017)"
            ],
            [
                "Discriminative approaches",
                "Recursive (2014)"
            ],
            [
                "Discriminative approaches",
                "Entity-Grid (2008)"
            ],
            [
                "Discriminative approaches",
                "Graph (2013)"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "Accidents"
            ],
            [
                "Earthquakes"
            ]
        ],
        "contents": [
            [
                "0.813",
                "0.946"
            ],
            [
                "0.77",
                "0.931"
            ],
            [
                "0.822",
                "0.938"
            ],
            [
                "0.842",
                "0.911"
            ],
            [
                "0.742",
                "0.953"
            ],
            [
                "0.93",
                "0.992"
            ],
            [
                "0.864",
                "0.976"
            ],
            [
                "0.904",
                "0.872"
            ],
            [
                "0.846",
                "0.635"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "accuracy",
            "accuracy"
        ],
        "target_entity": [
            "Sequential CG"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Accidents</th>      <th>Earthquakes</th>    </tr>  </thead>  <tbody>    <tr>      <td>- || Sequential CG</td>      <td>0.813</td>      <td>0.946</td>    </tr>    <tr>      <td>- || VLV-GM (2017)</td>      <td>0.77</td>      <td>0.931</td>    </tr>    <tr>      <td>- || HMM (2012)</td>      <td>0.822</td>      <td>0.938</td>    </tr>    <tr>      <td>- || HMM+Entity (2012)</td>      <td>0.842</td>      <td>0.911</td>    </tr>    <tr>      <td>- || HMM+Content (2012)</td>      <td>0.742</td>      <td>0.953</td>    </tr>    <tr>      <td>Discriminative approaches || DM (2017)</td>      <td>0.93</td>      <td>0.992</td>    </tr>    <tr>      <td>Discriminative approaches || Recursive (2014)</td>      <td>0.864</td>      <td>0.976</td>    </tr>    <tr>      <td>Discriminative approaches || Entity-Grid (2008)</td>      <td>0.904</td>      <td>0.872</td>    </tr>    <tr>      <td>Discriminative approaches || Graph (2013)</td>      <td>0.846</td>      <td>0.635</td>    </tr>  </tbody></table>",
        "table_name": "Table 2",
        "table_id": "table_2",
        "paper_id": "P18-1211",
        "page_no": 8,
        "dir": "acl2018",
        "valid": 1
    },
    {
        "table_id_paper": "P18-1230table_3",
        "caption": "F1-score (%) of different passes from 1 to 5 on the test data sets. It shows that appropriate number of passes can boost the performance as well as avoid over-fitting of the model.",
        "row_header_level": 2,
        "row_headers": [
            [
                "Pass",
                "1"
            ],
            [
                "Pass",
                "2"
            ],
            [
                "Pass",
                "3"
            ],
            [
                "Pass",
                "4"
            ],
            [
                "Pass",
                "5"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "SE2"
            ],
            [
                "SE3"
            ],
            [
                "SE13"
            ],
            [
                "SE15"
            ],
            [
                "ALL"
            ]
        ],
        "contents": [
            [
                "71.6",
                "70.3",
                "67.0",
                "72.5",
                "70.3"
            ],
            [
                "71.9",
                "70.2",
                "67.1",
                "72.8",
                "70.4"
            ],
            [
                "72.2",
                "70.5",
                "67.2",
                "72.6",
                "70.6"
            ],
            [
                "72.1",
                "70.4",
                "67.2",
                "72.4",
                "70.5"
            ],
            [
                "72.0",
                "70.4",
                "67.1",
                "71.5",
                "70.3"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "F1-score",
            "F1-score",
            "F1-score",
            "F1-score",
            "F1-score"
        ],
        "target_entity": [
            "Pass"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>SE2</th>      <th>SE3</th>      <th>SE13</th>      <th>SE15</th>      <th>ALL</th>    </tr>  </thead>  <tbody>    <tr>      <td>Pass || 1</td>      <td>71.6</td>      <td>70.3</td>      <td>67.0</td>      <td>72.5</td>      <td>70.3</td>    </tr>    <tr>      <td>Pass || 2</td>      <td>71.9</td>      <td>70.2</td>      <td>67.1</td>      <td>72.8</td>      <td>70.4</td>    </tr>    <tr>      <td>Pass || 3</td>      <td>72.2</td>      <td>70.5</td>      <td>67.2</td>      <td>72.6</td>      <td>70.6</td>    </tr>    <tr>      <td>Pass || 4</td>      <td>72.1</td>      <td>70.4</td>      <td>67.2</td>      <td>72.4</td>      <td>70.5</td>    </tr>    <tr>      <td>Pass || 5</td>      <td>72.0</td>      <td>70.4</td>      <td>67.1</td>      <td>71.5</td>      <td>70.3</td>    </tr>  </tbody></table>",
        "table_name": "Table 3",
        "table_id": "table_3",
        "paper_id": "P18-1230",
        "page_no": 8,
        "dir": "acl2018",
        "valid": 1
    },
    {
        "table_id_paper": "P18-1238table_2",
        "caption": "Human evaluation results on a sample from Conceptual Captions.",
        "row_header_level": 1,
        "row_headers": [
            [
                "Conceptual Captions"
            ]
        ],
        "column_header_level": 2,
        "column_headers": [
            [
                "GOOD (out of 3)",
                "1+"
            ],
            [
                "GOOD (out of 3)",
                "2+"
            ],
            [
                "GOOD (out of 3)",
                "3"
            ]
        ],
        "contents": [
            [
                "96.9%",
                "90.3%",
                "78.5%"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "GOOD (out of 3)",
            "GOOD (out of 3)",
            "GOOD (out of 3)"
        ],
        "target_entity": [
            "Conceptual Captions"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>GOOD (out of 3) || 1+</th>      <th>GOOD (out of 3) || 2+</th>      <th>GOOD (out of 3) || 3</th>    </tr>  </thead>  <tbody>    <tr>      <td>Conceptual Captions</td>      <td>96.9%</td>      <td>90.3%</td>      <td>78.5%</td>    </tr>  </tbody></table>",
        "table_name": "Table 2",
        "table_id": "table_2",
        "paper_id": "P18-1238",
        "page_no": 6,
        "dir": "acl2018",
        "valid": 1
    },
    {
        "table_id_paper": "P18-1239table_1",
        "caption": "The proportion of images determined to be good representations of their corresponding word. In columns 2-5, we bucket the results by the word\u2019s ground-truth concreteness, while column 6 shows the results over all words. The last row shows the number of words in each bucket of concreteness, and the number of words overall for each language.",
        "row_header_level": 2,
        "row_headers": [
            [
                "Language",
                "English"
            ],
            [
                "Language",
                "French"
            ],
            [
                "Language",
                "Indonesian"
            ],
            [
                "Language",
                "Uzbek"
            ],
            [
                "Language",
                "All"
            ],
            [
                "-",
                "# Words"
            ]
        ],
        "column_header_level": 2,
        "column_headers": [
            [
                "Concreteness Ratings",
                "1-2"
            ],
            [
                "Concreteness Ratings",
                "2-3"
            ],
            [
                "Concreteness Ratings",
                "3-4"
            ],
            [
                "Concreteness Ratings",
                "4-5"
            ],
            [
                "Concreteness Ratings",
                "Overall"
            ]
        ],
        "contents": [
            [
                "0.804",
                "0.814",
                "0.855",
                "0.913",
                "0.857"
            ],
            [
                "0.622",
                "0.653",
                "0.706",
                "0.828",
                "0.721"
            ],
            [
                "0.505",
                "0.569",
                "0.665",
                "0.785",
                "0.661"
            ],
            [
                "0.568",
                "0.53",
                "0.594",
                "0.683",
                "0.601"
            ],
            [
                "0.628",
                "0.649",
                "0.713",
                "0.81",
                "0.717"
            ],
            [
                "77",
                "292",
                "292",
                "302",
                "963"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "Concreteness Ratings",
            "Concreteness Ratings",
            "Concreteness Ratings",
            "Concreteness Ratings",
            "Concreteness Ratings"
        ],
        "target_entity": [
            "Concreteness Ratings"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Concreteness Ratings || 1-2</th>      <th>Concreteness Ratings || 2-3</th>      <th>Concreteness Ratings || 3-4</th>      <th>Concreteness Ratings || 4-5</th>      <th>Concreteness Ratings || Overall</th>    </tr>  </thead>  <tbody>    <tr>      <td>Language || English</td>      <td>0.804</td>      <td>0.814</td>      <td>0.855</td>      <td>0.913</td>      <td>0.857</td>    </tr>    <tr>      <td>Language || French</td>      <td>0.622</td>      <td>0.653</td>      <td>0.706</td>      <td>0.828</td>      <td>0.721</td>    </tr>    <tr>      <td>Language || Indonesian</td>      <td>0.505</td>      <td>0.569</td>      <td>0.665</td>      <td>0.785</td>      <td>0.661</td>    </tr>    <tr>      <td>Language || Uzbek</td>      <td>0.568</td>      <td>0.53</td>      <td>0.594</td>      <td>0.683</td>      <td>0.601</td>    </tr>    <tr>      <td>Language || All</td>      <td>0.628</td>      <td>0.649</td>      <td>0.713</td>      <td>0.81</td>      <td>0.717</td>    </tr>    <tr>      <td>- || # Words</td>      <td>77</td>      <td>292</td>      <td>292</td>      <td>302</td>      <td>963</td>    </tr>  </tbody></table>",
        "table_name": "Table 1",
        "table_id": "table_1",
        "paper_id": "P18-1239",
        "page_no": 4,
        "dir": "acl2018",
        "valid": 1
    },
    {
        "table_id_paper": "P18-2009table_3",
        "caption": "Results on the triplets data",
        "row_header_level": 2,
        "row_headers": [
            [
                "Method",
                "mean-vectors"
            ],
            [
                "Method",
                "skip-thoughts-CS"
            ],
            [
                "Method",
                "skip-thoughts-SICK"
            ],
            [
                "Method",
                "triplets-sen"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "accuracy"
            ]
        ],
        "contents": [
            [
                "0.65"
            ],
            [
                "0.615"
            ],
            [
                "0.547"
            ],
            [
                "0.74"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "accuracy"
        ],
        "target_entity": [
            "triplets-sen"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>accuracy</th>    </tr>  </thead>  <tbody>    <tr>      <td>Method || mean-vectors</td>      <td>0.65</td>    </tr>    <tr>      <td>Method || skip-thoughts-CS</td>      <td>0.615</td>    </tr>    <tr>      <td>Method || skip-thoughts-SICK</td>      <td>0.547</td>    </tr>    <tr>      <td>Method || triplets-sen</td>      <td>0.74</td>    </tr>  </tbody></table>",
        "table_name": "Table 3",
        "table_id": "table_3",
        "paper_id": "P18-2009",
        "page_no": 4,
        "dir": "acl2018",
        "valid": 1
    },
    {
        "table_id_paper": "P18-2015table_3",
        "caption": "Performance (AUCPR) of each noise reduction method; in bold are the best scores.",
        "row_header_level": 2,
        "row_headers": [
            [
                "System",
                "CNN+ONE"
            ],
            [
                "System",
                "CNN+ATT"
            ],
            [
                "System",
                "PCNN+ONE"
            ],
            [
                "System",
                "PCNN+ATT"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "Original"
            ],
            [
                "Original+HITS"
            ],
            [
                "Original+LSA"
            ],
            [
                "Original+NMF"
            ],
            [
                "Original+Ensemble"
            ]
        ],
        "contents": [
            [
                "0.18",
                "0.183",
                "0.173",
                "0.178",
                "0.181"
            ],
            [
                "0.234",
                "0.235",
                "0.235",
                "0.233",
                "0.236"
            ],
            [
                "0.231",
                "0.234",
                "0.233",
                "0.234",
                "0.235"
            ],
            [
                "0.248",
                "0.253",
                "0.25",
                "0.252",
                "0.255"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "AUCPR",
            "AUCPR",
            "AUCPR",
            "AUCPR",
            "AUCPR"
        ],
        "target_entity": [
            "Original+HITS",
            "Original+Ensemble"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Original</th>      <th>Original+HITS</th>      <th>Original+LSA</th>      <th>Original+NMF</th>      <th>Original+Ensemble</th>    </tr>  </thead>  <tbody>    <tr>      <td>System || CNN+ONE</td>      <td>0.18</td>      <td>0.183</td>      <td>0.173</td>      <td>0.178</td>      <td>0.181</td>    </tr>    <tr>      <td>System || CNN+ATT</td>      <td>0.234</td>      <td>0.235</td>      <td>0.235</td>      <td>0.233</td>      <td>0.236</td>    </tr>    <tr>      <td>System || PCNN+ONE</td>      <td>0.231</td>      <td>0.234</td>      <td>0.233</td>      <td>0.234</td>      <td>0.235</td>    </tr>    <tr>      <td>System || PCNN+ATT</td>      <td>0.248</td>      <td>0.253</td>      <td>0.25</td>      <td>0.252</td>      <td>0.255</td>    </tr>  </tbody></table>",
        "table_name": "Table 3",
        "table_id": "table_3",
        "paper_id": "P18-2015",
        "page_no": 5,
        "dir": "acl2018",
        "valid": 1
    },
    {
        "table_id_paper": "P18-2022table_1",
        "caption": "Average alignment performance across images. MSFC provides the best recall and lowest AER, and modified k-means the best precision. In all cases, the alignment framework yields stronger results than either of the timing-based baselines.",
        "row_header_level": 1,
        "row_headers": [
            [
                "Simultaneous"
            ],
            [
                "1-second delay"
            ],
            [
                "Alignment framework"
            ]
        ],
        "column_header_level": 2,
        "column_headers": [
            [
                "MSFC",
                "Precision"
            ],
            [
                "MSFC",
                "Recall"
            ],
            [
                "MSFC",
                "AER"
            ],
            [
                "Modified k-means",
                "Precision"
            ],
            [
                "Modified k-means",
                "Recall"
            ],
            [
                "Modified k-means",
                "AER"
            ]
        ],
        "contents": [
            [
                "0.42",
                "0.30",
                "0.65",
                "0.49",
                "0.17",
                "0.74"
            ],
            [
                "0.43",
                "0.31",
                "0.64",
                "0.50",
                "0.17",
                "0.74"
            ],
            [
                "0.43",
                "0.50",
                "0.54",
                "0.56",
                "0.31",
                "0.60"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "Precision",
            "Recall",
            "AER",
            "Precision",
            "Recall",
            "AER"
        ],
        "target_entity": [
            "Alignment framework"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>MSFC || Precision</th>      <th>MSFC || Recall</th>      <th>MSFC || AER</th>      <th>Modified k-means || Precision</th>      <th>Modified k-means || Recall</th>      <th>Modified k-means || AER</th>    </tr>  </thead>  <tbody>    <tr>      <td>Simultaneous</td>      <td>0.42</td>      <td>0.30</td>      <td>0.65</td>      <td>0.49</td>      <td>0.17</td>      <td>0.74</td>    </tr>    <tr>      <td>1-second delay</td>      <td>0.43</td>      <td>0.31</td>      <td>0.64</td>      <td>0.50</td>      <td>0.17</td>      <td>0.74</td>    </tr>    <tr>      <td>Alignment framework</td>      <td>0.43</td>      <td>0.50</td>      <td>0.54</td>      <td>0.56</td>      <td>0.31</td>      <td>0.60</td>    </tr>  </tbody></table>",
        "table_name": "Table 1",
        "table_id": "table_1",
        "paper_id": "P18-2022",
        "page_no": 5,
        "dir": "acl2018",
        "valid": 1
    },
    {
        "table_id_paper": "P19-1013table_8",
        "caption": "Results on math problems (\u00a75.5).",
        "row_header_level": 2,
        "row_headers": [
            [
                "Method",
                "depccg"
            ],
            [
                "Method",
                "+ ELMo"
            ],
            [
                "Method",
                "+ Proposed"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "UF1"
            ],
            [
                "LF1"
            ]
        ],
        "contents": [
            [
                "88.49",
                "66.15"
            ],
            [
                "89.32",
                "70.74"
            ],
            [
                "95.83",
                "80.53"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "UF1",
            "LF1"
        ],
        "target_entity": [
            "+ Proposed"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>UF1</th>      <th>LF1</th>    </tr>  </thead>  <tbody>    <tr>      <td>Method || depccg</td>      <td>88.49</td>      <td>66.15</td>    </tr>    <tr>      <td>Method || + ELMo</td>      <td>89.32</td>      <td>70.74</td>    </tr>    <tr>      <td>Method || + Proposed</td>      <td>95.83</td>      <td>80.53</td>    </tr>  </tbody></table>",
        "table_name": "Table 8",
        "table_id": "table_8",
        "paper_id": "P19-1013",
        "page_no": 9,
        "dir": "acl2019",
        "valid": 1
    },
    {
        "table_id_paper": "P19-1046table_4",
        "caption": "Unimodal, Bimodal and Trimodal Results of HFFN. Here, L, A and V denotes language, acoustic and visual modalities, respectively.",
        "row_header_level": 2,
        "row_headers": [
            [
                "Methods",
                "L"
            ],
            [
                "Methods",
                "A"
            ],
            [
                "Methods",
                "V"
            ],
            [
                "Methods",
                "L+A"
            ],
            [
                "Methods",
                "L+V"
            ],
            [
                "Methods",
                "A+V"
            ],
            [
                "Methods",
                "L+A+V"
            ]
        ],
        "column_header_level": 2,
        "column_headers": [
            [
                "CMU-MOSI",
                "Acc"
            ],
            [
                "CMU-MOSI",
                "F1"
            ],
            [
                "IEMOCAP",
                "Acc"
            ],
            [
                "IEMOCAP",
                "F1"
            ]
        ],
        "contents": [
            [
                "78.59",
                "78.52",
                "81.46",
                "81.54"
            ],
            [
                "48.14",
                "48.3",
                "38.08",
                "38.17"
            ],
            [
                "56.97",
                "57.48",
                "34.52",
                "29.15"
            ],
            [
                "78.06",
                "78.29",
                "80.38",
                "80.6"
            ],
            [
                "79.39",
                "79.38",
                "80.05",
                "80.26"
            ],
            [
                "55.17",
                "55.76",
                "55.17",
                "55.79"
            ],
            [
                "80.19",
                "80.34",
                "82.37",
                "82.42"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "Acc",
            "F1",
            "Acc",
            "F1"
        ],
        "target_entity": [
            "L+A+V"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>CMU-MOSI || Acc</th>      <th>CMU-MOSI || F1</th>      <th>IEMOCAP || Acc</th>      <th>IEMOCAP || F1</th>    </tr>  </thead>  <tbody>    <tr>      <td>Methods || L</td>      <td>78.59</td>      <td>78.52</td>      <td>81.46</td>      <td>81.54</td>    </tr>    <tr>      <td>Methods || A</td>      <td>48.14</td>      <td>48.3</td>      <td>38.08</td>      <td>38.17</td>    </tr>    <tr>      <td>Methods || V</td>      <td>56.97</td>      <td>57.48</td>      <td>34.52</td>      <td>29.15</td>    </tr>    <tr>      <td>Methods || L+A</td>      <td>78.06</td>      <td>78.29</td>      <td>80.38</td>      <td>80.6</td>    </tr>    <tr>      <td>Methods || L+V</td>      <td>79.39</td>      <td>79.38</td>      <td>80.05</td>      <td>80.26</td>    </tr>    <tr>      <td>Methods || A+V</td>      <td>55.17</td>      <td>55.76</td>      <td>55.17</td>      <td>55.79</td>    </tr>    <tr>      <td>Methods || L+A+V</td>      <td>80.19</td>      <td>80.34</td>      <td>82.37</td>      <td>82.42</td>    </tr>  </tbody></table>",
        "table_name": "Table 4",
        "table_id": "table_4",
        "paper_id": "P19-1046",
        "page_no": 8,
        "dir": "acl2019",
        "valid": 1
    },
    {
        "table_id_paper": "P19-1064table_2",
        "caption": "The overall mention detection results on the test set of OntoNotes. The F1 improvement is statistically significant under t-test with p < 0.05.",
        "row_header_level": 2,
        "row_headers": [
            [
                "Model",
                "Our full model"
            ],
            [
                "Model",
                "Lee et al. (2018)"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "Prec."
            ],
            [
                "Rec."
            ],
            [
                "F1"
            ]
        ],
        "contents": [
            [
                "89.6",
                "82.2",
                "85.7"
            ],
            [
                "86.2",
                "83.7",
                "84.9"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "Prec.",
            "Rec.",
            "F1"
        ],
        "target_entity": null,
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Prec.</th>      <th>Rec.</th>      <th>F1</th>    </tr>  </thead>  <tbody>    <tr>      <td>Model || Our full model</td>      <td>89.6</td>      <td>82.2</td>      <td>85.7</td>    </tr>    <tr>      <td>Model || Lee et al. (2018)</td>      <td>86.2</td>      <td>83.7</td>      <td>84.9</td>    </tr>  </tbody></table>",
        "table_name": "Table 2",
        "table_id": "table_2",
        "paper_id": "P19-1064",
        "page_no": 5,
        "dir": "acl2019",
        "valid": 1
    },
    {
        "table_id_paper": "P19-1117table_2",
        "caption": "Translation performance on one-to-two, one-to-three and one-to-four translation tasks. Rep denotes our proposed representor. Emb, Attn, and Dis represent our proposed language-sensitive methods to address multilingual translation. Note that the source language of all our experiments is English.",
        "row_header_level": 2,
        "row_headers": [
            [
                "One-to-Two",
                "De"
            ],
            [
                "One-to-Two",
                "Lv"
            ],
            [
                "One-to-Two",
                "De"
            ],
            [
                "One-to-Two",
                "Fi"
            ],
            [
                "One-to-Two",
                "De"
            ],
            [
                "One-to-Two",
                "Zh"
            ],
            [
                "One-to-Three",
                "De"
            ],
            [
                "One-to-Three",
                "Zh"
            ],
            [
                "One-to-Three",
                "Fi"
            ],
            [
                "One-to-Three",
                "De"
            ],
            [
                "One-to-Three",
                "Lv"
            ],
            [
                "One-to-Three",
                "Fi"
            ],
            [
                "One-to-Four",
                "De"
            ],
            [
                "One-to-Four",
                "Lv"
            ],
            [
                "One-to-Four",
                "Zh"
            ],
            [
                "One-to-Four",
                "Fi"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "NMT Baselines"
            ],
            [
                "Multi-NMT Baselines Johnson et al.(2017)"
            ],
            [
                "Three-Stgy Wang et al.(2018)"
            ],
            [
                "Rep+Emb"
            ],
            [
                "Rep+Emb+Attn"
            ],
            [
                "Rep+Emb+Attn+Dis"
            ]
        ],
        "contents": [
            [
                "27.5",
                "27.26",
                "27.35",
                "26.6",
                "26.96",
                "27.74"
            ],
            [
                "16.28",
                "16.32",
                "16.38",
                "15.37",
                "15.87",
                "16.79"
            ],
            [
                "27.5",
                "27.88",
                "27.89",
                "26.96",
                "27.32",
                "27.96"
            ],
            [
                "16.83",
                "16.47",
                "16.7",
                "15.78",
                "16.58",
                "16.89"
            ],
            [
                "27.5",
                "26.8",
                "26.99",
                "26.08",
                "26.68",
                "27.45"
            ],
            [
                "26.04",
                "25.54",
                "25.78",
                "24.48",
                "25.33",
                "26.17"
            ],
            [
                "27.5",
                "25.44",
                "25.55",
                "24.82",
                "25.45",
                "26.06"
            ],
            [
                "26.04",
                "24.87",
                "25.63",
                "24.12",
                "24.93",
                "26.12"
            ],
            [
                "16.83",
                "16.86",
                "16.97",
                "16.06",
                "16.78",
                "17.12"
            ],
            [
                "27.5",
                "25.98",
                "26.12",
                "24.88",
                "25.8",
                "26.42"
            ],
            [
                "16.28",
                "14.88",
                "15.44",
                "14.51",
                "15.58",
                "16.31"
            ],
            [
                "16.83",
                "16.94",
                "17.05",
                "16.15",
                "16.79",
                "17.22"
            ],
            [
                "27.5",
                "23.59",
                "22.88",
                "22.88",
                "23.58",
                "24.08"
            ],
            [
                "16.28",
                "15.57",
                "16.02",
                "15",
                "16.21",
                "16.57"
            ],
            [
                "26.04",
                "25.24",
                "25.83",
                "24.15",
                "25.27",
                "26.29"
            ],
            [
                "16.83",
                "13.45",
                "14.12",
                "12.99",
                "14.11",
                "15.03"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "BLEU",
            "BLEU",
            "BLEU",
            "BLEU",
            "BLEU",
            "BLEU"
        ],
        "target_entity": [
            "Rep+Emb+Attn+Dis"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>NMT Baselines</th>      <th>Multi-NMT Baselines Johnson et al.(2017)</th>      <th>Three-Stgy Wang et al.(2018)</th>      <th>Rep+Emb</th>      <th>Rep+Emb+Attn</th>      <th>Rep+Emb+Attn+Dis</th>    </tr>  </thead>  <tbody>    <tr>      <td>One-to-Two || De</td>      <td>27.5</td>      <td>27.26</td>      <td>27.35</td>      <td>26.6</td>      <td>26.96</td>      <td>27.74</td>    </tr>    <tr>      <td>One-to-Two || Lv</td>      <td>16.28</td>      <td>16.32</td>      <td>16.38</td>      <td>15.37</td>      <td>15.87</td>      <td>16.79</td>    </tr>    <tr>      <td>One-to-Two || De</td>      <td>27.5</td>      <td>27.88</td>      <td>27.89</td>      <td>26.96</td>      <td>27.32</td>      <td>27.96</td>    </tr>    <tr>      <td>One-to-Two || Fi</td>      <td>16.83</td>      <td>16.47</td>      <td>16.7</td>      <td>15.78</td>      <td>16.58</td>      <td>16.89</td>    </tr>    <tr>      <td>One-to-Two || De</td>      <td>27.5</td>      <td>26.8</td>      <td>26.99</td>      <td>26.08</td>      <td>26.68</td>      <td>27.45</td>    </tr>    <tr>      <td>One-to-Two || Zh</td>      <td>26.04</td>      <td>25.54</td>      <td>25.78</td>      <td>24.48</td>      <td>25.33</td>      <td>26.17</td>    </tr>    <tr>      <td>One-to-Three || De</td>      <td>27.5</td>      <td>25.44</td>      <td>25.55</td>      <td>24.82</td>      <td>25.45</td>      <td>26.06</td>    </tr>    <tr>      <td>One-to-Three || Zh</td>      <td>26.04</td>      <td>24.87</td>      <td>25.63</td>      <td>24.12</td>      <td>24.93</td>      <td>26.12</td>    </tr>    <tr>      <td>One-to-Three || Fi</td>      <td>16.83</td>      <td>16.86</td>      <td>16.97</td>      <td>16.06</td>      <td>16.78</td>      <td>17.12</td>    </tr>    <tr>      <td>One-to-Three || De</td>      <td>27.5</td>      <td>25.98</td>      <td>26.12</td>      <td>24.88</td>      <td>25.8</td>      <td>26.42</td>    </tr>    <tr>      <td>One-to-Three || Lv</td>      <td>16.28</td>      <td>14.88</td>      <td>15.44</td>      <td>14.51</td>      <td>15.58</td>      <td>16.31</td>    </tr>    <tr>      <td>One-to-Three || Fi</td>      <td>16.83</td>      <td>16.94</td>      <td>17.05</td>      <td>16.15</td>      <td>16.79</td>      <td>17.22</td>    </tr>    <tr>      <td>One-to-Four || De</td>      <td>27.5</td>      <td>23.59</td>      <td>22.88</td>      <td>22.88</td>      <td>23.58</td>      <td>24.08</td>    </tr>    <tr>      <td>One-to-Four || Lv</td>      <td>16.28</td>      <td>15.57</td>      <td>16.02</td>      <td>15</td>      <td>16.21</td>      <td>16.57</td>    </tr>    <tr>      <td>One-to-Four || Zh</td>      <td>26.04</td>      <td>25.24</td>      <td>25.83</td>      <td>24.15</td>      <td>25.27</td>      <td>26.29</td>    </tr>    <tr>      <td>One-to-Four || Fi</td>      <td>16.83</td>      <td>13.45</td>      <td>14.12</td>      <td>12.99</td>      <td>14.11</td>      <td>15.03</td>    </tr>  </tbody></table>",
        "table_name": "Table 2",
        "table_id": "table_2",
        "paper_id": "P19-1117",
        "page_no": 6,
        "dir": "acl2019",
        "valid": 1
    },
    {
        "table_id_paper": "P19-1134table_1",
        "caption": "Precision evaluated automatically for the top rated relation instances. \u2020 marks results reported in the original paper. \u2021 marks our results using the OpenNRE implementation.",
        "row_header_level": 2,
        "row_headers": [
            [
                "System",
                "Mintz"
            ],
            [
                "System",
                "PCNN+ATT"
            ],
            [
                "System",
                "RESIDE"
            ],
            [
                "System",
                "DISTRE"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "AUC"
            ],
            [
                "P@100"
            ],
            [
                "P@200"
            ],
            [
                "P@300"
            ],
            [
                "P@500"
            ],
            [
                "P@1000"
            ],
            [
                "P@2000"
            ]
        ],
        "contents": [
            [
                "0.107",
                "52.3",
                "50.2",
                "45",
                "39.7",
                "33.6",
                "23.4"
            ],
            [
                "0.341",
                "73",
                "68",
                "67.3",
                "63.6",
                "53.3",
                "40"
            ],
            [
                "0.415",
                "81.8",
                "75.4",
                "74.3",
                "69.7",
                "59.3",
                "45"
            ],
            [
                "0.422",
                "68",
                "67",
                "65.3",
                "65",
                "60.2",
                "47.9"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "AUC",
            "P@100",
            "P@200",
            "P@300",
            "P@500",
            "P@1000",
            "P@2000"
        ],
        "target_entity": [
            "DISTRE"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>AUC</th>      <th>P@100</th>      <th>P@200</th>      <th>P@300</th>      <th>P@500</th>      <th>P@1000</th>      <th>P@2000</th>    </tr>  </thead>  <tbody>    <tr>      <td>System || Mintz</td>      <td>0.107</td>      <td>52.3</td>      <td>50.2</td>      <td>45</td>      <td>39.7</td>      <td>33.6</td>      <td>23.4</td>    </tr>    <tr>      <td>System || PCNN+ATT</td>      <td>0.341</td>      <td>73</td>      <td>68</td>      <td>67.3</td>      <td>63.6</td>      <td>53.3</td>      <td>40</td>    </tr>    <tr>      <td>System || RESIDE</td>      <td>0.415</td>      <td>81.8</td>      <td>75.4</td>      <td>74.3</td>      <td>69.7</td>      <td>59.3</td>      <td>45</td>    </tr>    <tr>      <td>System || DISTRE</td>      <td>0.422</td>      <td>68</td>      <td>67</td>      <td>65.3</td>      <td>65</td>      <td>60.2</td>      <td>47.9</td>    </tr>  </tbody></table>",
        "table_name": "Table 1",
        "table_id": "table_1",
        "paper_id": "P19-1134",
        "page_no": 6,
        "dir": "acl2019",
        "valid": 1
    },
    {
        "table_id_paper": "P19-1170table_2",
        "caption": "Comparisons without post-processing of methods. Results reproduced from (Smith et al., 2017) for fair comparison. Left: Comparisons using the same expert dictionary as (Smith et al., 2017). Right: Comparisons using the pseudo-dictionary from (Smith et al., 2017).",
        "row_header_level": 2,
        "row_headers": [
            [
                "Methods",
                "Mikolov et. al."
            ],
            [
                "Methods",
                "CCA (Sklearn)"
            ],
            [
                "Methods",
                "CCA"
            ],
            [
                "Methods",
                "SVD"
            ],
            [
                "Methods",
                "IBFA (Ours)"
            ]
        ],
        "column_header_level": 2,
        "column_headers": [
            [
                "English to Italian",
                "@1"
            ],
            [
                "English to Italian",
                "@5"
            ],
            [
                "English to Italian",
                "@10"
            ],
            [
                "Italian to English",
                "@1"
            ],
            [
                "Italian to English",
                "@5"
            ],
            [
                "Italian to English",
                "@10"
            ],
            [
                "English to Italian",
                "@1"
            ],
            [
                "English to Italian",
                "@5"
            ],
            [
                "English to Italian",
                "@10"
            ],
            [
                "Italian to English",
                "@1"
            ],
            [
                "Italian to English",
                "@5"
            ],
            [
                "Italian to English",
                "@10"
            ]
        ],
        "contents": [
            [
                "33.8",
                "48.3",
                "53.9",
                "24.9",
                "41",
                "47.4",
                "1",
                "2.8",
                "3.9",
                "2.5",
                "6.4",
                "9.1"
            ],
            [
                "36.1",
                "52.7",
                "58.1",
                "31",
                "49.9",
                "57",
                "29.1",
                "46.4",
                "53",
                "27",
                "47",
                "52.3"
            ],
            [
                "30.9",
                "48.1",
                "52.7",
                "27.7",
                "45.5",
                "51",
                "26.5",
                "42.5",
                "48.1",
                "22.8",
                "40.1",
                "45.5"
            ],
            [
                "36.9",
                "52.7",
                "57.9",
                "32.2",
                "49.6",
                "55.7",
                "27.1",
                "43.4",
                "49.3",
                "26.2",
                "42.1",
                "49"
            ],
            [
                "39.3",
                "55.3",
                "60.1",
                "34.7",
                "53.5",
                "59.4",
                "34.7",
                "52.6",
                "58.3",
                "33.7",
                "53.3",
                "59.2"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "@1",
            "@5",
            "@10",
            "@1",
            "@5",
            "@10",
            "@1",
            "@5",
            "@10",
            "@1",
            "@5",
            "@10"
        ],
        "target_entity": [
            "IBFA (Ours)"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>English to Italian || @1</th>      <th>English to Italian || @5</th>      <th>English to Italian || @10</th>      <th>Italian to English || @1</th>      <th>Italian to English || @5</th>      <th>Italian to English || @10</th>      <th>English to Italian || @1</th>      <th>English to Italian || @5</th>      <th>English to Italian || @10</th>      <th>Italian to English || @1</th>      <th>Italian to English || @5</th>      <th>Italian to English || @10</th>    </tr>  </thead>  <tbody>    <tr>      <td>Methods || Mikolov et. al.</td>      <td>33.8</td>      <td>48.3</td>      <td>53.9</td>      <td>24.9</td>      <td>41</td>      <td>47.4</td>      <td>1</td>      <td>2.8</td>      <td>3.9</td>      <td>2.5</td>      <td>6.4</td>      <td>9.1</td>    </tr>    <tr>      <td>Methods || CCA (Sklearn)</td>      <td>36.1</td>      <td>52.7</td>      <td>58.1</td>      <td>31</td>      <td>49.9</td>      <td>57</td>      <td>29.1</td>      <td>46.4</td>      <td>53</td>      <td>27</td>      <td>47</td>      <td>52.3</td>    </tr>    <tr>      <td>Methods || CCA</td>      <td>30.9</td>      <td>48.1</td>      <td>52.7</td>      <td>27.7</td>      <td>45.5</td>      <td>51</td>      <td>26.5</td>      <td>42.5</td>      <td>48.1</td>      <td>22.8</td>      <td>40.1</td>      <td>45.5</td>    </tr>    <tr>      <td>Methods || SVD</td>      <td>36.9</td>      <td>52.7</td>      <td>57.9</td>      <td>32.2</td>      <td>49.6</td>      <td>55.7</td>      <td>27.1</td>      <td>43.4</td>      <td>49.3</td>      <td>26.2</td>      <td>42.1</td>      <td>49</td>    </tr>    <tr>      <td>Methods || IBFA (Ours)</td>      <td>39.3</td>      <td>55.3</td>      <td>60.1</td>      <td>34.7</td>      <td>53.5</td>      <td>59.4</td>      <td>34.7</td>      <td>52.6</td>      <td>58.3</td>      <td>33.7</td>      <td>53.3</td>      <td>59.2</td>    </tr>  </tbody></table>",
        "table_name": "Table 2",
        "table_id": "table_2",
        "paper_id": "P19-1170",
        "page_no": 6,
        "dir": "acl2019",
        "valid": 1
    },
    {
        "table_id_paper": "P19-1193table_4",
        "caption": "Human evaluations of ablation study.",
        "row_header_level": 2,
        "row_headers": [
            [
                "Methods",
                "Full model"
            ],
            [
                "Methods",
                "w/o Adversarial"
            ],
            [
                "Methods",
                "w/o Memory"
            ],
            [
                "Methods",
                "w/o Dynamic"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "Consistency"
            ],
            [
                "Novelty"
            ],
            [
                "Diversity"
            ],
            [
                "Coherence"
            ]
        ],
        "contents": [
            [
                "3.84",
                "3.24",
                "3.16",
                "3.61"
            ],
            [
                "3.31",
                "3.07",
                "3.14",
                "3.43"
            ],
            [
                "3.53",
                "2.73",
                "2.77",
                "3.19"
            ],
            [
                "3.62",
                "2.91",
                "2.95",
                "3.37"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "Consistency",
            "Novelty",
            "Diversity",
            "Coherence"
        ],
        "target_entity": [
            "Methods"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Consistency</th>      <th>Novelty</th>      <th>Diversity</th>      <th>Coherence</th>    </tr>  </thead>  <tbody>    <tr>      <td>Methods || Full model</td>      <td>3.84</td>      <td>3.24</td>      <td>3.16</td>      <td>3.61</td>    </tr>    <tr>      <td>Methods || w/o Adversarial</td>      <td>3.31</td>      <td>3.07</td>      <td>3.14</td>      <td>3.43</td>    </tr>    <tr>      <td>Methods || w/o Memory</td>      <td>3.53</td>      <td>2.73</td>      <td>2.77</td>      <td>3.19</td>    </tr>    <tr>      <td>Methods || w/o Dynamic</td>      <td>3.62</td>      <td>2.91</td>      <td>2.95</td>      <td>3.37</td>    </tr>  </tbody></table>",
        "table_name": "Table 4",
        "table_id": "table_4",
        "paper_id": "P19-1193",
        "page_no": 7,
        "dir": "acl2019",
        "valid": 1
    },
    {
        "table_id_paper": "P19-1230table_2",
        "caption": "English dev set performance of joint span HPSG parsing. The converted means the corresponding dependency parsing results are from the corresponding constituent parse tree using head rules.",
        "row_header_level": 2,
        "row_headers": [
            [
                "Model",
                "separate constituent"
            ],
            [
                "Model",
                "converted dependency"
            ],
            [
                "Model",
                "HPSG Parser joint span lambda = 1.0"
            ],
            [
                "Model",
                "HPSG Parser joint span lambda = 0.0"
            ],
            [
                "Model",
                "HPSG Parser joint span lambda = 0.5"
            ],
            [
                "Model",
                "HPSG Parser converted dependency"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "F1"
            ],
            [
                "UAS"
            ],
            [
                "LAS"
            ]
        ],
        "contents": [
            [
                "93.47",
                "-",
                "-"
            ],
            [
                "93.47",
                "95.06",
                "93.81"
            ],
            [
                "93.67",
                "-",
                "-"
            ],
            [
                "-",
                "95.82",
                "94.43"
            ],
            [
                "93.78",
                "95.92",
                "94.49"
            ],
            [
                "93.78",
                "95.69",
                "94.45"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "F1",
            "UAS",
            "LAS"
        ],
        "target_entity": [
            "HPSG Parser joint span lambda = 1.0",
            "HPSG Parser joint span lambda = 0.0",
            "HPSG Parser joint span lambda = 0.5",
            "HPSG Parser converted dependency"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>F1</th>      <th>UAS</th>      <th>LAS</th>    </tr>  </thead>  <tbody>    <tr>      <td>Model || separate constituent</td>      <td>93.47</td>      <td>-</td>      <td>-</td>    </tr>    <tr>      <td>Model || converted dependency</td>      <td>93.47</td>      <td>95.06</td>      <td>93.81</td>    </tr>    <tr>      <td>Model || HPSG Parser joint span lambda = 1.0</td>      <td>93.67</td>      <td>-</td>      <td>-</td>    </tr>    <tr>      <td>Model || HPSG Parser joint span lambda = 0.0</td>      <td>-</td>      <td>95.82</td>      <td>94.43</td>    </tr>    <tr>      <td>Model || HPSG Parser joint span lambda = 0.5</td>      <td>93.78</td>      <td>95.92</td>      <td>94.49</td>    </tr>    <tr>      <td>Model || HPSG Parser converted dependency</td>      <td>93.78</td>      <td>95.69</td>      <td>94.45</td>    </tr>  </tbody></table>",
        "table_name": "Table 2",
        "table_id": "table_2",
        "paper_id": "P19-1230",
        "page_no": 7,
        "dir": "acl2019",
        "valid": 1
    },
    {
        "table_id_paper": "P19-1276table_5",
        "caption": "Averaged slot coherence results.",
        "row_header_level": 2,
        "row_headers": [
            [
                "Method",
                "Nguyen et al. (2015)"
            ],
            [
                "Method",
                "ODEE-F"
            ],
            [
                "Method",
                "ODEE-FE"
            ],
            [
                "Method",
                "ODEE-FER"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "Ave Slot Coherence"
            ]
        ],
        "contents": [
            [
                "0.1"
            ],
            [
                "0.1"
            ],
            [
                "0.16"
            ],
            [
                "0.18"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "Ave Slot Coherence"
        ],
        "target_entity": [
            "ODEE-F",
            "ODEE-FE",
            "ODEE-FER"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Ave Slot Coherence</th>    </tr>  </thead>  <tbody>    <tr>      <td>Method || Nguyen et al. (2015)</td>      <td>0.1</td>    </tr>    <tr>      <td>Method || ODEE-F</td>      <td>0.1</td>    </tr>    <tr>      <td>Method || ODEE-FE</td>      <td>0.16</td>    </tr>    <tr>      <td>Method || ODEE-FER</td>      <td>0.18</td>    </tr>  </tbody></table>",
        "table_name": "Table 5",
        "table_id": "table_5",
        "paper_id": "P19-1276",
        "page_no": 7,
        "dir": "acl2019",
        "valid": 1
    },
    {
        "table_id_paper": "P19-1290table_1",
        "caption": "Performance of various models on EN-DE and EN-FR translation tasks.",
        "row_header_level": 2,
        "row_headers": [
            [
                "Architecture",
                "Vaswani et al. (2017) Transformer big"
            ],
            [
                "Architecture",
                "Wu et al. (2018) Transformer big + sequence-loss"
            ],
            [
                "Architecture",
                "Yang et al. (2018) Transformer big + localness"
            ],
            [
                "Architecture",
                "this work Transformer big + hard-attention"
            ]
        ],
        "column_header_level": 2,
        "column_headers": [
            [
                "BLEU",
                "EN-DE"
            ],
            [
                "BLEU",
                "EN-FR"
            ]
        ],
        "contents": [
            [
                "28.4",
                "41"
            ],
            [
                "28.75",
                "41.47"
            ],
            [
                "28.89",
                "n/a"
            ],
            [
                "29.29",
                "42.26"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "BLEU",
            "BLEU"
        ],
        "target_entity": [
            "this work Transformer big + hard-attention"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>BLEU || EN-DE</th>      <th>BLEU || EN-FR</th>    </tr>  </thead>  <tbody>    <tr>      <td>Architecture || Vaswani et al. (2017) Transformer big</td>      <td>28.4</td>      <td>41</td>    </tr>    <tr>      <td>Architecture || Wu et al. (2018) Transformer big + sequence-loss</td>      <td>28.75</td>      <td>41.47</td>    </tr>    <tr>      <td>Architecture || Yang et al. (2018) Transformer big + localness</td>      <td>28.89</td>      <td>n/a</td>    </tr>    <tr>      <td>Architecture || this work Transformer big + hard-attention</td>      <td>29.29</td>      <td>42.26</td>    </tr>  </tbody></table>",
        "table_name": "Table 1",
        "table_id": "table_1",
        "paper_id": "P19-1290",
        "page_no": 4,
        "dir": "acl2019",
        "valid": 1
    },
    {
        "table_id_paper": "P19-1305table_5",
        "caption": "Validation set performances of using different layers for attention relay.",
        "row_header_level": 2,
        "row_headers": [
            [
                "Layer",
                "1"
            ],
            [
                "Layer",
                "2"
            ],
            [
                "Layer",
                "3"
            ],
            [
                "Layer",
                "4"
            ],
            [
                "Layer",
                "5"
            ],
            [
                "Layer",
                "6"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "ROUGE-1"
            ],
            [
                "ROUGE-2"
            ],
            [
                "ROUGE-L"
            ]
        ],
        "contents": [
            [
                "44.7",
                "21.8",
                "41.6"
            ],
            [
                "44.7",
                "22.3",
                "41.7"
            ],
            [
                "45",
                "22",
                "41.8"
            ],
            [
                "44.9",
                "22.1",
                "41.3"
            ],
            [
                "44.9",
                "22.1",
                "41.9"
            ],
            [
                "45.1",
                "22.3",
                "42"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "ROUGE-1",
            "ROUGE-2",
            "ROUGE-L"
        ],
        "target_entity": [
            "Layer"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>ROUGE-1</th>      <th>ROUGE-2</th>      <th>ROUGE-L</th>    </tr>  </thead>  <tbody>    <tr>      <td>Layer || 1</td>      <td>44.7</td>      <td>21.8</td>      <td>41.6</td>    </tr>    <tr>      <td>Layer || 2</td>      <td>44.7</td>      <td>22.3</td>      <td>41.7</td>    </tr>    <tr>      <td>Layer || 3</td>      <td>45</td>      <td>22</td>      <td>41.8</td>    </tr>    <tr>      <td>Layer || 4</td>      <td>44.9</td>      <td>22.1</td>      <td>41.3</td>    </tr>    <tr>      <td>Layer || 5</td>      <td>44.9</td>      <td>22.1</td>      <td>41.9</td>    </tr>    <tr>      <td>Layer || 6</td>      <td>45.1</td>      <td>22.3</td>      <td>42</td>    </tr>  </tbody></table>",
        "table_name": "Table 5",
        "table_id": "table_5",
        "paper_id": "P19-1305",
        "page_no": 8,
        "dir": "acl2019",
        "valid": 1
    },
    {
        "table_id_paper": "P19-1309table_3",
        "caption": "BUCC results (F1) on the test set. We use the ratio function with maximum score retrieval and the filtering threshold optimized on the training set.",
        "row_header_level": 1,
        "row_headers": [
            [
                "Azpeitia et al. (2017)"
            ],
            [
                "Azpeitia et al. (2018)"
            ],
            [
                "Bouamor and Sajjad (2018)"
            ],
            [
                "Schwenk (2018)"
            ],
            [
                "Proposed method (Europarl)"
            ],
            [
                "Proposed method (UN)"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "en-de"
            ],
            [
                "en-fr"
            ],
            [
                "en-ru"
            ],
            [
                "en-zh"
            ]
        ],
        "contents": [
            [
                "83.7",
                "79.5",
                "-",
                "-"
            ],
            [
                "85.5",
                "81.5",
                "81.3",
                "77.5"
            ],
            [
                "-",
                "76",
                "-",
                "-"
            ],
            [
                "76.9",
                "75.8",
                "73.8",
                "71.6"
            ],
            [
                "95.6",
                "92.9",
                "-",
                "-"
            ],
            [
                "-",
                "-",
                "92",
                "92.6"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "F1",
            "F1",
            "F1",
            "F1"
        ],
        "target_entity": [
            "Proposed method (Europarl)",
            "Proposed method (UN)"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>en-de</th>      <th>en-fr</th>      <th>en-ru</th>      <th>en-zh</th>    </tr>  </thead>  <tbody>    <tr>      <td>Azpeitia et al. (2017)</td>      <td>83.7</td>      <td>79.5</td>      <td>-</td>      <td>-</td>    </tr>    <tr>      <td>Azpeitia et al. (2018)</td>      <td>85.5</td>      <td>81.5</td>      <td>81.3</td>      <td>77.5</td>    </tr>    <tr>      <td>Bouamor and Sajjad (2018)</td>      <td>-</td>      <td>76</td>      <td>-</td>      <td>-</td>    </tr>    <tr>      <td>Schwenk (2018)</td>      <td>76.9</td>      <td>75.8</td>      <td>73.8</td>      <td>71.6</td>    </tr>    <tr>      <td>Proposed method (Europarl)</td>      <td>95.6</td>      <td>92.9</td>      <td>-</td>      <td>-</td>    </tr>    <tr>      <td>Proposed method (UN)</td>      <td>-</td>      <td>-</td>      <td>92</td>      <td>92.6</td>    </tr>  </tbody></table>",
        "table_name": "Table 3",
        "table_id": "table_3",
        "paper_id": "P19-1309",
        "page_no": 4,
        "dir": "acl2019",
        "valid": 1
    },
    {
        "table_id_paper": "P19-1316table_1",
        "caption": "Baseline (Cordeiro et al., 2016) results on the reduced version of three gold-standard datasets ordered in decreasing overall performance along with the results of using only Poincar\u00b4e embedding.",
        "row_header_level": 2,
        "row_headers": [
            [
                "Base. Model",
                "W2V-CBOW"
            ],
            [
                "Base. Model",
                "W2V-SG"
            ],
            [
                "Base. Model",
                "GloVe"
            ],
            [
                "Base. Model",
                "PPMI-SVD"
            ],
            [
                "Base. Model",
                "Poincare"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "RD-R"
            ],
            [
                "RD++-R"
            ],
            [
                "FD-R"
            ]
        ],
        "contents": [
            [
                "0.8045",
                "0.6964",
                "0.3405"
            ],
            [
                "0.8034",
                "0.6963",
                "0.3396"
            ],
            [
                "0.7604",
                "0.6487",
                "0.262"
            ],
            [
                "0.7484",
                "0.6468",
                "0.2428"
            ],
            [
                "0.6023",
                "0.4765",
                "0.2007"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "correlation",
            "correlation",
            "correlation"
        ],
        "target_entity": [
            "Poincare",
            "W2V-CBOW"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>RD-R</th>      <th>RD++-R</th>      <th>FD-R</th>    </tr>  </thead>  <tbody>    <tr>      <td>Base. Model || W2V-CBOW</td>      <td>0.8045</td>      <td>0.6964</td>      <td>0.3405</td>    </tr>    <tr>      <td>Base. Model || W2V-SG</td>      <td>0.8034</td>      <td>0.6963</td>      <td>0.3396</td>    </tr>    <tr>      <td>Base. Model || GloVe</td>      <td>0.7604</td>      <td>0.6487</td>      <td>0.262</td>    </tr>    <tr>      <td>Base. Model || PPMI-SVD</td>      <td>0.7484</td>      <td>0.6468</td>      <td>0.2428</td>    </tr>    <tr>      <td>Base. Model || Poincare</td>      <td>0.6023</td>      <td>0.4765</td>      <td>0.2007</td>    </tr>  </tbody></table>",
        "table_name": "Table 1",
        "table_id": "table_1",
        "paper_id": "P19-1316",
        "page_no": 6,
        "dir": "acl2019",
        "valid": 1
    },
    {
        "table_id_paper": "P19-1332table_8",
        "caption": "Human Evaluation in WikiAnswers\u2192Quora",
        "row_header_level": 2,
        "row_headers": [
            [
                "Models",
                "MTL+Copy"
            ],
            [
                "Models",
                "Na\u00efve DNPG"
            ],
            [
                "Models",
                "Adapted DNPG"
            ],
            [
                "Models",
                "Reference"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "Mean Rank"
            ],
            [
                "Agreement"
            ]
        ],
        "contents": [
            [
                "3.22",
                "0.446"
            ],
            [
                "3.13",
                "0.323"
            ],
            [
                "1.79",
                "0.383"
            ],
            [
                "1.48",
                "0.338"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "Mean Rank",
            "Agreement"
        ],
        "target_entity": [
            "MTL+Copy",
            "Na\u00efve DNPG",
            "Adapted DNPG"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Mean Rank</th>      <th>Agreement</th>    </tr>  </thead>  <tbody>    <tr>      <td>Models || MTL+Copy</td>      <td>3.22</td>      <td>0.446</td>    </tr>    <tr>      <td>Models || Na\u00efve DNPG</td>      <td>3.13</td>      <td>0.323</td>    </tr>    <tr>      <td>Models || Adapted DNPG</td>      <td>1.79</td>      <td>0.383</td>    </tr>    <tr>      <td>Models || Reference</td>      <td>1.48</td>      <td>0.338</td>    </tr>  </tbody></table>",
        "table_name": "Table 8",
        "table_id": "table_8",
        "paper_id": "P19-1332",
        "page_no": 8,
        "dir": "acl2019",
        "valid": 1
    },
    {
        "table_id_paper": "P19-1370table_2",
        "caption": "Evaluation results of co-teaching initialized with different networks.",
        "row_header_level": 1,
        "row_headers": [
            [
                "SMN-Pre-training"
            ],
            [
                "SMN-Co-teaching"
            ],
            [
                "DAM-Pre-training"
            ],
            [
                "DAM-Co-teaching"
            ]
        ],
        "column_header_level": 2,
        "column_headers": [
            [
                "Douban (Margin)",
                "MAP"
            ],
            [
                "Douban (Margin)",
                "MRR"
            ],
            [
                "Douban (Margin)",
                "P@1"
            ],
            [
                "Douban (Margin)",
                "R10@1"
            ],
            [
                "Douban (Margin)",
                "R10@2"
            ],
            [
                "Douban (Margin)",
                "R10@5"
            ],
            [
                "ECD (Curriculum)",
                "MAP"
            ],
            [
                "ECD (Curriculum)",
                "MRR"
            ],
            [
                "ECD (Curriculum)",
                "P@1"
            ],
            [
                "ECD (Curriculum)",
                "R10@1"
            ],
            [
                "ECD (Curriculum)",
                "R10@2"
            ],
            [
                "ECD (Curriculum)",
                "R10@5"
            ]
        ],
        "contents": [
            [
                "0.527",
                "0.57",
                "0.396",
                "0.236",
                "0.392",
                "0.734",
                "0.662",
                "0.742",
                "0.598",
                "0.302",
                "0.464",
                "0.757"
            ],
            [
                "0.558",
                "0.602",
                "0.42",
                "0.255",
                "0.431",
                "0.787",
                "0.674",
                "0.765",
                "0.626",
                "0.322",
                "0.485",
                "0.779"
            ],
            [
                "0.552",
                "0.605",
                "0.426",
                "0.258",
                "0.408",
                "0.766",
                "0.685",
                "0.756",
                "0.621",
                "0.325",
                "0.491",
                "0.772"
            ],
            [
                "0.57",
                "0.617",
                "0.438",
                "0.27",
                "0.455",
                "0.781",
                "0.696",
                "0.775",
                "0.652",
                "0.341",
                "0.499",
                "0.784"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "MAP",
            "MRR",
            "P@1",
            "R10@1",
            "R10@2",
            "R10@5",
            "MAP",
            "MRR",
            "P@1",
            "R10@1",
            "R10@2",
            "R10@5"
        ],
        "target_entity": [
            "SMN-Co-teaching",
            "DAM-Co-teaching"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Douban (Margin) || MAP</th>      <th>Douban (Margin) || MRR</th>      <th>Douban (Margin) || P@1</th>      <th>Douban (Margin) || R10@1</th>      <th>Douban (Margin) || R10@2</th>      <th>Douban (Margin) || R10@5</th>      <th>ECD (Curriculum) || MAP</th>      <th>ECD (Curriculum) || MRR</th>      <th>ECD (Curriculum) || P@1</th>      <th>ECD (Curriculum) || R10@1</th>      <th>ECD (Curriculum) || R10@2</th>      <th>ECD (Curriculum) || R10@5</th>    </tr>  </thead>  <tbody>    <tr>      <td>SMN-Pre-training</td>      <td>0.527</td>      <td>0.57</td>      <td>0.396</td>      <td>0.236</td>      <td>0.392</td>      <td>0.734</td>      <td>0.662</td>      <td>0.742</td>      <td>0.598</td>      <td>0.302</td>      <td>0.464</td>      <td>0.757</td>    </tr>    <tr>      <td>SMN-Co-teaching</td>      <td>0.558</td>      <td>0.602</td>      <td>0.42</td>      <td>0.255</td>      <td>0.431</td>      <td>0.787</td>      <td>0.674</td>      <td>0.765</td>      <td>0.626</td>      <td>0.322</td>      <td>0.485</td>      <td>0.779</td>    </tr>    <tr>      <td>DAM-Pre-training</td>      <td>0.552</td>      <td>0.605</td>      <td>0.426</td>      <td>0.258</td>      <td>0.408</td>      <td>0.766</td>      <td>0.685</td>      <td>0.756</td>      <td>0.621</td>      <td>0.325</td>      <td>0.491</td>      <td>0.772</td>    </tr>    <tr>      <td>DAM-Co-teaching</td>      <td>0.57</td>      <td>0.617</td>      <td>0.438</td>      <td>0.27</td>      <td>0.455</td>      <td>0.781</td>      <td>0.696</td>      <td>0.775</td>      <td>0.652</td>      <td>0.341</td>      <td>0.499</td>      <td>0.784</td>    </tr>  </tbody></table>",
        "table_name": "Table 2",
        "table_id": "table_2",
        "paper_id": "P19-1370",
        "page_no": 7,
        "dir": "acl2019",
        "valid": 1
    },
    {
        "table_id_paper": "P19-1402table_1",
        "caption": "Performance on the Chimera benchmark dataset with different numbers of context sentences, which is measured by Spearman correlation. Baseline results are from the corresponding papers.",
        "row_header_level": 2,
        "row_headers": [
            [
                "Methods",
                "Word2vec   "
            ],
            [
                "Methods",
                "FastText   "
            ],
            [
                "Methods",
                "Additive   "
            ],
            [
                "Methods",
                "Additive, no stop words"
            ],
            [
                "Methods",
                "nonce2vec   "
            ],
            [
                "Methods",
                "\u00c3\u00a0 la carte "
            ],
            [
                "Methods",
                "HiCE w/o Morph "
            ],
            [
                "Methods",
                "HiCE + Morph "
            ],
            [
                "Methods",
                "HiCE + Morph + Fine-tune"
            ],
            [
                "Methods",
                "HiCE + Morph + MAML"
            ],
            [
                "Methods",
                "Oracle Embedding  "
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "2-shot"
            ],
            [
                "4-shot"
            ],
            [
                "6-shot"
            ]
        ],
        "contents": [
            [
                "0.1459",
                "0.2457",
                "0.2498"
            ],
            [
                "0.1775",
                "0.1738",
                "0.1294"
            ],
            [
                "0.3627",
                "0.3701",
                "0.3595"
            ],
            [
                "0.3376",
                "0.3624",
                "0.408"
            ],
            [
                "0.332",
                "0.3668",
                "0.389"
            ],
            [
                "0.3634",
                "0.3844",
                "0.3941"
            ],
            [
                "0.371",
                "0.3872",
                "0.4277"
            ],
            [
                "0.3796",
                "0.3916",
                "0.4253"
            ],
            [
                "0.1403",
                "0.1837",
                "0.3145"
            ],
            [
                "0.3781",
                "0.4053",
                "0.4307"
            ],
            [
                "0.416",
                "0.4381",
                "0.4427"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "correlation",
            "correlation",
            "correlation"
        ],
        "target_entity": [
            "HiCE + Morph + MAML"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>2-shot</th>      <th>4-shot</th>      <th>6-shot</th>    </tr>  </thead>  <tbody>    <tr>      <td>Methods || Word2vec</td>      <td>0.1459</td>      <td>0.2457</td>      <td>0.2498</td>    </tr>    <tr>      <td>Methods || FastText</td>      <td>0.1775</td>      <td>0.1738</td>      <td>0.1294</td>    </tr>    <tr>      <td>Methods || Additive</td>      <td>0.3627</td>      <td>0.3701</td>      <td>0.3595</td>    </tr>    <tr>      <td>Methods || Additive, no stop words</td>      <td>0.3376</td>      <td>0.3624</td>      <td>0.408</td>    </tr>    <tr>      <td>Methods || nonce2vec</td>      <td>0.332</td>      <td>0.3668</td>      <td>0.389</td>    </tr>    <tr>      <td>Methods || \u00c3\u00a0 la carte</td>      <td>0.3634</td>      <td>0.3844</td>      <td>0.3941</td>    </tr>    <tr>      <td>Methods || HiCE w/o Morph</td>      <td>0.371</td>      <td>0.3872</td>      <td>0.4277</td>    </tr>    <tr>      <td>Methods || HiCE + Morph</td>      <td>0.3796</td>      <td>0.3916</td>      <td>0.4253</td>    </tr>    <tr>      <td>Methods || HiCE + Morph + Fine-tune</td>      <td>0.1403</td>      <td>0.1837</td>      <td>0.3145</td>    </tr>    <tr>      <td>Methods || HiCE + Morph + MAML</td>      <td>0.3781</td>      <td>0.4053</td>      <td>0.4307</td>    </tr>    <tr>      <td>Methods || Oracle Embedding</td>      <td>0.416</td>      <td>0.4381</td>      <td>0.4427</td>    </tr>  </tbody></table>",
        "table_name": "Table 1",
        "table_id": "table_1",
        "paper_id": "P19-1402",
        "page_no": 6,
        "dir": "acl2019",
        "valid": 1
    },
    {
        "table_id_paper": "P19-1410table_1",
        "caption": "Discourse segmentation results. Superscript (cid:63) indicates the model is significantly superior to the WLYELMo model with a p-value < 0.01.",
        "row_header_level": 3,
        "row_headers": [
            [
                "Approach",
                "Human Agreement",
                "-"
            ],
            [
                "Approach",
                "Baselines",
                "SPADE (Soricut and Marcu, 2003)"
            ],
            [
                "Approach",
                "Baselines",
                "F&R (Fisher and Roark, 2007)"
            ],
            [
                "Approach",
                "Baselines",
                "JCN (Joty et al., 2012)"
            ],
            [
                "Approach",
                "Baselines",
                "SegBotglove (Li et al., 2018)"
            ],
            [
                "Approach",
                "Baselines",
                "WLYELMo (Wang et al., 2018)"
            ],
            [
                "Approach",
                "Our Segmenter",
                "Pointer Net (Glove)"
            ],
            [
                "Approach",
                "Our Segmenter",
                "Pointer Net (BERT)"
            ],
            [
                "Approach",
                "Our Segmenter",
                "Pointer Net (ELMo)"
            ],
            [
                "Approach",
                "Our Segmenter",
                "Pointer Net (ELMo) + Joint training"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "Precision"
            ],
            [
                "Recall"
            ],
            [
                "F1"
            ]
        ],
        "contents": [
            [
                "98.5",
                "98.2",
                "98.3"
            ],
            [
                "83.8",
                "86.8",
                "85.2"
            ],
            [
                "91.3",
                "89.7",
                "90.5"
            ],
            [
                "88",
                "92.3",
                "90.1"
            ],
            [
                "91.08\u00b10.46",
                "91.03 \u00b10.42",
                "91.05 \u00b10.11"
            ],
            [
                "92.04 \u00b10.43",
                "94.41 \u00b10.53",
                "93.21 \u00b10.33"
            ],
            [
                "90.55 \u00b10.33",
                "92.29 \u00b10.09",
                "91.41 \u00b10.21"
            ],
            [
                "92.05 \u00b10.44",
                "95.03 \u00b10.28",
                "93.51 \u00b10.16"
            ],
            [
                "94.12\u00b10.20",
                " 96.63\u00b10.12",
                " 95.35\u00b10.10"
            ],
            [
                "93.34\u00b10.23",
                "97.88\u00b10.16",
                "95.55\u00b10.13"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "Precision",
            "Recall",
            "F1"
        ],
        "target_entity": [
            "Our Segmenter"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Precision</th>      <th>Recall</th>      <th>F1</th>    </tr>  </thead>  <tbody>    <tr>      <td>Approach || Human Agreement || -</td>      <td>98.5</td>      <td>98.2</td>      <td>98.3</td>    </tr>    <tr>      <td>Approach || Baselines || SPADE (Soricut and Marcu, 2003)</td>      <td>83.8</td>      <td>86.8</td>      <td>85.2</td>    </tr>    <tr>      <td>Approach || Baselines || F&amp;R (Fisher and Roark, 2007)</td>      <td>91.3</td>      <td>89.7</td>      <td>90.5</td>    </tr>    <tr>      <td>Approach || Baselines || JCN (Joty et al., 2012)</td>      <td>88</td>      <td>92.3</td>      <td>90.1</td>    </tr>    <tr>      <td>Approach || Baselines || SegBotglove (Li et al., 2018)</td>      <td>91.08\u00b10.46</td>      <td>91.03 \u00b10.42</td>      <td>91.05 \u00b10.11</td>    </tr>    <tr>      <td>Approach || Baselines || WLYELMo (Wang et al., 2018)</td>      <td>92.04 \u00b10.43</td>      <td>94.41 \u00b10.53</td>      <td>93.21 \u00b10.33</td>    </tr>    <tr>      <td>Approach || Our Segmenter || Pointer Net (Glove)</td>      <td>90.55 \u00b10.33</td>      <td>92.29 \u00b10.09</td>      <td>91.41 \u00b10.21</td>    </tr>    <tr>      <td>Approach || Our Segmenter || Pointer Net (BERT)</td>      <td>92.05 \u00b10.44</td>      <td>95.03 \u00b10.28</td>      <td>93.51 \u00b10.16</td>    </tr>    <tr>      <td>Approach || Our Segmenter || Pointer Net (ELMo)</td>      <td>94.12\u00b10.20</td>      <td>96.63\u00b10.12</td>      <td>95.35\u00b10.10</td>    </tr>    <tr>      <td>Approach || Our Segmenter || Pointer Net (ELMo) + Joint training</td>      <td>93.34\u00b10.23</td>      <td>97.88\u00b10.16</td>      <td>95.55\u00b10.13</td>    </tr>  </tbody></table>",
        "table_name": "Table 1",
        "table_id": "table_1",
        "paper_id": "P19-1410",
        "page_no": 7,
        "dir": "acl2019",
        "valid": 1
    },
    {
        "table_id_paper": "P19-1410table_2",
        "caption": "Parsing results with gold segmentation. Superscript (cid:63) indicates the model is significantly superior to the 2-Stage Parser with a p-value < 0.01.",
        "row_header_level": 3,
        "row_headers": [
            [
                "Approach",
                "Human Agreement",
                "-"
            ],
            [
                "Approach",
                "Baselines",
                "SPADE (Soricut and Marcu, 2003)"
            ],
            [
                "Approach",
                "Baselines",
                "DCRF (Joty et al., 2012)"
            ],
            [
                "Approach",
                "Baselines",
                "DPLP (Ji and Eisenstein, 2014)"
            ],
            [
                "Approach",
                "Baselines",
                "2-Stage Parser (Wang et al., 2017)"
            ],
            [
                "Approach",
                "Our Parser",
                "Stack Pointer (ELMo-medium)"
            ],
            [
                "Approach",
                "Our Parser",
                "Stack Pointer (ELMo-large)"
            ],
            [
                "Approach",
                "Our Parser",
                "+ Partial tree information"
            ],
            [
                "Approach",
                "Our Parser",
                "+ Joint training"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "Span"
            ],
            [
                "Nuclearity"
            ],
            [
                "Relation"
            ]
        ],
        "contents": [
            [
                "95.7",
                "90.4",
                "83"
            ],
            [
                "93.5",
                "85.8",
                "67.6"
            ],
            [
                "94.6",
                "86.9",
                "77.1"
            ],
            [
                "93.5",
                "81.3",
                "70.5"
            ],
            [
                "95.6",
                "87.8",
                "77.6"
            ],
            [
                "96.37",
                "89.04*",
                "79.03*"
            ],
            [
                "96.86*",
                "90.77*",
                "81.12*"
            ],
            [
                "96.94*",
                "90.89*",
                "81.28*"
            ],
            [
                "97.44*",
                "91.34*",
                "81.70*"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "F1",
            "F1",
            "F1"
        ],
        "target_entity": [
            "Our Parser"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Span</th>      <th>Nuclearity</th>      <th>Relation</th>    </tr>  </thead>  <tbody>    <tr>      <td>Approach || Human Agreement || -</td>      <td>95.7</td>      <td>90.4</td>      <td>83</td>    </tr>    <tr>      <td>Approach || Baselines || SPADE (Soricut and Marcu, 2003)</td>      <td>93.5</td>      <td>85.8</td>      <td>67.6</td>    </tr>    <tr>      <td>Approach || Baselines || DCRF (Joty et al., 2012)</td>      <td>94.6</td>      <td>86.9</td>      <td>77.1</td>    </tr>    <tr>      <td>Approach || Baselines || DPLP (Ji and Eisenstein, 2014)</td>      <td>93.5</td>      <td>81.3</td>      <td>70.5</td>    </tr>    <tr>      <td>Approach || Baselines || 2-Stage Parser (Wang et al., 2017)</td>      <td>95.6</td>      <td>87.8</td>      <td>77.6</td>    </tr>    <tr>      <td>Approach || Our Parser || Stack Pointer (ELMo-medium)</td>      <td>96.37</td>      <td>89.04*</td>      <td>79.03*</td>    </tr>    <tr>      <td>Approach || Our Parser || Stack Pointer (ELMo-large)</td>      <td>96.86*</td>      <td>90.77*</td>      <td>81.12*</td>    </tr>    <tr>      <td>Approach || Our Parser || + Partial tree information</td>      <td>96.94*</td>      <td>90.89*</td>      <td>81.28*</td>    </tr>    <tr>      <td>Approach || Our Parser || + Joint training</td>      <td>97.44*</td>      <td>91.34*</td>      <td>81.70*</td>    </tr>  </tbody></table>",
        "table_name": "Table 2",
        "table_id": "table_2",
        "paper_id": "P19-1410",
        "page_no": 8,
        "dir": "acl2019",
        "valid": 1
    },
    {
        "table_id_paper": "P19-1427table_4",
        "caption": "Results on translating four languages to English for MLE, BLEU, SIMILE and Half. \u2020 denotes statistical significance (p < 0.05) over BLEU and \u2021 denotes statistical significance over MLE. Statistical significance was computed using paired bootstrap resampling.",
        "row_header_level": 2,
        "row_headers": [
            [
                "Model",
                "MLE"
            ],
            [
                "Model",
                "BLEU"
            ],
            [
                "Model",
                "SIMILE"
            ],
            [
                "Model",
                "Half"
            ]
        ],
        "column_header_level": 2,
        "column_headers": [
            [
                "de-en",
                "BLEU"
            ],
            [
                "de-en",
                "SIM"
            ],
            [
                "cs-en",
                "BLEU"
            ],
            [
                "cs-en",
                "SIM"
            ],
            [
                "ru-en",
                "BLEU"
            ],
            [
                "ru-en",
                "SIM"
            ],
            [
                "tr-en",
                "BLEU"
            ],
            [
                "tr-en",
                "SIM"
            ]
        ],
        "contents": [
            [
                "27.52",
                "74.96",
                "17.02",
                "67.18",
                "17.92",
                "70.24",
                "14.47",
                "63.52"
            ],
            [
                "27.95",
                "86.93",
                "17.29",
                "81.92",
                "17.92",
                "84.63",
                "15.00",
                "80.30"
            ],
            [
                "28.28",
                "87.32",
                "17.51",
                "82.12",
                "18.23",
                "85.12",
                "15.28",
                "81.04"
            ],
            [
                "28.24",
                "87.11",
                "17.50",
                "82.11",
                "18.24",
                "85.10",
                "15.34",
                "80.64"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "BLEU",
            "SIM",
            "BLEU",
            "SIM",
            "BLEU",
            "SIM",
            "BLEU",
            "SIM"
        ],
        "target_entity": [
            "SIMILE"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>de-en || BLEU</th>      <th>de-en || SIM</th>      <th>cs-en || BLEU</th>      <th>cs-en || SIM</th>      <th>ru-en || BLEU</th>      <th>ru-en || SIM</th>      <th>tr-en || BLEU</th>      <th>tr-en || SIM</th>    </tr>  </thead>  <tbody>    <tr>      <td>Model || MLE</td>      <td>27.52</td>      <td>74.96</td>      <td>17.02</td>      <td>67.18</td>      <td>17.92</td>      <td>70.24</td>      <td>14.47</td>      <td>63.52</td>    </tr>    <tr>      <td>Model || BLEU</td>      <td>27.95</td>      <td>86.93</td>      <td>17.29</td>      <td>81.92</td>      <td>17.92</td>      <td>84.63</td>      <td>15.00</td>      <td>80.30</td>    </tr>    <tr>      <td>Model || SIMILE</td>      <td>28.28</td>      <td>87.32</td>      <td>17.51</td>      <td>82.12</td>      <td>18.23</td>      <td>85.12</td>      <td>15.28</td>      <td>81.04</td>    </tr>    <tr>      <td>Model || Half</td>      <td>28.24</td>      <td>87.11</td>      <td>17.50</td>      <td>82.11</td>      <td>18.24</td>      <td>85.10</td>      <td>15.34</td>      <td>80.64</td>    </tr>  </tbody></table>",
        "table_name": "Table 4",
        "table_id": "table_4",
        "paper_id": "P19-1427",
        "page_no": 5,
        "dir": "acl2019",
        "valid": 1
    },
    {
        "table_id_paper": "P19-1444table_4",
        "caption": "Ablation study results. Base model means that we does not use schema linking (SL), memory augmented pointer network (MEM) and the coarse-to-fine framework (CF) on IRNet.",
        "row_header_level": 2,
        "row_headers": [
            [
                "Technique",
                "Base model"
            ],
            [
                "Technique",
                "+SL"
            ],
            [
                "Technique",
                "+SL + MEM"
            ],
            [
                "Technique",
                "+SL + MEM + CF"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "IRNet"
            ],
            [
                "IRNet(BERT)"
            ]
        ],
        "contents": [
            [
                " 40.5%",
                "53.90%"
            ],
            [
                " 48.5%",
                "60.30%"
            ],
            [
                " 51.3%",
                "60.60%"
            ],
            [
                " 53.2%",
                "61.90%"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "F1",
            "F1"
        ],
        "target_entity": [
            "IRNet",
            "IRNet(BERT)"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>IRNet</th>      <th>IRNet(BERT)</th>    </tr>  </thead>  <tbody>    <tr>      <td>Technique || Base model</td>      <td>40.5%</td>      <td>53.90%</td>    </tr>    <tr>      <td>Technique || +SL</td>      <td>48.5%</td>      <td>60.30%</td>    </tr>    <tr>      <td>Technique || +SL + MEM</td>      <td>51.3%</td>      <td>60.60%</td>    </tr>    <tr>      <td>Technique || +SL + MEM + CF</td>      <td>53.2%</td>      <td>61.90%</td>    </tr>  </tbody></table>",
        "table_name": "Table 4",
        "table_id": "table_4",
        "paper_id": "P19-1444",
        "page_no": 7,
        "dir": "acl2019",
        "valid": 1
    },
    {
        "table_id_paper": "P19-1458table_5",
        "caption": "Low-shot learning results for the Yahoo dataset, in error percentages. Transfer learning-based 3 of the total dataset, while the methods are trained on 1 other models are trained on the whole dataset.",
        "row_header_level": 2,
        "row_headers": [
            [
                "Model",
                "RNN Baseline"
            ],
            [
                "Model",
                "LSTM Baseline"
            ],
            [
                "Model",
                "KimCNN Kim (2014)"
            ],
            [
                "Model",
                "Self Attention Lin et al. (2017)"
            ],
            [
                "Model",
                "RCNN Lai et al. (2015)"
            ],
            [
                "Model",
                "BCN+ELMo"
            ],
            [
                "Model",
                "ULMFiT"
            ],
            [
                "Model",
                "BERTBASE"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "Yahoo Binary"
            ]
        ],
        "contents": [
            [
                "35.29"
            ],
            [
                "32.41"
            ],
            [
                "14.25"
            ],
            [
                "13.16"
            ],
            [
                "12.67"
            ],
            [
                "13.51"
            ],
            [
                "10.62"
            ],
            [
                "10.14"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "error"
        ],
        "target_entity": [
            "ULMFiT",
            "BERTBASE",
            "BCN+ELMo"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Yahoo Binary</th>    </tr>  </thead>  <tbody>    <tr>      <td>Model || RNN Baseline</td>      <td>35.29</td>    </tr>    <tr>      <td>Model || LSTM Baseline</td>      <td>32.41</td>    </tr>    <tr>      <td>Model || KimCNN Kim (2014)</td>      <td>14.25</td>    </tr>    <tr>      <td>Model || Self Attention Lin et al. (2017)</td>      <td>13.16</td>    </tr>    <tr>      <td>Model || RCNN Lai et al. (2015)</td>      <td>12.67</td>    </tr>    <tr>      <td>Model || BCN+ELMo</td>      <td>13.51</td>    </tr>    <tr>      <td>Model || ULMFiT</td>      <td>10.62</td>    </tr>    <tr>      <td>Model || BERTBASE</td>      <td>10.14</td>    </tr>  </tbody></table>",
        "table_name": "Table 5",
        "table_id": "table_5",
        "paper_id": "P19-1458",
        "page_no": 4,
        "dir": "acl2019",
        "valid": 1
    },
    {
        "table_id_paper": "P19-1475table_2",
        "caption": "Results on recast MNLI and JOCI.",
        "row_header_level": 2,
        "row_headers": [
            [
                "Dataset",
                "MNLI 1"
            ],
            [
                "Dataset",
                "MNLI 2"
            ],
            [
                "Dataset",
                "JOCI 1"
            ],
            [
                "Dataset",
                "JOCI 2"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "Log loss"
            ],
            [
                "Margin loss"
            ]
        ],
        "contents": [
            [
                "93.6",
                "93.4"
            ],
            [
                "87.9",
                "87.9"
            ],
            [
                "86.6",
                "86.9"
            ],
            [
                "76.6",
                "78"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "Log loss",
            "Margin loss"
        ],
        "target_entity": [
            "MNLI 1",
            "MNLI 2",
            "JOCI 1",
            "JOCI 2"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Log loss</th>      <th>Margin loss</th>    </tr>  </thead>  <tbody>    <tr>      <td>Dataset || MNLI 1</td>      <td>93.6</td>      <td>93.4</td>    </tr>    <tr>      <td>Dataset || MNLI 2</td>      <td>87.9</td>      <td>87.9</td>    </tr>    <tr>      <td>Dataset || JOCI 1</td>      <td>86.6</td>      <td>86.9</td>    </tr>    <tr>      <td>Dataset || JOCI 2</td>      <td>76.6</td>      <td>78</td>    </tr>  </tbody></table>",
        "table_name": "Table 2",
        "table_id": "table_2",
        "paper_id": "P19-1475",
        "page_no": 3,
        "dir": "acl2019",
        "valid": 1
    },
    {
        "table_id_paper": "P19-1475table_3",
        "caption": "Experimental results on COPA test set.",
        "row_header_level": 2,
        "row_headers": [
            [
                "Method",
                "PMI (Jabeen et al., 2014)"
            ],
            [
                "Method",
                "PMI EX (Gordon et al., 2011)"
            ],
            [
                "Method",
                "CS (Luo et al., 2016)"
            ],
            [
                "Method",
                "CS MWP (Sasaki et al., 2017)"
            ],
            [
                "Method",
                "BERTlog (ours)"
            ],
            [
                "Method",
                "BERTmargin (ours)"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "Acc (%)"
            ]
        ],
        "contents": [
            [
                "58.8"
            ],
            [
                "65.4"
            ],
            [
                "70.2"
            ],
            [
                "71.2"
            ],
            [
                "73.4"
            ],
            [
                "75.4"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "Acc (%)"
        ],
        "target_entity": [
            "BERTmargin (ours)",
            "BERTlog (ours)"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Acc (%)</th>    </tr>  </thead>  <tbody>    <tr>      <td>Method || PMI (Jabeen et al., 2014)</td>      <td>58.8</td>    </tr>    <tr>      <td>Method || PMI EX (Gordon et al., 2011)</td>      <td>65.4</td>    </tr>    <tr>      <td>Method || CS (Luo et al., 2016)</td>      <td>70.2</td>    </tr>    <tr>      <td>Method || CS MWP (Sasaki et al., 2017)</td>      <td>71.2</td>    </tr>    <tr>      <td>Method || BERTlog (ours)</td>      <td>73.4</td>    </tr>    <tr>      <td>Method || BERTmargin (ours)</td>      <td>75.4</td>    </tr>  </tbody></table>",
        "table_name": "Table 3",
        "table_id": "table_3",
        "paper_id": "P19-1475",
        "page_no": 3,
        "dir": "acl2019",
        "valid": 1
    },
    {
        "table_id_paper": "P19-1487table_2",
        "caption": "Results on CQA dev-random-split with CoS-E used during training.",
        "row_header_level": 2,
        "row_headers": [
            [
                "Method",
                "BERT (baseline)"
            ],
            [
                "Method",
                "CoS-E-open-ended"
            ],
            [
                "Method",
                "CAGE-reasoning"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "Accuracy (%)"
            ]
        ],
        "contents": [
            [
                "63.8"
            ],
            [
                "65.5"
            ],
            [
                "72.6"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "Accuracy (%)"
        ],
        "target_entity": [
            "CAGE-reasoning"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Accuracy (%)</th>    </tr>  </thead>  <tbody>    <tr>      <td>Method || BERT (baseline)</td>      <td>63.8</td>    </tr>    <tr>      <td>Method || CoS-E-open-ended</td>      <td>65.5</td>    </tr>    <tr>      <td>Method || CAGE-reasoning</td>      <td>72.6</td>    </tr>  </tbody></table>",
        "table_name": "Table 2",
        "table_id": "table_2",
        "paper_id": "P19-1487",
        "page_no": 6,
        "dir": "acl2019",
        "valid": 1
    },
    {
        "table_id_paper": "P19-1530table_2",
        "caption": "Comparison for nonlocal dependency identification on the test data.",
        "row_header_level": 1,
        "row_headers": [
            [
                "(Johnson, 2002)"
            ],
            [
                "(Dienes and Dubey, 2003)"
            ],
            [
                "(Campbell, 2004)"
            ],
            [
                "(Schmid, 2006)"
            ],
            [
                "(Cai et al., 2011)"
            ],
            [
                "(Hayashi and Nagata, 2016)"
            ],
            [
                "(Kato and Matsubara, 2016)"
            ],
            [
                "(Kummerfeld and Klein, 2017)"
            ],
            [
                "(Johnson, 2002)"
            ],
            [
                "(Campbell, 2004)"
            ],
            [
                "ours"
            ],
            [
                "ours (with ELMo)"
            ],
            [
                "ours (with BERT)"
            ]
        ],
        "column_header_level": 2,
        "column_headers": [
            [
                "Empty element detection (Fillers are ignored.)",
                "pre."
            ],
            [
                "Empty element detection (Fillers are ignored.)",
                "rec."
            ],
            [
                "Empty element detection (Fillers are ignored.)",
                "F1"
            ],
            [
                "Nonlocal dependency identification",
                "pre."
            ],
            [
                "Nonlocal dependency identification",
                "rec."
            ],
            [
                "Nonlocal dependency identification",
                "F1"
            ],
            [
                "Nonlocal dependency identification (Unindexed empty elements are excluded.)",
                "pre."
            ],
            [
                "Nonlocal dependency identification (Unindexed empty elements are excluded.)",
                "rec."
            ],
            [
                "Nonlocal dependency identification (Unindexed empty elements are excluded.)",
                "F1"
            ]
        ],
        "contents": [
            [
                "85",
                "74",
                "79",
                "73",
                "63",
                "68",
                "\u2013",
                "\u2013",
                "\u2013"
            ],
            [
                "\u2013",
                "\u2013",
                "\u2013",
                "81.5",
                "68.7",
                "74.6",
                "\u2013",
                "\u2013",
                "\u2013"
            ],
            [
                "85.2",
                "81.7",
                "83.4",
                "78.3",
                "75.1",
                "76.7",
                "\u2013",
                "\u2013",
                "\u2013"
            ],
            [
                "86",
                "82.3",
                "84.1",
                "\u2013",
                "\u2013",
                "\u2013",
                "81.7",
                "73.5",
                "77.4"
            ],
            [
                "90.1",
                "79.5",
                "84.5",
                "\u2013",
                "\u2013",
                "\u2013",
                "\u2013",
                "\u2013",
                "\u2013"
            ],
            [
                "90.3",
                "81.7",
                "85.8",
                "\u2013",
                "\u2013",
                "\u2013",
                "\u2013",
                "\u2013",
                "\u2013"
            ],
            [
                "88.5",
                "82.1",
                "85.2",
                "81.4",
                "75.5",
                "78.4",
                "79.8",
                "73.8",
                "76.7"
            ],
            [
                "89.5",
                "81.6",
                "85.4",
                "74.3",
                "67.3",
                "70.6",
                "\u2013",
                "\u2013",
                "\u2013"
            ],
            [
                "93",
                "83",
                "88",
                "80",
                "70",
                "75",
                "\u2013",
                "\u2013",
                "\u2013"
            ],
            [
                "94.9",
                "91.1",
                "93",
                "90.1",
                "86.6",
                "88.4",
                "\u2013",
                "\u2013",
                "\u2013"
            ],
            [
                "92.6",
                "87.7",
                "90.1",
                "88.1",
                "83.4",
                "85.7",
                "88.4",
                "81.1",
                "84.6"
            ],
            [
                "94.2",
                "90.3",
                "92.3",
                "89.9",
                "86.2",
                "88",
                "90.4",
                "84.1",
                "87.2"
            ],
            [
                "94.9",
                "91.4",
                "93.1",
                "90.8",
                "87.4",
                "89",
                "91.6",
                "84.9",
                "88.1"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "pre.",
            "rec.",
            "F1",
            "pre.",
            "rec.",
            "F1",
            "pre.",
            "rec.",
            "F1"
        ],
        "target_entity": [
            "ours"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Empty element detection (Fillers are ignored.) || pre.</th>      <th>Empty element detection (Fillers are ignored.) || rec.</th>      <th>Empty element detection (Fillers are ignored.) || F1</th>      <th>Nonlocal dependency identification || pre.</th>      <th>Nonlocal dependency identification || rec.</th>      <th>Nonlocal dependency identification || F1</th>      <th>Nonlocal dependency identification (Unindexed empty elements are excluded.) || pre.</th>      <th>Nonlocal dependency identification (Unindexed empty elements are excluded.) || rec.</th>      <th>Nonlocal dependency identification (Unindexed empty elements are excluded.) || F1</th>    </tr>  </thead>  <tbody>    <tr>      <td>(Johnson, 2002)</td>      <td>85</td>      <td>74</td>      <td>79</td>      <td>73</td>      <td>63</td>      <td>68</td>      <td>\u2013</td>      <td>\u2013</td>      <td>\u2013</td>    </tr>    <tr>      <td>(Dienes and Dubey, 2003)</td>      <td>\u2013</td>      <td>\u2013</td>      <td>\u2013</td>      <td>81.5</td>      <td>68.7</td>      <td>74.6</td>      <td>\u2013</td>      <td>\u2013</td>      <td>\u2013</td>    </tr>    <tr>      <td>(Campbell, 2004)</td>      <td>85.2</td>      <td>81.7</td>      <td>83.4</td>      <td>78.3</td>      <td>75.1</td>      <td>76.7</td>      <td>\u2013</td>      <td>\u2013</td>      <td>\u2013</td>    </tr>    <tr>      <td>(Schmid, 2006)</td>      <td>86</td>      <td>82.3</td>      <td>84.1</td>      <td>\u2013</td>      <td>\u2013</td>      <td>\u2013</td>      <td>81.7</td>      <td>73.5</td>      <td>77.4</td>    </tr>    <tr>      <td>(Cai et al., 2011)</td>      <td>90.1</td>      <td>79.5</td>      <td>84.5</td>      <td>\u2013</td>      <td>\u2013</td>      <td>\u2013</td>      <td>\u2013</td>      <td>\u2013</td>      <td>\u2013</td>    </tr>    <tr>      <td>(Hayashi and Nagata, 2016)</td>      <td>90.3</td>      <td>81.7</td>      <td>85.8</td>      <td>\u2013</td>      <td>\u2013</td>      <td>\u2013</td>      <td>\u2013</td>      <td>\u2013</td>      <td>\u2013</td>    </tr>    <tr>      <td>(Kato and Matsubara, 2016)</td>      <td>88.5</td>      <td>82.1</td>      <td>85.2</td>      <td>81.4</td>      <td>75.5</td>      <td>78.4</td>      <td>79.8</td>      <td>73.8</td>      <td>76.7</td>    </tr>    <tr>      <td>(Kummerfeld and Klein, 2017)</td>      <td>89.5</td>      <td>81.6</td>      <td>85.4</td>      <td>74.3</td>      <td>67.3</td>      <td>70.6</td>      <td>\u2013</td>      <td>\u2013</td>      <td>\u2013</td>    </tr>    <tr>      <td>(Johnson, 2002)</td>      <td>93</td>      <td>83</td>      <td>88</td>      <td>80</td>      <td>70</td>      <td>75</td>      <td>\u2013</td>      <td>\u2013</td>      <td>\u2013</td>    </tr>    <tr>      <td>(Campbell, 2004)</td>      <td>94.9</td>      <td>91.1</td>      <td>93</td>      <td>90.1</td>      <td>86.6</td>      <td>88.4</td>      <td>\u2013</td>      <td>\u2013</td>      <td>\u2013</td>    </tr>    <tr>      <td>ours</td>      <td>92.6</td>      <td>87.7</td>      <td>90.1</td>      <td>88.1</td>      <td>83.4</td>      <td>85.7</td>      <td>88.4</td>      <td>81.1</td>      <td>84.6</td>    </tr>    <tr>      <td>ours (with ELMo)</td>      <td>94.2</td>      <td>90.3</td>      <td>92.3</td>      <td>89.9</td>      <td>86.2</td>      <td>88</td>      <td>90.4</td>      <td>84.1</td>      <td>87.2</td>    </tr>    <tr>      <td>ours (with BERT)</td>      <td>94.9</td>      <td>91.4</td>      <td>93.1</td>      <td>90.8</td>      <td>87.4</td>      <td>89</td>      <td>91.6</td>      <td>84.9</td>      <td>88.1</td>    </tr>  </tbody></table>",
        "table_name": "Table 2",
        "table_id": "table_2",
        "paper_id": "P19-1530",
        "page_no": 4,
        "dir": "acl2019",
        "valid": 1
    },
    {
        "table_id_paper": "P19-1565table_4",
        "caption": "Results of Self-Play Evaluation.",
        "row_header_level": 2,
        "row_headers": [
            [
                "System",
                "Retrieval"
            ],
            [
                "System",
                "Retrieval-Stgy"
            ],
            [
                "System",
                "Ours-PMI"
            ],
            [
                "System",
                "Ours-Neural"
            ],
            [
                "System",
                "Ours-Kernel"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "Succ. (%)"
            ],
            [
                "#Turns"
            ]
        ],
        "contents": [
            [
                "9.8",
                "3.26"
            ],
            [
                "67.2",
                "6.56"
            ],
            [
                "47.4",
                "5.12"
            ],
            [
                "51.6",
                "4.29"
            ],
            [
                "75",
                "4.2"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "Succ. (%)",
            "#Turns"
        ],
        "target_entity": [
            "Ours-Kernel"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Succ. (%)</th>      <th>#Turns</th>    </tr>  </thead>  <tbody>    <tr>      <td>System || Retrieval</td>      <td>9.8</td>      <td>3.26</td>    </tr>    <tr>      <td>System || Retrieval-Stgy</td>      <td>67.2</td>      <td>6.56</td>    </tr>    <tr>      <td>System || Ours-PMI</td>      <td>47.4</td>      <td>5.12</td>    </tr>    <tr>      <td>System || Ours-Neural</td>      <td>51.6</td>      <td>4.29</td>    </tr>    <tr>      <td>System || Ours-Kernel</td>      <td>75</td>      <td>4.2</td>    </tr>  </tbody></table>",
        "table_name": "Table 4",
        "table_id": "table_4",
        "paper_id": "P19-1565",
        "page_no": 8,
        "dir": "acl2019",
        "valid": 1
    },
    {
        "table_id_paper": "P19-1570table_7",
        "caption": "Comparison on the SCWS task. Setting (a) for WordCtx2Sense uses \u03bb = 0.1 for all pairs, and setting (b) uses \u03bb = 10\u22123 for pairs containing same target words and \u03bb = 0.1 for all other pairs. Word2Sense, Word2Vec and Word2GM neglect context and compare target words. a numbers reported from (Mu et al., 2017) whose experimental setup we could replicate.",
        "row_header_level": 2,
        "row_headers": [
            [
                "Method",
                "WordCtx2Sense (a)"
            ],
            [
                "Method",
                "WordCtx2Sense (b)"
            ],
            [
                "Method",
                "Word2Sense"
            ],
            [
                "Method",
                "Word2vec"
            ],
            [
                "Method",
                "(Mu et al., 2017)"
            ],
            [
                "Method",
                "(Huang et al., 2012)"
            ],
            [
                "Method",
                "(Arora et al., 2018)"
            ],
            [
                "Method",
                "Word2GM"
            ],
            [
                "Method",
                "MSSG.300D.30K"
            ],
            [
                "Method",
                "MSSG.300D.6K"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "Pearson-coefficient"
            ]
        ],
        "contents": [
            [
                "0.666"
            ],
            [
                "0.67"
            ],
            [
                "0.644"
            ],
            [
                "0.651"
            ],
            [
                "0.637"
            ],
            [
                "0.657"
            ],
            [
                "0.652"
            ],
            [
                "0.655"
            ],
            [
                "0.679a"
            ],
            [
                "0.678a"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "Pearson-coefficient"
        ],
        "target_entity": [
            "WordCtx2Sense (a)",
            "WordCtx2Sense (b)"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Pearson-coefficient</th>    </tr>  </thead>  <tbody>    <tr>      <td>Method || WordCtx2Sense (a)</td>      <td>0.666</td>    </tr>    <tr>      <td>Method || WordCtx2Sense (b)</td>      <td>0.67</td>    </tr>    <tr>      <td>Method || Word2Sense</td>      <td>0.644</td>    </tr>    <tr>      <td>Method || Word2vec</td>      <td>0.651</td>    </tr>    <tr>      <td>Method || (Mu et al., 2017)</td>      <td>0.637</td>    </tr>    <tr>      <td>Method || (Huang et al., 2012)</td>      <td>0.657</td>    </tr>    <tr>      <td>Method || (Arora et al., 2018)</td>      <td>0.652</td>    </tr>    <tr>      <td>Method || Word2GM</td>      <td>0.655</td>    </tr>    <tr>      <td>Method || MSSG.300D.30K</td>      <td>0.679a</td>    </tr>    <tr>      <td>Method || MSSG.300D.6K</td>      <td>0.678a</td>    </tr>  </tbody></table>",
        "table_name": "Table 7",
        "table_id": "table_7",
        "paper_id": "P19-1570",
        "page_no": 9,
        "dir": "acl2019",
        "valid": 1
    },
    {
        "table_id_paper": "P19-1581table_2",
        "caption": "Medical bilingual lexicon induction results showing the quality of the BWE based dictionaries using 1-best and 5-best translations.",
        "row_header_level": 2,
        "row_headers": [
            [
                "freq",
                "(Braune et al., 2018)"
            ],
            [
                "freq",
                "EU+UFAL+orth"
            ],
            [
                "rare",
                "(Braune et al., 2018)"
            ],
            [
                "rare",
                "EU+UFAL+orth"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "Acc1"
            ],
            [
                "Acc5"
            ]
        ],
        "contents": [
            [
                "38.6",
                "47.4"
            ],
            [
                "25.9",
                "40.6"
            ],
            [
                "26.3",
                "28.2"
            ],
            [
                "17.5",
                "28.8"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "Acc1",
            "Acc5"
        ],
        "target_entity": [
            "EU+UFAL+orth"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Acc1</th>      <th>Acc5</th>    </tr>  </thead>  <tbody>    <tr>      <td>freq || (Braune et al., 2018)</td>      <td>38.6</td>      <td>47.4</td>    </tr>    <tr>      <td>freq || EU+UFAL+orth</td>      <td>25.9</td>      <td>40.6</td>    </tr>    <tr>      <td>rare || (Braune et al., 2018)</td>      <td>26.3</td>      <td>28.2</td>    </tr>    <tr>      <td>rare || EU+UFAL+orth</td>      <td>17.5</td>      <td>28.8</td>    </tr>  </tbody></table>",
        "table_name": "Table 2",
        "table_id": "table_2",
        "paper_id": "P19-1581",
        "page_no": 4,
        "dir": "acl2019",
        "valid": 1
    },
    {
        "table_id_paper": "P19-1603table_1",
        "caption": "Automatic evaluation of sentiment analyzers.",
        "row_header_level": 2,
        "row_headers": [
            [
                "Model",
                "Rule-Based (RB)"
            ],
            [
                "Model",
                "Regression Model (RM)"
            ],
            [
                "Model",
                "Domain Adversarial (DA)"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "H-M SentiCons"
            ]
        ],
        "contents": [
            [
                "0.936"
            ],
            [
                "0.846"
            ],
            [
                "0.747"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "H-M SentiCons"
        ],
        "target_entity": [
            "Rule-Based (RB)"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>H-M SentiCons</th>    </tr>  </thead>  <tbody>    <tr>      <td>Model || Rule-Based (RB)</td>      <td>0.936</td>    </tr>    <tr>      <td>Model || Regression Model (RM)</td>      <td>0.846</td>    </tr>    <tr>      <td>Model || Domain Adversarial (DA)</td>      <td>0.747</td>    </tr>  </tbody></table>",
        "table_name": "Table 1",
        "table_id": "table_1",
        "paper_id": "P19-1603",
        "page_no": 4,
        "dir": "acl2019",
        "valid": 1
    },
    {
        "table_id_paper": "P19-1613table_4",
        "caption": "F1 score on the test set of HOTPOTQA distractor and full wiki setting. All numbers from the official leaderboard. All models except BiDAF are concurrent work (not published). DECOMPRC achieves the best result out of models reported to both distractor and full wiki setting.",
        "row_header_level": 2,
        "row_headers": [
            [
                "Model",
                "DECOMPRC"
            ],
            [
                "Model",
                "Cognitive Graph"
            ],
            [
                "Model",
                "BERT Plus"
            ],
            [
                "Model",
                "MultiQA"
            ],
            [
                "Model",
                "DFGN+BERT"
            ],
            [
                "Model",
                "QFE"
            ],
            [
                "Model",
                "GRN"
            ],
            [
                "Model",
                "BiDAF"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "Dist F1"
            ],
            [
                "Open F1"
            ]
        ],
        "contents": [
            [
                "69.63",
                "40.65"
            ],
            [
                "-",
                "48.87"
            ],
            [
                "69.76",
                "-"
            ],
            [
                "-",
                "40.23"
            ],
            [
                "68.49",
                "-"
            ],
            [
                "68.06",
                "38.06"
            ],
            [
                "66.71",
                "36.48"
            ],
            [
                "59.02",
                ""
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "dist f1",
            "open f1"
        ],
        "target_entity": [
            "DECOMPRC"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Dist F1</th>      <th>Open F1</th>    </tr>  </thead>  <tbody>    <tr>      <td>Model || DECOMPRC</td>      <td>69.63</td>      <td>40.65</td>    </tr>    <tr>      <td>Model || Cognitive Graph</td>      <td>-</td>      <td>48.87</td>    </tr>    <tr>      <td>Model || BERT Plus</td>      <td>69.76</td>      <td>-</td>    </tr>    <tr>      <td>Model || MultiQA</td>      <td>-</td>      <td>40.23</td>    </tr>    <tr>      <td>Model || DFGN+BERT</td>      <td>68.49</td>      <td>-</td>    </tr>    <tr>      <td>Model || QFE</td>      <td>68.06</td>      <td>38.06</td>    </tr>    <tr>      <td>Model || GRN</td>      <td>66.71</td>      <td>36.48</td>    </tr>    <tr>      <td>Model || BiDAF</td>      <td>59.02</td>      <td></td>    </tr>  </tbody></table>",
        "table_name": "Table 4",
        "table_id": "table_4",
        "paper_id": "P19-1613",
        "page_no": 6,
        "dir": "acl2019",
        "valid": 1
    },
    {
        "table_id_paper": "P19-1617table_1",
        "caption": "Performance comparison on the private test set of HotpotQA in the distractor setting. Our DFGN is the second best result on the leaderboard before submission (on March 1st). The baseline model is from Yang et al. (2018) and the results with \u2217 is unpublished. DFGN(Ours)\u2020 refers to the same model with a revised entity graph, whose entities are recognized by a BERT NER model. Note that the result of DFGN(Ours)\u2020 is submitted to the leaderboard during the review process of our paper.",
        "row_header_level": 2,
        "row_headers": [
            [
                "Model",
                "Baseline Model"
            ],
            [
                "Model",
                "GRN\u2217"
            ],
            [
                "Model",
                "DFGN(Ours)"
            ],
            [
                "Model",
                "QFE\u2217"
            ],
            [
                "Model",
                "DFGN(Ours)\u2020"
            ]
        ],
        "column_header_level": 2,
        "column_headers": [
            [
                "Answer",
                "EM"
            ],
            [
                "Answer",
                "F1"
            ],
            [
                "Sup Fact",
                "EM"
            ],
            [
                "Sup Fact",
                "F1"
            ],
            [
                "Joint",
                "EM"
            ],
            [
                "Joint",
                "F1"
            ]
        ],
        "contents": [
            [
                "45.60",
                "59.02",
                "20.32",
                "64.49",
                "10.83",
                "40.16"
            ],
            [
                "52.92",
                "66.71",
                "52.37",
                "84.11",
                "31.77",
                "58.47"
            ],
            [
                "55.17",
                "68.49",
                "49.85",
                "81.06",
                "31.87",
                "58.23"
            ],
            [
                "53.86",
                "68.06",
                "57.75",
                "84.49",
                "34.63",
                "59.61"
            ],
            [
                "56.31",
                "69.69",
                "51.50",
                "81.62",
                "33.62",
                "59.82"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "EM",
            "F1",
            "EM",
            "F1",
            "EM",
            "F1"
        ],
        "target_entity": [
            "DFGN(Ours)",
            "DFGN(Ours)\u2020"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Answer || EM</th>      <th>Answer || F1</th>      <th>Sup Fact || EM</th>      <th>Sup Fact || F1</th>      <th>Joint || EM</th>      <th>Joint || F1</th>    </tr>  </thead>  <tbody>    <tr>      <td>Model || Baseline Model</td>      <td>45.60</td>      <td>59.02</td>      <td>20.32</td>      <td>64.49</td>      <td>10.83</td>      <td>40.16</td>    </tr>    <tr>      <td>Model || GRN\u2217</td>      <td>52.92</td>      <td>66.71</td>      <td>52.37</td>      <td>84.11</td>      <td>31.77</td>      <td>58.47</td>    </tr>    <tr>      <td>Model || DFGN(Ours)</td>      <td>55.17</td>      <td>68.49</td>      <td>49.85</td>      <td>81.06</td>      <td>31.87</td>      <td>58.23</td>    </tr>    <tr>      <td>Model || QFE\u2217</td>      <td>53.86</td>      <td>68.06</td>      <td>57.75</td>      <td>84.49</td>      <td>34.63</td>      <td>59.61</td>    </tr>    <tr>      <td>Model || DFGN(Ours)\u2020</td>      <td>56.31</td>      <td>69.69</td>      <td>51.50</td>      <td>81.62</td>      <td>33.62</td>      <td>59.82</td>    </tr>  </tbody></table>",
        "table_name": "Table 1",
        "table_id": "table_1",
        "paper_id": "P19-1617",
        "page_no": 7,
        "dir": "acl2019",
        "valid": 1
    }
]