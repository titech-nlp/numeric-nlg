[
    {
        "table_id_paper": "D16-1019table_4",
        "caption": "Link prediction results on the test-I, test-II, and test-all sets of FB122 and WN18 (raw setting).",
        "row_header_level": 2,
        "row_headers": [
            [
                "FB122",
                "TransH"
            ],
            [
                "FB122",
                "TransR"
            ],
            [
                "FB122",
                "KALE-Trip"
            ],
            [
                "FB122",
                "KALE-Pre"
            ],
            [
                "FB122",
                "KALE-Joint"
            ],
            [
                "WN18",
                "TransE"
            ],
            [
                "WN18",
                "TransH"
            ],
            [
                "WN18",
                "TransR"
            ],
            [
                "WN18",
                "KALE-Trip"
            ],
            [
                "WN18",
                "KALE-Pre"
            ],
            [
                "WN18",
                "KALE-Joint"
            ]
        ],
        "column_header_level": 3,
        "column_headers": [
            [
                "Test-I",
                "MRR",
                "0.220"
            ],
            [
                "Test-I",
                "MED",
                "29.0"
            ],
            [
                "Test-I",
                "HITS@3 (%)",
                "25.7"
            ],
            [
                "Test-I",
                "HITS@5 (%)",
                "32.4"
            ],
            [
                "Test-I",
                "HITS@10 (%)",
                "40.6"
            ],
            [
                "Test-II",
                "MRR",
                "0.296"
            ],
            [
                "Test-II",
                "MED",
                "5.0"
            ],
            [
                "Test-II",
                "HITS@3 (%)",
                "40.0"
            ],
            [
                "Test-II",
                "HITS@5 (%)",
                "50.8"
            ],
            [
                "Test-II",
                "HITS@10 (%)",
                "57.8"
            ],
            [
                "Test-ALL",
                "MRR",
                "0.262"
            ],
            [
                "Test-ALL",
                "MED",
                "10.0"
            ],
            [
                "Test-ALL",
                "HITS@3 (%)",
                "33.6"
            ],
            [
                "Test-ALL",
                "HITS@5 (%)",
                "42.5"
            ],
            [
                "Test-ALL",
                "HITS@10 (%)",
                "50.0"
            ]
        ],
        "contents": [
            [
                "0.218",
                "29.0",
                "25.0",
                "31.3",
                "39.2",
                "0.297",
                "6.0",
                "37.5",
                "48.5",
                "56.3",
                "0.249",
                "12.0",
                "31.9",
                "40.7",
                "48.6"
            ],
            [
                "0.219",
                "31.0",
                "24.7",
                "30.8",
                "38.9",
                "0.273",
                "9.0",
                "32.4",
                "42.8",
                "51.6",
                "0.261",
                "15.0",
                "28.9",
                "37.4",
                "45.9"
            ],
            [
                "0.201",
                "25.0",
                "23.9",
                "31.6",
                "40.1",
                "0.309",
                "5.0",
                "40.9",
                "51.3",
                "58.0",
                "0.261",
                "11.0",
                "33.3",
                "42.4",
                "50.0"
            ],
            [
                "0.203",
                "25.0",
                "24.1",
                "31.7",
                "40.2",
                "0.368",
                "4.0",
                "47.3",
                "55.4",
                "61.4",
                "0.294",
                "9.0",
                "36.9",
                "44.8",
                "51.9"
            ],
            [
                "0.229",
                "21.0",
                "26.3",
                "33.8",
                "42.2",
                "0.357",
                "4.0",
                "44.0",
                "53.0",
                "59.3",
                "0.299",
                "9.0",
                "36.1",
                "44.3",
                "51.6"
            ],
            [
                "0.248",
                "4.0",
                "40.9",
                "60.6",
                "77.0",
                "0.363",
                "3.0",
                "59.4",
                "70.8",
                "81.4",
                "0.331",
                "3.0",
                "54.3",
                "67.9",
                "80.2"
            ],
            [
                "0.242",
                "4.0",
                "39.2",
                "60.1",
                "75.9",
                "0.482",
                "2.0",
                "63.5",
                "70.8",
                "79.3",
                "0.415",
                "3.0",
                "56.7",
                "67.8",
                "78.3"
            ],
            [
                "0.240",
                "4.0",
                "40.1",
                "57.7",
                "71.6",
                "0.449",
                "3.0",
                "55.7",
                "64.5",
                "74.3",
                "0.391",
                "3.0",
                "51.3",
                "62.6",
                "73.5"
            ],
            [
                "0.250",
                "4.0",
                "40.6",
                "62.3",
                "78.1",
                "0.393",
                "2.0",
                "61.9",
                "71.2",
                "80.6",
                "0.353",
                "3.0",
                "56.0",
                "68.7",
                "79.9"
            ],
            [
                "0.248",
                "4.0",
                "40.4",
                "61.5",
                "78.2",
                "0.451",
                "3.0",
                "69.6",
                "77.5",
                "85.3",
                "0.395",
                "3.0",
                "61.4",
                "73.0",
                "83.3"
            ],
            [
                "0.260",
                "4.0",
                "43.6",
                "64.1",
                "79.2",
                "0.563",
                "2.0",
                "67.6",
                "73.8",
                "81.0",
                "0.478",
                "2.0",
                "60.9",
                "71.1",
                "80.5"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "MRR",
            "MED",
            "HITS@3%",
            "HITS@5%",
            "HITS@10%",
            "MRR",
            "MED",
            "HITS@3%",
            "HITS@5%",
            "HITS@10%",
            "MRR",
            "MED",
            "HITS@3%",
            "HITS@5%",
            "HITS@10%"
        ],
        "target_entity": [
            "KALE-Trip",
            "KALE-Pre",
            "KALE-Joint"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Test-I || MRR || 0.220</th>      <th>Test-I || MED || 29.0</th>      <th>Test-I || HITS@3 (%) || 25.7</th>      <th>Test-I || HITS@5 (%) || 32.4</th>      <th>Test-I || HITS@10 (%) || 40.6</th>      <th>Test-II || MRR || 0.296</th>      <th>Test-II || MED || 5.0</th>      <th>Test-II || HITS@3 (%) || 40.0</th>      <th>Test-II || HITS@5 (%) || 50.8</th>      <th>Test-II || HITS@10 (%) || 57.8</th>      <th>Test-ALL || MRR || 0.262</th>      <th>Test-ALL || MED || 10.0</th>      <th>Test-ALL || HITS@3 (%) || 33.6</th>      <th>Test-ALL || HITS@5 (%) || 42.5</th>      <th>Test-ALL || HITS@10 (%) || 50.0</th>    </tr>  </thead>  <tbody>    <tr>      <td>FB122 || TransH</td>      <td>0.218</td>      <td>29.0</td>      <td>25.0</td>      <td>31.3</td>      <td>39.2</td>      <td>0.297</td>      <td>6.0</td>      <td>37.5</td>      <td>48.5</td>      <td>56.3</td>      <td>0.249</td>      <td>12.0</td>      <td>31.9</td>      <td>40.7</td>      <td>48.6</td>    </tr>    <tr>      <td>FB122 || TransR</td>      <td>0.219</td>      <td>31.0</td>      <td>24.7</td>      <td>30.8</td>      <td>38.9</td>      <td>0.273</td>      <td>9.0</td>      <td>32.4</td>      <td>42.8</td>      <td>51.6</td>      <td>0.261</td>      <td>15.0</td>      <td>28.9</td>      <td>37.4</td>      <td>45.9</td>    </tr>    <tr>      <td>FB122 || KALE-Trip</td>      <td>0.201</td>      <td>25.0</td>      <td>23.9</td>      <td>31.6</td>      <td>40.1</td>      <td>0.309</td>      <td>5.0</td>      <td>40.9</td>      <td>51.3</td>      <td>58.0</td>      <td>0.261</td>      <td>11.0</td>      <td>33.3</td>      <td>42.4</td>      <td>50.0</td>    </tr>    <tr>      <td>FB122 || KALE-Pre</td>      <td>0.203</td>      <td>25.0</td>      <td>24.1</td>      <td>31.7</td>      <td>40.2</td>      <td>0.368</td>      <td>4.0</td>      <td>47.3</td>      <td>55.4</td>      <td>61.4</td>      <td>0.294</td>      <td>9.0</td>      <td>36.9</td>      <td>44.8</td>      <td>51.9</td>    </tr>    <tr>      <td>FB122 || KALE-Joint</td>      <td>0.229</td>      <td>21.0</td>      <td>26.3</td>      <td>33.8</td>      <td>42.2</td>      <td>0.357</td>      <td>4.0</td>      <td>44.0</td>      <td>53.0</td>      <td>59.3</td>      <td>0.299</td>      <td>9.0</td>      <td>36.1</td>      <td>44.3</td>      <td>51.6</td>    </tr>    <tr>      <td>WN18 || TransE</td>      <td>0.248</td>      <td>4.0</td>      <td>40.9</td>      <td>60.6</td>      <td>77.0</td>      <td>0.363</td>      <td>3.0</td>      <td>59.4</td>      <td>70.8</td>      <td>81.4</td>      <td>0.331</td>      <td>3.0</td>      <td>54.3</td>      <td>67.9</td>      <td>80.2</td>    </tr>    <tr>      <td>WN18 || TransH</td>      <td>0.242</td>      <td>4.0</td>      <td>39.2</td>      <td>60.1</td>      <td>75.9</td>      <td>0.482</td>      <td>2.0</td>      <td>63.5</td>      <td>70.8</td>      <td>79.3</td>      <td>0.415</td>      <td>3.0</td>      <td>56.7</td>      <td>67.8</td>      <td>78.3</td>    </tr>    <tr>      <td>WN18 || TransR</td>      <td>0.240</td>      <td>4.0</td>      <td>40.1</td>      <td>57.7</td>      <td>71.6</td>      <td>0.449</td>      <td>3.0</td>      <td>55.7</td>      <td>64.5</td>      <td>74.3</td>      <td>0.391</td>      <td>3.0</td>      <td>51.3</td>      <td>62.6</td>      <td>73.5</td>    </tr>    <tr>      <td>WN18 || KALE-Trip</td>      <td>0.250</td>      <td>4.0</td>      <td>40.6</td>      <td>62.3</td>      <td>78.1</td>      <td>0.393</td>      <td>2.0</td>      <td>61.9</td>      <td>71.2</td>      <td>80.6</td>      <td>0.353</td>      <td>3.0</td>      <td>56.0</td>      <td>68.7</td>      <td>79.9</td>    </tr>    <tr>      <td>WN18 || KALE-Pre</td>      <td>0.248</td>      <td>4.0</td>      <td>40.4</td>      <td>61.5</td>      <td>78.2</td>      <td>0.451</td>      <td>3.0</td>      <td>69.6</td>      <td>77.5</td>      <td>85.3</td>      <td>0.395</td>      <td>3.0</td>      <td>61.4</td>      <td>73.0</td>      <td>83.3</td>    </tr>    <tr>      <td>WN18 || KALE-Joint</td>      <td>0.260</td>      <td>4.0</td>      <td>43.6</td>      <td>64.1</td>      <td>79.2</td>      <td>0.563</td>      <td>2.0</td>      <td>67.6</td>      <td>73.8</td>      <td>81.0</td>      <td>0.478</td>      <td>2.0</td>      <td>60.9</td>      <td>71.1</td>      <td>80.5</td>    </tr>  </tbody></table>",
        "table_name": "Table 4",
        "table_id": "table_4",
        "paper_id": "D16-1019",
        "page_no": 8,
        "dir": "emnlp2016",
        "valid": 1
    },
    {
        "table_id_paper": "D16-1038table_6",
        "caption": "Event Co-reference End-To-End Results.",
        "row_header_level": 2,
        "row_headers": [
            [
                "ACE (Cross-Validation)",
                "SSED + SupervisedExtend"
            ],
            [
                "ACE (Cross-Validation)",
                "SSED + MSEP-CorefESA+AUG+KNOW"
            ],
            [
                "ACE (Cross-Validation)",
                "MSEP-EMD + MSEP-CorefESA+AUG+KNOW"
            ],
            [
                "TAC-KBP (Test Data)",
                "TAC-TOP"
            ],
            [
                "TAC-KBP (Test Data)",
                "SSED + SupervisedExtend"
            ],
            [
                "TAC-KBP (Test Data)",
                "SSED + MSEP-CorefESA+AUG+KNOW"
            ],
            [
                "TAC-KBP (Test Data)",
                "MSEP-EMD + MSEP-CorefESA+AUG+KNOW"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "MUC"
            ],
            [
                "B3"
            ],
            [
                "CEAFe"
            ],
            [
                "BLANC"
            ],
            [
                "AVG"
            ]
        ],
        "contents": [
            [
                "47.1",
                "59.9",
                "58.7",
                "44.4",
                "52.5"
            ],
            [
                "42.1",
                "60.3",
                "59.0",
                "44.1",
                "51.4"
            ],
            [
                "40.2",
                "58.6",
                "57.4",
                "43.8",
                "50.0"
            ],
            [
                "\u2014",
                "\u2014",
                "\u2014",
                "\u2014",
                "39.1"
            ],
            [
                "34.9",
                "44.2",
                "39.6",
                "37.1",
                "39.0"
            ],
            [
                "33.1",
                "44.6",
                "39.7",
                "36.8",
                "38.5"
            ],
            [
                "30.2",
                "43.9",
                "38.7",
                "35.7",
                "37.1"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "MUC",
            "B3",
            "CEAFe",
            "BLANC",
            "AVG"
        ],
        "target_entity": [
            "SSED + SupervisedExtend"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>MUC</th>      <th>B3</th>      <th>CEAFe</th>      <th>BLANC</th>      <th>AVG</th>    </tr>  </thead>  <tbody>    <tr>      <td>ACE (Cross-Validation) || SSED + SupervisedExtend</td>      <td>47.1</td>      <td>59.9</td>      <td>58.7</td>      <td>44.4</td>      <td>52.5</td>    </tr>    <tr>      <td>ACE (Cross-Validation) || SSED + MSEP-CorefESA+AUG+KNOW</td>      <td>42.1</td>      <td>60.3</td>      <td>59.0</td>      <td>44.1</td>      <td>51.4</td>    </tr>    <tr>      <td>ACE (Cross-Validation) || MSEP-EMD + MSEP-CorefESA+AUG+KNOW</td>      <td>40.2</td>      <td>58.6</td>      <td>57.4</td>      <td>43.8</td>      <td>50.0</td>    </tr>    <tr>      <td>TAC-KBP (Test Data) || TAC-TOP</td>      <td>\u2014</td>      <td>\u2014</td>      <td>\u2014</td>      <td>\u2014</td>      <td>39.1</td>    </tr>    <tr>      <td>TAC-KBP (Test Data) || SSED + SupervisedExtend</td>      <td>34.9</td>      <td>44.2</td>      <td>39.6</td>      <td>37.1</td>      <td>39.0</td>    </tr>    <tr>      <td>TAC-KBP (Test Data) || SSED + MSEP-CorefESA+AUG+KNOW</td>      <td>33.1</td>      <td>44.6</td>      <td>39.7</td>      <td>36.8</td>      <td>38.5</td>    </tr>    <tr>      <td>TAC-KBP (Test Data) || MSEP-EMD + MSEP-CorefESA+AUG+KNOW</td>      <td>30.2</td>      <td>43.9</td>      <td>38.7</td>      <td>35.7</td>      <td>37.1</td>    </tr>  </tbody></table>",
        "table_name": "Table 6",
        "table_id": "table_6",
        "paper_id": "D16-1038",
        "page_no": 9,
        "dir": "emnlp2016",
        "valid": 1
    },
    {
        "table_id_paper": "D16-1042table_3",
        "caption": "Perplexity results on the test data for LTLMs and STLMs with different number of roles. Deterministic inference is denoted as det. and non-deterministic inference as non-det.",
        "row_header_level": 2,
        "row_headers": [
            [
                "Model",
                "STLM"
            ],
            [
                "Model",
                "non-det. LTLM"
            ],
            [
                "Model",
                "det. LTLM"
            ],
            [
                "Model",
                "4-gram MKN + STLM"
            ],
            [
                "Model",
                "4-gram MKN + non-det. LTLM"
            ],
            [
                "Model",
                "4-gram MKN + det. LTLM"
            ]
        ],
        "column_header_level": 3,
        "column_headers": [
            [
                "EN",
                "roles",
                "10"
            ],
            [
                "EN",
                "roles",
                "20"
            ],
            [
                "EN",
                "roles",
                "50"
            ],
            [
                "EN",
                "roles",
                "100"
            ],
            [
                "EN",
                "roles",
                "200"
            ],
            [
                "EN",
                "roles",
                "500"
            ],
            [
                "EN",
                "roles",
                "1000"
            ],
            [
                "CS",
                "roles",
                "10"
            ],
            [
                "CS",
                "roles",
                "20"
            ],
            [
                "CS",
                "roles",
                "50"
            ],
            [
                "CS",
                "roles",
                "100"
            ],
            [
                "CS",
                "roles",
                "200"
            ],
            [
                "CS",
                "500"
            ],
            [
                "CS",
                "1000"
            ]
        ],
        "contents": [
            [
                "408.5",
                "335.2",
                "261.7",
                "212.6",
                "178.9",
                "137.8",
                "113.7",
                "992.7",
                "764.2",
                "556.4",
                "451.0",
                "365.9",
                "265.7",
                "211.0"
            ],
            [
                "329.5",
                "215.1",
                "160.4",
                "126.5",
                "105.6",
                "86.7",
                "78.4",
                "851.0",
                "536.6",
                "367.4",
                "292.6",
                "235.2",
                "186.1",
                "157.6"
            ],
            [
                "252.4",
                "166.4",
                "115.3",
                "92.0",
                "75.4",
                "60.9",
                "54.2",
                "708.5",
                "390.2",
                "267.8",
                "213.2",
                "167.9",
                "133.5",
                "111.1"
            ],
            [
                "42.7",
                "41.6",
                "39.9",
                "37.9",
                "36.3",
                "34.9",
                "33.6",
                "67.5",
                "65.1",
                "61.4",
                "58.3",
                "55.5",
                "52.4",
                "50.1"
            ],
            [
                "41.1",
                "38.0",
                "35.2",
                "32.7",
                "30.7",
                "28.9",
                "27.8",
                "65.8",
                "59.4",
                "55.1",
                "51.1",
                "47.5",
                "43.7",
                "41.3"
            ],
            [
                "39.9",
                "36.4",
                "32.8",
                "30.3",
                "28.1",
                "26.0",
                "24.9",
                "64.4",
                "56.1",
                "51.5",
                "47.3",
                "43.4",
                "39.9",
                "37.2"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "perplexity",
            "perplexity",
            "perplexity",
            "perplexity",
            "perplexity",
            "perplexity",
            "perplexity",
            "perplexity",
            "perplexity",
            "perplexity",
            "perplexity",
            "perplexity",
            "perplexity",
            "perplexity"
        ],
        "target_entity": [
            "Model"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>EN || 10</th>      <th>EN || 20</th>      <th>EN || 50</th>      <th>EN || 100</th>      <th>EN || 200</th>      <th>EN || 500</th>      <th>EN || 1000</th>      <th>CS || 10</th>      <th>CS || 20</th>      <th>CS || 50</th>      <th>CS || 100</th>      <th>CS || 200</th>      <th>CS || 500</th>      <th>CS || 1000</th>    </tr>  </thead>  <tbody>    <tr>      <td>Model\\roles || STLM</td>      <td>408.5</td>      <td>335.2</td>      <td>261.7</td>      <td>212.6</td>      <td>178.9</td>      <td>137.8</td>      <td>113.7</td>      <td>992.7</td>      <td>764.2</td>      <td>556.4</td>      <td>451.0</td>      <td>365.9</td>      <td>265.7</td>      <td>211.0</td>    </tr>    <tr>      <td>Model\\roles || non-det. LTLM</td>      <td>329.5</td>      <td>215.1</td>      <td>160.4</td>      <td>126.5</td>      <td>105.6</td>      <td>86.7</td>      <td>78.4</td>      <td>851.0</td>      <td>536.6</td>      <td>367.4</td>      <td>292.6</td>      <td>235.2</td>      <td>186.1</td>      <td>157.6</td>    </tr>    <tr>      <td>Model\\roles || det. LTLM</td>      <td>252.4</td>      <td>166.4</td>      <td>115.3</td>      <td>92.0</td>      <td>75.4</td>      <td>60.9</td>      <td>54.2</td>      <td>708.5</td>      <td>390.2</td>      <td>267.8</td>      <td>213.2</td>      <td>167.9</td>      <td>133.5</td>      <td>111.1</td>    </tr>    <tr>      <td>Model\\roles || 4-gram MKN + STLM</td>      <td>42.7</td>      <td>41.6</td>      <td>39.9</td>      <td>37.9</td>      <td>36.3</td>      <td>34.9</td>      <td>33.6</td>      <td>67.5</td>      <td>65.1</td>      <td>61.4</td>      <td>58.3</td>      <td>55.5</td>      <td>52.4</td>      <td>50.1</td>    </tr>    <tr>      <td>Model\\roles || 4-gram MKN + non-det. LTLM</td>      <td>41.1</td>      <td>38.0</td>      <td>35.2</td>      <td>32.7</td>      <td>30.7</td>      <td>28.9</td>      <td>27.8</td>      <td>65.8</td>      <td>59.4</td>      <td>55.1</td>      <td>51.1</td>      <td>47.5</td>      <td>43.7</td>      <td>41.3</td>    </tr>    <tr>      <td>Model\\roles || 4-gram MKN + det. LTLM</td>      <td>39.9</td>      <td>36.4</td>      <td>32.8</td>      <td>30.3</td>      <td>28.1</td>      <td>26.0</td>      <td>24.9</td>      <td>64.4</td>      <td>56.1</td>      <td>51.5</td>      <td>47.3</td>      <td>43.4</td>      <td>39.9</td>      <td>37.2</td>    </tr>  </tbody></table>",
        "table_name": "Table 3",
        "table_id": "table_3",
        "paper_id": "D16-1042",
        "page_no": 8,
        "dir": "emnlp2016",
        "valid": 1
    },
    {
        "table_id_paper": "D16-1084table_5",
        "caption": "Results for the unseen target stance detection development setup for tweets containing the target vs tweets not containing the target.",
        "row_header_level": 6,
        "row_headers": [
            [
                "Method",
                "Concat",
                "inTwe",
                "Yes",
                "Stance",
                "FAVOR"
            ],
            [
                "Method",
                "Concat",
                "inTwe",
                "Yes",
                "Stance",
                "AGAINST"
            ],
            [
                "Method",
                "Concat",
                "inTwe",
                "Yes",
                "Stance",
                "Macro"
            ],
            [
                "Method",
                "Concat",
                "inTwe",
                "No",
                "Stance",
                "FAVOR"
            ],
            [
                "Method",
                "Concat",
                "inTwe",
                "No",
                "Stance",
                "AGAINST"
            ],
            [
                "Method",
                "Concat",
                "inTwe",
                "No",
                "Stance",
                "Macro"
            ],
            [
                "Method",
                "TweetCondTar",
                "inTwe",
                "Yes",
                "Stance",
                "FAVOR"
            ],
            [
                "Method",
                "TweetCondTar",
                "inTwe",
                "Yes",
                "Stance",
                "AGAINST"
            ],
            [
                "Method",
                "TweetCondTar",
                "inTwe",
                "Yes",
                "Stance",
                "Macro"
            ],
            [
                "Method",
                "TweetCondTar",
                "inTwe",
                "No",
                "Stance",
                "FAVOR"
            ],
            [
                "Method",
                "TweetCondTar",
                "inTwe",
                "No",
                "Stance",
                "AGAINST"
            ],
            [
                "Method",
                "TweetCondTar",
                "inTwe",
                "No",
                "Stance",
                "Macro"
            ],
            [
                "Method",
                "BiCond",
                "inTwe",
                "Yes",
                "Stance",
                "FAVOR"
            ],
            [
                "Method",
                "BiCond",
                "inTwe",
                "Yes",
                "Stance",
                "AGAINST"
            ],
            [
                "Method",
                "BiCond",
                "inTwe",
                "Yes",
                "Stance",
                "Macro"
            ],
            [
                "Method",
                "BiCond",
                "inTwe",
                "No",
                "Stance",
                "FAVOR"
            ],
            [
                "Method",
                "BiCond",
                "inTwe",
                "No",
                "Stance",
                "AGAINST"
            ],
            [
                "Method",
                "BiCond",
                "inTwe",
                "No",
                "Stance",
                "Macro"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "P"
            ],
            [
                "R"
            ],
            [
                "F1"
            ]
        ],
        "contents": [
            [
                "0.3153",
                "0.6214",
                "0.4183"
            ],
            [
                "0.7438",
                "0.4630",
                "0.5707"
            ],
            [
                "-",
                "-",
                "0.4945"
            ],
            [
                "0.0450",
                "0.6429",
                "0.0841"
            ],
            [
                "0.4793",
                "0.4265",
                "0.4514"
            ],
            [
                "-",
                "-",
                "0.2677"
            ],
            [
                "0.3529",
                "0.2330",
                "0.2807"
            ],
            [
                "0.7254",
                "0.8327",
                "0.7754"
            ],
            [
                "-",
                "-",
                "0.5280"
            ],
            [
                "0.0441",
                "0.2143",
                "0.0732"
            ],
            [
                "0.4663",
                "0.5588",
                "0.5084"
            ],
            [
                "-",
                "-",
                "0.2908"
            ],
            [
                "0.3585",
                "0.3689",
                "0.3636"
            ],
            [
                "0.7393",
                "0.7393",
                "0.7393"
            ],
            [
                "-",
                "-",
                "0.5515"
            ],
            [
                "0.0938",
                "0.4286",
                "0.1538"
            ],
            [
                "0.5846",
                "0.2794",
                "0.3781"
            ],
            [
                "-",
                "-",
                "0.2660"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "P",
            "R",
            "F1"
        ],
        "target_entity": [
            "BiCond"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>P</th>      <th>R</th>      <th>F1</th>    </tr>  </thead>  <tbody>    <tr>      <td>Method || Concat || inTwe || Yes || Stance || FAVOR</td>      <td>0.3153</td>      <td>0.6214</td>      <td>0.4183</td>    </tr>    <tr>      <td>Method || Concat || inTwe || Yes || Stance || AGAINST</td>      <td>0.7438</td>      <td>0.4630</td>      <td>0.5707</td>    </tr>    <tr>      <td>Method || Concat || inTwe || Yes || Stance || Macro</td>      <td>-</td>      <td>-</td>      <td>0.4945</td>    </tr>    <tr>      <td>Method || Concat || inTwe || No || Stance || FAVOR</td>      <td>0.0450</td>      <td>0.6429</td>      <td>0.0841</td>    </tr>    <tr>      <td>Method || Concat || inTwe || No || Stance || AGAINST</td>      <td>0.4793</td>      <td>0.4265</td>      <td>0.4514</td>    </tr>    <tr>      <td>Method || Concat || inTwe || No || Stance || Macro</td>      <td>-</td>      <td>-</td>      <td>0.2677</td>    </tr>    <tr>      <td>Method || TweetCondTar || inTwe || Yes || Stance || FAVOR</td>      <td>0.3529</td>      <td>0.2330</td>      <td>0.2807</td>    </tr>    <tr>      <td>Method || TweetCondTar || inTwe || Yes || Stance || AGAINST</td>      <td>0.7254</td>      <td>0.8327</td>      <td>0.7754</td>    </tr>    <tr>      <td>Method || TweetCondTar || inTwe || Yes || Stance || Macro</td>      <td>-</td>      <td>-</td>      <td>0.5280</td>    </tr>    <tr>      <td>Method || TweetCondTar || inTwe || No || Stance || FAVOR</td>      <td>0.0441</td>      <td>0.2143</td>      <td>0.0732</td>    </tr>    <tr>      <td>Method || TweetCondTar || inTwe || No || Stance || AGAINST</td>      <td>0.4663</td>      <td>0.5588</td>      <td>0.5084</td>    </tr>    <tr>      <td>Method || TweetCondTar || inTwe || No || Stance || Macro</td>      <td>-</td>      <td>-</td>      <td>0.2908</td>    </tr>    <tr>      <td>Method || BiCond || inTwe || Yes || Stance || FAVOR</td>      <td>0.3585</td>      <td>0.3689</td>      <td>0.3636</td>    </tr>    <tr>      <td>Method || BiCond || inTwe || Yes || Stance || AGAINST</td>      <td>0.7393</td>      <td>0.7393</td>      <td>0.7393</td>    </tr>    <tr>      <td>Method || BiCond || inTwe || Yes || Stance || Macro</td>      <td>-</td>      <td>-</td>      <td>0.5515</td>    </tr>    <tr>      <td>Method || BiCond || inTwe || No || Stance || FAVOR</td>      <td>0.0938</td>      <td>0.4286</td>      <td>0.1538</td>    </tr>    <tr>      <td>Method || BiCond || inTwe || No || Stance || AGAINST</td>      <td>0.5846</td>      <td>0.2794</td>      <td>0.3781</td>    </tr>    <tr>      <td>Method || BiCond || inTwe || No || Stance || Macro</td>      <td>-</td>      <td>-</td>      <td>0.2660</td>    </tr>  </tbody></table>",
        "table_name": "Table 5",
        "table_id": "table_5",
        "paper_id": "D16-1084",
        "page_no": 6,
        "dir": "emnlp2016",
        "valid": 1
    },
    {
        "table_id_paper": "D16-1116table_2",
        "caption": "Non-neural and neural model results on GEOQUERY using the train/test split from (Zettlemoyer and Collins, 2005).",
        "row_header_level": 2,
        "row_headers": [
            [
                "Model",
                "Zettlemoyer and Collins (2005)"
            ],
            [
                "Model",
                "Zettlemoyer and Collins (2007)"
            ],
            [
                "Model",
                "Liang et al. (2013)"
            ],
            [
                "Model",
                "Kwiatkowski et al. (2011)"
            ],
            [
                "Model",
                "Zhao and Huang (2014)"
            ],
            [
                "Model",
                "Kwiatkowski et al. (2013)"
            ],
            [
                "Model",
                "Dong and Lapata (2016)"
            ],
            [
                "Model",
                "Jia and Liang (2016)6"
            ],
            [
                "Model",
                "S2S"
            ],
            [
                "Model",
                "SEQ4"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "Accuracy"
            ]
        ],
        "contents": [
            [
                "79.3"
            ],
            [
                "86.1"
            ],
            [
                "87.9"
            ],
            [
                "88.6"
            ],
            [
                "88.9"
            ],
            [
                "89.0"
            ],
            [
                "84.6"
            ],
            [
                "89.3"
            ],
            [
                "86.5"
            ],
            [
                "87.3"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "accuracy"
        ],
        "target_entity": [
            "S2S",
            "SEQ4"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Accuracy</th>    </tr>  </thead>  <tbody>    <tr>      <td>Model || Zettlemoyer and Collins (2005)</td>      <td>79.3</td>    </tr>    <tr>      <td>Model || Zettlemoyer and Collins (2007)</td>      <td>86.1</td>    </tr>    <tr>      <td>Model || Liang et al. (2013)</td>      <td>87.9</td>    </tr>    <tr>      <td>Model || Kwiatkowski et al. (2011)</td>      <td>88.6</td>    </tr>    <tr>      <td>Model || Zhao and Huang (2014)</td>      <td>88.9</td>    </tr>    <tr>      <td>Model || Kwiatkowski et al. (2013)</td>      <td>89.0</td>    </tr>    <tr>      <td>Model || Dong and Lapata (2016)</td>      <td>84.6</td>    </tr>    <tr>      <td>Model || Jia and Liang (2016)6</td>      <td>89.3</td>    </tr>    <tr>      <td>Model || S2S</td>      <td>86.5</td>    </tr>    <tr>      <td>Model || SEQ4</td>      <td>87.3</td>    </tr>  </tbody></table>",
        "table_name": "Table 2",
        "table_id": "table_2",
        "paper_id": "D16-1116",
        "page_no": 5,
        "dir": "emnlp2016",
        "valid": 1
    },
    {
        "table_id_paper": "D16-1129table_4",
        "caption": "Results for experiment 2. P = precision, R = recall, M-F1 = macro F1, C.I. = confidence interval at 0.95. Both BLSTM and BLSTM/ATT/CNN are significantly better than SVM-RBF (p < 0.05, exact Liddell\u2019s test).",
        "row_header_level": 2,
        "row_headers": [
            [
                "Model",
                "SVM-RBF"
            ],
            [
                "Model",
                "BLSTM"
            ],
            [
                "Model",
                "BLSTM/ATT/CNN"
            ]
        ],
        "column_header_level": 2,
        "column_headers": [
            [
                "Class C5",
                "P"
            ],
            [
                "Class C5",
                "R"
            ],
            [
                "Class C5",
                "F1"
            ],
            [
                "Class C6",
                "P"
            ],
            [
                "Class C6",
                "R"
            ],
            [
                "Class C6",
                "F1"
            ],
            [
                "Class C7",
                "P"
            ],
            [
                "Class C7",
                "R"
            ],
            [
                "Class C7",
                "F1"
            ],
            [
                "-",
                "M-F1"
            ],
            [
                "-",
                "C.I."
            ]
        ],
        "contents": [
            [
                "0.351",
                "0.023",
                "0.044",
                "0.394",
                "0.083",
                "0.137",
                "0.446",
                "0.918",
                "0.600",
                "0.260",
                "0.014"
            ],
            [
                "0.265",
                "0.600",
                "0.368",
                "0.376",
                "0.229",
                "0.285",
                "0.479",
                "0.301",
                "0.370",
                "0.341",
                "0.015"
            ],
            [
                "0.270",
                "0.625",
                "0.378",
                "0.421",
                "0.247",
                "0.311",
                "0.484",
                "0.301",
                "0.371",
                "0.353",
                "0.015"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "P",
            "R",
            "F1",
            "P",
            "R",
            "F1",
            "P",
            "R",
            "F1",
            "M-F1",
            "C.I."
        ],
        "target_entity": [
            "BLSTM",
            "BLSTM/ATT/CNN"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Class C5 || P</th>      <th>Class C5 || R</th>      <th>Class C5 || F1</th>      <th>Class C6 || P</th>      <th>Class C6 || R</th>      <th>Class C6 || F1</th>      <th>Class C7 || P</th>      <th>Class C7 || R</th>      <th>Class C7 || F1</th>      <th>- || M-F1</th>      <th>- || C.I.</th>    </tr>  </thead>  <tbody>    <tr>      <td>Model || SVM-RBF</td>      <td>0.351</td>      <td>0.023</td>      <td>0.044</td>      <td>0.394</td>      <td>0.083</td>      <td>0.137</td>      <td>0.446</td>      <td>0.918</td>      <td>0.600</td>      <td>0.260</td>      <td>0.014</td>    </tr>    <tr>      <td>Model || BLSTM</td>      <td>0.265</td>      <td>0.600</td>      <td>0.368</td>      <td>0.376</td>      <td>0.229</td>      <td>0.285</td>      <td>0.479</td>      <td>0.301</td>      <td>0.370</td>      <td>0.341</td>      <td>0.015</td>    </tr>    <tr>      <td>Model || BLSTM/ATT/CNN</td>      <td>0.270</td>      <td>0.625</td>      <td>0.378</td>      <td>0.421</td>      <td>0.247</td>      <td>0.311</td>      <td>0.484</td>      <td>0.301</td>      <td>0.371</td>      <td>0.353</td>      <td>0.015</td>    </tr>  </tbody></table>",
        "table_name": "Table 4",
        "table_id": "table_4",
        "paper_id": "D16-1129",
        "page_no": 8,
        "dir": "emnlp2016",
        "valid": 1
    },
    {
        "table_id_paper": "D16-1154table_2",
        "caption": "LMs performance on the PTB test set.",
        "row_header_level": 2,
        "row_headers": [
            [
                "-",
                "N-1="
            ],
            [
                "-",
                "KN"
            ],
            [
                "-",
                "KN+cache"
            ],
            [
                "1 Hidden Layer",
                "FFNN"
            ],
            [
                "1 Hidden Layer",
                "FOFE"
            ],
            [
                "Recurrent Models (1 Layer)",
                "RNN"
            ],
            [
                "Recurrent Models (1 Layer)",
                "LSTM (1L)"
            ],
            [
                "Recurrent Models (1 Layer)",
                "LSRC (100)"
            ],
            [
                "Recurrent Models (1 Layer)",
                "LSRC (200)"
            ],
            [
                "2 Hidden Layers",
                "FFNN"
            ],
            [
                "2 Hidden Layers",
                "FOFE"
            ],
            [
                "Deep Recurrent Models",
                "D-LSTM (2L)"
            ],
            [
                "Deep Recurrent Models",
                "D-RNN4 (3L)"
            ],
            [
                "Deep Recurrent Models",
                "D-LSRC (100)"
            ],
            [
                "Deep Recurrent Models",
                "D-LSRC (200)"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "model"
            ],
            [
                "model"
            ],
            [
                "model"
            ],
            [
                "model+KN5"
            ],
            [
                "model+KN5"
            ],
            [
                "model+KN5"
            ],
            [
                "NoP"
            ]
        ],
        "contents": [
            [
                "1",
                "2",
                "4",
                "1",
                "2",
                "4",
                "4"
            ],
            [
                "186",
                "148",
                "141",
                "-",
                "-",
                "-",
                "-"
            ],
            [
                "168",
                "134",
                "129",
                "-",
                "-",
                "-",
                "-"
            ],
            [
                "176",
                "131",
                "119",
                "132",
                "116",
                "107",
                "6.32M"
            ],
            [
                "123",
                "111",
                "112",
                "108",
                "100",
                "101",
                "6.32M"
            ],
            [
                "117",
                "117",
                "117",
                "104",
                "104",
                "104",
                "8.16M"
            ],
            [
                "113",
                "113",
                "113",
                "99",
                "99",
                "99",
                "6.96M"
            ],
            [
                "109",
                "109",
                "109",
                "96",
                "96",
                "96",
                "5.81M"
            ],
            [
                "104",
                "104",
                "104",
                "94",
                "94",
                "94",
                "7.0M"
            ],
            [
                "176",
                "129",
                "114",
                "132",
                "114",
                "102",
                "6.96M"
            ],
            [
                "116",
                "108",
                "109",
                "104",
                "98",
                "97",
                "6.96M"
            ],
            [
                "110",
                "110",
                "110",
                "97",
                "97",
                "97",
                "8.42M"
            ],
            [
                "107.5",
                "107.5",
                "107.5",
                "NR",
                "NR",
                "NR",
                "6.16M"
            ],
            [
                "103",
                "103",
                "103",
                "93",
                "93",
                "93",
                "5.97M"
            ],
            [
                "102",
                "102",
                "102",
                "92",
                "92",
                "92",
                "7.16M"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "perplexity",
            "perplexity",
            "perplexity",
            "perplexity",
            "perplexity",
            "perplexity",
            "NoP"
        ],
        "target_entity": [
            "LSRC (100)",
            "LSRC (200)",
            "D-LSRC (200)",
            "D-LSRC (100)"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>model</th>      <th>model</th>      <th>model</th>      <th>model+KN5</th>      <th>model+KN5</th>      <th>model+KN5</th>      <th>NoP</th>    </tr>  </thead>  <tbody>    <tr>      <td>- || N-1=</td>      <td>1</td>      <td>2</td>      <td>4</td>      <td>1</td>      <td>2</td>      <td>4</td>      <td>4</td>    </tr>    <tr>      <td>- || KN</td>      <td>186</td>      <td>148</td>      <td>141</td>      <td>-</td>      <td>-</td>      <td>-</td>      <td>-</td>    </tr>    <tr>      <td>- || KN+cache</td>      <td>168</td>      <td>134</td>      <td>129</td>      <td>-</td>      <td>-</td>      <td>-</td>      <td>-</td>    </tr>    <tr>      <td>1 Hidden Layer || FFNN</td>      <td>176</td>      <td>131</td>      <td>119</td>      <td>132</td>      <td>116</td>      <td>107</td>      <td>6.32M</td>    </tr>    <tr>      <td>1 Hidden Layer || FOFE</td>      <td>123</td>      <td>111</td>      <td>112</td>      <td>108</td>      <td>100</td>      <td>101</td>      <td>6.32M</td>    </tr>    <tr>      <td>Recurrent Models (1 Layer) || RNN</td>      <td>117</td>      <td>117</td>      <td>117</td>      <td>104</td>      <td>104</td>      <td>104</td>      <td>8.16M</td>    </tr>    <tr>      <td>Recurrent Models (1 Layer) || LSTM (1L)</td>      <td>113</td>      <td>113</td>      <td>113</td>      <td>99</td>      <td>99</td>      <td>99</td>      <td>6.96M</td>    </tr>    <tr>      <td>Recurrent Models (1 Layer) || LSRC (100)</td>      <td>109</td>      <td>109</td>      <td>109</td>      <td>96</td>      <td>96</td>      <td>96</td>      <td>5.81M</td>    </tr>    <tr>      <td>Recurrent Models (1 Layer) || LSRC (200)</td>      <td>104</td>      <td>104</td>      <td>104</td>      <td>94</td>      <td>94</td>      <td>94</td>      <td>7.0M</td>    </tr>    <tr>      <td>2 Hidden Layers || FFNN</td>      <td>176</td>      <td>129</td>      <td>114</td>      <td>132</td>      <td>114</td>      <td>102</td>      <td>6.96M</td>    </tr>    <tr>      <td>2 Hidden Layers || FOFE</td>      <td>116</td>      <td>108</td>      <td>109</td>      <td>104</td>      <td>98</td>      <td>97</td>      <td>6.96M</td>    </tr>    <tr>      <td>Deep Recurrent Models || D-LSTM (2L)</td>      <td>110</td>      <td>110</td>      <td>110</td>      <td>97</td>      <td>97</td>      <td>97</td>      <td>8.42M</td>    </tr>    <tr>      <td>Deep Recurrent Models || D-RNN4 (3L)</td>      <td>107.5</td>      <td>107.5</td>      <td>107.5</td>      <td>NR</td>      <td>NR</td>      <td>NR</td>      <td>6.16M</td>    </tr>    <tr>      <td>Deep Recurrent Models || D-LSRC (100)</td>      <td>103</td>      <td>103</td>      <td>103</td>      <td>93</td>      <td>93</td>      <td>93</td>      <td>5.97M</td>    </tr>    <tr>      <td>Deep Recurrent Models || D-LSRC (200)</td>      <td>102</td>      <td>102</td>      <td>102</td>      <td>92</td>      <td>92</td>      <td>92</td>      <td>7.16M</td>    </tr>  </tbody></table>",
        "table_name": "Table 2",
        "table_id": "table_2",
        "paper_id": "D16-1154",
        "page_no": 7,
        "dir": "emnlp2016",
        "valid": 1
    },
    {
        "table_id_paper": "D16-1159table_5",
        "caption": "Perplexity, labeled F1-score, and Tree Edit Distance (TED) of various systems. Labeled F1-scores are calculated on EVALB-trees only. Tree edit distances are calculated on the well-formed trees only. EVALB-trees are those whose number of leaves match the number of words in the source sentence, and are otherwise accepted by standard Treebank evaluation software.",
        "row_header_level": 2,
        "row_headers": [
            [
                "Model",
                "PE2PE2P"
            ],
            [
                "Model",
                "E2E2P"
            ],
            [
                "Model",
                "E2G2P"
            ],
            [
                "Model",
                "E2F2P"
            ],
            [
                "Model",
                "E2P"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "Perplexity on Train"
            ],
            [
                "Perplexity on WSJ 22"
            ],
            [
                "Labeled F1 on WSJ23"
            ],
            [
                "# EVALB-trees (out of 2416)"
            ],
            [
                "Average TED per sentence"
            ],
            [
                "# Well-formed trees (out of 2416)"
            ]
        ],
        "contents": [
            [
                "1.83",
                "1.92",
                "46.64",
                "818",
                "34.43",
                "2416"
            ],
            [
                "1.69",
                "1.77",
                "59.35",
                "796",
                "31.25",
                "2416"
            ],
            [
                "1.39",
                "1.41",
                "80.34",
                "974",
                "17.11",
                "2340"
            ],
            [
                "1.36",
                "1.38",
                "79.27",
                "1093",
                "17.77",
                "2415"
            ],
            [
                "1.11",
                "1.18",
                "89.61",
                "2362",
                "11.50",
                "2415"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "Perplexity on Train",
            "Perplexity on WSJ 22",
            "Labeled F1 on WSJ23",
            "# EVALB-trees (out of 2416)",
            "Average TED per sentence",
            "# Well-formed trees (out of 2416)"
        ],
        "target_entity": [
            "Model"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Perplexity on Train</th>      <th>Perplexity on WSJ 22</th>      <th>Labeled F1 on WSJ23</th>      <th># EVALB-trees (out of 2416)</th>      <th>Average TED per sentence</th>      <th># Well-formed trees (out of 2416)</th>    </tr>  </thead>  <tbody>    <tr>      <td>Model || PE2PE2P</td>      <td>1.83</td>      <td>1.92</td>      <td>46.64</td>      <td>818</td>      <td>34.43</td>      <td>2416</td>    </tr>    <tr>      <td>Model || E2E2P</td>      <td>1.69</td>      <td>1.77</td>      <td>59.35</td>      <td>796</td>      <td>31.25</td>      <td>2416</td>    </tr>    <tr>      <td>Model || E2G2P</td>      <td>1.39</td>      <td>1.41</td>      <td>80.34</td>      <td>974</td>      <td>17.11</td>      <td>2340</td>    </tr>    <tr>      <td>Model || E2F2P</td>      <td>1.36</td>      <td>1.38</td>      <td>79.27</td>      <td>1093</td>      <td>17.77</td>      <td>2415</td>    </tr>    <tr>      <td>Model || E2P</td>      <td>1.11</td>      <td>1.18</td>      <td>89.61</td>      <td>2362</td>      <td>11.50</td>      <td>2415</td>    </tr>  </tbody></table>",
        "table_name": "Table 5",
        "table_id": "table_5",
        "paper_id": "D16-1159",
        "page_no": 7,
        "dir": "emnlp2016",
        "valid": 1
    },
    {
        "table_id_paper": "D16-1165table_1",
        "caption": "Results on the answer ranking task of our full NN vs. variants using partial information.",
        "row_header_level": 3,
        "row_headers": [
            [
                "System",
                "Relevance relations only",
                "-"
            ],
            [
                "System",
                "Relevance relations only",
                "+ Appropriateness"
            ],
            [
                "System",
                "Relevance relations only",
                "+ Relatedness"
            ],
            [
                "System",
                "Full Network",
                "-"
            ],
            [
                "System",
                "Baseline 1 (random)",
                "-"
            ],
            [
                "System",
                "Baseline 2 (IR+chron.)",
                "-"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "MAP"
            ],
            [
                "AvgRec"
            ],
            [
                "MRR"
            ]
        ],
        "contents": [
            [
                "21.78",
                "20.66",
                "22.59"
            ],
            [
                "30.94",
                "29.86",
                "35.02"
            ],
            [
                "52.43",
                "57.05",
                "60.14"
            ],
            [
                "54.51",
                "60.93",
                "62.94"
            ],
            [
                "15.01",
                "11.44",
                "15.19"
            ],
            [
                "40.36",
                "45.97",
                "45.83"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "MAP",
            "AvgRec",
            "MRR"
        ],
        "target_entity": [
            "Full Network"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>MAP</th>      <th>AvgRec</th>      <th>MRR</th>    </tr>  </thead>  <tbody>    <tr>      <td>System || Relevance relations only || -</td>      <td>21.78</td>      <td>20.66</td>      <td>22.59</td>    </tr>    <tr>      <td>System || Relevance relations only || '+ Appropriateness'</td>      <td>30.94</td>      <td>29.86</td>      <td>35.02</td>    </tr>    <tr>      <td>System || Relevance relations only || '+ Relatedness'</td>      <td>52.43</td>      <td>57.05</td>      <td>60.14</td>    </tr>    <tr>      <td>System || Full Network || -</td>      <td>54.51</td>      <td>60.93</td>      <td>62.94</td>    </tr>    <tr>      <td>System || Baseline 1 (random) || -</td>      <td>15.01</td>      <td>11.44</td>      <td>15.19</td>    </tr>    <tr>      <td>System || Baseline 2 (IR+chron.) || -</td>      <td>40.36</td>      <td>45.97</td>      <td>45.83</td>    </tr>  </tbody></table>",
        "table_name": "Table 1",
        "table_id": "table_1",
        "paper_id": "D16-1165",
        "page_no": 7,
        "dir": "emnlp2016",
        "valid": 1
    },
    {
        "table_id_paper": "D16-1173table_3",
        "caption": "Comparisons between our mutual distillation (rows 4-5) and other knowledge optimization methods, on SST2. See the text for details. The numbers in parentheses are the accuracy of the learned knowledge component (Figure 1, right part) if we take it as a standalone classifier. All knowledge is used.",
        "row_header_level": 3,
        "row_headers": [
            [
                "Model",
                "1",
                "CNN (Kim, 2014)"
            ],
            [
                "Model",
                "2",
                "opt-joint"
            ],
            [
                "Model",
                "3",
                "opt-knwl-pipeline"
            ],
            [
                "Model",
                "4",
                "opt-joint-iterative-p"
            ],
            [
                "Model",
                "5",
                "opt-joint-iterative-q"
            ],
            [
                "Model",
                "6",
                "mutual-p"
            ],
            [
                "Model",
                "7",
                "mutual-q"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "Accuracy (%)"
            ]
        ],
        "contents": [
            [
                "86.6"
            ],
            [
                "86.9 (68.8)"
            ],
            [
                "86.7 (70.4)"
            ],
            [
                "86.9"
            ],
            [
                "87.6 (68.6)"
            ],
            [
                "87.2"
            ],
            [
                "88.0 (72.5)"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "Accuracy (%)"
        ],
        "target_entity": [
            "Model"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Accuracy (%)</th>    </tr>  </thead>  <tbody>    <tr>      <td>Model || 1 || CNN (Kim, 2014)</td>      <td>86.6</td>    </tr>    <tr>      <td>Model || 2 || opt-joint</td>      <td>86.9 (68.8)</td>    </tr>    <tr>      <td>Model || 3 || opt-knwl-pipeline</td>      <td>86.7 (70.4)</td>    </tr>    <tr>      <td>Model || 4 || opt-joint-iterative-p</td>      <td>86.9</td>    </tr>    <tr>      <td>Model || 5 || opt-joint-iterative-q</td>      <td>87.6 (68.6)</td>    </tr>    <tr>      <td>Model || 6 || mutual-p</td>      <td>87.2</td>    </tr>    <tr>      <td>Model || 7 || mutual-q</td>      <td>88.0 (72.5)</td>    </tr>  </tbody></table>",
        "table_name": "Table 3",
        "table_id": "table_3",
        "paper_id": "D16-1173",
        "page_no": 8,
        "dir": "emnlp2016",
        "valid": 1
    },
    {
        "table_id_paper": "D16-1174table_3",
        "caption": "Pearson (r \u00d7 100) and Spearman (\u03c1 \u00d7 100) correlation scores on four standard word similarity benchmarks. For each benchmark, we show the results reported by any of the comparison systems along with the scores for their corresponding initial word representations (word-based).",
        "row_header_level": 4,
        "row_headers": [
            [
                "Dataset",
                "MEN-3K",
                "Approach",
                "Iacobacci et al. (2015)"
            ],
            [
                "Dataset",
                "MEN-3K",
                "Approach",
                "DECONF"
            ],
            [
                "Dataset",
                "MEN-3K",
                "Approach",
                "Faruqui et al. (2015)"
            ],
            [
                "Dataset",
                "MEN-3K",
                "Approach",
                "Pilehvar and Navigli (2015)"
            ],
            [
                "Dataset",
                "RG-65",
                "Approach",
                "DECONF"
            ],
            [
                "Dataset",
                "RG-66",
                "Approach",
                "Iacobacci et al. (2015)"
            ],
            [
                "Dataset",
                "RG-67",
                "Approach",
                "Faruqui et al. (2015)"
            ],
            [
                "Dataset",
                "RG-68",
                "Approach",
                "Pilehvar and Navigli (2015)"
            ],
            [
                "Dataset",
                "YP-130",
                "Approach",
                "DECONF"
            ],
            [
                "Dataset",
                "YP-131",
                "Approach",
                "Pilehvar and Navigli (2015)"
            ],
            [
                "Dataset",
                "YP-132",
                "Approach",
                "Iacobacci et al. (2015)"
            ],
            [
                "Dataset",
                "SimLex-999",
                "Approach",
                "DECONF"
            ],
            [
                "Dataset",
                "SimLex-999",
                "Approach",
                "Pilehvar and Navigli (2015)"
            ]
        ],
        "column_header_level": 2,
        "column_headers": [
            [
                "Sense-based score",
                "r"
            ],
            [
                "Sense-based score",
                "rho"
            ],
            [
                "Word-based score",
                "r"
            ],
            [
                "Word-based score",
                "rho"
            ]
        ],
        "contents": [
            [
                "?",
                "80.5",
                "?",
                "66.5"
            ],
            [
                "78.0",
                "78.6",
                "72.3",
                "73.2"
            ],
            [
                "?",
                "75.9",
                "?",
                "73.7"
            ],
            [
                "61.7",
                "66.6",
                "?",
                "?"
            ],
            [
                "90.5",
                "89.6",
                "77.2",
                "76.1"
            ],
            [
                "?",
                "87.1",
                "?",
                "73.2"
            ],
            [
                "?",
                "84.2",
                "?",
                "76.7"
            ],
            [
                "80.2",
                "84.3",
                "?",
                "?"
            ],
            [
                "81.6",
                "75.2",
                "58.0",
                "55.9"
            ],
            [
                "79.0",
                "71.0",
                "?",
                "?"
            ],
            [
                "?",
                "63.9",
                "?",
                "34.3"
            ],
            [
                "54.2",
                "51.7",
                "45.4",
                "44.2"
            ],
            [
                "43.4",
                "43.6",
                "?",
                "?"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "r",
            "rho",
            "r",
            "rho"
        ],
        "target_entity": [
            "DECONF"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Sense-based score || r</th>      <th>Sense-based score || ?</th>      <th>Word-based score || r</th>      <th>Word-based score || ?</th>    </tr>  </thead>  <tbody>    <tr>      <td>Dataset || MEN-3K || Approach || Iacobacci et al. (2015)</td>      <td>?</td>      <td>80.5</td>      <td>?</td>      <td>66.5</td>    </tr>    <tr>      <td>Dataset || MEN-3K || Approach || DECONF</td>      <td>78.0</td>      <td>78.6</td>      <td>72.3</td>      <td>73.2</td>    </tr>    <tr>      <td>Dataset || MEN-3K || Approach || Faruqui et al. (2015)</td>      <td>?</td>      <td>75.9</td>      <td>?</td>      <td>73.7</td>    </tr>    <tr>      <td>Dataset || MEN-3K || Approach || Pilehvar and Navigli (2015)</td>      <td>61.7</td>      <td>66.6</td>      <td>?</td>      <td>?</td>    </tr>    <tr>      <td>Dataset || RG-65 || Approach || DECONF</td>      <td>90.5</td>      <td>89.6</td>      <td>77.2</td>      <td>76.1</td>    </tr>    <tr>      <td>Dataset || RG-66 || Approach || Iacobacci et al. (2015)</td>      <td>?</td>      <td>87.1</td>      <td>?</td>      <td>73.2</td>    </tr>    <tr>      <td>Dataset || RG-67 || Approach || Faruqui et al. (2015)</td>      <td>?</td>      <td>84.2</td>      <td>?</td>      <td>76.7</td>    </tr>    <tr>      <td>Dataset || RG-68 || Approach || Pilehvar and Navigli (2015)</td>      <td>80.2</td>      <td>84.3</td>      <td>?</td>      <td>?</td>    </tr>    <tr>      <td>Dataset || YP-130 || Approach || DECONF</td>      <td>81.6</td>      <td>75.2</td>      <td>58.0</td>      <td>55.9</td>    </tr>    <tr>      <td>Dataset || YP-131 || Approach || Pilehvar and Navigli (2015)</td>      <td>79.0</td>      <td>71.0</td>      <td>?</td>      <td>?</td>    </tr>    <tr>      <td>Dataset || YP-132 || Approach || Iacobacci et al. (2015)</td>      <td>?</td>      <td>63.9</td>      <td>?</td>      <td>34.3</td>    </tr>    <tr>      <td>Dataset || SimLex-999 || Approach || DECONF</td>      <td>54.2</td>      <td>51.7</td>      <td>45.4</td>      <td>44.2</td>    </tr>    <tr>      <td>Dataset || SimLex-999 || Approach || Pilehvar and Navigli (2015)</td>      <td>43.4</td>      <td>43.6</td>      <td>?</td>      <td>?</td>    </tr>  </tbody></table>",
        "table_name": "Table 3",
        "table_id": "table_3",
        "paper_id": "D16-1174",
        "page_no": 7,
        "dir": "emnlp2016",
        "valid": 1
    },
    {
        "table_id_paper": "D16-1175table_2",
        "caption": "Comparison of composition by union and composition by intersection. Not all features are displayed for space reasons.",
        "row_header_level": 3,
        "row_headers": [
            [
                "Composition by union",
                "Distributional Features",
                ":shoes"
            ],
            [
                "Composition by union",
                "Distributional Features",
                "amod:clean"
            ],
            [
                "Composition by union",
                "Distributional Features",
                "dobj:bought"
            ],
            [
                "Composition by union",
                "Distributional Features",
                "dobj:folded"
            ],
            [
                "Composition by union",
                "Distributional Features",
                "dobj:folded"
            ],
            [
                "Composition by union",
                "Distributional Features",
                "dobj:like"
            ],
            [
                "Composition by intersection",
                "Distributional Features",
                "dobj:nsubj:we"
            ],
            [
                "Composition by intersection",
                "Distributional Features",
                "dobj:nsubj:we"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "Co-occurrence Count"
            ]
        ],
        "contents": [
            [
                "1"
            ],
            [
                "1"
            ],
            [
                "1"
            ],
            [
                "2"
            ],
            [
                "2"
            ],
            [
                "1"
            ],
            [
                "2"
            ],
            [
                "2"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "Co-occurrence Count"
        ],
        "target_entity": [
            "Composition by union",
            "Composition by intersection"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Co-occurrence Count</th>    </tr>  </thead>  <tbody>    <tr>      <td>Composition by union || Distributional Features || :shoes</td>      <td>1</td>    </tr>    <tr>      <td>Composition by union || Distributional Features || amod:clean</td>      <td>1</td>    </tr>    <tr>      <td>Composition by union || Distributional Features || dobj:bought</td>      <td>1</td>    </tr>    <tr>      <td>Composition by union || Distributional Features || dobj:folded</td>      <td>2</td>    </tr>    <tr>      <td>Composition by union || Distributional Features || dobj:folded</td>      <td>2</td>    </tr>    <tr>      <td>Composition by union || Distributional Features || dobj:like</td>      <td>1</td>    </tr>    <tr>      <td>Composition by intersection || Distributional Features || dobj:nsubj:we</td>      <td>2</td>    </tr>    <tr>      <td>Composition by intersection || Distributional Features || dobj:nsubj:we</td>      <td>2</td>    </tr>  </tbody></table>",
        "table_name": "Table 2",
        "table_id": "table_2",
        "paper_id": "D16-1175",
        "page_no": 4,
        "dir": "emnlp2016",
        "valid": 1
    },
    {
        "table_id_paper": "D16-1186table_8",
        "caption": "Evaluation results for the on-/off-topic classification with the ExtraTreeClassifier",
        "row_header_level": 2,
        "row_headers": [
            [
                "Class",
                "off-topic info"
            ],
            [
                "Class",
                "requirements"
            ],
            [
                "Class",
                "Avg."
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "Precision"
            ],
            [
                "Recall"
            ],
            [
                "F1"
            ]
        ],
        "contents": [
            [
                "0.94",
                "0.85",
                "0.89"
            ],
            [
                "0.89",
                "0.96",
                "0.93"
            ],
            [
                "0.92",
                "0.91",
                "0.91"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "Precision",
            "Recall",
            "F1"
        ],
        "target_entity": [
            "Avg."
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Precision</th>      <th>Recall</th>      <th>F1</th>    </tr>  </thead>  <tbody>    <tr>      <td>Class || off-topic info</td>      <td>0.94</td>      <td>0.85</td>      <td>0.89</td>    </tr>    <tr>      <td>Class || requirements</td>      <td>0.89</td>      <td>0.96</td>      <td>0.93</td>    </tr>    <tr>      <td>Class || Avg.</td>      <td>0.92</td>      <td>0.91</td>      <td>0.91</td>    </tr>  </tbody></table>",
        "table_name": "Table 8",
        "table_id": "table_8",
        "paper_id": "D16-1186",
        "page_no": 8,
        "dir": "emnlp2016",
        "valid": 1
    },
    {
        "table_id_paper": "D16-1189table_2",
        "caption": "Mean and standard deviation of random and upperbound performance (with N = 10, K = 3) across different subreddits.",
        "row_header_level": 2,
        "row_headers": [
            [
                "Subreddit",
                "askscience"
            ],
            [
                "Subreddit",
                "askmen"
            ],
            [
                "Subreddit",
                "todayilearned"
            ],
            [
                "Subreddit",
                "worldnews"
            ],
            [
                "Subreddit",
                "nfl"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "Random"
            ],
            [
                "Upper bound"
            ]
        ],
        "contents": [
            [
                "321.3 (7.0)",
                "2109.0 (16.5)"
            ],
            [
                "132.4 (0.7)",
                "651.4 (2.8)"
            ],
            [
                "390.3 (5.7)",
                "2679.6 (30.1)"
            ],
            [
                "205.8 (4.5)",
                "1853.4 (44.4)"
            ],
            [
                "237.1 (1.4",
                "1338.2 (13.2)"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "mean",
            "mean"
        ],
        "target_entity": [
            "Subreddit"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Random</th>      <th>Upper bound</th>    </tr>  </thead>  <tbody>    <tr>      <td>Subreddit || askscience</td>      <td>321.3 (7.0)</td>      <td>2109.0 (16.5)</td>    </tr>    <tr>      <td>Subreddit || askmen</td>      <td>132.4 (0.7)</td>      <td>651.4 (2.8)</td>    </tr>    <tr>      <td>Subreddit || todayilearned</td>      <td>390.3 (5.7)</td>      <td>2679.6 (30.1)</td>    </tr>    <tr>      <td>Subreddit || worldnews</td>      <td>205.8 (4.5)</td>      <td>1853.4 (44.4)</td>    </tr>    <tr>      <td>Subreddit || nfl</td>      <td>237.1 (1.4</td>      <td>1338.2 (13.2)</td>    </tr>  </tbody></table>",
        "table_name": "Table 2",
        "table_id": "table_2",
        "paper_id": "D16-1189",
        "page_no": 6,
        "dir": "emnlp2016",
        "valid": 1
    },
    {
        "table_id_paper": "D16-1199table_3",
        "caption": "Results of five-fold cross validation. Our Tri-CNN model achieves the best results in MAP and MRR.",
        "row_header_level": 2,
        "row_headers": [
            [
                "Model",
                "TF-IDF"
            ],
            [
                "Model",
                "BM-25"
            ],
            [
                "Model",
                "AVG"
            ],
            [
                "Model",
                "RNN"
            ],
            [
                "Model",
                "ATTN1511"
            ],
            [
                "Model",
                "CNN"
            ],
            [
                "Model",
                "Tri-CNN"
            ]
        ],
        "column_header_level": 2,
        "column_headers": [
            [
                "MAP",
                "Avg"
            ],
            [
                "MAP",
                "SD"
            ],
            [
                "MRR",
                "Avg"
            ],
            [
                "MRR",
                "SD"
            ]
        ],
        "contents": [
            [
                "0.503",
                "0.004",
                "0.501",
                "0.065"
            ],
            [
                "0.531",
                "0.007",
                "0.532",
                "0.056"
            ],
            [
                "0.593",
                "0.021",
                "0.609",
                "0.042"
            ],
            [
                "0.685",
                "0.024",
                "0.674",
                "0.028"
            ],
            [
                "0.772",
                "0.016",
                "0.771",
                "0.014"
            ],
            [
                "0.757",
                "0.015",
                "0.754",
                "0.024"
            ],
            [
                "0.806",
                "0.014",
                "0.781",
                "0.025"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "MAP",
            "MAP",
            "MRR",
            "MRR"
        ],
        "target_entity": [
            "Tri-CNN"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>MAP || Avg</th>      <th>MAP || SD</th>      <th>MRR || Avg</th>      <th>MRR || SD</th>    </tr>  </thead>  <tbody>    <tr>      <td>Model || TF-IDF</td>      <td>0.503</td>      <td>0.004</td>      <td>0.501</td>      <td>0.065</td>    </tr>    <tr>      <td>Model || BM-25</td>      <td>0.531</td>      <td>0.007</td>      <td>0.532</td>      <td>0.056</td>    </tr>    <tr>      <td>Model || AVG</td>      <td>0.593</td>      <td>0.021</td>      <td>0.609</td>      <td>0.042</td>    </tr>    <tr>      <td>Model || RNN</td>      <td>0.685</td>      <td>0.024</td>      <td>0.674</td>      <td>0.028</td>    </tr>    <tr>      <td>Model || ATTN1511</td>      <td>0.772</td>      <td>0.016</td>      <td>0.771</td>      <td>0.014</td>    </tr>    <tr>      <td>Model || CNN</td>      <td>0.757</td>      <td>0.015</td>      <td>0.754</td>      <td>0.024</td>    </tr>    <tr>      <td>Model || Tri-CNN</td>      <td>0.806</td>      <td>0.014</td>      <td>0.781</td>      <td>0.025</td>    </tr>  </tbody></table>",
        "table_name": "Table 3",
        "table_id": "table_3",
        "paper_id": "D16-1199",
        "page_no": 4,
        "dir": "emnlp2016",
        "valid": 1
    },
    {
        "table_id_paper": "D17-1008table_8",
        "caption": "Performance comparison between T-O-M and SemEval-2015\u2019s best SUDOKU Run.",
        "row_header_level": 4,
        "row_headers": [
            [
                "Language",
                "Italian",
                "Dataset",
                "ALL"
            ],
            [
                "Language",
                "Italian",
                "Dataset",
                "Computers & Math"
            ],
            [
                "Language",
                "Italian",
                "Dataset",
                "Biomedicine"
            ],
            [
                "Language",
                "Spanish",
                "Dataset",
                "ALL"
            ],
            [
                "Language",
                "Spanish",
                "Dataset",
                "Computers & Math"
            ],
            [
                "Language",
                "Spanish",
                "Dataset",
                "Biomedicine"
            ]
        ],
        "column_header_level": 2,
        "column_headers": [
            [
                "Best System",
                "F1"
            ],
            [
                "Train-O-Matic",
                "P"
            ],
            [
                "Train-O-Matic",
                "R"
            ],
            [
                "Train-O-Matic",
                "F1"
            ]
        ],
        "contents": [
            [
                "56.6",
                "65.1",
                "55.6",
                "59.9"
            ],
            [
                "46.6",
                "52.7",
                "43.3",
                "47.6"
            ],
            [
                "65.9",
                "76.6",
                "67.6",
                "71.8"
            ],
            [
                "56.3",
                "61.3",
                "54.8",
                "57.9"
            ],
            [
                "42.4",
                "53.3",
                "44.4",
                "48.5"
            ],
            [
                "65.5",
                "71.8",
                "65.5",
                "68.5"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "F1",
            "P",
            "R",
            "F1"
        ],
        "target_entity": [
            "Train-O-Matic"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Best System || F1</th>      <th>Train-O-Matic || P</th>      <th>Train-O-Matic || R</th>      <th>Train-O-Matic || F1</th>    </tr>  </thead>  <tbody>    <tr>      <td>Language || Italian || Dataset || ALL</td>      <td>56.6</td>      <td>65.1</td>      <td>55.6</td>      <td>59.9</td>    </tr>    <tr>      <td>Language || Italian || Dataset || Computers &amp; Math</td>      <td>46.6</td>      <td>52.7</td>      <td>43.3</td>      <td>47.6</td>    </tr>    <tr>      <td>Language || Italian || Dataset || Biomedicine</td>      <td>65.9</td>      <td>76.6</td>      <td>67.6</td>      <td>71.8</td>    </tr>    <tr>      <td>Language || Spanish || Dataset || ALL</td>      <td>56.3</td>      <td>61.3</td>      <td>54.8</td>      <td>57.9</td>    </tr>    <tr>      <td>Language || Spanish || Dataset || Computers &amp; Math</td>      <td>42.4</td>      <td>53.3</td>      <td>44.4</td>      <td>48.5</td>    </tr>    <tr>      <td>Language || Spanish || Dataset || Biomedicine</td>      <td>65.5</td>      <td>71.8</td>      <td>65.5</td>      <td>68.5</td>    </tr>  </tbody></table>",
        "table_name": "Table 8",
        "table_id": "table_8",
        "paper_id": "D17-1008",
        "page_no": 8,
        "dir": "emnlp2017",
        "valid": 1
    },
    {
        "table_id_paper": "D17-1215table_2",
        "caption": "Adversarial evaluation on the MatchLSTM and BiDAF systems. All four systems can be fooled by adversarial examples.",
        "row_header_level": 1,
        "row_headers": [
            [
                "Original"
            ],
            [
                "ADDSENT"
            ],
            [
                "ADDONESENT"
            ],
            [
                "ADDANY"
            ],
            [
                "ADDCOMMON"
            ]
        ],
        "column_header_level": 2,
        "column_headers": [
            [
                "Match",
                "Single"
            ],
            [
                "Match",
                "Ens."
            ],
            [
                "BiDAF",
                "Single"
            ],
            [
                "BiDAF",
                "Ens."
            ]
        ],
        "contents": [
            [
                "71.4",
                "75.4",
                "75.5",
                "80"
            ],
            [
                "27.3",
                "29.4",
                "34.3",
                "34.2"
            ],
            [
                "39",
                "41.8",
                "45.7",
                "46.9"
            ],
            [
                "7.6",
                "11.7",
                "4.8",
                "2.7"
            ],
            [
                "38.9",
                "51",
                "41.7",
                "52.6"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "F1",
            "F1",
            "F1",
            "F1"
        ],
        "target_entity": [
            "ADDSENT",
            "ADDONESENT",
            "ADDANY",
            "ADDCOMMON"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Match || Single</th>      <th>Match || Ens.</th>      <th>BiDAF || Single</th>      <th>BiDAF || Ens.</th>    </tr>  </thead>  <tbody>    <tr>      <td>Original</td>      <td>71.4</td>      <td>75.4</td>      <td>75.5</td>      <td>80</td>    </tr>    <tr>      <td>ADDSENT</td>      <td>27.3</td>      <td>29.4</td>      <td>34.3</td>      <td>34.2</td>    </tr>    <tr>      <td>ADDONESENT</td>      <td>39</td>      <td>41.8</td>      <td>45.7</td>      <td>46.9</td>    </tr>    <tr>      <td>ADDANY</td>      <td>7.6</td>      <td>11.7</td>      <td>4.8</td>      <td>2.7</td>    </tr>    <tr>      <td>ADDCOMMON</td>      <td>38.9</td>      <td>51</td>      <td>41.7</td>      <td>52.6</td>    </tr>  </tbody></table>",
        "table_name": "Table 2",
        "table_id": "table_2",
        "paper_id": "D17-1215",
        "page_no": 5,
        "dir": "emnlp2017",
        "valid": 1
    },
    {
        "table_id_paper": "D17-1224table_3",
        "caption": "Comparison results on two-part evaluation II",
        "row_header_level": 2,
        "row_headers": [
            [
                "Method",
                "Lead"
            ],
            [
                "Method",
                "Coverage"
            ],
            [
                "Method",
                "TextRank"
            ],
            [
                "Method",
                "Centroid"
            ],
            [
                "Method",
                "ILP"
            ],
            [
                "Method",
                "ClusterCMRW"
            ],
            [
                "Method",
                "Submodular"
            ],
            [
                "Method",
                "SenDivRank"
            ],
            [
                "Method",
                "Our Approach"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "R-1"
            ],
            [
                "R-2"
            ],
            [
                "R-SU4"
            ]
        ],
        "contents": [
            [
                "0.3985",
                "0.11888",
                "0.16209"
            ],
            [
                "0.39957",
                "0.1161",
                "0.15753"
            ],
            [
                "0.41132",
                "0.12045",
                "0.16317"
            ],
            [
                "0.40071",
                "0.11772",
                "0.15859"
            ],
            [
                "0.40795",
                "0.12149",
                "0.1635"
            ],
            [
                "0.41379",
                "0.12769",
                "0.16935"
            ],
            [
                "0.40677",
                "0.11903",
                "0.16163"
            ],
            [
                "0.4021",
                "0.12704",
                "0.17001"
            ],
            [
                "0.42207",
                "0.14401",
                "0.18392"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "R-1",
            "R-2",
            "R-SU4"
        ],
        "target_entity": [
            "Our Approach"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>R-1</th>      <th>R-2</th>      <th>R-SU4</th>    </tr>  </thead>  <tbody>    <tr>      <td>Method || Lead</td>      <td>0.3985</td>      <td>0.11888</td>      <td>0.16209</td>    </tr>    <tr>      <td>Method || Coverage</td>      <td>0.39957</td>      <td>0.1161</td>      <td>0.15753</td>    </tr>    <tr>      <td>Method || TextRank</td>      <td>0.41132</td>      <td>0.12045</td>      <td>0.16317</td>    </tr>    <tr>      <td>Method || Centroid</td>      <td>0.40071</td>      <td>0.11772</td>      <td>0.15859</td>    </tr>    <tr>      <td>Method || ILP</td>      <td>0.40795</td>      <td>0.12149</td>      <td>0.1635</td>    </tr>    <tr>      <td>Method || ClusterCMRW</td>      <td>0.41379</td>      <td>0.12769</td>      <td>0.16935</td>    </tr>    <tr>      <td>Method || Submodular</td>      <td>0.40677</td>      <td>0.11903</td>      <td>0.16163</td>    </tr>    <tr>      <td>Method || SenDivRank</td>      <td>0.4021</td>      <td>0.12704</td>      <td>0.17001</td>    </tr>    <tr>      <td>Method || Our Approach</td>      <td>0.42207</td>      <td>0.14401</td>      <td>0.18392</td>    </tr>  </tbody></table>",
        "table_name": "Table 3",
        "table_id": "table_3",
        "paper_id": "D17-1224",
        "page_no": 4,
        "dir": "emnlp2017",
        "valid": 1
    },
    {
        "table_id_paper": "D17-1231table_6",
        "caption": "DA classification results (%) using different systems.",
        "row_header_level": 1,
        "row_headers": [
            [
                "CNN baseline no context"
            ],
            [
                "CNN + DA predictions"
            ],
            [
                "CNN + RNN/BLSTM"
            ],
            [
                "CNN + CNN"
            ],
            [
                "CNN prob + DA transition"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "set 1"
            ],
            [
                "set 2"
            ]
        ],
        "contents": [
            [
                "74.73",
                "77.12"
            ],
            [
                "76.73",
                "79.9"
            ],
            [
                "76.91",
                "79.7"
            ],
            [
                "77.15",
                "79.74"
            ],
            [
                "76.7",
                "79.69"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "accuracy",
            "accuracy"
        ],
        "target_entity": [
            "CNN baseline no context",
            "CNN + DA predictions",
            "CNN + RNN/BLSTM",
            "CNN + CNN",
            "CNN prob + DA transition"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>set 1</th>      <th>set 2</th>    </tr>  </thead>  <tbody>    <tr>      <td>CNN baseline no context</td>      <td>74.73</td>      <td>77.12</td>    </tr>    <tr>      <td>CNN + DA predictions</td>      <td>76.73</td>      <td>79.9</td>    </tr>    <tr>      <td>CNN + RNN/BLSTM</td>      <td>76.91</td>      <td>79.7</td>    </tr>    <tr>      <td>CNN + CNN</td>      <td>77.15</td>      <td>79.74</td>    </tr>    <tr>      <td>CNN prob + DA transition</td>      <td>76.7</td>      <td>79.69</td>    </tr>  </tbody></table>",
        "table_name": "Table 6",
        "table_id": "table_6",
        "paper_id": "D17-1231",
        "page_no": 8,
        "dir": "emnlp2017",
        "valid": 1
    },
    {
        "table_id_paper": "D17-1252table_3",
        "caption": "Implicit Supervision: Semantic Parsing. By updating the entity linking and semantic parsing models jointly, MMRN-JOINT improves over MMRN-PIPELINE by 5 points in F1 and outperforms REINFORCE+ (SP). It also improves the entity linking result on the WebQSP questions (EL).",
        "row_header_level": 1,
        "row_headers": [
            [
                "MMRN-PIPELINE"
            ],
            [
                "MMRN-JOINT"
            ],
            [
                "REINFORCE"
            ],
            [
                "REINFORCE+"
            ],
            [
                "STAGG"
            ]
        ],
        "column_header_level": 2,
        "column_headers": [
            [
                "SP",
                "Avg. F1"
            ],
            [
                "EL",
                "P"
            ],
            [
                "EL",
                "R"
            ],
            [
                "EL",
                "F1"
            ]
        ],
        "contents": [
            [
                "62.5",
                "85.6",
                "77.5",
                "81.3"
            ],
            [
                "68.1",
                "89.3",
                "78.9",
                "83.7"
            ],
            [
                "62.9",
                "87.5",
                "76.6",
                "81.7"
            ],
            [
                "66.7",
                "91.1",
                "76.9",
                "83.4"
            ],
            [
                "66.8",
                "-",
                "-",
                "-"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "Avg. F1",
            "P",
            "R",
            "F1"
        ],
        "target_entity": [
            "MMRN-JOINT"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>SP || Avg. F1</th>      <th>EL || P</th>      <th>EL || R</th>      <th>EL || F1</th>    </tr>  </thead>  <tbody>    <tr>      <td>MMRN-PIPELINE</td>      <td>62.5</td>      <td>85.6</td>      <td>77.5</td>      <td>81.3</td>    </tr>    <tr>      <td>MMRN-JOINT</td>      <td>68.1</td>      <td>89.3</td>      <td>78.9</td>      <td>83.7</td>    </tr>    <tr>      <td>REINFORCE</td>      <td>62.9</td>      <td>87.5</td>      <td>76.6</td>      <td>81.7</td>    </tr>    <tr>      <td>REINFORCE+</td>      <td>66.7</td>      <td>91.1</td>      <td>76.9</td>      <td>83.4</td>    </tr>    <tr>      <td>STAGG</td>      <td>66.8</td>      <td>-</td>      <td>-</td>      <td>-</td>    </tr>  </tbody></table>",
        "table_name": "Table 3",
        "table_id": "table_3",
        "paper_id": "D17-1252",
        "page_no": 8,
        "dir": "emnlp2017",
        "valid": 1
    },
    {
        "table_id_paper": "D17-1274table_5",
        "caption": "Overall Performance for SFV: all the Baseline Systems are from Yu et al. (2014a).",
        "row_header_level": 2,
        "row_headers": [
            [
                "Methods",
                "Random"
            ],
            [
                "Methods",
                "Voting"
            ],
            [
                "Methods",
                "Linguistic Indicators"
            ],
            [
                "Methods",
                "SVM"
            ],
            [
                "Methods",
                "MTM (Yu et al., 2014a)"
            ],
            [
                "Our Approach",
                "-"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "Precision (%)"
            ],
            [
                "Recall (%)"
            ],
            [
                "F-score (%)"
            ]
        ],
        "contents": [
            [
                "28.64",
                "50.48",
                "36.54"
            ],
            [
                "42.16",
                "70.18",
                "52.68"
            ],
            [
                "50.24",
                "70.69",
                "58.73"
            ],
            [
                "56.59",
                "48.72",
                "52.36"
            ],
            [
                "53.94",
                "72.11",
                "61.72"
            ],
            [
                "70.46",
                "64.07",
                "67.11"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "Precision (%)",
            "Recall (%)",
            "F-score (%)"
        ],
        "target_entity": [
            "Our Approach"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Precision (%)</th>      <th>Recall (%)</th>      <th>F-score (%)</th>    </tr>  </thead>  <tbody>    <tr>      <td>Methods || Random</td>      <td>28.64</td>      <td>50.48</td>      <td>36.54</td>    </tr>    <tr>      <td>Methods || Voting</td>      <td>42.16</td>      <td>70.18</td>      <td>52.68</td>    </tr>    <tr>      <td>Methods || Linguistic Indicators</td>      <td>50.24</td>      <td>70.69</td>      <td>58.73</td>    </tr>    <tr>      <td>Methods || SVM</td>      <td>56.59</td>      <td>48.72</td>      <td>52.36</td>    </tr>    <tr>      <td>Methods || MTM (Yu et al., 2014a)</td>      <td>53.94</td>      <td>72.11</td>      <td>61.72</td>    </tr>    <tr>      <td>Our Approach || -</td>      <td>70.46</td>      <td>64.07</td>      <td>67.11</td>    </tr>  </tbody></table>",
        "table_name": "Table 5",
        "table_id": "table_5",
        "paper_id": "D17-1274",
        "page_no": 8,
        "dir": "emnlp2017",
        "valid": 1
    },
    {
        "table_id_paper": "D17-1276table_2",
        "caption": "Main results (on ACE).",
        "row_header_level": 1,
        "row_headers": [
            [
                "LCRF (single)"
            ],
            [
                "LCRF (multiple)"
            ],
            [
                "Lu and Roth (2015)"
            ],
            [
                "This work (STATE)"
            ],
            [
                "This work (EDGE)"
            ]
        ],
        "column_header_level": 2,
        "column_headers": [
            [
                "ACE-2004",
                "P"
            ],
            [
                "ACE-2004",
                "R"
            ],
            [
                "ACE-2004",
                "F1"
            ],
            [
                "ACE-2005",
                "w/s"
            ],
            [
                "ACE-2005",
                "P"
            ],
            [
                "ACE-2005",
                "R"
            ],
            [
                "ACE-2005",
                "F1"
            ],
            [
                "ACE-2005",
                "w/s"
            ],
            [
                "ACE-2004 (F1 optimized)",
                "P"
            ],
            [
                "ACE-2004 (F1 optimized)",
                "R"
            ],
            [
                "ACE-2004 (F1 optimized)",
                "F1"
            ],
            [
                "ACE-2005 (F1 optimized)",
                "P"
            ],
            [
                "ACE-2005 (F1 optimized)",
                "R"
            ],
            [
                "ACE-2005 (F1 optimized)",
                "F1"
            ]
        ],
        "contents": [
            [
                "70.6",
                "41.7",
                "52.5",
                "40.2",
                "66",
                "45",
                "53.5",
                "41.2",
                "66.2",
                "47.7",
                "55.4",
                "62.1",
                "48.9",
                "54.7"
            ],
            [
                "78.6",
                "44.5",
                "56.9",
                "119.4",
                "76.2",
                "46.8",
                "58",
                "118.7",
                "69.9",
                "55.1",
                "61.6",
                "66.5",
                "55.3",
                "60.4"
            ],
            [
                "81.2",
                "45.9",
                "58.6",
                "472.5",
                "78.6",
                "46.9",
                "58.7",
                "516.6",
                "72.5",
                "55.7",
                "63",
                "66.3",
                "57.3",
                "61.5"
            ],
            [
                "78",
                "51.2",
                "61.8",
                "50.5",
                "75.3",
                "51.7",
                "61.3",
                "52.1",
                "71.2",
                "58",
                "64",
                "67.6",
                "58.4",
                "62.7"
            ],
            [
                "79.5",
                "51.1",
                "62.2",
                "251.5",
                "75.5",
                "51.7",
                "61.3",
                "253.3",
                "72.7",
                "58",
                "64.5",
                "69.1",
                "58.1",
                "63.1"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "P",
            "R",
            "F1",
            "w/s",
            "P",
            "R",
            "F1",
            "w/s",
            "P",
            "R",
            "F1",
            "P",
            "R",
            "F1"
        ],
        "target_entity": [
            "This work (STATE)",
            "This work (EDGE)"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>ACE-2004 || P</th>      <th>ACE-2004 || R</th>      <th>ACE-2004 || F1</th>      <th>ACE-2005 || w/s</th>      <th>ACE-2005 || P</th>      <th>ACE-2005 || R</th>      <th>ACE-2005 || F1</th>      <th>ACE-2005 || w/s</th>      <th>ACE-2004 (F1 optimized) || P</th>      <th>ACE-2004 (F1 optimized) || R</th>      <th>ACE-2004 (F1 optimized) || F1</th>      <th>ACE-2005 (F1 optimized) || P</th>      <th>ACE-2005 (F1 optimized) || R</th>      <th>ACE-2005 (F1 optimized) || F1</th>    </tr>  </thead>  <tbody>    <tr>      <td>LCRF (single)</td>      <td>70.6</td>      <td>41.7</td>      <td>52.5</td>      <td>40.2</td>      <td>66</td>      <td>45</td>      <td>53.5</td>      <td>41.2</td>      <td>66.2</td>      <td>47.7</td>      <td>55.4</td>      <td>62.1</td>      <td>48.9</td>      <td>54.7</td>    </tr>    <tr>      <td>LCRF (multiple)</td>      <td>78.6</td>      <td>44.5</td>      <td>56.9</td>      <td>119.4</td>      <td>76.2</td>      <td>46.8</td>      <td>58</td>      <td>118.7</td>      <td>69.9</td>      <td>55.1</td>      <td>61.6</td>      <td>66.5</td>      <td>55.3</td>      <td>60.4</td>    </tr>    <tr>      <td>Lu and Roth (2015)</td>      <td>81.2</td>      <td>45.9</td>      <td>58.6</td>      <td>472.5</td>      <td>78.6</td>      <td>46.9</td>      <td>58.7</td>      <td>516.6</td>      <td>72.5</td>      <td>55.7</td>      <td>63</td>      <td>66.3</td>      <td>57.3</td>      <td>61.5</td>    </tr>    <tr>      <td>This work (STATE)</td>      <td>78</td>      <td>51.2</td>      <td>61.8</td>      <td>50.5</td>      <td>75.3</td>      <td>51.7</td>      <td>61.3</td>      <td>52.1</td>      <td>71.2</td>      <td>58</td>      <td>64</td>      <td>67.6</td>      <td>58.4</td>      <td>62.7</td>    </tr>    <tr>      <td>This work (EDGE)</td>      <td>79.5</td>      <td>51.1</td>      <td>62.2</td>      <td>251.5</td>      <td>75.5</td>      <td>51.7</td>      <td>61.3</td>      <td>253.3</td>      <td>72.7</td>      <td>58</td>      <td>64.5</td>      <td>69.1</td>      <td>58.1</td>      <td>63.1</td>    </tr>  </tbody></table>",
        "table_name": "Table 2",
        "table_id": "table_2",
        "paper_id": "D17-1276",
        "page_no": 7,
        "dir": "emnlp2017",
        "valid": 1
    },
    {
        "table_id_paper": "D17-1279table_5",
        "caption": "F1 score results on the test set for different categories: T indicates TASK, P indicates PROCESS, M is MATERIAL and K is Keyword identification (SubTask A). * is transductive model.",
        "row_header_level": 2,
        "row_headers": [
            [
                "Span Level",
                "Best SemEval"
            ],
            [
                "Span Level",
                "supervised"
            ],
            [
                "Span Level",
                "ULM+GRAPHINTERP"
            ],
            [
                "Span Level",
                "ULM+GRAPHFEAT"
            ],
            [
                "Token Level",
                "supervised"
            ],
            [
                "Token Level",
                "ULM+GRAPHINTERP"
            ],
            [
                "Token Level",
                "ULM+GRAPHFEAT"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "T"
            ],
            [
                "P"
            ],
            [
                "M"
            ],
            [
                "K"
            ]
        ],
        "contents": [
            [
                "19",
                "44",
                "48",
                "55"
            ],
            [
                "13.3",
                "40.5",
                "43.7",
                "52.1"
            ],
            [
                "17",
                "45.4",
                "49.4",
                "56.9"
            ],
            [
                "17.2",
                "46.5",
                "50.7",
                "57.6"
            ],
            [
                "29.6",
                "56",
                "59.3",
                "70.8"
            ],
            [
                "40",
                "60.7",
                "61.2",
                "77"
            ],
            [
                "40.1",
                "62.8",
                "63.4",
                "78.1"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "F1",
            "F1",
            "F1",
            "F1"
        ],
        "target_entity": [
            "ULM+GRAPHINTERP",
            "ULM+GRAPHFEAT"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>T</th>      <th>P</th>      <th>M</th>      <th>K</th>    </tr>  </thead>  <tbody>    <tr>      <td>Span Level || Best SemEval</td>      <td>19</td>      <td>44</td>      <td>48</td>      <td>55</td>    </tr>    <tr>      <td>Span Level || supervised</td>      <td>13.3</td>      <td>40.5</td>      <td>43.7</td>      <td>52.1</td>    </tr>    <tr>      <td>Span Level || ULM+GRAPHINTERP</td>      <td>17</td>      <td>45.4</td>      <td>49.4</td>      <td>56.9</td>    </tr>    <tr>      <td>Span Level || ULM+GRAPHFEAT</td>      <td>17.2</td>      <td>46.5</td>      <td>50.7</td>      <td>57.6</td>    </tr>    <tr>      <td>Token Level || supervised</td>      <td>29.6</td>      <td>56</td>      <td>59.3</td>      <td>70.8</td>    </tr>    <tr>      <td>Token Level || ULM+GRAPHINTERP</td>      <td>40</td>      <td>60.7</td>      <td>61.2</td>      <td>77</td>    </tr>    <tr>      <td>Token Level || ULM+GRAPHFEAT</td>      <td>40.1</td>      <td>62.8</td>      <td>63.4</td>      <td>78.1</td>    </tr>  </tbody></table>",
        "table_name": "Table 5",
        "table_id": "table_5",
        "paper_id": "D17-1279",
        "page_no": 9,
        "dir": "emnlp2017",
        "valid": 1
    },
    {
        "table_id_paper": "D17-1284table_1",
        "caption": "Entity Linking Performance: Accuracy of existing systems, and variations of our model on gold mentions. The model using context information is labeled C, entity-description as D, contexttyping as T, and entity-type encoding as E. Existing models marked in Italics* train domain-specific linkers for each dataset. Our system performs competitively to these systems, and outperforms Plato (Sup) that uses the same indirect supervision.",
        "row_header_level": 1,
        "row_headers": [
            [
                "Plato(sup)"
            ],
            [
                "Plato(Semi-Sup)"
            ],
            [
                "AIDA*"
            ],
            [
                "BerkCNN:Sparse*"
            ],
            [
                "BerkCNN:CNN*"
            ],
            [
                "BerkCNN:Full*"
            ],
            [
                "Priors"
            ],
            [
                "Model C"
            ],
            [
                "Model CD"
            ],
            [
                "Model CT"
            ],
            [
                "Model CDT"
            ],
            [
                "Model CDTE"
            ]
        ],
        "column_header_level": 2,
        "column_headers": [
            [
                "CoNLL",
                "Test"
            ],
            [
                "CoNLL",
                "Dev"
            ],
            [
                "ACE05",
                "-"
            ],
            [
                "Wiki",
                "-"
            ]
        ],
        "contents": [
            [
                "79.7",
                "-",
                "-",
                "-"
            ],
            [
                "86.4",
                "-",
                "-",
                "-"
            ],
            [
                "81.8",
                "-",
                "-",
                "-"
            ],
            [
                "74.9",
                "-",
                "83.6",
                "81.5"
            ],
            [
                "81.2",
                "86.91",
                "84.5",
                "75.7"
            ],
            [
                "85.5",
                "-",
                "89.9",
                "82.2"
            ],
            [
                "68.5",
                "70.9",
                "81.1",
                "78.1"
            ],
            [
                "81.4",
                "83.4",
                "83.7",
                "86.1"
            ],
            [
                "81",
                "83.2",
                "85.8",
                "86.1"
            ],
            [
                "82.3",
                "83.9",
                "86.5",
                "88.2"
            ],
            [
                "82.5",
                "85.6",
                "86.8",
                "88"
            ],
            [
                "82.9",
                "84.9",
                "85.6",
                "89"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "accuracy",
            "accuracy",
            "accuracy",
            "accuracy"
        ],
        "target_entity": [
            "Model C",
            "Model CD",
            "Model CT",
            "Model CDT",
            "Model CDTE"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>CoNLL || Test</th>      <th>CoNLL || Dev</th>      <th>ACE05 || -</th>      <th>Wiki || -</th>    </tr>  </thead>  <tbody>    <tr>      <td>Plato(sup)</td>      <td>79.7</td>      <td>-</td>      <td>-</td>      <td>-</td>    </tr>    <tr>      <td>Plato(Semi-Sup)</td>      <td>86.4</td>      <td>-</td>      <td>-</td>      <td>-</td>    </tr>    <tr>      <td>AIDA*</td>      <td>81.8</td>      <td>-</td>      <td>-</td>      <td>-</td>    </tr>    <tr>      <td>BerkCNN:Sparse*</td>      <td>74.9</td>      <td>-</td>      <td>83.6</td>      <td>81.5</td>    </tr>    <tr>      <td>BerkCNN:CNN*</td>      <td>81.2</td>      <td>86.91</td>      <td>84.5</td>      <td>75.7</td>    </tr>    <tr>      <td>BerkCNN:Full*</td>      <td>85.5</td>      <td>-</td>      <td>89.9</td>      <td>82.2</td>    </tr>    <tr>      <td>Priors</td>      <td>68.5</td>      <td>70.9</td>      <td>81.1</td>      <td>78.1</td>    </tr>    <tr>      <td>Model C</td>      <td>81.4</td>      <td>83.4</td>      <td>83.7</td>      <td>86.1</td>    </tr>    <tr>      <td>Model CD</td>      <td>81</td>      <td>83.2</td>      <td>85.8</td>      <td>86.1</td>    </tr>    <tr>      <td>Model CT</td>      <td>82.3</td>      <td>83.9</td>      <td>86.5</td>      <td>88.2</td>    </tr>    <tr>      <td>Model CDT</td>      <td>82.5</td>      <td>85.6</td>      <td>86.8</td>      <td>88</td>    </tr>    <tr>      <td>Model CDTE</td>      <td>82.9</td>      <td>84.9</td>      <td>85.6</td>      <td>89</td>    </tr>  </tbody></table>",
        "table_name": "Table 1",
        "table_id": "table_1",
        "paper_id": "D17-1284",
        "page_no": 6,
        "dir": "emnlp2017",
        "valid": 1
    },
    {
        "table_id_paper": "D17-1310table_2",
        "caption": "Experiment results",
        "row_header_level": 1,
        "row_headers": [
            [
                "CRF"
            ],
            [
                "Semi-CRF"
            ],
            [
                "IHS_RD"
            ],
            [
                "DLIREC"
            ],
            [
                "NLANGP"
            ],
            [
                "AUEB"
            ],
            [
                "WDEmb"
            ],
            [
                "LSTM"
            ],
            [
                "RNCRF"
            ],
            [
                "Our Work"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "D1"
            ],
            [
                "D2"
            ]
        ],
        "contents": [
            [
                "74.01%",
                "69.56%"
            ],
            [
                "68.75%",
                "66.35%"
            ],
            [
                "74.55%",
                " -"
            ],
            [
                "73.78%",
                " -"
            ],
            [
                " -",
                "72.34%"
            ],
            [
                " -",
                "70.44%"
            ],
            [
                "75.16%",
                " -"
            ],
            [
                "75.25%",
                "71.26%"
            ],
            [
                "77.26%",
                "69.74%"
            ],
            [
                "77.58%",
                "73.44%"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "F1",
            "F1"
        ],
        "target_entity": [
            "Our Work"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>D1</th>      <th>D2</th>    </tr>  </thead>  <tbody>    <tr>      <td>CRF</td>      <td>74.01%</td>      <td>69.56%</td>    </tr>    <tr>      <td>Semi-CRF</td>      <td>68.75%</td>      <td>66.35%</td>    </tr>    <tr>      <td>IHS_RD</td>      <td>74.55%</td>      <td>-</td>    </tr>    <tr>      <td>DLIREC</td>      <td>73.78%</td>      <td>-</td>    </tr>    <tr>      <td>NLANGP</td>      <td>-</td>      <td>72.34%</td>    </tr>    <tr>      <td>AUEB</td>      <td>-</td>      <td>70.44%</td>    </tr>    <tr>      <td>WDEmb</td>      <td>75.16%</td>      <td>-</td>    </tr>    <tr>      <td>LSTM</td>      <td>75.25%</td>      <td>71.26%</td>    </tr>    <tr>      <td>RNCRF</td>      <td>77.26%</td>      <td>69.74%</td>    </tr>    <tr>      <td>Our Work</td>      <td>77.58%</td>      <td>73.44%</td>    </tr>  </tbody></table>",
        "table_name": "Table 2",
        "table_id": "table_2",
        "paper_id": "D17-1310",
        "page_no": 5,
        "dir": "emnlp2017",
        "valid": 1
    },
    {
        "table_id_paper": "D17-1320table_4",
        "caption": "Baseline performance on test set.",
        "row_header_level": 2,
        "row_headers": [
            [
                "Metric",
                "Strict Match"
            ],
            [
                "Metric",
                "METEOR"
            ],
            [
                "Metric",
                "ROUGE-2"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "Pr"
            ],
            [
                "Re"
            ],
            [
                "F1"
            ]
        ],
        "contents": [
            [
                "0.0006",
                "0.0026",
                "0.001"
            ],
            [
                "0.1512",
                "0.1949",
                "0.17"
            ],
            [
                "0.0603",
                "0.1798",
                "0.0891"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "Pr",
            "Re",
            "F1"
        ],
        "target_entity": [
            "ROUGE-2"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Pr</th>      <th>Re</th>      <th>F1</th>    </tr>  </thead>  <tbody>    <tr>      <td>Metric || Strict Match</td>      <td>0.0006</td>      <td>0.0026</td>      <td>0.001</td>    </tr>    <tr>      <td>Metric || METEOR</td>      <td>0.1512</td>      <td>0.1949</td>      <td>0.17</td>    </tr>    <tr>      <td>Metric || ROUGE-2</td>      <td>0.0603</td>      <td>0.1798</td>      <td>0.0891</td>    </tr>  </tbody></table>",
        "table_name": "Table 4",
        "table_id": "table_4",
        "paper_id": "D17-1320",
        "page_no": 8,
        "dir": "emnlp2017",
        "valid": 1
    },
    {
        "table_id_paper": "D18-1016table_3",
        "caption": "The annotation quality\u2019s impact on model performance. Each row shows the development set performance of the EE2E-Coref model (training details in Section 4.1) trained by data of different annotation quality. Each training set contains 2.5K documents. In the training set \u201cOnce\u201d, each document is annotated by one annotator. In the training set \u201cAB-merge\u201d, each document is annotated by two annotators independently, and the annotations are compared and merged by a third annotator.",
        "row_header_level": 2,
        "row_headers": [
            [
                "Annotation",
                "Once"
            ],
            [
                "Annotation",
                "AB-merge"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "Avg. Prec"
            ],
            [
                "Avg. Rec"
            ],
            [
                "Avg. F1"
            ]
        ],
        "contents": [
            [
                "79.3",
                "69.1",
                "73.9"
            ],
            [
                "78.1",
                "76.5",
                "77.3"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "Avg. Prec",
            "Avg. Rec",
            "Avg. F1"
        ],
        "target_entity": [
            "Once",
            "AB-merge"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Avg. Prec</th>      <th>Avg. Rec</th>      <th>Avg. F1</th>    </tr>  </thead>  <tbody>    <tr>      <td>Annotation || Once</td>      <td>79.3</td>      <td>69.1</td>      <td>73.9</td>    </tr>    <tr>      <td>Annotation || AB-merge</td>      <td>78.1</td>      <td>76.5</td>      <td>77.3</td>    </tr>  </tbody></table>",
        "table_name": "Table 3",
        "table_id": "table_3",
        "paper_id": "D18-1016",
        "page_no": 6,
        "dir": "emnlp2018",
        "valid": 1
    },
    {
        "table_id_paper": "D18-1020table_4",
        "caption": "Results on Twitter and NER dev sets. For each model, we show supervised results for the models with variational regularization (\u201cacc.\u201d or F1) and results when replacing variational components with their deterministic counterparts (\u201cno VR\u201d).",
        "row_header_level": 1,
        "row_headers": [
            [
                "BiGRU baseline"
            ],
            [
                "VSL-G"
            ],
            [
                "VSL-GG-Flat"
            ],
            [
                "VSL-GG-Hier"
            ]
        ],
        "column_header_level": 2,
        "column_headers": [
            [
                "Twitter",
                "acc."
            ],
            [
                "Twitter",
                "no VR"
            ],
            [
                "NER",
                "F1"
            ],
            [
                "NER",
                "no VR"
            ]
        ],
        "contents": [
            [
                "90.8",
                "-",
                "87.6",
                "-"
            ],
            [
                "91.1",
                "90.9",
                "87.8",
                "87.7"
            ],
            [
                "91.4",
                "90.9",
                "88.0",
                "87.8"
            ],
            [
                "91.6",
                "91.0",
                "88.4",
                "87.9"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "acc.",
            "no VR",
            "F1",
            "no VR"
        ],
        "target_entity": [
            "VSL-G"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Twitter || acc.</th>      <th>Twitter || no VR</th>      <th>NER || F1</th>      <th>NER || no VR</th>    </tr>  </thead>  <tbody>    <tr>      <td>BiGRU baseline</td>      <td>90.8</td>      <td>-</td>      <td>87.6</td>      <td>-</td>    </tr>    <tr>      <td>VSL-G</td>      <td>91.1</td>      <td>90.9</td>      <td>87.8</td>      <td>87.7</td>    </tr>    <tr>      <td>VSL-GG-Flat</td>      <td>91.4</td>      <td>90.9</td>      <td>88.0</td>      <td>87.8</td>    </tr>    <tr>      <td>VSL-GG-Hier</td>      <td>91.6</td>      <td>91.0</td>      <td>88.4</td>      <td>87.9</td>    </tr>  </tbody></table>",
        "table_name": "Table 4",
        "table_id": "table_4",
        "paper_id": "D18-1020",
        "page_no": 8,
        "dir": "emnlp2018",
        "valid": 1
    },
    {
        "table_id_paper": "D18-1023table_6",
        "caption": "Comparison on Monolingual Embedding Quality: name tagging performance (F-score, %) using monolingual embedding and multilingual embeddings.",
        "row_header_level": 2,
        "row_headers": [
            [
                "Train & Test",
                "Amh"
            ],
            [
                "Train & Test",
                "Tig"
            ],
            [
                "Train & Test",
                "Uig"
            ],
            [
                "Train & Test",
                "Tur"
            ]
        ],
        "column_header_level": 3,
        "column_headers": [
            [
                "Monolingual",
                "-",
                "-"
            ],
            [
                "Multilingual",
                "MultiCCA",
                "-"
            ],
            [
                "Multilingual",
                "MultiCluster",
                "-"
            ],
            [
                "Multilingual",
                "CorrNet",
                "W"
            ],
            [
                "Multilingual",
                "CorrNet",
                "W+N+C+L"
            ]
        ],
        "contents": [
            [
                "52.0",
                "50.6",
                "53.4",
                "52.4",
                "55.8"
            ],
            [
                "78.2",
                "78.4",
                "76.4",
                "77.9",
                "78.5"
            ],
            [
                "63.3",
                "59.6",
                "60.1",
                "61.9",
                "65.2"
            ],
            [
                "62.9",
                "47.7",
                "54.0",
                "59.3",
                "64.9"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "F-score",
            "F-score",
            "F-score",
            "F-score",
            "F-score"
        ],
        "target_entity": [
            "W+N+C+L"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Monolingual || - || -</th>      <th>Multilingual || MultiCCA || -</th>      <th>Multilingual || MultiCluster || -</th>      <th>Multilingual || CorrNet || W</th>      <th>Multilingual || CorrNet || W+N+C+L</th>    </tr>  </thead>  <tbody>    <tr>      <td>Train &amp; Test || Amh</td>      <td>52.0</td>      <td>50.6</td>      <td>53.4</td>      <td>52.4</td>      <td>55.8</td>    </tr>    <tr>      <td>Train &amp; Test || Tig</td>      <td>78.2</td>      <td>78.4</td>      <td>76.4</td>      <td>77.9</td>      <td>78.5</td>    </tr>    <tr>      <td>Train &amp; Test || Uig</td>      <td>63.3</td>      <td>59.6</td>      <td>60.1</td>      <td>61.9</td>      <td>65.2</td>    </tr>    <tr>      <td>Train &amp; Test || Tur</td>      <td>62.9</td>      <td>47.7</td>      <td>54.0</td>      <td>59.3</td>      <td>64.9</td>    </tr>  </tbody></table>",
        "table_name": "Table 6",
        "table_id": "table_6",
        "paper_id": "D18-1023",
        "page_no": 8,
        "dir": "emnlp2018",
        "valid": 1
    },
    {
        "table_id_paper": "D18-1048table_2",
        "caption": "Evaluation of the NIST Chinese-English translation task. The BLEU scores are case-insensitive. \u201cParams\u201d denotes the number the parameters in each model. The \u201cSpeed\u201d denotes the generation speed in seconds on the development set. RNNSearch is an attention-based neural machine translation model(Bahdanau et al., 2014) with one-pass left-to-right decoding. RNNSearch(R2L) is a variant of RNNSearch with one-pass right-to-left decoding. As a comparison, Deliberation Network (Xia et al., 2017) and ABDNMT (Zhang et al., 2018) involve two independent decoders to adopt polishing mechanism to extend the ability of conventional NMT. Deliberation Network utilizes two left-to-right decoders coupled with reinforcement learning. However, ABDNMT exploits a backward decoder to perform first-pass right-to-left decoding. {2,3,4,5}-pass decoder utilizes our multi-pass decoder with a fixed number of decoding passes. Furthermore, adaptive multi-pass decoder involves a policy network to enhance our multi-pass decoder to choose a proper decoding depth.",
        "row_header_level": 2,
        "row_headers": [
            [
                "System",
                "Moses"
            ],
            [
                "System",
                "RNNSearch"
            ],
            [
                "System",
                "Deliberation Network"
            ],
            [
                "System",
                "ABDNMT"
            ],
            [
                "System",
                "2-pass decoder"
            ],
            [
                "System",
                "3-pass decoder"
            ],
            [
                "System",
                "4-pass decoder"
            ],
            [
                "System",
                "5-pass decoder"
            ],
            [
                "System",
                "Adaptive multi-pass decoder"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "#Params"
            ],
            [
                "Speed"
            ],
            [
                "MT02"
            ],
            [
                "MT03"
            ],
            [
                "MT04"
            ],
            [
                "MT05"
            ],
            [
                "MT06"
            ],
            [
                "Ave."
            ]
        ],
        "contents": [
            [
                "-",
                "-",
                "33.79",
                "30.86",
                "32.71",
                "30.02",
                "30.49",
                "31.02"
            ],
            [
                "83.99M",
                "87",
                "39.68",
                "36.51",
                "40.20",
                "36.87",
                "36.43",
                "37.50"
            ],
            [
                "125.16M",
                "162",
                "40.98",
                "37.82",
                "40.56",
                "37.67",
                "37.20",
                "38.31"
            ],
            [
                "122.86M",
                "132",
                "41.12",
                "38.01",
                "41.20",
                "38.07",
                "37.59",
                "38.71"
            ],
            [
                "87.81M",
                "160",
                "41.18",
                "37.76",
                "41.06",
                "38.02",
                "37.41",
                "38.56"
            ],
            [
                "87.81M",
                "245",
                "41.28.41.05",
                "37.99",
                "40.72",
                "37.86",
                "37.63",
                "38.55"
            ],
            [
                "87.81M",
                "293",
                "41.05",
                "37.86",
                "40.87",
                "38.18",
                "37.57",
                "38.62"
            ],
            [
                "87.81M",
                "322",
                "40.88",
                "37.70",
                "40.84",
                "38.06",
                "37.97",
                "38.64"
            ],
            [
                "96.01M",
                "180",
                "41.42",
                "38.39",
                "41.43",
                "38.54",
                "37.86",
                "39.05"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "#Params",
            "Speed",
            "BLEU",
            "BLEU",
            "BLEU",
            "BLEU",
            "BLEU",
            "BLEU"
        ],
        "target_entity": [
            "Adaptive multi-pass decoder"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>#Params</th>      <th>Speed</th>      <th>MT02</th>      <th>MT03</th>      <th>MT04</th>      <th>MT05</th>      <th>MT06</th>      <th>Ave.</th>    </tr>  </thead>  <tbody>    <tr>      <td>System || Moses</td>      <td>-</td>      <td>-</td>      <td>33.79</td>      <td>30.86</td>      <td>32.71</td>      <td>30.02</td>      <td>30.49</td>      <td>31.02</td>    </tr>    <tr>      <td>System || RNNSearch</td>      <td>83.99M</td>      <td>87</td>      <td>39.68</td>      <td>36.51</td>      <td>40.20</td>      <td>36.87</td>      <td>36.43</td>      <td>37.50</td>    </tr>    <tr>      <td>System || Deliberation Network</td>      <td>125.16M</td>      <td>162</td>      <td>40.98</td>      <td>37.82</td>      <td>40.56</td>      <td>37.67</td>      <td>37.20</td>      <td>38.31</td>    </tr>    <tr>      <td>System || ABDNMT</td>      <td>122.86M</td>      <td>132</td>      <td>41.12</td>      <td>38.01</td>      <td>41.20</td>      <td>38.07</td>      <td>37.59</td>      <td>38.71</td>    </tr>    <tr>      <td>System || 2-pass decoder</td>      <td>87.81M</td>      <td>160</td>      <td>41.18</td>      <td>37.76</td>      <td>41.06</td>      <td>38.02</td>      <td>37.41</td>      <td>38.56</td>    </tr>    <tr>      <td>System || 3-pass decoder</td>      <td>87.81M</td>      <td>245</td>      <td>41.28.41.05</td>      <td>37.99</td>      <td>40.72</td>      <td>37.86</td>      <td>37.63</td>      <td>38.55</td>    </tr>    <tr>      <td>System || 4-pass decoder</td>      <td>87.81M</td>      <td>293</td>      <td>41.05</td>      <td>37.86</td>      <td>40.87</td>      <td>38.18</td>      <td>37.57</td>      <td>38.62</td>    </tr>    <tr>      <td>System || 5-pass decoder</td>      <td>87.81M</td>      <td>322</td>      <td>40.88</td>      <td>37.70</td>      <td>40.84</td>      <td>38.06</td>      <td>37.97</td>      <td>38.64</td>    </tr>    <tr>      <td>System || Adaptive multi-pass decoder</td>      <td>96.01M</td>      <td>180</td>      <td>41.42</td>      <td>38.39</td>      <td>41.43</td>      <td>38.54</td>      <td>37.86</td>      <td>39.05</td>    </tr>  </tbody></table>",
        "table_name": "Table 2",
        "table_id": "table_2",
        "paper_id": "D18-1048",
        "page_no": 6,
        "dir": "emnlp2018",
        "valid": 1
    },
    {
        "table_id_paper": "D18-1101table_1",
        "caption": "Translation results on German\u2194English newstest2016 and French\u2194English newstest2014. Beam size is 10 and top 100 words are considered in the nearest neighbor search.",
        "row_header_level": 4,
        "row_headers": [
            [
                "System",
                "Word-by-Word",
                "-",
                "-"
            ],
            [
                "System",
                "Word-by-Word",
                "+LM",
                "-"
            ],
            [
                "System",
                "Word-by-Word",
                "+LM",
                "+ Denoising"
            ],
            [
                "System",
                "(Lample et al. 2018)",
                "-",
                "-"
            ],
            [
                "System",
                "(Artetxe et al. 2018)",
                "-",
                "-"
            ]
        ],
        "column_header_level": 2,
        "column_headers": [
            [
                "de-en",
                "BLEU [%]"
            ],
            [
                "en-de",
                "BLEU [%]"
            ],
            [
                "fr-en",
                "BLEU [%]"
            ],
            [
                "en-fr",
                "BLEU [%]"
            ]
        ],
        "contents": [
            [
                "11.1",
                "6.7",
                "10.6",
                "7.8"
            ],
            [
                "14.5",
                "9.9",
                "13.6",
                "10.9"
            ],
            [
                "17.2",
                "11.0",
                "16.5",
                "13.9"
            ],
            [
                "13.3",
                "9.6",
                "14.3",
                "15.1"
            ],
            [
                "-",
                "-",
                "15.6",
                "15.1"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "BLEU [%]",
            "BLEU [%]",
            "BLEU [%]",
            "BLEU [%]"
        ],
        "target_entity": [
            "Word-by-Word",
            "+LM",
            "+ Denoising"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>de-en || BLEU [%]</th>      <th>en-de || BLEU [%]</th>      <th>fr-en || BLEU [%]</th>      <th>en-fr || BLEU [%]</th>    </tr>  </thead>  <tbody>    <tr>      <td>System || Word-by-Word || - || -</td>      <td>11.1</td>      <td>6.7</td>      <td>10.6</td>      <td>7.8</td>    </tr>    <tr>      <td>System || Word-by-Word || +LM || -</td>      <td>14.5</td>      <td>9.9</td>      <td>13.6</td>      <td>10.9</td>    </tr>    <tr>      <td>System || Word-by-Word || +LM || + Denoising</td>      <td>17.2</td>      <td>11.0</td>      <td>16.5</td>      <td>13.9</td>    </tr>    <tr>      <td>System || (Lample et al. 2018) || - || -</td>      <td>13.3</td>      <td>9.6</td>      <td>14.3</td>      <td>15.1</td>    </tr>    <tr>      <td>System || (Artetxe et al. 2018) || - || -</td>      <td>-</td>      <td>-</td>      <td>15.6</td>      <td>15.1</td>    </tr>  </tbody></table>",
        "table_name": "Table 1",
        "table_id": "table_1",
        "paper_id": "D18-1101",
        "page_no": 4,
        "dir": "emnlp2018",
        "valid": 1
    },
    {
        "table_id_paper": "D18-1180table_2",
        "caption": "Performance of the unsupervised PSD compared with the state-of-the-art. (`, i), (`, r) and (r, i) correspond to feature ablation results.",
        "row_header_level": 2,
        "row_headers": [
            [
                "System",
                "Accuracy"
            ]
        ],
        "column_header_level": 2,
        "column_headers": [
            [
                "State-of-art (Hovy et al. 2011)",
                "-"
            ],
            [
                "k-means clustering",
                "average"
            ],
            [
                "k-means clustering",
                "(l r)"
            ],
            [
                "k-means clustering",
                "(l i)"
            ],
            [
                "k-means clustering",
                "(r i)"
            ],
            [
                "k-means clustering",
                "(l r i)"
            ]
        ],
        "contents": [
            [
                "0.56",
                "0.555",
                "0.561",
                "0.565",
                "0.534",
                "0.584"
            ]
        ],
        "metrics_loc": "row",
        "metrics_type": [
            "Accuracy"
        ],
        "target_entity": [
            "k-means clustering"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>State-of-art (Hovy et al. 2011) || -</th>      <th>k-means clustering || average</th>      <th>k-means clustering || (l r)</th>      <th>k-means clustering || (l i)</th>      <th>k-means clustering || (r i)</th>      <th>k-means clustering || (l r i)</th>    </tr>  </thead>  <tbody>    <tr>      <td>System || Accuracy</td>      <td>0.56</td>      <td>0.555</td>      <td>0.561</td>      <td>0.565</td>      <td>0.534</td>      <td>0.584</td>    </tr>  </tbody></table>",
        "table_name": "Table 2",
        "table_id": "table_2",
        "paper_id": "D18-1180",
        "page_no": 5,
        "dir": "emnlp2018",
        "valid": 1
    },
    {
        "table_id_paper": "D18-1222table_4",
        "caption": "Experimental results on subClassOf triple classification(%).",
        "row_header_level": 2,
        "row_headers": [
            [
                "Metric",
                "TransE"
            ],
            [
                "Metric",
                "TransH"
            ],
            [
                "Metric",
                "TransR"
            ],
            [
                "Metric",
                "TransD"
            ],
            [
                "Metric",
                "HolE"
            ],
            [
                "Metric",
                "DistMult"
            ],
            [
                "Metric",
                "ComplEx"
            ],
            [
                "Metric",
                "TransC (unif)"
            ],
            [
                "Metric",
                "TransC (bern)"
            ]
        ],
        "column_header_level": 3,
        "column_headers": [
            [
                "Datasets",
                "YAGO39K",
                "Accuracy"
            ],
            [
                "Datasets",
                "YAGO39K",
                "Precision"
            ],
            [
                "Datasets",
                "YAGO39K",
                "Recall"
            ],
            [
                "Datasets",
                "YAGO39K",
                "F1-Score"
            ],
            [
                "Datasets",
                "M-YAGO39K",
                "Accuracy"
            ],
            [
                "Datasets",
                "M-YAGO39K",
                "Precision"
            ],
            [
                "Datasets",
                "M-YAGO39K",
                "Recall"
            ],
            [
                "Datasets",
                "M-YAGO39K",
                "F1-Score"
            ]
        ],
        "contents": [
            [
                "77.6",
                "72.2",
                "89.8",
                "80.0",
                "76.9",
                "72.3",
                "87.2",
                "79.0"
            ],
            [
                "80.2",
                "76.4",
                "87.5",
                "81.5",
                "79.1",
                "72.8",
                "92.9",
                "81.6"
            ],
            [
                "80.4",
                "74.7",
                "91.9",
                "82.4",
                "80.0",
                "73.9",
                "92.9",
                "82.3"
            ],
            [
                "75.9",
                "70.6",
                "88.8",
                "78.7",
                "76.1",
                "70.7",
                "89.0",
                "78.8"
            ],
            [
                "70.5",
                "73.9",
                "63.3",
                "68.2",
                "66.6",
                "72.3",
                "53.7",
                "61.7"
            ],
            [
                "61.9",
                "68.7",
                "43.7",
                "53.4",
                "60.7",
                "71.7",
                "35.5",
                "47.7"
            ],
            [
                "61.6",
                "71.5",
                "38.6",
                "50.1",
                "59.8",
                "65.6",
                "41.4",
                "50.7"
            ],
            [
                "82.9",
                "77.1",
                "93.7",
                "84.6",
                "83.0",
                "77.5",
                "93.1",
                "84.7"
            ],
            [
                "83.7",
                "78.1",
                "93.9",
                "85.2",
                "84.4",
                "80.7",
                "90.4",
                "85.3"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "Accuracy",
            "Precision",
            "Recall",
            "F1-Score",
            "Accuracy",
            "Precision",
            "Recall",
            "F1-Score"
        ],
        "target_entity": [
            "TransC (unif)",
            "TransC (bern)"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Datasets || YAGO39K || Accuracy</th>      <th>Datasets || YAGO39K || Precision</th>      <th>Datasets || YAGO39K || Recall</th>      <th>Datasets || YAGO39K || F1-Score</th>      <th>Datasets || M-YAGO39K || Accuracy</th>      <th>Datasets || M-YAGO39K || Precision</th>      <th>Datasets || M-YAGO39K || Recall</th>      <th>Datasets || M-YAGO39K || F1-Score</th>    </tr>  </thead>  <tbody>    <tr>      <td>Metric || TransE</td>      <td>77.6</td>      <td>72.2</td>      <td>89.8</td>      <td>80.0</td>      <td>76.9</td>      <td>72.3</td>      <td>87.2</td>      <td>79.0</td>    </tr>    <tr>      <td>Metric || TransH</td>      <td>80.2</td>      <td>76.4</td>      <td>87.5</td>      <td>81.5</td>      <td>79.1</td>      <td>72.8</td>      <td>92.9</td>      <td>81.6</td>    </tr>    <tr>      <td>Metric || TransR</td>      <td>80.4</td>      <td>74.7</td>      <td>91.9</td>      <td>82.4</td>      <td>80.0</td>      <td>73.9</td>      <td>92.9</td>      <td>82.3</td>    </tr>    <tr>      <td>Metric || TransD</td>      <td>75.9</td>      <td>70.6</td>      <td>88.8</td>      <td>78.7</td>      <td>76.1</td>      <td>70.7</td>      <td>89.0</td>      <td>78.8</td>    </tr>    <tr>      <td>Metric || HolE</td>      <td>70.5</td>      <td>73.9</td>      <td>63.3</td>      <td>68.2</td>      <td>66.6</td>      <td>72.3</td>      <td>53.7</td>      <td>61.7</td>    </tr>    <tr>      <td>Metric || DistMult</td>      <td>61.9</td>      <td>68.7</td>      <td>43.7</td>      <td>53.4</td>      <td>60.7</td>      <td>71.7</td>      <td>35.5</td>      <td>47.7</td>    </tr>    <tr>      <td>Metric || ComplEx</td>      <td>61.6</td>      <td>71.5</td>      <td>38.6</td>      <td>50.1</td>      <td>59.8</td>      <td>65.6</td>      <td>41.4</td>      <td>50.7</td>    </tr>    <tr>      <td>Metric || TransC (unif)</td>      <td>82.9</td>      <td>77.1</td>      <td>93.7</td>      <td>84.6</td>      <td>83.0</td>      <td>77.5</td>      <td>93.1</td>      <td>84.7</td>    </tr>    <tr>      <td>Metric || TransC (bern)</td>      <td>83.7</td>      <td>78.1</td>      <td>93.9</td>      <td>85.2</td>      <td>84.4</td>      <td>80.7</td>      <td>90.4</td>      <td>85.3</td>    </tr>  </tbody></table>",
        "table_name": "Table 4",
        "table_id": "table_4",
        "paper_id": "D18-1222",
        "page_no": 7,
        "dir": "emnlp2018",
        "valid": 1
    },
    {
        "table_id_paper": "D18-1229table_1",
        "caption": "We show performance in terms of recall, computed per-category and averaged across categories, for the baseline, list and scatterplot interfaces. This is shown for the last round of bootstrapping (c.f. Fig. 3a) and extrapolation (c.f. Fig. 3b).",
        "row_header_level": 1,
        "row_headers": [
            [
                "bootstrapping"
            ],
            [
                "extrapolation"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "scatterplot"
            ],
            [
                "list"
            ],
            [
                "baseline"
            ]
        ],
        "contents": [
            [
                "88.8",
                "87.2",
                "85.1"
            ],
            [
                "84.7",
                "83.5",
                "78.6"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "recall",
            "recall",
            "recall"
        ],
        "target_entity": [
            "scatterplot"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>scatterplot</th>      <th>list</th>      <th>baseline</th>    </tr>  </thead>  <tbody>    <tr>      <td>bootstrapping</td>      <td>88.8</td>      <td>87.2</td>      <td>85.1</td>    </tr>    <tr>      <td>extrapolation</td>      <td>84.7</td>      <td>83.5</td>      <td>78.6</td>    </tr>  </tbody></table>",
        "table_name": "Table 1",
        "table_id": "table_1",
        "paper_id": "D18-1229",
        "page_no": 7,
        "dir": "emnlp2018",
        "valid": 1
    },
    {
        "table_id_paper": "D18-1275table_3",
        "caption": "Accuracy comparison of different methods on NPSChat Corpus.",
        "row_header_level": 2,
        "row_headers": [
            [
                "Methods",
                "Forsyth (2007)"
            ],
            [
                "Methods",
                "ARK Tagger"
            ],
            [
                "Methods",
                "Gui et al. (2017)"
            ],
            [
                "Methods",
                "Bi-LSTM(IRC)"
            ],
            [
                "Methods",
                "Bi-LSTM(WSJ + IRC)"
            ],
            [
                "Methods",
                "DCNN"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "Acc."
            ]
        ],
        "contents": [
            [
                "90.8%"
            ],
            [
                "93.4%\u00b10.3%"
            ],
            [
                "94.1%"
            ],
            [
                "90.3%"
            ],
            [
                "93.2%"
            ],
            [
                "94.0%"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "Acc."
        ],
        "target_entity": [
            "DCNN"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Acc.</th>    </tr>  </thead>  <tbody>    <tr>      <td>Methods || Forsyth (2007)</td>      <td>90.8%</td>    </tr>    <tr>      <td>Methods || ARK Tagger</td>      <td>93.4%\u00b10.3%</td>    </tr>    <tr>      <td>Methods || Gui et al. (2017)</td>      <td>94.1%</td>    </tr>    <tr>      <td>Methods || Bi-LSTM(IRC)</td>      <td>90.3%</td>    </tr>    <tr>      <td>Methods || Bi-LSTM(WSJ + IRC)</td>      <td>93.2%</td>    </tr>    <tr>      <td>Methods || DCNN</td>      <td>94.0%</td>    </tr>  </tbody></table>",
        "table_name": "Table 3",
        "table_id": "table_3",
        "paper_id": "D18-1275",
        "page_no": 7,
        "dir": "emnlp2018",
        "valid": 1
    },
    {
        "table_id_paper": "D18-1333table_2",
        "caption": "Evaluation of translation performance for Chinese\u2013English. \u201cBaseline\u201d is trained and evaluated on the original data, while \u201cBaseline (+DPs)\u201d and \u201cBaseline (+DPPs)\u201d are trained on the data annotated with DPs and DPPs, respectively. Training and decoding (beam size is 10) speeds are measured in words/second. \u201c\u2020\u201d and \u201c\u2021\u201d indicate statistically significant difference (p < 0.01) from \u201cBaseline (+DDPs)\u201d and \u201cSeparate-Recs\u21d2(+DPs)\u201d, respectively.",
        "row_header_level": 4,
        "row_headers": [
            [
                "1",
                "Model",
                "Existing system (Wang et al., 2018)",
                "Baseline"
            ],
            [
                "2",
                "Model",
                "Existing system (Wang et al., 2018)",
                "Baseline (+DPs)"
            ],
            [
                "3",
                "Model",
                "Existing system (Wang et al., 2018)",
                "Separate-Recs\u21d2(+DPs)"
            ],
            [
                "4",
                "Model",
                "Our system",
                "Baseline (+DPPs)"
            ],
            [
                "5",
                "Model",
                "Our system",
                "Shared-Recindependent\u21d2(+DPPs)"
            ],
            [
                "6",
                "Model",
                "Our system",
                "Shared-Recindependent\u21d2(+DPPs) + joint prediction"
            ],
            [
                "7",
                "Model",
                "Our system",
                "Shared-Recenc\u2192dec\u21d2(+DPPs) + joint prediction"
            ],
            [
                "8",
                "Model",
                "Our system",
                "Shared-Recdec\u2192enc\u21d2(+DPPs) + joint prediction"
            ]
        ],
        "column_header_level": 2,
        "column_headers": [
            [
                "# Params",
                "-"
            ],
            [
                "Speed",
                "Train"
            ],
            [
                "Speed",
                "Decode"
            ],
            [
                "BLEU",
                "-"
            ]
        ],
        "contents": [
            [
                "86.7M",
                "1.60K",
                "15.23",
                "31.80"
            ],
            [
                "86.7M",
                "1.59K",
                "15.20",
                "32.67"
            ],
            [
                "+73.8M",
                "0.57K",
                "12.00",
                "35.08"
            ],
            [
                "86.7M",
                "1.54K",
                "15.19",
                "33.18"
            ],
            [
                "+86.6M",
                "0.52K",
                "11.87",
                "35.27\u2020\u2021"
            ],
            [
                "+87.9M",
                "0.51K",
                "11.88",
                "35.88\u2020\u2021"
            ],
            [
                "+91.9M",
                "0.48K",
                "11.84",
                "36.53\u2020\u2021"
            ],
            [
                "+89.9M",
                "0.49K",
                "11.85",
                "35.99\u2020\u2021"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "# Params",
            "Speed",
            "Speed",
            "BLEU"
        ],
        "target_entity": [
            "Shared-Recindependent\u21d2(+DPPs)",
            "Shared-Recindependent\u21d2(+DPPs) + joint prediction",
            "Shared-Recenc\u2192dec\u21d2(+DPPs) + joint prediction",
            "Shared-Recdec\u2192enc\u21d2(+DPPs) + joint prediction"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th># Params || -</th>      <th>Speed || Train</th>      <th>Speed || Decode</th>      <th>BLEU || -</th>    </tr>  </thead>  <tbody>    <tr>      <td>1 || Model || Existing system (Wang et al., 2018) || Baseline</td>      <td>86.7M</td>      <td>1.60K</td>      <td>15.23</td>      <td>31.80</td>    </tr>    <tr>      <td>2 || Model || Existing system (Wang et al., 2018) || Baseline (+DPs)</td>      <td>86.7M</td>      <td>1.59K</td>      <td>15.20</td>      <td>32.67</td>    </tr>    <tr>      <td>3 || Model || Existing system (Wang et al., 2018) || Separate-Recs\u21d2(+DPs)</td>      <td>+73.8M</td>      <td>0.57K</td>      <td>12.00</td>      <td>35.08</td>    </tr>    <tr>      <td>4 || Model || Our system || Baseline (+DPPs)</td>      <td>86.7M</td>      <td>1.54K</td>      <td>15.19</td>      <td>33.18</td>    </tr>    <tr>      <td>5 || Model || Our system || Shared-Recindependent\u21d2(+DPPs)</td>      <td>+86.6M</td>      <td>0.52K</td>      <td>11.87</td>      <td>35.27\u2020\u2021</td>    </tr>    <tr>      <td>6 || Model || Our system || Shared-Recindependent\u21d2(+DPPs) + joint prediction</td>      <td>+87.9M</td>      <td>0.51K</td>      <td>11.88</td>      <td>35.88\u2020\u2021</td>    </tr>    <tr>      <td>7 || Model || Our system || Shared-Recenc\u2192dec\u21d2(+DPPs) + joint prediction</td>      <td>+91.9M</td>      <td>0.48K</td>      <td>11.84</td>      <td>36.53\u2020\u2021</td>    </tr>    <tr>      <td>8 || Model || Our system || Shared-Recdec\u2192enc\u21d2(+DPPs) + joint prediction</td>      <td>+89.9M</td>      <td>0.49K</td>      <td>11.85</td>      <td>35.99\u2020\u2021</td>    </tr>  </tbody></table>",
        "table_name": "Table 2",
        "table_id": "table_2",
        "paper_id": "D18-1333",
        "page_no": 4,
        "dir": "emnlp2018",
        "valid": 1
    },
    {
        "table_id_paper": "D18-1344table_1",
        "caption": "The performance of different pre-trained embeddings on Sentiment (F1 score) and POS tasks (Accuracy). The reported values are mean and deviation (in parentheses) values computed over multiple runs.",
        "row_header_level": 2,
        "row_headers": [
            [
                "Embedding",
                "None"
            ],
            [
                "Embedding",
                "BiCCA"
            ],
            [
                "Embedding",
                "BiCVM"
            ],
            [
                "Embedding",
                "BiSkip"
            ],
            [
                "Embedding",
                "\u03c7-gCM-Skip"
            ],
            [
                "Embedding",
                "\u03c1-gCM-Skip"
            ]
        ],
        "column_header_level": 3,
        "column_headers": [
            [
                "Sentiment",
                "CM Overall",
                "F1 score"
            ],
            [
                "Sentiment",
                "SemEval 2014",
                "F1 score"
            ],
            [
                "Sentiment",
                "TASS 2016",
                "F1 score"
            ],
            [
                "POS",
                "CM Overall",
                "accuracy"
            ],
            [
                "POS",
                "at SP",
                "accuracy"
            ]
        ],
        "contents": [
            [
                "54.4(1.3)",
                "64.5(0.6)",
                "61.4(1.0)",
                "84.5(0.3)",
                "74.0(0.7)"
            ],
            [
                "57.6(3.0)",
                "64.6(1.0)",
                "59.5(1.8)",
                "84.7(0.8)",
                "75.0(1.8)"
            ],
            [
                "64.3(1.3)",
                "66.8(1.0))",
                "61.9(1.0)",
                "82.0(0.5)",
                "70.6(1.7)"
            ],
            [
                "61.5(1.7)",
                "66.6(0.9)",
                "63.9(1.2)",
                "84.4(0.7)",
                "73.8(0.9)"
            ],
            [
                "62.0(1.9)",
                "67.4(1.3)",
                "63.2(1.5)",
                "84.8(0.6)",
                "74.0(0.6)"
            ],
            [
                "64.6(2.0)",
                "67.7(1.4)",
                "63.8(2.2)",
                "84.9(0.7)",
                "75.3(1.7)"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "F1 score",
            "F1 score",
            "F1 score",
            "accuracy",
            "accuracy"
        ],
        "target_entity": [
            "BiCCA",
            "BiCVM",
            "BiSkip",
            "\u03c7-gCM-Skip",
            "\u03c1-gCM-Skip"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Sentiment || CM Overall</th>      <th>Sentiment || SemEval 2014</th>      <th>Sentiment || TASS 2016</th>      <th>POS || CM Overall</th>      <th>POS || at SP</th>    </tr>  </thead>  <tbody>    <tr>      <td>Embedding || None</td>      <td>54.4(1.3)</td>      <td>64.5(0.6)</td>      <td>61.4(1.0)</td>      <td>84.5(0.3)</td>      <td>74.0(0.7)</td>    </tr>    <tr>      <td>Embedding || BiCCA</td>      <td>57.6(3.0)</td>      <td>64.6(1.0)</td>      <td>59.5(1.8)</td>      <td>84.7(0.8)</td>      <td>75.0(1.8)</td>    </tr>    <tr>      <td>Embedding || BiCVM</td>      <td>64.3(1.3)</td>      <td>66.8(1.0))</td>      <td>61.9(1.0)</td>      <td>82.0(0.5)</td>      <td>70.6(1.7)</td>    </tr>    <tr>      <td>Embedding || BiSkip</td>      <td>61.5(1.7)</td>      <td>66.6(0.9)</td>      <td>63.9(1.2)</td>      <td>84.4(0.7)</td>      <td>73.8(0.9)</td>    </tr>    <tr>      <td>Embedding || \u03c7-gCM-Skip</td>      <td>62.0(1.9)</td>      <td>67.4(1.3)</td>      <td>63.2(1.5)</td>      <td>84.8(0.6)</td>      <td>74.0(0.6)</td>    </tr>    <tr>      <td>Embedding || \u03c1-gCM-Skip</td>      <td>64.6(2.0)</td>      <td>67.7(1.4)</td>      <td>63.8(2.2)</td>      <td>84.9(0.7)</td>      <td>75.3(1.7)</td>    </tr>  </tbody></table>",
        "table_name": "Table 1",
        "table_id": "table_1",
        "paper_id": "D18-1344",
        "page_no": 4,
        "dir": "emnlp2018",
        "valid": 1
    },
    {
        "table_id_paper": "D18-1352table_4",
        "caption": "P@k, R@k, and macro-F1 results over all labels (the union of S, F, and Z).",
        "row_header_level": 1,
        "row_headers": [
            [
                "CNN"
            ],
            [
                "ACNN"
            ],
            [
                "Match-CNN"
            ],
            [
                "ZACNN"
            ],
            [
                "ZAGCNN"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "P@10"
            ],
            [
                "R@10"
            ],
            [
                "Macro-F1"
            ]
        ],
        "contents": [
            [
                "0.562",
                "0.407",
                "0.028"
            ],
            [
                "0.624",
                "0.452",
                "0.068"
            ],
            [
                "0.561",
                "0.415",
                "0.033"
            ],
            [
                "0.577",
                "0.429",
                "0.037"
            ],
            [
                "0.587",
                "0.439",
                "0.038"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "P@10",
            "R@10",
            "Macro-F1"
        ],
        "target_entity": [
            "ZAGCNN",
            "ZACNN"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>P@10</th>      <th>R@10</th>      <th>Macro-F1</th>    </tr>  </thead>  <tbody>    <tr>      <td>CNN</td>      <td>0.562</td>      <td>0.407</td>      <td>0.028</td>    </tr>    <tr>      <td>ACNN</td>      <td>0.624</td>      <td>0.452</td>      <td>0.068</td>    </tr>    <tr>      <td>Match-CNN</td>      <td>0.561</td>      <td>0.415</td>      <td>0.033</td>    </tr>    <tr>      <td>ZACNN</td>      <td>0.577</td>      <td>0.429</td>      <td>0.037</td>    </tr>    <tr>      <td>ZAGCNN</td>      <td>0.587</td>      <td>0.439</td>      <td>0.038</td>    </tr>  </tbody></table>",
        "table_name": "Table 4",
        "table_id": "table_4",
        "paper_id": "D18-1352",
        "page_no": 8,
        "dir": "emnlp2018",
        "valid": 1
    },
    {
        "table_id_paper": "D18-1354table_1",
        "caption": "Experimental results on the OpenSubtitles dataset.",
        "row_header_level": 2,
        "row_headers": [
            [
                "Method",
                "Ground Truth"
            ],
            [
                "Method",
                "Seq2Seq"
            ],
            [
                "Method",
                "CVAE"
            ],
            [
                "Method",
                "CVAE+BOW loss"
            ],
            [
                "Method",
                "Ours (without SBOW)"
            ],
            [
                "Method",
                "Ours"
            ]
        ],
        "column_header_level": 2,
        "column_headers": [
            [
                "Embedding Similarity",
                "EMBA"
            ],
            [
                "Embedding Similarity",
                "EMBE"
            ],
            [
                "Embedding Similarity",
                "EMBG"
            ],
            [
                "RUBER",
                "RubG"
            ],
            [
                "RUBER",
                "RubA"
            ],
            [
                "Diversity",
                "Dist1"
            ],
            [
                "Diversity",
                "Dist2"
            ],
            [
                "Diversity",
                "Entropy"
            ]
        ],
        "contents": [
            [
                "1.000",
                "1.000",
                "1.000",
                "0.872",
                "0.881",
                "0.091",
                "0.423",
                "11.886"
            ],
            [
                "0.572",
                "0.493",
                "0.487",
                "0.441",
                "0.462",
                "0.015",
                "0.053",
                "6.730"
            ],
            [
                "0.639",
                "0.531",
                "0.578",
                "0.562",
                "0.580",
                "0.026",
                "0.102",
                "8.215"
            ],
            [
                "0.659",
                "0.530",
                "0.526",
                "0.602",
                "0.597",
                "0.041",
                "0.302",
                "9.519"
            ],
            [
                "0.678",
                "0.520",
                "0.563",
                "0.591",
                "0.604",
                "0.031",
                "0.259",
                "8.815"
            ],
            [
                "0.714",
                "0.582",
                "0.642",
                "0.635",
                "0.642",
                "0.053",
                "0.404",
                "10.976"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "Embedding Similarity",
            "Embedding Similarity",
            "Embedding Similarity",
            "RUBER",
            "RUBER",
            "Diversity",
            "Diversity",
            "Diversity"
        ],
        "target_entity": [
            "Ours (without SBOW)",
            "Ours"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Embedding Similarity || EMBA</th>      <th>Embedding Similarity || EMBE</th>      <th>Embedding Similarity || EMBG</th>      <th>RUBER || RubG</th>      <th>RUBER || RubA</th>      <th>Diversity || Dist1</th>      <th>Diversity || Dist2</th>      <th>Diversity || Entropy</th>    </tr>  </thead>  <tbody>    <tr>      <td>Method || Ground Truth</td>      <td>1.000</td>      <td>1.000</td>      <td>1.000</td>      <td>0.872</td>      <td>0.881</td>      <td>0.091</td>      <td>0.423</td>      <td>11.886</td>    </tr>    <tr>      <td>Method || Seq2Seq</td>      <td>0.572</td>      <td>0.493</td>      <td>0.487</td>      <td>0.441</td>      <td>0.462</td>      <td>0.015</td>      <td>0.053</td>      <td>6.730</td>    </tr>    <tr>      <td>Method || CVAE</td>      <td>0.639</td>      <td>0.531</td>      <td>0.578</td>      <td>0.562</td>      <td>0.580</td>      <td>0.026</td>      <td>0.102</td>      <td>8.215</td>    </tr>    <tr>      <td>Method || CVAE+BOW loss</td>      <td>0.659</td>      <td>0.530</td>      <td>0.526</td>      <td>0.602</td>      <td>0.597</td>      <td>0.041</td>      <td>0.302</td>      <td>9.519</td>    </tr>    <tr>      <td>Method || Ours (without SBOW)</td>      <td>0.678</td>      <td>0.520</td>      <td>0.563</td>      <td>0.591</td>      <td>0.604</td>      <td>0.031</td>      <td>0.259</td>      <td>8.815</td>    </tr>    <tr>      <td>Method || Ours</td>      <td>0.714</td>      <td>0.582</td>      <td>0.642</td>      <td>0.635</td>      <td>0.642</td>      <td>0.053</td>      <td>0.404</td>      <td>10.976</td>    </tr>  </tbody></table>",
        "table_name": "Table 1",
        "table_id": "table_1",
        "paper_id": "D18-1354",
        "page_no": 7,
        "dir": "emnlp2018",
        "valid": 1
    },
    {
        "table_id_paper": "D18-1360table_3",
        "caption": "Ablation study for multitask learning on SCIERC development set. Each column shows results for the target task.",
        "row_header_level": 2,
        "row_headers": [
            [
                "Task",
                "Multi Task (SCIIE)"
            ],
            [
                "Task",
                "Single Task"
            ],
            [
                "Task",
                "Single Task+Entity Rec."
            ],
            [
                "Task",
                "Single Task+Relation"
            ],
            [
                "Task",
                "Single Task+Coreference"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "Entity Rec."
            ],
            [
                "Relation"
            ],
            [
                "Coref."
            ]
        ],
        "contents": [
            [
                "68.1",
                "39.5",
                "58.0"
            ],
            [
                "65.7",
                "37.9",
                "55.3"
            ],
            [
                "-",
                "38.9",
                "57.1"
            ],
            [
                "66.8",
                "-",
                "57.6"
            ],
            [
                "67.5",
                "39.5",
                "-"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "Entity Rec.",
            "Relation",
            "Coref."
        ],
        "target_entity": [
            "Single Task+Entity Rec.",
            "Single Task+Relation",
            "Single Task+Coreference"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Entity Rec.</th>      <th>Relation</th>      <th>Coref.</th>    </tr>  </thead>  <tbody>    <tr>      <td>Task || Multi Task (SCIIE)</td>      <td>68.1</td>      <td>39.5</td>      <td>58.0</td>    </tr>    <tr>      <td>Task || Single Task</td>      <td>65.7</td>      <td>37.9</td>      <td>55.3</td>    </tr>    <tr>      <td>Task || Single Task+Entity Rec.</td>      <td>-</td>      <td>38.9</td>      <td>57.1</td>    </tr>    <tr>      <td>Task || Single Task+Relation</td>      <td>66.8</td>      <td>-</td>      <td>57.6</td>    </tr>    <tr>      <td>Task || Single Task+Coreference</td>      <td>67.5</td>      <td>39.5</td>      <td>-</td>    </tr>  </tbody></table>",
        "table_name": "Table 3",
        "table_id": "table_3",
        "paper_id": "D18-1360",
        "page_no": 9,
        "dir": "emnlp2018",
        "valid": 1
    },
    {
        "table_id_paper": "D18-1370table_5",
        "caption": "Single-task results for sentence-level tasks (macro-averaged F1 scores).",
        "row_header_level": 2,
        "row_headers": [
            [
                "Model",
                "SVMtfidf"
            ],
            [
                "Model",
                "SVMembeddings"
            ],
            [
                "Model",
                "Neural: Simple"
            ],
            [
                "Model",
                "Neural: Hierarchical"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "DRC"
            ],
            [
                "SAC"
            ],
            [
                "SRC"
            ]
        ],
        "contents": [
            [
                "34.0",
                "10.3",
                "22.2"
            ],
            [
                "25.7",
                "08.5",
                "19.3"
            ],
            [
                "44.1",
                "20.5",
                "31.5"
            ],
            [
                "42.6",
                "19.1",
                "33.2"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "F1",
            "F1",
            "F1"
        ],
        "target_entity": [
            "Neural: Simple",
            "Neural: Hierarchical"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>DRC</th>      <th>SAC</th>      <th>SRC</th>    </tr>  </thead>  <tbody>    <tr>      <td>Model || SVMtfidf</td>      <td>34.0</td>      <td>10.3</td>      <td>22.2</td>    </tr>    <tr>      <td>Model || SVMembeddings</td>      <td>25.7</td>      <td>08.5</td>      <td>19.3</td>    </tr>    <tr>      <td>Model || Neural: Simple</td>      <td>44.1</td>      <td>20.5</td>      <td>31.5</td>    </tr>    <tr>      <td>Model || Neural: Hierarchical</td>      <td>42.6</td>      <td>19.1</td>      <td>33.2</td>    </tr>  </tbody></table>",
        "table_name": "Table 5",
        "table_id": "table_5",
        "paper_id": "D18-1370",
        "page_no": 8,
        "dir": "emnlp2018",
        "valid": 1
    },
    {
        "table_id_paper": "D18-1423table_3",
        "caption": "Results of automatic and human evaluations. BLEU-1 and BLEU-2 are BLEU scores on unigrams and bigrams (p < 0.01); Sim refer to the similarity score; Dist-n corresponds to the distinctness of n-gram, with n = 1 to 4; Con., Flu., Mea., Poe., Ovr. represent consistency, \ufb02uency, meaning, poeticness, and overall, respectively.",
        "row_header_level": 2,
        "row_headers": [
            [
                "Model",
                "S2S"
            ],
            [
                "Model",
                "AS2S"
            ],
            [
                "Model",
                "Key-AS2S"
            ],
            [
                "Model",
                "MeM-AS2S"
            ],
            [
                "Model",
                "GAN"
            ],
            [
                "Model",
                "CVAE"
            ],
            [
                "Model",
                "CVAE-Key"
            ],
            [
                "Model",
                "CVAE-D"
            ]
        ],
        "column_header_level": 2,
        "column_headers": [
            [
                "Automatic Evaluation",
                "BLEU-1"
            ],
            [
                "Automatic Evaluation",
                "BLEU-2"
            ],
            [
                "Automatic Evaluation",
                "Sim"
            ],
            [
                "Automatic Evaluation",
                "Dist-1"
            ],
            [
                "Automatic Evaluation",
                "Dist-2"
            ],
            [
                "Automatic Evaluation",
                "Dist-3"
            ],
            [
                "Automatic Evaluation",
                "Dist-4"
            ],
            [
                "Human Evaluation",
                "Con."
            ],
            [
                "Human Evaluation",
                "Flu."
            ],
            [
                "Human Evaluation",
                "Mea."
            ],
            [
                "Human Evaluation",
                "Poe."
            ],
            [
                "Human Evaluation",
                "Ovr."
            ]
        ],
        "contents": [
            [
                "13.8",
                "2.48",
                "14.7",
                "2.50",
                "16.2",
                "34.9",
                "50.0",
                "1.79",
                "1.84",
                "1.71",
                "1.60",
                "1.74"
            ],
            [
                "15.5",
                "2.59",
                "14.8",
                "2.30",
                "15.2",
                "31.4",
                "44.3",
                "1.92",
                "1.71",
                "1.80",
                "1.74",
                "1.79"
            ],
            [
                "15.8",
                "1.92",
                "19.8",
                "3.00",
                "16.3",
                "33.0",
                "45.6",
                "2.21",
                "2.15",
                "1.92",
                "2.23",
                "2.13"
            ],
            [
                "16.0",
                "1.48",
                "22.0",
                "3.40",
                "51.4",
                "87.9",
                "96.8",
                "1.70",
                "2.23",
                "2.09",
                "2.89",
                "2.23"
            ],
            [
                "17.7",
                "2.54",
                "22.5",
                "2.50",
                "16.8",
                "35.3",
                "49.6",
                "2.36",
                "2.08",
                "2.01",
                "2.08",
                "2.13"
            ],
            [
                "17.0",
                "1.73",
                "13.7",
                "4.70",
                "52.3",
                "90.6",
                "99.0",
                "1.69",
                "2.16",
                "2.14",
                "2.58",
                "2.14"
            ],
            [
                "16.4",
                "1.83",
                "31.0",
                "4.31",
                "43.0",
                "80.6",
                "95.8",
                "1.83",
                "2.29",
                "2.08",
                "2.53",
                "2.18"
            ],
            [
                "18.1",
                "2.85",
                "36.3",
                "5.20",
                "59.2",
                "94.2",
                "99.8",
                "2.58",
                "2.35",
                "2.34",
                "2.96",
                "2.56"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "BLEU-1",
            "BLEU-2",
            "Sim",
            "Dist-1",
            "Dist-2",
            "Dist-3",
            "Dist-4",
            "Con.",
            "Flu.",
            "Mea.",
            "Poe.",
            "Ovr."
        ],
        "target_entity": [
            "CVAE-D"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Automatic Evaluation || BLEU-1</th>      <th>Automatic Evaluation || BLEU-2</th>      <th>Automatic Evaluation || Sim</th>      <th>Automatic Evaluation || Dist-1</th>      <th>Automatic Evaluation || Dist-2</th>      <th>Automatic Evaluation || Dist-3</th>      <th>Automatic Evaluation || Dist-4</th>      <th>Human Evaluation || Con.</th>      <th>Human Evaluation || Flu.</th>      <th>Human Evaluation || Mea.</th>      <th>Human Evaluation || Poe.</th>      <th>Human Evaluation || Ovr.</th>    </tr>  </thead>  <tbody>    <tr>      <td>Model || S2S</td>      <td>13.8</td>      <td>2.48</td>      <td>14.7</td>      <td>2.50</td>      <td>16.2</td>      <td>34.9</td>      <td>50.0</td>      <td>1.79</td>      <td>1.84</td>      <td>1.71</td>      <td>1.60</td>      <td>1.74</td>    </tr>    <tr>      <td>Model || AS2S</td>      <td>15.5</td>      <td>2.59</td>      <td>14.8</td>      <td>2.30</td>      <td>15.2</td>      <td>31.4</td>      <td>44.3</td>      <td>1.92</td>      <td>1.71</td>      <td>1.80</td>      <td>1.74</td>      <td>1.79</td>    </tr>    <tr>      <td>Model || Key-AS2S</td>      <td>15.8</td>      <td>1.92</td>      <td>19.8</td>      <td>3.00</td>      <td>16.3</td>      <td>33.0</td>      <td>45.6</td>      <td>2.21</td>      <td>2.15</td>      <td>1.92</td>      <td>2.23</td>      <td>2.13</td>    </tr>    <tr>      <td>Model || MeM-AS2S</td>      <td>16.0</td>      <td>1.48</td>      <td>22.0</td>      <td>3.40</td>      <td>51.4</td>      <td>87.9</td>      <td>96.8</td>      <td>1.70</td>      <td>2.23</td>      <td>2.09</td>      <td>2.89</td>      <td>2.23</td>    </tr>    <tr>      <td>Model || GAN</td>      <td>17.7</td>      <td>2.54</td>      <td>22.5</td>      <td>2.50</td>      <td>16.8</td>      <td>35.3</td>      <td>49.6</td>      <td>2.36</td>      <td>2.08</td>      <td>2.01</td>      <td>2.08</td>      <td>2.13</td>    </tr>    <tr>      <td>Model || CVAE</td>      <td>17.0</td>      <td>1.73</td>      <td>13.7</td>      <td>4.70</td>      <td>52.3</td>      <td>90.6</td>      <td>99.0</td>      <td>1.69</td>      <td>2.16</td>      <td>2.14</td>      <td>2.58</td>      <td>2.14</td>    </tr>    <tr>      <td>Model || CVAE-Key</td>      <td>16.4</td>      <td>1.83</td>      <td>31.0</td>      <td>4.31</td>      <td>43.0</td>      <td>80.6</td>      <td>95.8</td>      <td>1.83</td>      <td>2.29</td>      <td>2.08</td>      <td>2.53</td>      <td>2.18</td>    </tr>    <tr>      <td>Model || CVAE-D</td>      <td>18.1</td>      <td>2.85</td>      <td>36.3</td>      <td>5.20</td>      <td>59.2</td>      <td>94.2</td>      <td>99.8</td>      <td>2.58</td>      <td>2.35</td>      <td>2.34</td>      <td>2.96</td>      <td>2.56</td>    </tr>  </tbody></table>",
        "table_name": "Table 3",
        "table_id": "table_3",
        "paper_id": "D18-1423",
        "page_no": 6,
        "dir": "emnlp2018",
        "valid": 1
    },
    {
        "table_id_paper": "D18-1434table_2",
        "caption": "State-of-the-Art comparison on VQA-1.0 Dataset. The first block consists of the state-of-the-art results, second block refers to the baselines mentioned in section 5.2, third block provides the results for the variants of mixture module present in section 4.1.3.",
        "row_header_level": 2,
        "row_headers": [
            [
                "Methods",
                "Sample (Yang 2015)"
            ],
            [
                "Methods",
                "Max (Yang 2015)"
            ],
            [
                "Methods",
                "Image Only"
            ],
            [
                "Methods",
                "Caption Only"
            ],
            [
                "Methods",
                "MDN-Attention"
            ],
            [
                "Methods",
                "MDN-Hadamard"
            ],
            [
                "Methods",
                "MDN-Addition"
            ],
            [
                "Methods",
                "MDN-Joint (Ours)"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "BLEU1"
            ],
            [
                "METEOR"
            ],
            [
                "ROUGE"
            ],
            [
                "CIDEr"
            ]
        ],
        "contents": [
            [
                "38.8",
                "12.7",
                "34.2",
                "13.3"
            ],
            [
                "59.4",
                "17.8",
                "49.3",
                "33.1"
            ],
            [
                "56.6",
                "15.1",
                "40.0",
                "31.0"
            ],
            [
                "57.1",
                "15.5",
                "36.6",
                "30.5"
            ],
            [
                "60.7",
                "16.7",
                "49.8",
                "33.6"
            ],
            [
                "61.7",
                "16.7",
                "50.1",
                "29.3"
            ],
            [
                "61.7",
                "18.3",
                "50.4",
                "42.6"
            ],
            [
                "65.1",
                "22.7",
                "52.0",
                "33.1"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "BLEU1",
            "METEOR",
            "ROUGE",
            "CIDEr"
        ],
        "target_entity": [
            "MDN-Joint (Ours)"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>BLEU1</th>      <th>METEOR</th>      <th>ROUGE</th>      <th>CIDEr</th>    </tr>  </thead>  <tbody>    <tr>      <td>Methods || Sample (Yang 2015)</td>      <td>38.8</td>      <td>12.7</td>      <td>34.2</td>      <td>13.3</td>    </tr>    <tr>      <td>Methods || Max (Yang 2015)</td>      <td>59.4</td>      <td>17.8</td>      <td>49.3</td>      <td>33.1</td>    </tr>    <tr>      <td>Methods || Image Only</td>      <td>56.6</td>      <td>15.1</td>      <td>40.0</td>      <td>31.0</td>    </tr>    <tr>      <td>Methods || Caption Only</td>      <td>57.1</td>      <td>15.5</td>      <td>36.6</td>      <td>30.5</td>    </tr>    <tr>      <td>Methods || MDN-Attention</td>      <td>60.7</td>      <td>16.7</td>      <td>49.8</td>      <td>33.6</td>    </tr>    <tr>      <td>Methods || MDN-Hadamard</td>      <td>61.7</td>      <td>16.7</td>      <td>50.1</td>      <td>29.3</td>    </tr>    <tr>      <td>Methods || MDN-Addition</td>      <td>61.7</td>      <td>18.3</td>      <td>50.4</td>      <td>42.6</td>    </tr>    <tr>      <td>Methods || MDN-Joint (Ours)</td>      <td>65.1</td>      <td>22.7</td>      <td>52.0</td>      <td>33.1</td>    </tr>  </tbody></table>",
        "table_name": "Table 2",
        "table_id": "table_2",
        "paper_id": "D18-1434",
        "page_no": 8,
        "dir": "emnlp2018",
        "valid": 1
    },
    {
        "table_id_paper": "D18-1441table_5",
        "caption": "Results of adding different components of our method in terms of ROUGE-1, ROUGE-2, ROUGE-L, strCom (Equation 1) and strCov (Equation 2) scores.",
        "row_header_level": 2,
        "row_headers": [
            [
                "Method",
                "Hierarchical-b."
            ],
            [
                "Method",
                "+strCom"
            ],
            [
                "Method",
                "+strCov"
            ],
            [
                "Method",
                "+hierD"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "R-1"
            ],
            [
                "R-2"
            ],
            [
                "R-L"
            ],
            [
                "strCom"
            ],
            [
                "strCov"
            ]
        ],
        "contents": [
            [
                "34.95",
                "14.79",
                "32.68",
                "0.22",
                "0.31"
            ],
            [
                "37.03",
                "16.21",
                "34.44",
                "0.64",
                "0.71"
            ],
            [
                "39.52",
                "17.12",
                "36.44",
                "0.65",
                "0.87"
            ],
            [
                "40.30",
                "18.02",
                "37.36",
                "0.68",
                "0.93"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "R-1",
            "R-2",
            "R-L",
            "strCom",
            "strCov"
        ],
        "target_entity": [
            "+hierD"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>R-1</th>      <th>R-2</th>      <th>R-L</th>      <th>strCom</th>      <th>strCov</th>    </tr>  </thead>  <tbody>    <tr>      <td>Method || Hierarchical-b.</td>      <td>34.95</td>      <td>14.79</td>      <td>32.68</td>      <td>0.22</td>      <td>0.31</td>    </tr>    <tr>      <td>Method || +strCom</td>      <td>37.03</td>      <td>16.21</td>      <td>34.44</td>      <td>0.64</td>      <td>0.71</td>    </tr>    <tr>      <td>Method || +strCov</td>      <td>39.52</td>      <td>17.12</td>      <td>36.44</td>      <td>0.65</td>      <td>0.87</td>    </tr>    <tr>      <td>Method || +hierD</td>      <td>40.30</td>      <td>18.02</td>      <td>37.36</td>      <td>0.68</td>      <td>0.93</td>    </tr>  </tbody></table>",
        "table_name": "Table 5",
        "table_id": "table_5",
        "paper_id": "D18-1441",
        "page_no": 7,
        "dir": "emnlp2018",
        "valid": 1
    },
    {
        "table_id_paper": "D18-1458table_2",
        "caption": "The results of different NMT models, including the BLEU scores on newstest2014 and newstest2017, the perplexity on the validation set, and the accuracy of long-range dependencies.",
        "row_header_level": 2,
        "row_headers": [
            [
                "Model",
                "RNNS2S"
            ],
            [
                "Model",
                "ConvS2S"
            ],
            [
                "Model",
                "Transformer"
            ],
            [
                "Model",
                "RNN-bideep"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "BLEU 2014"
            ],
            [
                "BLEU 2017"
            ],
            [
                "PPL"
            ],
            [
                "Acc (%)"
            ]
        ],
        "contents": [
            [
                "23.3",
                "25.1",
                "6.1",
                "95.1"
            ],
            [
                "23.9",
                "25.2",
                "7.0",
                "84.9"
            ],
            [
                "26.7",
                "27.5",
                "4.5",
                "97.1"
            ],
            [
                "24.7",
                "26.1",
                "5.7",
                "96.3"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "BLEU 2014",
            "BLEU 2017",
            "PPL",
            "Acc (%)"
        ],
        "target_entity": [
            "RNNS2S",
            "ConvS2S",
            "Transformer"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>2014</th>      <th>2017</th>      <th>PPL</th>      <th>Acc(%)</th>    </tr>  </thead>  <tbody>    <tr>      <td>Model || RNNS2S</td>      <td>23.3</td>      <td>25.1</td>      <td>6.1</td>      <td>95.1</td>    </tr>    <tr>      <td>Model || ConvS2S</td>      <td>23.9</td>      <td>25.2</td>      <td>7.0</td>      <td>84.9</td>    </tr>    <tr>      <td>Model || Transformer</td>      <td>26.7</td>      <td>27.5</td>      <td>4.5</td>      <td>97.1</td>    </tr>    <tr>      <td>Model || RNN-bideep</td>      <td>24.7</td>      <td>26.1</td>      <td>5.7</td>      <td>96.3</td>    </tr>  </tbody></table>",
        "table_name": "Table 2",
        "table_id": "table_2",
        "paper_id": "D18-1458",
        "page_no": 5,
        "dir": "emnlp2018",
        "valid": 1
    },
    {
        "table_id_paper": "D18-1458table_5",
        "caption": "The results of different architectures on newstest sets and ContraWSD. PPL is the perplexity on the validation set. Acc means accuracy on the test set.",
        "row_header_level": 2,
        "row_headers": [
            [
                "Model",
                "RNNS2S"
            ],
            [
                "Model",
                "ConvS2S"
            ],
            [
                "Model",
                "Transformer"
            ],
            [
                "Model",
                "uedin-wmt17"
            ],
            [
                "Model",
                "TransRNN"
            ]
        ],
        "column_header_level": 2,
        "column_headers": [
            [
                "DE\u2192EN",
                "PPL"
            ],
            [
                "DE\u2192EN",
                "2014"
            ],
            [
                "DE\u2192EN",
                "2017"
            ],
            [
                "DE\u2192EN",
                "Acc(%)"
            ],
            [
                "DE\u2192FR",
                "PPL"
            ],
            [
                "DE\u2192FR",
                "2012"
            ],
            [
                "DE\u2192FR",
                "Acc(%)"
            ]
        ],
        "contents": [
            [
                "5.7",
                "29.1",
                "30.1",
                "84.0",
                "7.06",
                "16.4",
                "72.2"
            ],
            [
                "6.3",
                "29.1",
                "30.4",
                "82.3",
                "7.93",
                "16.8",
                "72.7"
            ],
            [
                "4.3",
                "32.7",
                "33.7",
                "90.3",
                "4.9",
                "18.7",
                "76.7"
            ],
            [
                "-",
                "-",
                "35.1",
                "87.9",
                "-",
                "-",
                "-"
            ],
            [
                "5.2",
                "30.5",
                "31.9",
                "86.1",
                "6.3",
                "17.6",
                "74.2"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "PPL",
            "BLEU 2014",
            "BLEU 2017",
            "Acc (%)",
            "PPL",
            "BLEU 2012",
            "Acc (%)"
        ],
        "target_entity": [
            "RNNS2S",
            "ConvS2S",
            "Transformer"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>DE\u2192EN || PPL</th>      <th>DE\u2192EN || 2014</th>      <th>DE\u2192EN || 2017</th>      <th>DE\u2192EN || Acc(%)</th>      <th>DE\u2192FR || PPL</th>      <th>DE\u2192FR || 2012</th>      <th>DE\u2192FR || Acc(%)</th>    </tr>  </thead>  <tbody>    <tr>      <td>Model || RNNS2S</td>      <td>5.7</td>      <td>29.1</td>      <td>30.1</td>      <td>84.0</td>      <td>7.06</td>      <td>16.4</td>      <td>72.2</td>    </tr>    <tr>      <td>Model || ConvS2S</td>      <td>6.3</td>      <td>29.1</td>      <td>30.4</td>      <td>82.3</td>      <td>7.93</td>      <td>16.8</td>      <td>72.7</td>    </tr>    <tr>      <td>Model || Transformer</td>      <td>4.3</td>      <td>32.7</td>      <td>33.7</td>      <td>90.3</td>      <td>4.9</td>      <td>18.7</td>      <td>76.7</td>    </tr>    <tr>      <td>Model || uedin-wmt17</td>      <td>-</td>      <td>-</td>      <td>35.1</td>      <td>87.9</td>      <td>-</td>      <td>-</td>      <td>-</td>    </tr>    <tr>      <td>Model || TransRNN</td>      <td>5.2</td>      <td>30.5</td>      <td>31.9</td>      <td>86.1</td>      <td>6.3</td>      <td>17.6</td>      <td>74.2</td>    </tr>  </tbody></table>",
        "table_name": "Table 5",
        "table_id": "table_5",
        "paper_id": "D18-1458",
        "page_no": 8,
        "dir": "emnlp2018",
        "valid": 1
    },
    {
        "table_id_paper": "D18-1477table_3",
        "caption": "English!German translation results (Section 4.3). We perform 3 independent runs for each configuration. We select the best epoch based on the valid BLEU score for each run, and report the average results and the standard deviation over 3 runs. In addition, we experiment with averaging model 4.0 checkpoints and use the averaged version for evaluation, following (Vaswani et al., 2017). We show the best BLEU results achieved in brackets.",
        "row_header_level": 4,
        "row_headers": [
            [
                "Model",
                "Transformer (base)",
                "# layers",
                "6"
            ],
            [
                "Model",
                "Transformer (+SRU)",
                "# layers",
                "4"
            ],
            [
                "Model",
                "Transformer (+SRU)",
                "# layers",
                "5"
            ]
        ],
        "column_header_level": 2,
        "column_headers": [
            [
                "Size",
                "-"
            ],
            [
                "BLEU score",
                "Valid"
            ],
            [
                "BLEU score",
                "Test"
            ],
            [
                "Speed (toks/sec)",
                "-"
            ],
            [
                "Hours per epoch",
                "-"
            ]
        ],
        "contents": [
            [
                "76m",
                "26.6\u00b10.2 (26.9)",
                "27.6\u00b10.2 (27.9)",
                "20k",
                "2"
            ],
            [
                "79m",
                "26.7\u00b10.1 (26.8)",
                "27.8\u00b10.1 (28.3)",
                "22k",
                "1.8"
            ],
            [
                "90m",
                "27.1\u00b10.0 (27.2)",
                "28.3\u00b10.1 (28.4)",
                "19k",
                "2.1"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "Size",
            "BLEU score",
            "BLEU score",
            "Speed (toks/sec)",
            "Hours per epoch"
        ],
        "target_entity": [
            "Transformer (+SRU)"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Size || -</th>      <th>BLEU score || Valid</th>      <th>BLEU score || Test</th>      <th>Speed (toks/sec) || -</th>      <th>Hours per epoch || -</th>    </tr>  </thead>  <tbody>    <tr>      <td>Model || Transformer (base) || # layers || 6</td>      <td>76m</td>      <td>26.6\u00b10.2 (26.9)</td>      <td>27.6\u00b10.2 (27.9)</td>      <td>20k</td>      <td>2</td>    </tr>    <tr>      <td>Model || Transformer (+SRU) || # layers || 4</td>      <td>79m</td>      <td>26.7\u00b10.1 (26.8)</td>      <td>27.8\u00b10.1 (28.3)</td>      <td>22k</td>      <td>1.8</td>    </tr>    <tr>      <td>Model || Transformer (+SRU) || # layers || 5</td>      <td>90m</td>      <td>27.1\u00b10.0 (27.2)</td>      <td>28.3\u00b10.1 (28.4)</td>      <td>19k</td>      <td>2.1</td>    </tr>  </tbody></table>",
        "table_name": "Table 3",
        "table_id": "table_3",
        "paper_id": "D18-1477",
        "page_no": 8,
        "dir": "emnlp2018",
        "valid": 1
    },
    {
        "table_id_paper": "D18-1482table_4",
        "caption": "Pearson\u2019s scores of WME against other unsupervised, semi-supervised, and supervised methods on 22 textual similarity tasks. Results are collected from (Arora et al., 2017) except our approach.",
        "row_header_level": 2,
        "row_headers": [
            [
                "Tasks",
                "STS\u201912"
            ],
            [
                "Tasks",
                "STS\u201913"
            ],
            [
                "Tasks",
                "STS\u201914"
            ],
            [
                "Tasks",
                "STS\u201915"
            ],
            [
                "Tasks",
                "SICK\u201914"
            ],
            [
                "Tasks",
                "Twitter\u201915"
            ]
        ],
        "column_header_level": 5,
        "column_headers": [
            [
                "Approaches",
                "Supervised",
                "WordEmbeddings",
                "PSL",
                "PP"
            ],
            [
                "Approaches",
                "Supervised",
                "WordEmbeddings",
                "PSL",
                " Dan"
            ],
            [
                "Approaches",
                "Supervised",
                "WordEmbeddings",
                "PSL",
                "RNN"
            ],
            [
                "Approaches",
                "Supervised",
                "WordEmbeddings",
                "PSL",
                "iRNN"
            ],
            [
                "Approaches",
                "Supervised",
                "WordEmbeddings",
                "PSL",
                "LSTM(no)"
            ],
            [
                "Approaches",
                "Supervised",
                "WordEmbeddings",
                "PSL",
                "LSTM(o.g.)"
            ],
            [
                "Approaches",
                "Unsupervised",
                "WordEmbeddings",
                "GloVe",
                "ST"
            ],
            [
                "Approaches",
                "Unsupervised",
                "WordEmbeddings",
                "GloVe",
                "nbow"
            ],
            [
                "Approaches",
                "Unsupervised",
                "WordEmbeddings",
                "GloVe",
                "tf-idf"
            ],
            [
                "Approaches",
                "Unsupervised",
                "WordEmbeddings",
                "GloVe",
                "SIF"
            ],
            [
                "Approaches",
                "Unsupervised",
                "WordEmbeddings",
                "GloVe",
                "WME"
            ],
            [
                "Approaches",
                "Semi-supervised",
                "WordEmbeddings",
                "PSL",
                "SIF"
            ],
            [
                "Approaches",
                "Semi-supervised",
                "WordEmbeddings",
                "PSL",
                "WME"
            ]
        ],
        "contents": [
            [
                "58.7",
                "56.0",
                "48.1",
                "58.4",
                "51.0",
                "46.4",
                "30.8",
                "52.5",
                "58.7",
                "56.2",
                "60.6",
                "59.5",
                "62.8"
            ],
            [
                "55.8",
                "54.2",
                "44.7",
                "56.7",
                "45.2",
                "41.5",
                "24.8",
                "42.3",
                "52.1",
                "56.6",
                "54.5",
                "61.8",
                "56.3"
            ],
            [
                "70.9",
                "69.5",
                "57.7",
                "70.9",
                "59.8",
                "51.5",
                "31.4",
                "54.2",
                "63.8",
                "68.5",
                "65.5",
                "73.5",
                "68.0"
            ],
            [
                "75.8",
                "72.7",
                "57.2",
                "75.6",
                "63.9",
                "56.0",
                "31.0",
                "52.7",
                "60.6",
                "71.7",
                "61.8",
                "76.3",
                "64.2"
            ],
            [
                "71.6",
                "70.7",
                "61.2",
                "71.2",
                "63.9",
                "59.0",
                "49.8",
                "65.9",
                "69.4",
                "72.2",
                "68.0",
                "72.9",
                "68.1"
            ],
            [
                "52.9",
                "53.7",
                "45.1",
                "52.9",
                "47.6",
                "36.1",
                "24.7",
                "30.3",
                "33.8",
                "48.0",
                "41.6",
                "49.0",
                "47.4"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "similarity",
            "similarity",
            "similarity",
            "similarity",
            "similarity",
            "similarity",
            "similarity",
            "similarity",
            "similarity",
            "similarity",
            "similarity",
            "similarity",
            "similarity"
        ],
        "target_entity": [
            "WME"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Approaches || Supervised || WordEmbeddings || PSL || PP</th>      <th>Approaches || Supervised || WordEmbeddings || PSL ||  Dan</th>      <th>Approaches || Supervised || WordEmbeddings || PSL || RNN</th>      <th>Approaches || Supervised || WordEmbeddings || PSL || iRNN</th>      <th>Approaches || Supervised || WordEmbeddings || PSL || LSTM(no)</th>      <th>Approaches || Supervised || WordEmbeddings || PSL || LSTM(o.g.)</th>      <th>Approaches || Unsupervised || WordEmbeddings || GloVe || ST</th>      <th>Approaches || Unsupervised || WordEmbeddings || GloVe || nbow</th>      <th>Approaches || Unsupervised || WordEmbeddings || GloVe || tf-idf</th>      <th>Approaches || Unsupervised || WordEmbeddings || GloVe || SIF</th>      <th>Approaches || Unsupervised || WordEmbeddings || GloVe || WME</th>      <th>Approaches || Semi-supervised || WordEmbeddings || PSL || SIF</th>      <th>Approaches || Semi-supervised || WordEmbeddings || PSL || WME</th>    </tr>  </thead>  <tbody>    <tr>      <td>Tasks || STS\u201912</td>      <td>58.7</td>      <td>56.0</td>      <td>48.1</td>      <td>58.4</td>      <td>51.0</td>      <td>46.4</td>      <td>30.8</td>      <td>52.5</td>      <td>58.7</td>      <td>56.2</td>      <td>60.6</td>      <td>59.5</td>      <td>62.8</td>    </tr>    <tr>      <td>Tasks || STS\u201913</td>      <td>55.8</td>      <td>54.2</td>      <td>44.7</td>      <td>56.7</td>      <td>45.2</td>      <td>41.5</td>      <td>24.8</td>      <td>42.3</td>      <td>52.1</td>      <td>56.6</td>      <td>54.5</td>      <td>61.8</td>      <td>56.3</td>    </tr>    <tr>      <td>Tasks || STS\u201914</td>      <td>70.9</td>      <td>69.5</td>      <td>57.7</td>      <td>70.9</td>      <td>59.8</td>      <td>51.5</td>      <td>31.4</td>      <td>54.2</td>      <td>63.8</td>      <td>68.5</td>      <td>65.5</td>      <td>73.5</td>      <td>68.0</td>    </tr>    <tr>      <td>Tasks || STS\u201915</td>      <td>75.8</td>      <td>72.7</td>      <td>57.2</td>      <td>75.6</td>      <td>63.9</td>      <td>56.0</td>      <td>31.0</td>      <td>52.7</td>      <td>60.6</td>      <td>71.7</td>      <td>61.8</td>      <td>76.3</td>      <td>64.2</td>    </tr>    <tr>      <td>Tasks || SICK\u201914</td>      <td>71.6</td>      <td>70.7</td>      <td>61.2</td>      <td>71.2</td>      <td>63.9</td>      <td>59.0</td>      <td>49.8</td>      <td>65.9</td>      <td>69.4</td>      <td>72.2</td>      <td>68.0</td>      <td>72.9</td>      <td>68.1</td>    </tr>    <tr>      <td>Tasks || Twitter\u201915</td>      <td>52.9</td>      <td>53.7</td>      <td>45.1</td>      <td>52.9</td>      <td>47.6</td>      <td>36.1</td>      <td>24.7</td>      <td>30.3</td>      <td>33.8</td>      <td>48.0</td>      <td>41.6</td>      <td>49.0</td>      <td>47.4</td>    </tr>  </tbody></table>",
        "table_name": "Table 4",
        "table_id": "table_4",
        "paper_id": "D18-1482",
        "page_no": 8,
        "dir": "emnlp2018",
        "valid": 1
    },
    {
        "table_id_paper": "D19-1018table_2",
        "caption": "Performance for classifying review segments as good or bad for recommendation justification.",
        "row_header_level": 2,
        "row_headers": [
            [
                "Method",
                "BOW-Xgboost"
            ],
            [
                "Method",
                "CNN"
            ],
            [
                "Method",
                "LSTM-MaxPool"
            ],
            [
                "Method",
                "BERT"
            ],
            [
                "Method",
                "BERT-SA (one epoch)"
            ],
            [
                "Method",
                "BERT-SA (three epoch)"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "F1"
            ],
            [
                "Recall"
            ],
            [
                "Precision"
            ]
        ],
        "contents": [
            [
                "0.559",
                "0.679",
                "0.475"
            ],
            [
                "0.644",
                "0.596",
                "0.7"
            ],
            [
                "0.675",
                "0.703",
                "0.65"
            ],
            [
                "0.747",
                "0.7",
                "0.8"
            ],
            [
                "0.481",
                "0.975",
                "0.32"
            ],
            [
                "0.491",
                "1",
                "0.325"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "F1",
            "Recall",
            "Precision"
        ],
        "target_entity": [
            "BERT",
            "BERT-SA (one epoch)",
            "BERT-SA (three epoch)"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>F1</th>      <th>Recall</th>      <th>Precision</th>    </tr>  </thead>  <tbody>    <tr>      <td>Method || BOW-Xgboost</td>      <td>0.559</td>      <td>0.679</td>      <td>0.475</td>    </tr>    <tr>      <td>Method || CNN</td>      <td>0.644</td>      <td>0.596</td>      <td>0.7</td>    </tr>    <tr>      <td>Method || LSTM-MaxPool</td>      <td>0.675</td>      <td>0.703</td>      <td>0.65</td>    </tr>    <tr>      <td>Method || BERT</td>      <td>0.747</td>      <td>0.7</td>      <td>0.8</td>    </tr>    <tr>      <td>Method || BERT-SA (one epoch)</td>      <td>0.481</td>      <td>0.975</td>      <td>0.32</td>    </tr>    <tr>      <td>Method || BERT-SA (three epoch)</td>      <td>0.491</td>      <td>1</td>      <td>0.325</td>    </tr>  </tbody></table>",
        "table_name": "Table 2",
        "table_id": "table_2",
        "paper_id": "D19-1018",
        "page_no": 3,
        "dir": "emnlp2019",
        "valid": 1
    },
    {
        "table_id_paper": "D19-1054table_4",
        "caption": "Human evaluation on \ufb02uency, intraconsistency and inter-diversity of content selection on DUC 2004.",
        "row_header_level": 2,
        "row_headers": [
            [
                "Method",
                "Reference"
            ],
            [
                "Method",
                "Enc-Dec"
            ],
            [
                "Method",
                "Bo.Up."
            ],
            [
                "Method",
                "SS"
            ],
            [
                "Method",
                "RS"
            ],
            [
                "Method",
                "VRS"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "Fluency"
            ],
            [
                "intra-consistency"
            ],
            [
                "inter-diversity"
            ]
        ],
        "contents": [
            [
                "0.96",
                "-",
                "-"
            ],
            [
                "0.83",
                "-",
                "-"
            ],
            [
                "0.46",
                "0.48",
                "0.61"
            ],
            [
                "0.27",
                "0.41",
                "0.54"
            ],
            [
                "0.78",
                "0.39",
                "0.47"
            ],
            [
                "0.74",
                "0.72",
                "0.87"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "Fluency",
            "intra-consistency",
            "inter-diversity"
        ],
        "target_entity": [
            "Enc-Dec"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Fluency</th>      <th>intra-consistency</th>      <th>inter-diversity</th>    </tr>  </thead>  <tbody>    <tr>      <td>Method || Reference</td>      <td>0.96</td>      <td>-</td>      <td>-</td>    </tr>    <tr>      <td>Method || Enc-Dec</td>      <td>0.83</td>      <td>-</td>      <td>-</td>    </tr>    <tr>      <td>Method || Bo.Up.</td>      <td>0.46</td>      <td>0.48</td>      <td>0.61</td>    </tr>    <tr>      <td>Method || SS</td>      <td>0.27</td>      <td>0.41</td>      <td>0.54</td>    </tr>    <tr>      <td>Method || RS</td>      <td>0.78</td>      <td>0.39</td>      <td>0.47</td>    </tr>    <tr>      <td>Method || VRS</td>      <td>0.74</td>      <td>0.72</td>      <td>0.87</td>    </tr>  </tbody></table>",
        "table_name": "Table 4",
        "table_id": "table_4",
        "paper_id": "D19-1054",
        "page_no": 7,
        "dir": "emnlp2019",
        "valid": 1
    },
    {
        "table_id_paper": "D19-1069table_3",
        "caption": "The performance of our baseline approaches is well below human performance.",
        "row_header_level": 2,
        "row_headers": [
            [
                "System",
                "Baseline 1"
            ],
            [
                "System",
                "Baseline 2"
            ],
            [
                "System",
                "Baseline 3"
            ],
            [
                "System",
                "Baseline 4"
            ],
            [
                "System",
                "Baseline 5"
            ],
            [
                "System",
                "Human"
            ]
        ],
        "column_header_level": 2,
        "column_headers": [
            [
                "Text Evaluation",
                "P"
            ],
            [
                "Text Evaluation",
                "R"
            ],
            [
                "Text Evaluation",
                "F1"
            ],
            [
                "Link Evaluation",
                "P"
            ],
            [
                "Link Evaluation",
                "R"
            ],
            [
                "Link Evaluation",
                "F1"
            ]
        ],
        "contents": [
            [
                "0.44",
                "0.64",
                "0.52",
                "0.31",
                "0.26",
                "0.28"
            ],
            [
                "0.49",
                "0.64",
                "0.55",
                "0.37",
                "0.32",
                "0.34"
            ],
            [
                "0.47",
                "0.66",
                "0.55",
                "0.35",
                "0.37",
                "0.36"
            ],
            [
                "0.6",
                "0.65",
                "0.62",
                "0.51",
                "0.48",
                "0.49"
            ],
            [
                "0.68",
                "0.7",
                "0.69",
                "0.53",
                "0.48",
                "0.5"
            ],
            [
                "0.88",
                "0.88",
                "0.88",
                "0.81",
                "0.84",
                "0.82"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "P",
            "R",
            "F1",
            "P",
            "R",
            "F1"
        ],
        "target_entity": [
            "Baseline 5"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Text Evaluation || P</th>      <th>Text Evaluation || R</th>      <th>Text Evaluation || F1</th>      <th>Link Evaluation || P</th>      <th>Link Evaluation || R</th>      <th>Link Evaluation || F1</th>    </tr>  </thead>  <tbody>    <tr>      <td>System || Baseline 1</td>      <td>0.44</td>      <td>0.64</td>      <td>0.52</td>      <td>0.31</td>      <td>0.26</td>      <td>0.28</td>    </tr>    <tr>      <td>System || Baseline 2</td>      <td>0.49</td>      <td>0.64</td>      <td>0.55</td>      <td>0.37</td>      <td>0.32</td>      <td>0.34</td>    </tr>    <tr>      <td>System || Baseline 3</td>      <td>0.47</td>      <td>0.66</td>      <td>0.55</td>      <td>0.35</td>      <td>0.37</td>      <td>0.36</td>    </tr>    <tr>      <td>System || Baseline 4</td>      <td>0.6</td>      <td>0.65</td>      <td>0.62</td>      <td>0.51</td>      <td>0.48</td>      <td>0.49</td>    </tr>    <tr>      <td>System || Baseline 5</td>      <td>0.68</td>      <td>0.7</td>      <td>0.69</td>      <td>0.53</td>      <td>0.48</td>      <td>0.5</td>    </tr>    <tr>      <td>System || Human</td>      <td>0.88</td>      <td>0.88</td>      <td>0.88</td>      <td>0.81</td>      <td>0.84</td>      <td>0.82</td>    </tr>  </tbody></table>",
        "table_name": "Table 3",
        "table_id": "table_3",
        "paper_id": "D19-1069",
        "page_no": 8,
        "dir": "emnlp2019",
        "valid": 1
    },
    {
        "table_id_paper": "D19-1124table_1",
        "caption": "Results of NLL on Ubuntu and Movie datasets with different models. The \u2264 symbol denotes the variational bound.",
        "row_header_level": 3,
        "row_headers": [
            [
                "Ubuntu dataset",
                "Model",
                "HRED"
            ],
            [
                "Ubuntu dataset",
                "Model",
                "VHRED"
            ],
            [
                "Ubuntu dataset",
                "Model",
                "Dir-VHRED"
            ],
            [
                "Movie dataset",
                " Model",
                "HRED"
            ],
            [
                "Movie dataset",
                " Model",
                "VHRED"
            ],
            [
                "Movie dataset",
                "Model",
                "Dir-VHRED"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "NLL"
            ],
            [
                "reconstruction"
            ],
            [
                "KL-div."
            ]
        ],
        "contents": [
            [
                "3.844",
                "-",
                "-"
            ],
            [
                "\u2264 4.132",
                "3.765",
                "0.367"
            ],
            [
                "\u2264 3.999",
                "3.614",
                "0.385"
            ],
            [
                "3.944",
                "-",
                "-"
            ],
            [
                "\u2264 4.233",
                "3.904",
                "0.33"
            ],
            [
                "\u2264 4.073",
                "3.741",
                "0.332"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "loss",
            "loss",
            "loss"
        ],
        "target_entity": [
            "Dir-VHRED"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>NLL</th>      <th>reconstruction</th>      <th>KL-div.</th>    </tr>  </thead>  <tbody>    <tr>      <td>Ubuntu dataset || Model || HRED</td>      <td>3.844</td>      <td>-</td>      <td>-</td>    </tr>    <tr>      <td>Ubuntu dataset || Model || VHRED</td>      <td>\u2264 4.132</td>      <td>3.765</td>      <td>0.367</td>    </tr>    <tr>      <td>Ubuntu dataset || Model || Dir-VHRED</td>      <td>\u2264 3.999</td>      <td>3.614</td>      <td>0.385</td>    </tr>    <tr>      <td>Movie dataset ||  Model || HRED</td>      <td>3.944</td>      <td>-</td>      <td>-</td>    </tr>    <tr>      <td>Movie dataset ||  Model || VHRED</td>      <td>\u2264 4.233</td>      <td>3.904</td>      <td>0.33</td>    </tr>    <tr>      <td>Movie dataset ||  Model || Dir-VHRED</td>      <td>\u2264 4.073</td>      <td>3.741</td>      <td>0.332</td>    </tr>  </tbody></table>",
        "table_name": "Table 1",
        "table_id": "table_1",
        "paper_id": "D19-1124",
        "page_no": 4,
        "dir": "emnlp2019",
        "valid": 1
    },
    {
        "table_id_paper": "D19-1154table_2",
        "caption": "Results on the image and video datasets of Semantic Textual Similarity task. (Pearson\u2019s r \u00d7 100 ).",
        "row_header_level": 2,
        "row_headers": [
            [
                "Method",
                "STS Baseline"
            ],
            [
                "Method",
                "STS Best System"
            ],
            [
                "Method",
                "GRAN (Wieting et al. 2017)"
            ],
            [
                "Method",
                "VSE (Kiros et al. 2014)"
            ],
            [
                "Method",
                "OE (Vendrov et al. 2015)"
            ],
            [
                "Method",
                "DAN (Nam et al. 2017)"
            ],
            [
                "Method",
                "VSE++ (Faghri et al. 2018)"
            ],
            [
                "Method",
                "SCAN (Lee et al. 2018)"
            ],
            [
                "Method",
                "PIVOT (Gella et al. 2017)"
            ],
            [
                "Method",
                "Ours (w/ Random)"
            ],
            [
                "Method",
                "Ours (w/ FastText)"
            ],
            [
                "Method",
                "Ours (w/ BERT)"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "MS-Vid (2012)"
            ],
            [
                "Pascal (2014)"
            ],
            [
                "Pascal (2015)"
            ]
        ],
        "contents": [
            [
                "29.9",
                "51.3",
                "60.4"
            ],
            [
                "86.3",
                "83.4",
                "86.4"
            ],
            [
                "83.7",
                "84.5",
                "85.0"
            ],
            [
                "80.6",
                "82.7",
                "89.6"
            ],
            [
                "82.2",
                "84.1",
                "90.8"
            ],
            [
                "84.1",
                "84.3",
                "90.8"
            ],
            [
                "84.5",
                "84.8",
                "91.2"
            ],
            [
                "84.0",
                "83.9",
                "90.7"
            ],
            [
                "84.6",
                "84.5",
                "91.5"
            ],
            [
                "85.8",
                "87.8",
                "91.5"
            ],
            [
                "86.2",
                "88.3",
                "91.8"
            ],
            [
                "86.4",
                "88.0",
                "91.7"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "r",
            "r",
            "r"
        ],
        "target_entity": [
            "Ours (w/ FastText)",
            "Ours (w/ BERT)",
            "Ours (w/ Random)"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>MS-Vid (2012)</th>      <th>Pascal (2014)</th>      <th>Pascal (2015)</th>    </tr>  </thead>  <tbody>    <tr>      <td>Method || STS Baseline</td>      <td>29.9</td>      <td>51.3</td>      <td>60.4</td>    </tr>    <tr>      <td>Method || STS Best System</td>      <td>86.3</td>      <td>83.4</td>      <td>86.4</td>    </tr>    <tr>      <td>Method || GRAN (Wieting et al. 2017)</td>      <td>83.7</td>      <td>84.5</td>      <td>85.0</td>    </tr>    <tr>      <td>Method || VSE (Kiros et al. 2014)</td>      <td>80.6</td>      <td>82.7</td>      <td>89.6</td>    </tr>    <tr>      <td>Method || OE (Vendrov et al. 2015)</td>      <td>82.2</td>      <td>84.1</td>      <td>90.8</td>    </tr>    <tr>      <td>Method || DAN (Nam et al. 2017)</td>      <td>84.1</td>      <td>84.3</td>      <td>90.8</td>    </tr>    <tr>      <td>Method || VSE++ (Faghri et al. 2018)</td>      <td>84.5</td>      <td>84.8</td>      <td>91.2</td>    </tr>    <tr>      <td>Method || SCAN (Lee et al. 2018)</td>      <td>84.0</td>      <td>83.9</td>      <td>90.7</td>    </tr>    <tr>      <td>Method || PIVOT (Gella et al. 2017)</td>      <td>84.6</td>      <td>84.5</td>      <td>91.5</td>    </tr>    <tr>      <td>Method || Ours (w/ Random)</td>      <td>85.8</td>      <td>87.8</td>      <td>91.5</td>    </tr>    <tr>      <td>Method || Ours (w/ FastText)</td>      <td>86.2</td>      <td>88.3</td>      <td>91.8</td>    </tr>    <tr>      <td>Method || Ours (w/ BERT)</td>      <td>86.4</td>      <td>88.0</td>      <td>91.7</td>    </tr>  </tbody></table>",
        "table_name": "Table 2",
        "table_id": "table_2",
        "paper_id": "D19-1154",
        "page_no": 4,
        "dir": "emnlp2019",
        "valid": 1
    },
    {
        "table_id_paper": "D19-1158table_1",
        "caption": "Average cosine similarity score and Delta-E distance over 5 runs. A smaller Delta-E distance means a less significant difference between two colors. Bold: best performance. Hard: the hard ensemble model. WM18\u2217: the performance from WM18 paper. See Supplementary Material for example outputs and ensemble analysis.",
        "row_header_level": 2,
        "row_headers": [
            [
                "Test Condition",
                "Seen Pairings"
            ],
            [
                "Test Condition",
                "Unseen Pairings"
            ],
            [
                "Test Condition",
                "Unseen Ref. Color"
            ],
            [
                "Test Condition",
                "Unseen Modifiers"
            ],
            [
                "Test Condition",
                "Fully Unseen"
            ],
            [
                "Test Condition",
                "Overall"
            ]
        ],
        "column_header_level": 2,
        "column_headers": [
            [
                "Cosine Similarity \u00b1 SD",
                "RGB"
            ],
            [
                "Cosine Similarity \u00b1 SD",
                "WM18 HSV"
            ],
            [
                "Cosine Similarity \u00b1 SD",
                "Ensemble"
            ],
            [
                "Cosine Similarity \u00b1 SD",
                "WM18*"
            ],
            [
                "Cosine Similarity \u00b1 SD",
                "RGB"
            ],
            [
                "Delta-E \u00b1 SD",
                "WM18 HSV"
            ],
            [
                "Delta-E \u00b1 SD",
                "Ensemble"
            ],
            [
                "Delta-E \u00b1 SD",
                "WM18*"
            ]
        ],
        "contents": [
            [
                "0.954\u00b10.001",
                "0.953\u00b10.000 0.934\u00b10.089",
                "0.954\u00b10.0",
                "0.68",
                "3.121\u00b10.027",
                "3.188\u00b10.062 5.380\u00b14.846",
                "4.093\u00b10.1",
                "6.1"
            ],
            [
                "0.799\u00b10.044",
                "0.771\u00b10.032 0.843\u00b10.144",
                "0.797\u00b10.0",
                "0.68",
                "6.454\u00b10.233",
                "6.825\u00b10.093 11.701\u00b13.358",
                "5.873\u00b10.0",
                "7.9"
            ],
            [
                "0.781\u00b10.015",
                "0.767\u00b10.010 0.945\u00b10.019",
                "0.804\u00b10.0",
                "0.4",
                "7.456\u00b10.184",
                "7.658\u00b10.363 10.429\u00b12.523",
                "7.171\u00b10.0",
                "11.4"
            ],
            [
                "0.633\u00b10.042",
                "0.637\u00b10.032 0.724\u00b10.131",
                "0.629\u00b10.0",
                "0.41",
                "13.288\u00b11.082",
                "13.891\u00b11.077 14.183\u00b15.175",
                "10.927\u00b10.0",
                "10.5"
            ],
            [
                "0.370\u00b10.029",
                "0.358\u00b10.038 0.919\u00b10.026",
                "0.445\u00b10.0",
                "-0.21",
                "13.859\u00b10.874",
                "14.516\u00b10.587 12.432\u00b12.170",
                "13.448\u00b10.0",
                "15.9"
            ],
            [
                "0.858\u00b10.006",
                "0.856\u00b10.003 0.911\u00b10.057",
                "0.868\u00b10.0",
                "0.65",
                "5.412\u00b10.169",
                "5.595\u00b10.128 7.487\u00b13.940",
                "5.777\u00b10.0",
                "6.8"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "Cosine Similarity \u00b1 SD ",
            "Cosine Similarity \u00b1 SD ",
            "Cosine Similarity \u00b1 SD",
            "Cosine Similarity \u00b1 SD ",
            "Cosine Similarity \u00b1 SD ",
            "Delta-E \u00b1 SD ",
            "Delta-E \u00b1 SD ",
            "Delta-E \u00b1 SD"
        ],
        "target_entity": [
            "RGB"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Cosine Similarity \u00b1 SD || RGB</th>      <th>Cosine Similarity \u00b1 SD || WM18 HSV</th>      <th>Cosine Similarity \u00b1 SD || Ensemble</th>      <th>Cosine Similarity \u00b1 SD || WM18*</th>      <th>Cosine Similarity \u00b1 SD || RGB</th>      <th>Delta-E \u00b1 SD || WM18 HSV</th>      <th>Delta-E \u00b1 SD || Ensemble</th>      <th>Delta-E \u00b1 SD || WM18*</th>    </tr>  </thead>  <tbody>    <tr>      <td>Test Condition || Seen Pairings</td>      <td>0.954\u00b10.001</td>      <td>0.953\u00b10.000 0.934\u00b10.089</td>      <td>0.954\u00b10.0</td>      <td>0.68</td>      <td>3.121\u00b10.027</td>      <td>3.188\u00b10.062 5.380\u00b14.846</td>      <td>4.093\u00b10.1</td>      <td>6.1</td>    </tr>    <tr>      <td>Test Condition || Unseen Pairings</td>      <td>0.799\u00b10.044</td>      <td>0.771\u00b10.032 0.843\u00b10.144</td>      <td>0.797\u00b10.0</td>      <td>0.68</td>      <td>6.454\u00b10.233</td>      <td>6.825\u00b10.093 11.701\u00b13.358</td>      <td>5.873\u00b10.0</td>      <td>7.9</td>    </tr>    <tr>      <td>Test Condition || Unseen Ref. Color</td>      <td>0.781\u00b10.015</td>      <td>0.767\u00b10.010 0.945\u00b10.019</td>      <td>0.804\u00b10.0</td>      <td>0.4</td>      <td>7.456\u00b10.184</td>      <td>7.658\u00b10.363 10.429\u00b12.523</td>      <td>7.171\u00b10.0</td>      <td>11.4</td>    </tr>    <tr>      <td>Test Condition || Unseen Modifiers</td>      <td>0.633\u00b10.042</td>      <td>0.637\u00b10.032 0.724\u00b10.131</td>      <td>0.629\u00b10.0</td>      <td>0.41</td>      <td>13.288\u00b11.082</td>      <td>13.891\u00b11.077 14.183\u00b15.175</td>      <td>10.927\u00b10.0</td>      <td>10.5</td>    </tr>    <tr>      <td>Test Condition || Fully Unseen</td>      <td>0.370\u00b10.029</td>      <td>0.358\u00b10.038 0.919\u00b10.026</td>      <td>0.445\u00b10.0</td>      <td>-0.21</td>      <td>13.859\u00b10.874</td>      <td>14.516\u00b10.587 12.432\u00b12.170</td>      <td>13.448\u00b10.0</td>      <td>15.9</td>    </tr>    <tr>      <td>Test Condition || Overall</td>      <td>0.858\u00b10.006</td>      <td>0.856\u00b10.003 0.911\u00b10.057</td>      <td>0.868\u00b10.0</td>      <td>0.65</td>      <td>5.412\u00b10.169</td>      <td>5.595\u00b10.128 7.487\u00b13.940</td>      <td>5.777\u00b10.0</td>      <td>6.8</td>    </tr>  </tbody></table>",
        "table_name": "Table 1",
        "table_id": "table_1",
        "paper_id": "D19-1158",
        "page_no": 4,
        "dir": "emnlp2019",
        "valid": 1
    },
    {
        "table_id_paper": "D19-1160table_2",
        "caption": "Results for dependency parsing evaluated on PTB treebank with gaze features as auxiliary task(s) learned from the disjoint dataset: Dundee treebank.",
        "row_header_level": 3,
        "row_headers": [
            [
                "baseline",
                "Gaze features",
                "baseline"
            ],
            [
                "Basic",
                "Gaze features",
                "total fix dur"
            ],
            [
                "Basic",
                "Gaze features",
                "mean fix dur"
            ],
            [
                "Basic",
                "Gaze features",
                "n fix"
            ],
            [
                "Basic",
                "Gaze features",
                "fix prob"
            ],
            [
                "Basic",
                "Gaze features",
                "basic feats aux"
            ],
            [
                "Early",
                "Gaze features",
                "first fix dur"
            ],
            [
                "Early",
                "Gaze features",
                "first pass dur"
            ],
            [
                "Early",
                "Gaze features",
                "early feats aux"
            ],
            [
                "Late",
                "Gaze features",
                "n re-fix"
            ],
            [
                "Late",
                "Gaze features",
                "reread prob"
            ],
            [
                "Late",
                "Gaze features",
                "late feats aux"
            ],
            [
                "Context",
                "Gaze features",
                "w \u2212 1 fix prob"
            ],
            [
                "Context",
                "Gaze features",
                "w + 1 fix prob"
            ],
            [
                "Context",
                "Gaze features",
                "w \u2212 1 fix dur"
            ],
            [
                "Context",
                "Gaze features",
                "w + 1 fix dur"
            ],
            [
                "Context",
                "Gaze features",
                "context feats aux"
            ]
        ],
        "column_header_level": 2,
        "column_headers": [
            [
                "dev set",
                "UAS"
            ],
            [
                "dev set",
                "LAS"
            ],
            [
                "test set",
                "UAS"
            ],
            [
                "test set",
                "LAS"
            ]
        ],
        "contents": [
            [
                "93.98",
                "91.67",
                "93.86",
                "91.80"
            ],
            [
                "93.94",
                "91.60",
                "93.99",
                "91.92"
            ],
            [
                "94.12",
                "91.84",
                "93.95",
                "91.82"
            ],
            [
                "93.97",
                "91.70",
                "93.91",
                "91.87"
            ],
            [
                "93.98",
                "91.71",
                "93.99",
                "91.93"
            ],
            [
                "94.00",
                "91.69",
                "93.84",
                "91.81"
            ],
            [
                "94.07",
                "91.81",
                "93.87",
                "91.80"
            ],
            [
                "93.93",
                "91.58",
                "93.79",
                "91.70"
            ],
            [
                "94.04",
                "91.78",
                "93.96",
                "91.88"
            ],
            [
                "94.01",
                "91.69",
                "93.87",
                "91.79"
            ],
            [
                "94.03",
                "91.74",
                "93.98",
                "91.89"
            ],
            [
                "93.98",
                "91.58",
                "93.92",
                "91.90"
            ],
            [
                "94.02",
                "91.65",
                "93.95",
                "91.93"
            ],
            [
                "93.88",
                "91.61",
                "93.89",
                "91.82"
            ],
            [
                "94.06",
                "91.65",
                "93.86",
                "91.83"
            ],
            [
                "93.91",
                "91.69",
                "93.89",
                "91.84"
            ],
            [
                "93.93",
                "91.63",
                "94.01",
                "91.98"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "UAS",
            "LAS",
            "UAS",
            "LAS"
        ],
        "target_entity": [
            "mean fix dur",
            "context feats aux"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>dev set || UAS</th>      <th>dev set || LAS</th>      <th>test set || UAS</th>      <th>test set || LAS</th>    </tr>  </thead>  <tbody>    <tr>      <td>baseline || Gaze features || baseline</td>      <td>93.98</td>      <td>91.67</td>      <td>93.86</td>      <td>91.80</td>    </tr>    <tr>      <td>Basic || Gaze features || total fix dur</td>      <td>93.94</td>      <td>91.60</td>      <td>93.99</td>      <td>91.92</td>    </tr>    <tr>      <td>Basic || Gaze features || mean fix dur</td>      <td>94.12</td>      <td>91.84</td>      <td>93.95</td>      <td>91.82</td>    </tr>    <tr>      <td>Basic || Gaze features || n fix</td>      <td>93.97</td>      <td>91.70</td>      <td>93.91</td>      <td>91.87</td>    </tr>    <tr>      <td>Basic || Gaze features || fix prob</td>      <td>93.98</td>      <td>91.71</td>      <td>93.99</td>      <td>91.93</td>    </tr>    <tr>      <td>Basic || Gaze features || basic feats aux</td>      <td>94.00</td>      <td>91.69</td>      <td>93.84</td>      <td>91.81</td>    </tr>    <tr>      <td>Early || Gaze features || first fix dur</td>      <td>94.07</td>      <td>91.81</td>      <td>93.87</td>      <td>91.80</td>    </tr>    <tr>      <td>Early || Gaze features || first pass dur</td>      <td>93.93</td>      <td>91.58</td>      <td>93.79</td>      <td>91.70</td>    </tr>    <tr>      <td>Early || Gaze features || early feats aux</td>      <td>94.04</td>      <td>91.78</td>      <td>93.96</td>      <td>91.88</td>    </tr>    <tr>      <td>Late || Gaze features || n re-fix</td>      <td>94.01</td>      <td>91.69</td>      <td>93.87</td>      <td>91.79</td>    </tr>    <tr>      <td>Late || Gaze features || reread prob</td>      <td>94.03</td>      <td>91.74</td>      <td>93.98</td>      <td>91.89</td>    </tr>    <tr>      <td>Late || Gaze features || late feats aux</td>      <td>93.98</td>      <td>91.58</td>      <td>93.92</td>      <td>91.90</td>    </tr>    <tr>      <td>Context || Gaze features || w \u2212 1 fix prob</td>      <td>94.02</td>      <td>91.65</td>      <td>93.95</td>      <td>91.93</td>    </tr>    <tr>      <td>Context || Gaze features || w + 1 fix prob</td>      <td>93.88</td>      <td>91.61</td>      <td>93.89</td>      <td>91.82</td>    </tr>    <tr>      <td>Context || Gaze features || w \u2212 1 fix dur</td>      <td>94.06</td>      <td>91.65</td>      <td>93.86</td>      <td>91.83</td>    </tr>    <tr>      <td>Context || Gaze features || w + 1 fix dur</td>      <td>93.91</td>      <td>91.69</td>      <td>93.89</td>      <td>91.84</td>    </tr>    <tr>      <td>Context || Gaze features || context feats aux</td>      <td>93.93</td>      <td>91.63</td>      <td>94.01</td>      <td>91.98</td>    </tr>  </tbody></table>",
        "table_name": "Table 2",
        "table_id": "table_2",
        "paper_id": "D19-1160",
        "page_no": 5,
        "dir": "emnlp2019",
        "valid": 1
    },
    {
        "table_id_paper": "D19-1174table_6",
        "caption": "Performance variation across #labels per post",
        "row_header_level": 2,
        "row_headers": [
            [
                "#Labels per post",
                "1"
            ],
            [
                "#Labels per post",
                "2"
            ],
            [
                "#Labels per post",
                "3"
            ],
            [
                "#Labels per post",
                "4"
            ],
            [
                "#Labels per post",
                "5"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "FI"
            ],
            [
                "Fmacro"
            ],
            [
                "AccI"
            ],
            [
                "Fmicro"
            ]
        ],
        "contents": [
            [
                "0.729",
                "0.527",
                "0.632",
                "0.637"
            ],
            [
                "0.754",
                "0.675",
                "0.631",
                "0.722"
            ],
            [
                "0.781",
                "0.721",
                "0.652",
                "0.764"
            ],
            [
                "0.743",
                "0.722",
                "0.604",
                "0.735"
            ],
            [
                "0.739",
                "0.592",
                "0.592",
                "0.735"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "FI",
            "Fmacro",
            "AccI",
            "Fmicro"
        ],
        "target_entity": [
            "#Labels per post"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>FI</th>      <th>Fmacro</th>      <th>AccI</th>      <th>Fmicro</th>    </tr>  </thead>  <tbody>    <tr>      <td>#Labels per post || 1</td>      <td>0.729</td>      <td>0.527</td>      <td>0.632</td>      <td>0.637</td>    </tr>    <tr>      <td>#Labels per post || 2</td>      <td>0.754</td>      <td>0.675</td>      <td>0.631</td>      <td>0.722</td>    </tr>    <tr>      <td>#Labels per post || 3</td>      <td>0.781</td>      <td>0.721</td>      <td>0.652</td>      <td>0.764</td>    </tr>    <tr>      <td>#Labels per post || 4</td>      <td>0.743</td>      <td>0.722</td>      <td>0.604</td>      <td>0.735</td>    </tr>    <tr>      <td>#Labels per post || 5</td>      <td>0.739</td>      <td>0.592</td>      <td>0.592</td>      <td>0.735</td>    </tr>  </tbody></table>",
        "table_name": "Table 6",
        "table_id": "table_6",
        "paper_id": "D19-1174",
        "page_no": 9,
        "dir": "emnlp2019",
        "valid": 1
    },
    {
        "table_id_paper": "D19-1189table_3",
        "caption": "Automatic and human evaluation of dialog generation. For automatic evaluation, we evaluate the perplexity (PPL) and distinct n-gram (Dist-3 and Dist4 refer to distinct 3-gram and 4-gram respectively) of the generated dialogs. For human evaluation, we ask human annotators to evaluate the consistency (CSTC) of the generated utterances with the dialog history. Our proposed method performs the best in all evaluations compared with the baselines.",
        "row_header_level": 2,
        "row_headers": [
            [
                "Model",
                "REDIAL"
            ],
            [
                "Model",
                "Transformer"
            ],
            [
                "Model",
                "KBRD"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "PPL"
            ],
            [
                "Dist-3"
            ],
            [
                "Dist-4"
            ],
            [
                "CSTC"
            ]
        ],
        "contents": [
            [
                "28.1",
                "0.11",
                "0.13",
                "1.73"
            ],
            [
                "18.0",
                "0.27",
                "0.39",
                "-"
            ],
            [
                "17.9",
                "0.30",
                "0.45",
                "1.99"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "PPL",
            "Dist-3",
            "Dist-4",
            "CSTC"
        ],
        "target_entity": [
            "KBRD"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>PPL</th>      <th>Dist-3</th>      <th>Dist-4</th>      <th>CSTC</th>    </tr>  </thead>  <tbody>    <tr>      <td>Model || REDIAL</td>      <td>28.1</td>      <td>0.11</td>      <td>0.13</td>      <td>1.73</td>    </tr>    <tr>      <td>Model || Transformer</td>      <td>18.0</td>      <td>0.27</td>      <td>0.39</td>      <td>-</td>    </tr>    <tr>      <td>Model || KBRD</td>      <td>17.9</td>      <td>0.30</td>      <td>0.45</td>      <td>1.99</td>    </tr>  </tbody></table>",
        "table_name": "Table 3",
        "table_id": "table_3",
        "paper_id": "D19-1189",
        "page_no": 6,
        "dir": "emnlp2019",
        "valid": 1
    },
    {
        "table_id_paper": "D19-1197table_1",
        "caption": "Automatic evaluation results for the task of question response generation. Numbers in bold mean that the improvement over the best performing baseline is statistically significant (t-test with p-value< 0.01).",
        "row_header_level": 1,
        "row_headers": [
            [
                "Seq2Seq"
            ],
            [
                "CVAE"
            ],
            [
                "HTD"
            ],
            [
                "S2S-Temp-MLE"
            ],
            [
                "S2S-Temp-None"
            ],
            [
                "S2S-Temp-50%"
            ],
            [
                "S2S-Temp"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "BLEU-1"
            ],
            [
                "ROUGE-L"
            ],
            [
                "AVERAGE"
            ],
            [
                "EXTREME"
            ],
            [
                "GREEDY"
            ]
        ],
        "contents": [
            [
                "0.037",
                "0.111",
                "0.656",
                "0.438",
                "0.456"
            ],
            [
                "0.094",
                "0.088",
                "0.685",
                "0.414",
                "0.422"
            ],
            [
                "0.073",
                "0.103",
                "0.647",
                "0.425",
                "0.439"
            ],
            [
                "0.097",
                "0.119",
                "0.699",
                "0.438",
                "0.457"
            ],
            [
                "0.069",
                "0.092",
                "0.677",
                "0.429",
                "0.416"
            ],
            [
                "0.091",
                "0.113",
                "0.702",
                "0.442",
                "0.461"
            ],
            [
                "0.102",
                "0.128",
                "0.710",
                "0.451",
                "0.469"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "BLEU-1",
            "ROUGE-L",
            "AVERAGE",
            "EXTREME",
            "GREEDY"
        ],
        "target_entity": [
            "S2S-Temp"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>BLEU-1</th>      <th>ROUGE-L</th>      <th>AVERAGE</th>      <th>EXTREME</th>      <th>GREEDY</th>    </tr>  </thead>  <tbody>    <tr>      <td>Seq2Seq</td>      <td>0.037</td>      <td>0.111</td>      <td>0.656</td>      <td>0.438</td>      <td>0.456</td>    </tr>    <tr>      <td>CVAE</td>      <td>0.094</td>      <td>0.088</td>      <td>0.685</td>      <td>0.414</td>      <td>0.422</td>    </tr>    <tr>      <td>HTD</td>      <td>0.073</td>      <td>0.103</td>      <td>0.647</td>      <td>0.425</td>      <td>0.439</td>    </tr>    <tr>      <td>S2S-Temp-MLE</td>      <td>0.097</td>      <td>0.119</td>      <td>0.699</td>      <td>0.438</td>      <td>0.457</td>    </tr>    <tr>      <td>S2S-Temp-None</td>      <td>0.069</td>      <td>0.092</td>      <td>0.677</td>      <td>0.429</td>      <td>0.416</td>    </tr>    <tr>      <td>S2S-Temp-50%</td>      <td>0.091</td>      <td>0.113</td>      <td>0.702</td>      <td>0.442</td>      <td>0.461</td>    </tr>    <tr>      <td>S2S-Temp</td>      <td>0.102</td>      <td>0.128</td>      <td>0.710</td>      <td>0.451</td>      <td>0.469</td>    </tr>  </tbody></table>",
        "table_name": "Table 1",
        "table_id": "table_1",
        "paper_id": "D19-1197",
        "page_no": 7,
        "dir": "emnlp2019",
        "valid": 1
    },
    {
        "table_id_paper": "D19-1203table_2",
        "caption": "Evaluation on supervised models. We incrementally add di\ufb00erent aspects of modules: Generate, predict, and Decide for supervised multi-aspect learning and Plan for bot-play fine-tuning.",
        "row_header_level": 2,
        "row_headers": [
            [
                "Baseline",
                "TFIDF-RANKER"
            ],
            [
                "Baseline",
                "BERT-RANKER"
            ],
            [
                "Baseline",
                "RANDOM RECC."
            ],
            [
                "Baseline",
                "BERT RECC."
            ],
            [
                "Ours",
                "GENERATE"
            ],
            [
                "Ours",
                "+PREDICT"
            ],
            [
                "Ours",
                "+DECIDE"
            ],
            [
                "Ours",
                "+PLAN"
            ]
        ],
        "column_header_level": 2,
        "column_headers": [
            [
                "Generation",
                "F1"
            ],
            [
                "Generation",
                "BLEU"
            ],
            [
                "Recommendation",
                "Turn@1"
            ],
            [
                "Recommendation",
                "Turn@3"
            ],
            [
                "Recommendation",
                "Chat@1"
            ],
            [
                "Recommendation",
                "Chat@3"
            ],
            [
                "Decision",
                "ACC"
            ]
        ],
        "contents": [
            [
                "32.5",
                "27.8",
                "-",
                "-",
                "-",
                "-",
                "-"
            ],
            [
                "38.3",
                "23.9",
                "-",
                "-",
                "-",
                "-"
            ],
            [
                "3.6",
                "0.1",
                "21.3",
                "59.2",
                "23.1",
                "62.2",
                "-"
            ],
            [
                "16.5",
                "0.2",
                "25.5",
                "66.3",
                "26.4",
                "68.3",
                "-"
            ],
            [
                "39.5",
                "26.0",
                "-",
                "-",
                "-",
                "-",
                "-"
            ],
            [
                "40.2",
                "26.4",
                "76.4",
                "96.9",
                "75.7",
                "97.0",
                "-"
            ],
            [
                "41.0",
                "27.4",
                "77.8",
                "97.1",
                "78.2",
                "97.7",
                "67.6"
            ],
            [
                "40.9",
                "26.8",
                "76.3",
                "95.7",
                "77.5",
                "97.6",
                "53.6"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "F1",
            "BLEU",
            "Turn@1",
            "Turn@3",
            "Chat@1",
            "Chat@3",
            "ACC"
        ],
        "target_entity": [
            "Ours"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Generation || F1</th>      <th>Generation || BLEU</th>      <th>Recommendation || Turn@1</th>      <th>Recommendation || Turn@3</th>      <th>Recommendation || Chat@1</th>      <th>Recommendation || Chat@3</th>      <th>Decision || ACC</th>    </tr>  </thead>  <tbody>    <tr>      <td>Baseline || TFIDF-RANKER</td>      <td>32.5</td>      <td>27.8</td>      <td>-</td>      <td>-</td>      <td>-</td>      <td>-</td>      <td>-</td>    </tr>    <tr>      <td>Baseline || BERT-RANKER</td>      <td>38.3</td>      <td>23.9</td>      <td>-</td>      <td>-</td>      <td>-</td>      <td>-</td>      <td>None</td>    </tr>    <tr>      <td>Baseline || RANDOM RECC.</td>      <td>3.6</td>      <td>0.1</td>      <td>21.3</td>      <td>59.2</td>      <td>23.1</td>      <td>62.2</td>      <td>-</td>    </tr>    <tr>      <td>Baseline || BERT RECC.</td>      <td>16.5</td>      <td>0.2</td>      <td>25.5</td>      <td>66.3</td>      <td>26.4</td>      <td>68.3</td>      <td>-</td>    </tr>    <tr>      <td>Ours || GENERATE</td>      <td>39.5</td>      <td>26.0</td>      <td>-</td>      <td>-</td>      <td>-</td>      <td>-</td>      <td>-</td>    </tr>    <tr>      <td>Ours || +PREDICT</td>      <td>40.2</td>      <td>26.4</td>      <td>76.4</td>      <td>96.9</td>      <td>75.7</td>      <td>97.0</td>      <td>-</td>    </tr>    <tr>      <td>Ours || +DECIDE</td>      <td>41.0</td>      <td>27.4</td>      <td>77.8</td>      <td>97.1</td>      <td>78.2</td>      <td>97.7</td>      <td>67.6</td>    </tr>    <tr>      <td>Ours || +PLAN</td>      <td>40.9</td>      <td>26.8</td>      <td>76.3</td>      <td>95.7</td>      <td>77.5</td>      <td>97.6</td>      <td>53.6</td>    </tr>  </tbody></table>",
        "table_name": "Table 2",
        "table_id": "table_2",
        "paper_id": "D19-1203",
        "page_no": 7,
        "dir": "emnlp2019",
        "valid": 1
    },
    {
        "table_id_paper": "D19-1210table_3",
        "caption": "Performance on the organically-multimodal data; values within 1% of best-in-column are bolded.",
        "row_header_level": 1,
        "row_headers": [
            [
                "Random"
            ],
            [
                "Obj Detect"
            ],
            [
                "NoStruct"
            ],
            [
                "DC"
            ],
            [
                "TK"
            ],
            [
                "TK+1/2k"
            ],
            [
                "AP"
            ],
            [
                "AP+1/2k"
            ]
        ],
        "column_header_level": 2,
        "column_headers": [
            [
                "RQA",
                "AUC"
            ],
            [
                "RQA",
                "p@1"
            ],
            [
                "RQA",
                "p@5"
            ],
            [
                "DIY",
                "AUC"
            ],
            [
                "DIY",
                "p@1"
            ],
            [
                "DIY",
                "p@5"
            ]
        ],
        "contents": [
            [
                "49.4",
                "17.8",
                "16.7",
                "49.8",
                "6.3",
                "6.8"
            ],
            [
                "58.7",
                "25.1",
                "21.5",
                "53.4",
                "17.9",
                "11.8"
            ],
            [
                "60.5",
                "33.8",
                "27",
                "57",
                "13.3",
                "11.8"
            ],
            [
                "63.5",
                "38.3",
                "30.6",
                "59.3",
                "20.8",
                "16.1"
            ],
            [
                "67.9",
                "44",
                "35.8",
                "60.5",
                "21.2",
                "16"
            ],
            [
                "68.1",
                "44.5",
                "35.4",
                "56",
                "14.1",
                "12.5"
            ],
            [
                "69.3",
                "47.3",
                "37.3",
                "61.8",
                "22.5",
                "17.2"
            ],
            [
                "68.7",
                "47.2",
                "36.2",
                "59.4",
                "21.6",
                "15.3"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "AUC",
            "p@1",
            "p@5",
            "AUC",
            "p@1",
            "p@5"
        ],
        "target_entity": [
            "AP"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>RQA || AUC</th>      <th>RQA || p@1</th>      <th>RQA || p@5</th>      <th>DIY || AUC</th>      <th>DIY || p@1</th>      <th>DIY || p@5</th>    </tr>  </thead>  <tbody>    <tr>      <td>Random</td>      <td>49.4</td>      <td>17.8</td>      <td>16.7</td>      <td>49.8</td>      <td>6.3</td>      <td>6.8</td>    </tr>    <tr>      <td>Obj Detect</td>      <td>58.7</td>      <td>25.1</td>      <td>21.5</td>      <td>53.4</td>      <td>17.9</td>      <td>11.8</td>    </tr>    <tr>      <td>NoStruct</td>      <td>60.5</td>      <td>33.8</td>      <td>27</td>      <td>57</td>      <td>13.3</td>      <td>11.8</td>    </tr>    <tr>      <td>DC</td>      <td>63.5</td>      <td>38.3</td>      <td>30.6</td>      <td>59.3</td>      <td>20.8</td>      <td>16.1</td>    </tr>    <tr>      <td>TK</td>      <td>67.9</td>      <td>44</td>      <td>35.8</td>      <td>60.5</td>      <td>21.2</td>      <td>16</td>    </tr>    <tr>      <td>TK+1/2k</td>      <td>68.1</td>      <td>44.5</td>      <td>35.4</td>      <td>56</td>      <td>14.1</td>      <td>12.5</td>    </tr>    <tr>      <td>AP</td>      <td>69.3</td>      <td>47.3</td>      <td>37.3</td>      <td>61.8</td>      <td>22.5</td>      <td>17.2</td>    </tr>    <tr>      <td>AP+1/2k</td>      <td>68.7</td>      <td>47.2</td>      <td>36.2</td>      <td>59.4</td>      <td>21.6</td>      <td>15.3</td>    </tr>  </tbody></table>",
        "table_name": "Table 3",
        "table_id": "table_3",
        "paper_id": "D19-1210",
        "page_no": 7,
        "dir": "emnlp2019",
        "valid": 1
    },
    {
        "table_id_paper": "D19-1230table_8",
        "caption": "Performance comparison for different features with the BiLSTM-CRF model.",
        "row_header_level": 2,
        "row_headers": [
            [
                "Embeddings",
                "word"
            ],
            [
                "Embeddings",
                "word+chunking label"
            ],
            [
                "Embeddings",
                "word+dependency label"
            ],
            [
                "Embeddings",
                "word+PoS tag"
            ],
            [
                "Embeddings",
                "word+semantic role"
            ],
            [
                "Embeddings",
                "all features"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "Acc"
            ]
        ],
        "contents": [
            [
                "67.28"
            ],
            [
                "67.84"
            ],
            [
                "68.12"
            ],
            [
                "68.26"
            ],
            [
                "68.82"
            ],
            [
                "68.54"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "Acc"
        ],
        "target_entity": [
            "word+semantic role"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Acc</th>    </tr>  </thead>  <tbody>    <tr>      <td>Embeddings || word</td>      <td>67.28</td>    </tr>    <tr>      <td>Embeddings || word+chunking label</td>      <td>67.84</td>    </tr>    <tr>      <td>Embeddings || word+dependency label</td>      <td>68.12</td>    </tr>    <tr>      <td>Embeddings || word+PoS tag</td>      <td>68.26</td>    </tr>    <tr>      <td>Embeddings || word+semantic role</td>      <td>68.82</td>    </tr>    <tr>      <td>Embeddings || all features</td>      <td>68.54</td>    </tr>  </tbody></table>",
        "table_name": "Table 8",
        "table_id": "table_8",
        "paper_id": "D19-1230",
        "page_no": 8,
        "dir": "emnlp2019",
        "valid": 1
    },
    {
        "table_id_paper": "D19-1271table_4",
        "caption": "Comparison with previous models on the MultiNLI dataset.",
        "row_header_level": 3,
        "row_headers": [
            [
                "Model",
                "Single Models",
                "ESIM (Chen et al., 2016)"
            ],
            [
                "Model",
                "Single Models",
                "DIIN (Gong et al., 2017)"
            ],
            [
                "Model",
                "Single Models",
                "AF-DMN (Duan et al., 2018)"
            ],
            [
                "Model",
                "Single Models",
                "CAFE (Tay et al., 2018)"
            ],
            [
                "Model",
                "Single Models",
                "MwAN (Tan et al., 2018)"
            ],
            [
                "Model",
                "Single Models",
                "ADIN (ours)"
            ],
            [
                "Model",
                "Ensemble Models",
                "DIIN (Gong et al., 2017)"
            ],
            [
                "Model",
                "Ensemble Models",
                "CAFE (Tay et al., 2018)"
            ],
            [
                "Model",
                "Ensemble Models",
                "MwAN (Tan et al., 2018)"
            ],
            [
                "Model",
                "Ensemble Models",
                "ADIN (ours)"
            ]
        ],
        "column_header_level": 2,
        "column_headers": [
            [
                "Test Accuracy",
                "Matched"
            ],
            [
                "Test Accuracy",
                "Mismatched"
            ]
        ],
        "contents": [
            [
                "72.3",
                "72.1"
            ],
            [
                "78.8",
                "77.8"
            ],
            [
                "76.9",
                "76.3"
            ],
            [
                "78.7",
                "77.9"
            ],
            [
                "78.5",
                "77.7"
            ],
            [
                "78.8",
                "77.9"
            ],
            [
                "80",
                "78.7"
            ],
            [
                "80.2",
                "79"
            ],
            [
                "79.8",
                "79.4"
            ],
            [
                "80.3",
                "79.6"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "Test Accuracy",
            "Test Accuracy"
        ],
        "target_entity": [
            "ADIN (ours)"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Test Accuracy || Matched</th>      <th>Test Accuracy || Mismatched</th>    </tr>  </thead>  <tbody>    <tr>      <td>Model || Single Models || ESIM (Chen et al., 2016)</td>      <td>72.3</td>      <td>72.1</td>    </tr>    <tr>      <td>Model || Single Models || DIIN (Gong et al., 2017)</td>      <td>78.8</td>      <td>77.8</td>    </tr>    <tr>      <td>Model || Single Models || AF-DMN (Duan et al., 2018)</td>      <td>76.9</td>      <td>76.3</td>    </tr>    <tr>      <td>Model || Single Models || CAFE (Tay et al., 2018)</td>      <td>78.7</td>      <td>77.9</td>    </tr>    <tr>      <td>Model || Single Models || MwAN (Tan et al., 2018)</td>      <td>78.5</td>      <td>77.7</td>    </tr>    <tr>      <td>Model || Single Models || ADIN (ours)</td>      <td>78.8</td>      <td>77.9</td>    </tr>    <tr>      <td>Model || Ensemble Models || DIIN (Gong et al., 2017)</td>      <td>80</td>      <td>78.7</td>    </tr>    <tr>      <td>Model || Ensemble Models || CAFE (Tay et al., 2018)</td>      <td>80.2</td>      <td>79</td>    </tr>    <tr>      <td>Model || Ensemble Models || MwAN (Tan et al., 2018)</td>      <td>79.8</td>      <td>79.4</td>    </tr>    <tr>      <td>Model || Ensemble Models || ADIN (ours)</td>      <td>80.3</td>      <td>79.6</td>    </tr>  </tbody></table>",
        "table_name": "Table 4",
        "table_id": "table_4",
        "paper_id": "D19-1271",
        "page_no": 6,
        "dir": "emnlp2019",
        "valid": 1
    },
    {
        "table_id_paper": "D19-1345table_3",
        "caption": "Comparison of memory consuming. The number of edges in the whole model is in parentheses.",
        "row_header_level": 2,
        "row_headers": [
            [
                "Datasets",
                "R8"
            ],
            [
                "Datasets",
                "R52"
            ],
            [
                "Datasets",
                "Ohsumed"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                " Text-GCN"
            ],
            [
                "Our Model"
            ]
        ],
        "contents": [
            [
                " 9979M (2841760)",
                "954M(250623)"
            ],
            [
                " 8699M (3574162)",
                "951M(316669)"
            ],
            [
                "13510M (6867490)",
                "1167M (419583)"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "memory",
            "memory"
        ],
        "target_entity": [
            "Our Model"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Text-GCN</th>      <th>Our Model</th>    </tr>  </thead>  <tbody>    <tr>      <td>Datasets || R8</td>      <td>9979M (2841760)</td>      <td>954M(250623)</td>    </tr>    <tr>      <td>Datasets || R52</td>      <td>8699M (3574162)</td>      <td>951M(316669)</td>    </tr>    <tr>      <td>Datasets || Ohsumed</td>      <td>13510M (6867490)</td>      <td>1167M (419583)</td>    </tr>  </tbody></table>",
        "table_name": "Table 3",
        "table_id": "table_3",
        "paper_id": "D19-1345",
        "page_no": 4,
        "dir": "emnlp2019",
        "valid": 1
    },
    {
        "table_id_paper": "D19-1386table_5",
        "caption": "An evaluation using the recall variant of ROUGE of the different extractive preprocessing steps.",
        "row_header_level": 2,
        "row_headers": [
            [
                "Model",
                "HEURISTIC LABELS"
            ],
            [
                "Model",
                "LEAD-200"
            ],
            [
                "Model",
                "BM25"
            ],
            [
                "Model",
                "SUMFOCUS"
            ],
            [
                "Model",
                "SUMFOCUS -TOPIC"
            ],
            [
                "Model",
                "SUMFOCUS -CONTEXT"
            ],
            [
                "Model",
                "SUMFOCUS -TOPIC,-CONTEXT"
            ],
            [
                "Model",
                "CONTENTSELECTOR"
            ],
            [
                "Model",
                "CONTENTSELECTOR -TOPIC"
            ],
            [
                "Model",
                "CONTENTSELECTOR -CONTEXT"
            ],
            [
                "Model",
                "CONTENTSELECTOR -TOPIC,-CONTEXT"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "R1-R"
            ],
            [
                "R2-R"
            ],
            [
                "RL-R"
            ]
        ],
        "contents": [
            [
                "80.25",
                "35.75",
                "55.11"
            ],
            [
                "60.89",
                "22.31",
                "44.97"
            ],
            [
                "64.19",
                "25.04",
                "56.24"
            ],
            [
                "61.79",
                "22.77",
                "54.15"
            ],
            [
                "60.95",
                "22.38",
                "53.61"
            ],
            [
                "61.03",
                "22.08",
                "53.32"
            ],
            [
                "59.11",
                "20.62",
                "51.93"
            ],
            [
                "66.27",
                "27.59",
                "58.25"
            ],
            [
                "66.32",
                "27.63",
                "58.32"
            ],
            [
                "63.86",
                "24.48",
                "55.8"
            ],
            [
                "63.11",
                "23.76",
                "55.09"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "R1-R",
            "R2-R",
            "RL-R"
        ],
        "target_entity": [
            "SUMFOCUS -TOPIC"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>R1-R</th>      <th>R2-R</th>      <th>RL-R</th>    </tr>  </thead>  <tbody>    <tr>      <td>Model || HEURISTIC LABELS</td>      <td>80.25</td>      <td>35.75</td>      <td>55.11</td>    </tr>    <tr>      <td>Model || LEAD-200</td>      <td>60.89</td>      <td>22.31</td>      <td>44.97</td>    </tr>    <tr>      <td>Model || BM25</td>      <td>64.19</td>      <td>25.04</td>      <td>56.24</td>    </tr>    <tr>      <td>Model || SUMFOCUS</td>      <td>61.79</td>      <td>22.77</td>      <td>54.15</td>    </tr>    <tr>      <td>Model || SUMFOCUS -TOPIC</td>      <td>60.95</td>      <td>22.38</td>      <td>53.61</td>    </tr>    <tr>      <td>Model || SUMFOCUS -CONTEXT</td>      <td>61.03</td>      <td>22.08</td>      <td>53.32</td>    </tr>    <tr>      <td>Model || SUMFOCUS -TOPIC,-CONTEXT</td>      <td>59.11</td>      <td>20.62</td>      <td>51.93</td>    </tr>    <tr>      <td>Model || CONTENTSELECTOR</td>      <td>66.27</td>      <td>27.59</td>      <td>58.25</td>    </tr>    <tr>      <td>Model || CONTENTSELECTOR -TOPIC</td>      <td>66.32</td>      <td>27.63</td>      <td>58.32</td>    </tr>    <tr>      <td>Model || CONTENTSELECTOR -CONTEXT</td>      <td>63.86</td>      <td>24.48</td>      <td>55.8</td>    </tr>    <tr>      <td>Model || CONTENTSELECTOR -TOPIC,-CONTEXT</td>      <td>63.11</td>      <td>23.76</td>      <td>55.09</td>    </tr>  </tbody></table>",
        "table_name": "Table 5",
        "table_id": "table_5",
        "paper_id": "D19-1386",
        "page_no": 8,
        "dir": "emnlp2019",
        "valid": 1
    },
    {
        "table_id_paper": "D19-1387table_4",
        "caption": "ROUGE F1 results on the XSum test set. Results for comparison systems are taken from the authors\u2019 respective papers or obtained on our data by running publicly released software.",
        "row_header_level": 3,
        "row_headers": [
            [
                "Model",
                " -",
                "ORACLE.1"
            ],
            [
                "Model",
                " -",
                "LEAD"
            ],
            [
                "Model",
                "Abstractive",
                "PTGEN (See et al., 2017)"
            ],
            [
                "Model",
                "Abstractive",
                "PTGEN+COV (See et al., 2017)"
            ],
            [
                "Model",
                "Abstractive",
                "TCONVS2S (Narayan et al., 2018a)"
            ],
            [
                "Model",
                "Abstractive",
                "TransformerABS"
            ],
            [
                "Model",
                "BERT-based",
                "BERTSUMABS"
            ],
            [
                "Model",
                "BERT-based",
                "BERTSUMEXTABS"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "R1"
            ],
            [
                "R2"
            ],
            [
                "RL"
            ]
        ],
        "contents": [
            [
                "29.79",
                "8.81",
                "22.66"
            ],
            [
                "16.30",
                " 1.60",
                "11.95"
            ],
            [
                "29.70",
                " 9.21",
                "23.24"
            ],
            [
                "28.10",
                " 8.02",
                "21.72"
            ],
            [
                "31.89",
                " 11.54",
                "25.75"
            ],
            [
                "29.41",
                " 9.77",
                "23.01"
            ],
            [
                "38.76",
                " 16.33",
                "31.15"
            ],
            [
                "38.81",
                " 16.50",
                "31.27"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "R1",
            "R2",
            "RL"
        ],
        "target_entity": [
            "BERT-based"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>R1</th>      <th>R2</th>      <th>RL</th>    </tr>  </thead>  <tbody>    <tr>      <td>Model ||  - || ORACLE.1</td>      <td>29.79</td>      <td>8.81</td>      <td>22.66</td>    </tr>    <tr>      <td>Model ||  - || LEAD</td>      <td>16.30</td>      <td>1.60</td>      <td>11.95</td>    </tr>    <tr>      <td>Model || Abstractive || PTGEN (See et al., 2017)</td>      <td>29.70</td>      <td>9.21</td>      <td>23.24</td>    </tr>    <tr>      <td>Model || Abstractive || PTGEN+COV (See et al., 2017)</td>      <td>28.10</td>      <td>8.02</td>      <td>21.72</td>    </tr>    <tr>      <td>Model || Abstractive || TCONVS2S (Narayan et al., 2018a)</td>      <td>31.89</td>      <td>11.54</td>      <td>25.75</td>    </tr>    <tr>      <td>Model || Abstractive || TransformerABS</td>      <td>29.41</td>      <td>9.77</td>      <td>23.01</td>    </tr>    <tr>      <td>Model || BERT-based || BERTSUMABS</td>      <td>38.76</td>      <td>16.33</td>      <td>31.15</td>    </tr>    <tr>      <td>Model || BERT-based || BERTSUMEXTABS</td>      <td>38.81</td>      <td>16.50</td>      <td>31.27</td>    </tr>  </tbody></table>",
        "table_name": "Table 4",
        "table_id": "table_4",
        "paper_id": "D19-1387",
        "page_no": 7,
        "dir": "emnlp2019",
        "valid": 1
    },
    {
        "table_id_paper": "D19-1399table_3",
        "caption": "Performance comparison on the OntoNotes 5.0 English dataset.",
        "row_header_level": 2,
        "row_headers": [
            [
                "Model",
                "Chiu and Nichols (2016)"
            ],
            [
                "Model",
                "Li et al. (2017)"
            ],
            [
                "Model",
                "Ghaddar and Langlais (2018)"
            ],
            [
                "Model",
                "Strubell et al. (2017)"
            ],
            [
                "Model",
                "BiLSTM-CRF (L = 0)"
            ],
            [
                "Model",
                "BiLSTM-CRF (L = 1)"
            ],
            [
                "Model",
                "BiLSTM-CRF (L = 2)"
            ],
            [
                "Model",
                "BiLSTM-CRF (L = 3)"
            ],
            [
                "Model",
                "BiLSTM-GCN-CRF"
            ],
            [
                "Model",
                "DGLSTM-CRF (L = 0)"
            ],
            [
                "Model",
                "DGLSTM-CRF (L = 1)"
            ],
            [
                "Model",
                "DGLSTM-CRF (L = 2)"
            ],
            [
                "Model",
                "DGLSTM-CRF (L = 3)"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "Prec."
            ],
            [
                "Rec."
            ],
            [
                "F1"
            ]
        ],
        "contents": [
            [
                "86.04",
                "86.53",
                "86.28"
            ],
            [
                "88",
                "86.5",
                "87.21"
            ],
            [
                "-",
                "-",
                "87.95"
            ],
            [
                "-",
                "-",
                "86.84"
            ],
            [
                "82.03",
                "80.78",
                "81.4"
            ],
            [
                "87.21",
                "86.93",
                "87.07"
            ],
            [
                "87.89",
                "87.68",
                "87.78"
            ],
            [
                "87.81",
                "87.5",
                "87.65"
            ],
            [
                "88.3",
                "88.06",
                "88.18"
            ],
            [
                "85.31",
                "82.19",
                "84.09"
            ],
            [
                "88.78",
                "87.29",
                "88.03"
            ],
            [
                "88.53",
                "88.5",
                "88.52"
            ],
            [
                "87.59",
                "88.93",
                "88.25"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "Prec.",
            "Rec.",
            "F1"
        ],
        "target_entity": [
            "DGLSTM-CRF (L = 0)",
            "DGLSTM-CRF (L = 1)",
            "DGLSTM-CRF (L = 2)",
            "DGLSTM-CRF (L = 3)"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Prec.</th>      <th>Rec.</th>      <th>F1</th>    </tr>  </thead>  <tbody>    <tr>      <td>Model || Chiu and Nichols (2016)</td>      <td>86.04</td>      <td>86.53</td>      <td>86.28</td>    </tr>    <tr>      <td>Model || Li et al. (2017)</td>      <td>88</td>      <td>86.5</td>      <td>87.21</td>    </tr>    <tr>      <td>Model || Ghaddar and Langlais (2018)</td>      <td>-</td>      <td>-</td>      <td>87.95</td>    </tr>    <tr>      <td>Model || Strubell et al. (2017)</td>      <td>-</td>      <td>-</td>      <td>86.84</td>    </tr>    <tr>      <td>Model || BiLSTM-CRF (L = 0)</td>      <td>82.03</td>      <td>80.78</td>      <td>81.4</td>    </tr>    <tr>      <td>Model || BiLSTM-CRF (L = 1)</td>      <td>87.21</td>      <td>86.93</td>      <td>87.07</td>    </tr>    <tr>      <td>Model || BiLSTM-CRF (L = 2)</td>      <td>87.89</td>      <td>87.68</td>      <td>87.78</td>    </tr>    <tr>      <td>Model || BiLSTM-CRF (L = 3)</td>      <td>87.81</td>      <td>87.5</td>      <td>87.65</td>    </tr>    <tr>      <td>Model || BiLSTM-GCN-CRF</td>      <td>88.3</td>      <td>88.06</td>      <td>88.18</td>    </tr>    <tr>      <td>Model || DGLSTM-CRF (L = 0)</td>      <td>85.31</td>      <td>82.19</td>      <td>84.09</td>    </tr>    <tr>      <td>Model || DGLSTM-CRF (L = 1)</td>      <td>88.78</td>      <td>87.29</td>      <td>88.03</td>    </tr>    <tr>      <td>Model || DGLSTM-CRF (L = 2)</td>      <td>88.53</td>      <td>88.5</td>      <td>88.52</td>    </tr>    <tr>      <td>Model || DGLSTM-CRF (L = 3)</td>      <td>87.59</td>      <td>88.93</td>      <td>88.25</td>    </tr>  </tbody></table>",
        "table_name": "Table 3",
        "table_id": "table_3",
        "paper_id": "D19-1399",
        "page_no": 6,
        "dir": "emnlp2019",
        "valid": 1
    },
    {
        "table_id_paper": "D19-1399table_8",
        "caption": "F1 performance of DGLSTM-CRF with predicted dependencies against the best performing BiLSTM-CRF. \u2020: LAS is label attachment score which is the metric for dependency evaluation.",
        "row_header_level": 1,
        "row_headers": [
            [
                "BiLSTM-CRF"
            ],
            [
                "DGLSTM-CRF (Predicted)"
            ],
            [
                "DGLSTM-CRF (Gold)"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "English"
            ],
            [
                "Chinese"
            ],
            [
                "Catalan"
            ],
            [
                "Spanish"
            ]
        ],
        "contents": [
            [
                "88.98",
                "79.2",
                "78.46",
                "80.59"
            ],
            [
                "89.64",
                "79.59",
                "82.37",
                "83.92"
            ],
            [
                "89.88",
                "79.92",
                "84.22",
                "87.56"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "F1",
            "F1",
            "F1",
            "F1"
        ],
        "target_entity": [
            "DGLSTM-CRF (Predicted)",
            "DGLSTM-CRF (Gold)"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>English</th>      <th>Chinese</th>      <th>Catalan</th>      <th>Spanish</th>    </tr>  </thead>  <tbody>    <tr>      <td>BiLSTM-CRF</td>      <td>88.98</td>      <td>79.2</td>      <td>78.46</td>      <td>80.59</td>    </tr>    <tr>      <td>DGLSTM-CRF (Predicted)</td>      <td>89.64</td>      <td>79.59</td>      <td>82.37</td>      <td>83.92</td>    </tr>    <tr>      <td>DGLSTM-CRF (Gold)</td>      <td>89.88</td>      <td>79.92</td>      <td>84.22</td>      <td>87.56</td>    </tr>  </tbody></table>",
        "table_name": "Table 8",
        "table_id": "table_8",
        "paper_id": "D19-1399",
        "page_no": 8,
        "dir": "emnlp2019",
        "valid": 1
    },
    {
        "table_id_paper": "D19-1401table_2",
        "caption": "IMDB test set results.",
        "row_header_level": 1,
        "row_headers": [
            [
                "RB-BOW-PROTO"
            ],
            [
                "RB-BOW-SVM"
            ],
            [
                "BOW-PROTO"
            ],
            [
                "RB-WAVG-BERT"
            ],
            [
                "AVG-BERT"
            ],
            [
                "RA-SVM"
            ],
            [
                "SVM"
            ],
            [
                "RA-CNN"
            ],
            [
                "CNN"
            ],
            [
                "ULMFiT"
            ]
        ],
        "column_header_level": 2,
        "column_headers": [
            [
                "Number of Training Instances",
                "2"
            ],
            [
                "Number of Training Instances",
                "6"
            ],
            [
                "Number of Training Instances",
                "10"
            ],
            [
                "Number of Training Instances",
                "20"
            ],
            [
                "Number of Training Instances",
                "60"
            ],
            [
                "Number of Training Instances",
                "200"
            ],
            [
                "Number of Training Instances",
                "400"
            ]
        ],
        "contents": [
            [
                "53.6",
                "63.6",
                "68.2",
                "75.9",
                "80.9",
                "82.5",
                "82.6"
            ],
            [
                "53.6",
                "63.5",
                "67.0",
                "73.4",
                "80.2",
                "79.7",
                "80.2"
            ],
            [
                "50.8",
                "55.6",
                "58.5",
                "62.5",
                "70.2",
                "71.3",
                "71.8"
            ],
            [
                "51.8",
                "53.2",
                "52.3",
                "58.4",
                "81.6",
                "90.9",
                "92.2"
            ],
            [
                "50.9",
                "53.5",
                "52.9",
                "58.5",
                "70.7",
                "83.8",
                "86.2"
            ],
            [
                "50.6",
                "54",
                "52.7",
                "59.1",
                "70.2",
                "78.3",
                "81.5"
            ],
            [
                "50.7",
                "52.5",
                "52.1",
                "54.9",
                "62.5",
                "71.2",
                "75.8"
            ],
            [
                "*",
                "*",
                "52.6",
                "59.8",
                "79.9",
                "86.2",
                "87.3"
            ],
            [
                "*",
                "*",
                "52.6",
                "54",
                "62",
                "79.1",
                "83.5"
            ],
            [
                "*",
                "*",
                "*",
                "54.7",
                "62",
                "71.3",
                "78.8"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "accuracy",
            "accuracy",
            "accuracy",
            "accuracy",
            "accuracy",
            "accuracy",
            "accuracy"
        ],
        "target_entity": [
            "RB-WAVG-BERT",
            "RB-BOW-PROTO",
            "RB-BOW-SVM"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Number of Training Instances || 2</th>      <th>Number of Training Instances || 6</th>      <th>Number of Training Instances || 10</th>      <th>Number of Training Instances || 20</th>      <th>Number of Training Instances || 60</th>      <th>Number of Training Instances || 200</th>      <th>Number of Training Instances || 400</th>    </tr>  </thead>  <tbody>    <tr>      <td>RB-BOW-PROTO</td>      <td>53.6</td>      <td>63.6</td>      <td>68.2</td>      <td>75.9</td>      <td>80.9</td>      <td>82.5</td>      <td>82.6</td>    </tr>    <tr>      <td>RB-BOW-SVM</td>      <td>53.6</td>      <td>63.5</td>      <td>67.0</td>      <td>73.4</td>      <td>80.2</td>      <td>79.7</td>      <td>80.2</td>    </tr>    <tr>      <td>BOW-PROTO</td>      <td>50.8</td>      <td>55.6</td>      <td>58.5</td>      <td>62.5</td>      <td>70.2</td>      <td>71.3</td>      <td>71.8</td>    </tr>    <tr>      <td>RB-WAVG-BERT</td>      <td>51.8</td>      <td>53.2</td>      <td>52.3</td>      <td>58.4</td>      <td>81.6</td>      <td>90.9</td>      <td>92.2</td>    </tr>    <tr>      <td>AVG-BERT</td>      <td>50.9</td>      <td>53.5</td>      <td>52.9</td>      <td>58.5</td>      <td>70.7</td>      <td>83.8</td>      <td>86.2</td>    </tr>    <tr>      <td>RA-SVM</td>      <td>50.6</td>      <td>54</td>      <td>52.7</td>      <td>59.1</td>      <td>70.2</td>      <td>78.3</td>      <td>81.5</td>    </tr>    <tr>      <td>SVM</td>      <td>50.7</td>      <td>52.5</td>      <td>52.1</td>      <td>54.9</td>      <td>62.5</td>      <td>71.2</td>      <td>75.8</td>    </tr>    <tr>      <td>RA-CNN</td>      <td>*</td>      <td>*</td>      <td>52.6</td>      <td>59.8</td>      <td>79.9</td>      <td>86.2</td>      <td>87.3</td>    </tr>    <tr>      <td>CNN</td>      <td>*</td>      <td>*</td>      <td>52.6</td>      <td>54</td>      <td>62</td>      <td>79.1</td>      <td>83.5</td>    </tr>    <tr>      <td>ULMFiT</td>      <td>*</td>      <td>*</td>      <td>*</td>      <td>54.7</td>      <td>62</td>      <td>71.3</td>      <td>78.8</td>    </tr>  </tbody></table>",
        "table_name": "Table 2",
        "table_id": "table_2",
        "paper_id": "D19-1401",
        "page_no": 9,
        "dir": "emnlp2019",
        "valid": 1
    },
    {
        "table_id_paper": "D19-1403table_3",
        "caption": "Comparison of mean accuracy (%) on ODIC",
        "row_header_level": 2,
        "row_headers": [
            [
                "Model",
                "Matching Networks (Vinyals et al., 2016)"
            ],
            [
                "Model",
                "Prototypical Networks (Snell et al., 2017)"
            ],
            [
                "Model",
                "Graph Network (Garcia and Bruna, 2017)"
            ],
            [
                "Model",
                "Relation Network (Sung et al., 2018)"
            ],
            [
                "Model",
                "SNAIL (Mishra et al., 2018)"
            ],
            [
                "Model",
                "Induction Networks (ours)"
            ]
        ],
        "column_header_level": 2,
        "column_headers": [
            [
                "5-way Acc.",
                "5-shot"
            ],
            [
                "5-way Acc.",
                "10-shot"
            ],
            [
                "10-way Acc.",
                "5-shot"
            ],
            [
                "10-way Acc.",
                "10-shot"
            ]
        ],
        "contents": [
            [
                "82.54\u00b10.12",
                "84.63\u00b10.08",
                "73.64\u00b10.15",
                "76.72\u00b10.07"
            ],
            [
                "81.82\u00b10.08",
                "85.83\u00b10.06",
                "73.31\u00b10.14",
                "75.97\u00b10.11"
            ],
            [
                "84.15\u00b10.16",
                "87.24\u00b10.09",
                "75.58\u00b10.12",
                "78.27\u00b10.10"
            ],
            [
                "84.41\u00b10.14",
                "86.93\u00b10.15",
                "75.28\u00b10.13",
                "78.61\u00b10.06"
            ],
            [
                "84.62\u00b10.16",
                "87.31\u00b10.11",
                "75.74\u00b10.07",
                "79.26\u00b10.09"
            ],
            [
                "87.16\u00b10.09",
                "88.49\u00b10.17",
                "78.27\u00b10.14",
                "81.64\u00b10.08"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "5-way Acc.",
            "5-way Acc.",
            "10-way Acc.",
            "10-way Acc."
        ],
        "target_entity": [
            "Induction Networks (ours)"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>5-way Acc. || 5-shot</th>      <th>5-way Acc. || 10-shot</th>      <th>10-way Acc. || 5-shot</th>      <th>10-way Acc. || 10-shot</th>    </tr>  </thead>  <tbody>    <tr>      <td>Model || Matching Networks (Vinyals et al., 2016)</td>      <td>82.54\u00b10.12</td>      <td>84.63\u00b10.08</td>      <td>73.64\u00b10.15</td>      <td>76.72\u00b10.07</td>    </tr>    <tr>      <td>Model || Prototypical Networks (Snell et al., 2017)</td>      <td>81.82\u00b10.08</td>      <td>85.83\u00b10.06</td>      <td>73.31\u00b10.14</td>      <td>75.97\u00b10.11</td>    </tr>    <tr>      <td>Model || Graph Network (Garcia and Bruna, 2017)</td>      <td>84.15\u00b10.16</td>      <td>87.24\u00b10.09</td>      <td>75.58\u00b10.12</td>      <td>78.27\u00b10.10</td>    </tr>    <tr>      <td>Model || Relation Network (Sung et al., 2018)</td>      <td>84.41\u00b10.14</td>      <td>86.93\u00b10.15</td>      <td>75.28\u00b10.13</td>      <td>78.61\u00b10.06</td>    </tr>    <tr>      <td>Model || SNAIL (Mishra et al., 2018)</td>      <td>84.62\u00b10.16</td>      <td>87.31\u00b10.11</td>      <td>75.74\u00b10.07</td>      <td>79.26\u00b10.09</td>    </tr>    <tr>      <td>Model || Induction Networks (ours)</td>      <td>87.16\u00b10.09</td>      <td>88.49\u00b10.17</td>      <td>78.27\u00b10.14</td>      <td>81.64\u00b10.08</td>    </tr>  </tbody></table>",
        "table_name": "Table 3",
        "table_id": "table_3",
        "paper_id": "D19-1403",
        "page_no": 7,
        "dir": "emnlp2019",
        "valid": 1
    },
    {
        "table_id_paper": "D19-1437table_2",
        "caption": "BLEU scores on two WMT datasets of models using advanced decoding methods. The first block are Transformer-base (Vaswani et al., 2017). The second and the third block are results of models trained w/w.o. knowledge distillation, respectively. n = l \u21e5 r is the total number of candidates for rescoring.",
        "row_header_level": 3,
        "row_headers": [
            [
                "Models",
                "Autoregressive Methods",
                "Transformer-base"
            ],
            [
                "Models",
                "Autoregressive Methods",
                "Our Implementation"
            ],
            [
                "Models",
                "Raw Data",
                "CMLM-base (refinement 4)"
            ],
            [
                "Models",
                "Raw Data",
                "CMLM-base (refinement 10)"
            ],
            [
                "Models",
                "Raw Data",
                "FlowSeq-base (IWD n = 15)"
            ],
            [
                "Models",
                "Raw Data",
                "FlowSeq-base (NPD n = 15)"
            ],
            [
                "Models",
                "Raw Data",
                "FlowSeq-base (NPD n = 30)"
            ],
            [
                "Models",
                "Raw Data",
                "FlowSeq-large (IWD n = 15)"
            ],
            [
                "Models",
                "Raw Data",
                "FlowSeq-large (NPD n = 15)"
            ],
            [
                "Models",
                "Raw Data",
                "FlowSeq-large (NPD n = 30)"
            ],
            [
                "Models",
                "Knowledge Distillation",
                "NAT-IR (refinement 10)"
            ],
            [
                "Models",
                "Knowledge Distillation",
                "NAT w/ FT (NPD n = 10)"
            ],
            [
                "Models",
                "Knowledge Distillation",
                "NAT-REG (NPD n = 9)"
            ],
            [
                "Models",
                "Knowledge Distillation",
                "LV NAR (refinement 4)"
            ],
            [
                "Models",
                "Knowledge Distillation",
                "CMLM-small (refinement 10)"
            ],
            [
                "Models",
                "Knowledge Distillation",
                "CMLM-base (refinement 10)"
            ],
            [
                "Models",
                "Knowledge Distillation",
                "FlowSeq-base (IWD n = 15)"
            ],
            [
                "Models",
                "Knowledge Distillation",
                "FlowSeq-base (NPD n = 15)"
            ],
            [
                "Models",
                "Knowledge Distillation",
                "FlowSeq-base (NPD n = 30)"
            ],
            [
                "Models",
                "Knowledge Distillation",
                "FlowSeq-large (IWD n = 15)"
            ],
            [
                "Models",
                "Knowledge Distillation",
                "FlowSeq-large (NPD n = 15)"
            ],
            [
                "Models",
                "Knowledge Distillation",
                "FlowSeq-large (NPD n = 30)"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "EN-DE"
            ],
            [
                "DE-EN"
            ],
            [
                "EN-RO"
            ],
            [
                "RO-EN"
            ]
        ],
        "contents": [
            [
                "27.3",
                "-",
                "-",
                "-"
            ],
            [
                "27.16",
                "31.44",
                "32.92",
                "33.09"
            ],
            [
                "22.06",
                "-",
                "30.89",
                "-"
            ],
            [
                "24.65",
                "-",
                "32.53",
                "-"
            ],
            [
                "20.2",
                "24.63",
                "30.61",
                "31.5"
            ],
            [
                "20.81",
                "25.76",
                "31.38",
                "32.01"
            ],
            [
                "21.15",
                "26.04",
                "31.74",
                "32.45"
            ],
            [
                "22.94",
                "27.16",
                "31.08",
                "32.03"
            ],
            [
                "23.14",
                "27.71",
                "31.97",
                "32.46"
            ],
            [
                "23.64",
                "28.29",
                "32.35",
                "32.91"
            ],
            [
                "21.61",
                "25.48",
                "29.32",
                "30.19"
            ],
            [
                "18.66",
                "22.42",
                "29.02",
                "31.44"
            ],
            [
                "24.61",
                "28.9",
                "-",
                "-"
            ],
            [
                "24.2",
                "-",
                "-",
                "-"
            ],
            [
                "25.51",
                "29.47",
                "31.65",
                "32.27"
            ],
            [
                "26.92",
                "30.86",
                "32.42",
                "33.06"
            ],
            [
                "22.49",
                "27.4",
                "30.59",
                "31.58"
            ],
            [
                "23.08",
                "28.07",
                "31.35",
                "32.11"
            ],
            [
                "23.48",
                "28.4",
                "31.75",
                "32.49"
            ],
            [
                "24.7",
                "29.44",
                "31.02",
                "31.97"
            ],
            [
                "25.03",
                "30.48",
                "31.89",
                "32.43"
            ],
            [
                "25.31",
                "30.68",
                "32.2",
                "32.84"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "BLEU",
            "BLEU",
            "BLEU",
            "BLEU"
        ],
        "target_entity": [
            "FlowSeq-base (IWD n = 15)",
            "FlowSeq-base (NPD n = 15)",
            "FlowSeq-base (NPD n = 30)"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>EN-DE</th>      <th>DE-EN</th>      <th>EN-RO</th>      <th>RO-EN</th>    </tr>  </thead>  <tbody>    <tr>      <td>Models || Autoregressive Methods || Transformer-base</td>      <td>27.3</td>      <td>-</td>      <td>-</td>      <td>-</td>    </tr>    <tr>      <td>Models || Autoregressive Methods || Our Implementation</td>      <td>27.16</td>      <td>31.44</td>      <td>32.92</td>      <td>33.09</td>    </tr>    <tr>      <td>Models || Raw Data || CMLM-base (refinement 4)</td>      <td>22.06</td>      <td>-</td>      <td>30.89</td>      <td>-</td>    </tr>    <tr>      <td>Models || Raw Data || CMLM-base (refinement 10)</td>      <td>24.65</td>      <td>-</td>      <td>32.53</td>      <td>-</td>    </tr>    <tr>      <td>Models || Raw Data || FlowSeq-base (IWD n = 15)</td>      <td>20.2</td>      <td>24.63</td>      <td>30.61</td>      <td>31.5</td>    </tr>    <tr>      <td>Models || Raw Data || FlowSeq-base (NPD n = 15)</td>      <td>20.81</td>      <td>25.76</td>      <td>31.38</td>      <td>32.01</td>    </tr>    <tr>      <td>Models || Raw Data || FlowSeq-base (NPD n = 30)</td>      <td>21.15</td>      <td>26.04</td>      <td>31.74</td>      <td>32.45</td>    </tr>    <tr>      <td>Models || Raw Data || FlowSeq-large (IWD n = 15)</td>      <td>22.94</td>      <td>27.16</td>      <td>31.08</td>      <td>32.03</td>    </tr>    <tr>      <td>Models || Raw Data || FlowSeq-large (NPD n = 15)</td>      <td>23.14</td>      <td>27.71</td>      <td>31.97</td>      <td>32.46</td>    </tr>    <tr>      <td>Models || Raw Data || FlowSeq-large (NPD n = 30)</td>      <td>23.64</td>      <td>28.29</td>      <td>32.35</td>      <td>32.91</td>    </tr>    <tr>      <td>Models || Knowledge Distillation || NAT-IR (refinement 10)</td>      <td>21.61</td>      <td>25.48</td>      <td>29.32</td>      <td>30.19</td>    </tr>    <tr>      <td>Models || Knowledge Distillation || NAT w/ FT (NPD n = 10)</td>      <td>18.66</td>      <td>22.42</td>      <td>29.02</td>      <td>31.44</td>    </tr>    <tr>      <td>Models || Knowledge Distillation || NAT-REG (NPD n = 9)</td>      <td>24.61</td>      <td>28.9</td>      <td>-</td>      <td>-</td>    </tr>    <tr>      <td>Models || Knowledge Distillation || LV NAR (refinement 4)</td>      <td>24.2</td>      <td>-</td>      <td>-</td>      <td>-</td>    </tr>    <tr>      <td>Models || Knowledge Distillation || CMLM-small (refinement 10)</td>      <td>25.51</td>      <td>29.47</td>      <td>31.65</td>      <td>32.27</td>    </tr>    <tr>      <td>Models || Knowledge Distillation || CMLM-base (refinement 10)</td>      <td>26.92</td>      <td>30.86</td>      <td>32.42</td>      <td>33.06</td>    </tr>    <tr>      <td>Models || Knowledge Distillation || FlowSeq-base (IWD n = 15)</td>      <td>22.49</td>      <td>27.4</td>      <td>30.59</td>      <td>31.58</td>    </tr>    <tr>      <td>Models || Knowledge Distillation || FlowSeq-base (NPD n = 15)</td>      <td>23.08</td>      <td>28.07</td>      <td>31.35</td>      <td>32.11</td>    </tr>    <tr>      <td>Models || Knowledge Distillation || FlowSeq-base (NPD n = 30)</td>      <td>23.48</td>      <td>28.4</td>      <td>31.75</td>      <td>32.49</td>    </tr>    <tr>      <td>Models || Knowledge Distillation || FlowSeq-large (IWD n = 15)</td>      <td>24.7</td>      <td>29.44</td>      <td>31.02</td>      <td>31.97</td>    </tr>    <tr>      <td>Models || Knowledge Distillation || FlowSeq-large (NPD n = 15)</td>      <td>25.03</td>      <td>30.48</td>      <td>31.89</td>      <td>32.43</td>    </tr>    <tr>      <td>Models || Knowledge Distillation || FlowSeq-large (NPD n = 30)</td>      <td>25.31</td>      <td>30.68</td>      <td>32.2</td>      <td>32.84</td>    </tr>  </tbody></table>",
        "table_name": "Table 2",
        "table_id": "table_2",
        "paper_id": "D19-1437",
        "page_no": 7,
        "dir": "emnlp2019",
        "valid": 1
    },
    {
        "table_id_paper": "D19-1440table_2",
        "caption": "Performance comparison (recall) against a random sample of categorized triples. The last row shows the relative gain of the combined model over the best performing individual model.",
        "row_header_level": 2,
        "row_headers": [
            [
                "Model",
                "DBM"
            ],
            [
                "Model",
                "CKG"
            ],
            [
                "Model",
                "VFM"
            ],
            [
                "Model",
                "EDAM(DBM+CKG+VFM)"
            ],
            [
                "Model",
                "EDAM gain"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "Sensory"
            ],
            [
                "Logical"
            ],
            [
                "Relative"
            ],
            [
                "Absolute"
            ],
            [
                "Essential"
            ],
            [
                "Incidental"
            ]
        ],
        "contents": [
            [
                "0.49",
                "0.33",
                "0.4",
                "0.41",
                "0.29",
                "0.46"
            ],
            [
                "0.28",
                "0.5",
                "0.2",
                "0.44",
                "0.58",
                "0.31"
            ],
            [
                "0.13",
                "0.11",
                "0.05",
                "0.14",
                "0.1",
                "0.13"
            ],
            [
                "0.62",
                "0.63",
                "0.5",
                "0.65",
                "0.68",
                "0.6"
            ],
            [
                "27%",
                "26%",
                "25%",
                "48%",
                "17%",
                "30%"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "recall",
            "recall",
            "recall",
            "recall",
            "recall",
            "recall"
        ],
        "target_entity": [
            "EDAM(DBM+CKG+VFM)"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Sensory</th>      <th>Logical</th>      <th>Relative</th>      <th>Absolute</th>      <th>Essential</th>      <th>Incidental</th>    </tr>  </thead>  <tbody>    <tr>      <td>Model || DBM</td>      <td>0.49</td>      <td>0.33</td>      <td>0.4</td>      <td>0.41</td>      <td>0.29</td>      <td>0.46</td>    </tr>    <tr>      <td>Model || CKG</td>      <td>0.28</td>      <td>0.5</td>      <td>0.2</td>      <td>0.44</td>      <td>0.58</td>      <td>0.31</td>    </tr>    <tr>      <td>Model || VFM</td>      <td>0.13</td>      <td>0.11</td>      <td>0.05</td>      <td>0.14</td>      <td>0.1</td>      <td>0.13</td>    </tr>    <tr>      <td>Model || EDAM(DBM+CKG+VFM)</td>      <td>0.62</td>      <td>0.63</td>      <td>0.5</td>      <td>0.65</td>      <td>0.68</td>      <td>0.6</td>    </tr>    <tr>      <td>Model || EDAM gain</td>      <td>27%</td>      <td>26%</td>      <td>25%</td>      <td>48%</td>      <td>17%</td>      <td>30%</td>    </tr>  </tbody></table>",
        "table_name": "Table 2",
        "table_id": "table_2",
        "paper_id": "D19-1440",
        "page_no": 7,
        "dir": "emnlp2019",
        "valid": 1
    },
    {
        "table_id_paper": "D19-1460table_7",
        "caption": "Dialogue act (DA), Intent class (IC), and slot labeling (SL) F1 scores by domain for the majority class, LSTM, and ELMO baselines on data annotated at the sentence (S) and turn (T) level. Bold text denotes the model architecture with the best performance for a given annotation granularity, i.e. sentence or turn level. Red highlight denotes the model with the best performance on a given task across annotation granularities.",
        "row_header_level": 4,
        "row_headers": [
            [
                "Model",
                "MFC",
                "Annot",
                "S"
            ],
            [
                "Model",
                "LSTM",
                "Annot",
                "S"
            ],
            [
                "Model",
                "ELMO",
                "Annot",
                "S"
            ],
            [
                "Model",
                "MFC",
                "Annot",
                "T"
            ],
            [
                "Model",
                "LSTM",
                "Annot",
                "T"
            ],
            [
                "Model",
                "ELMO",
                "Annot",
                "T"
            ]
        ],
        "column_header_level": 2,
        "column_headers": [
            [
                "Airline",
                "DA"
            ],
            [
                "Airline",
                "IC"
            ],
            [
                "Airline",
                "SL"
            ],
            [
                "Fast Food",
                "DA"
            ],
            [
                "Fast Food",
                "IC"
            ],
            [
                "Fast Food",
                "SL"
            ],
            [
                "Finance",
                "DA"
            ],
            [
                "Finance",
                "IC"
            ],
            [
                "Finance",
                "SL"
            ],
            [
                "Insurance",
                "DA"
            ],
            [
                "Insurance",
                "IC"
            ],
            [
                "Insurance",
                "SL"
            ],
            [
                "Media",
                "DA"
            ],
            [
                "Media",
                "IC"
            ],
            [
                "Media",
                "SL"
            ],
            [
                "Software",
                "DA"
            ],
            [
                "Software",
                "IC"
            ],
            [
                "Software",
                "SL"
            ]
        ],
        "contents": [
            [
                "60.57",
                "33.69",
                "38.71",
                "57.14",
                "25.42",
                "61.92",
                "51.73",
                "37.37",
                "34.07",
                "56.87",
                "38.37",
                "53.75",
                "57.02",
                "30.42",
                "82.06",
                "58.14",
                "33.32",
                "53.96"
            ],
            [
                "97.2",
                "90.84",
                "74.16",
                "90.4",
                "86.09",
                "72.93",
                "93.9",
                "90.06",
                "69.09",
                "94.73",
                "93.3",
                "75.27",
                "94.27",
                "92.35",
                "90.84",
                "93.22",
                "90.95",
                "69.48"
            ],
            [
                "97.32",
                "91.88",
                "86.55",
                "91.03",
                "87.95",
                "77.51",
                "94.07",
                "91.15",
                "77.36",
                "94.63",
                "94.27",
                "88.45",
                "94.27",
                "93.32",
                "93.99",
                "93.66",
                "92.25",
                "76.04"
            ],
            [
                "33.04",
                "32.79",
                "37.73",
                "33.07",
                "25.33",
                "61.84",
                "36.52",
                "38.16",
                "34.31",
                "36.39",
                "39.42",
                "54.66",
                "29.9",
                "31.82",
                "78.83",
                "36.79",
                "33.78",
                "54.84"
            ],
            [
                "84.25",
                "89.15",
                "75.78",
                "66.41",
                "87.35",
                "73.57",
                "76.19",
                "92.3",
                "70.92",
                "75.37",
                "94.75",
                "76.84",
                "77.94",
                "94.35",
                "87.33",
                "83.32",
                "89.78",
                "72.34"
            ],
            [
                "84.04",
                "89.99",
                "85.64",
                "65.69",
                "88.96",
                "79.63",
                "76.29",
                "94.5",
                "79.47",
                "75.34",
                "95.39",
                "89.51",
                "77.81",
                "94.76",
                "91.48",
                "82.97",
                "90.85",
                "76.48"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "F1",
            "F1",
            "F1",
            "F1",
            "F1",
            "F1",
            "F1",
            "F1",
            "F1",
            "F1",
            "F1",
            "F1",
            "F1",
            "F1",
            "F1",
            "F1",
            "F1",
            "F1"
        ],
        "target_entity": [
            "ELMO",
            "MFC",
            "LSTM"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Airline || DA</th>      <th>Airline || IC</th>      <th>Airline || SL</th>      <th>Fast Food || DA</th>      <th>Fast Food || IC</th>      <th>Fast Food || SL</th>      <th>Finance || DA</th>      <th>Finance || IC</th>      <th>Finance || SL</th>      <th>Insurance || DA</th>      <th>Insurance || IC</th>      <th>Insurance || SL</th>      <th>Media || DA</th>      <th>Media || IC</th>      <th>Media || SL</th>      <th>Software || DA</th>      <th>Software || IC</th>      <th>Software || SL</th>    </tr>  </thead>  <tbody>    <tr>      <td>Model || MFC || Annot || S</td>      <td>60.57</td>      <td>33.69</td>      <td>38.71</td>      <td>57.14</td>      <td>25.42</td>      <td>61.92</td>      <td>51.73</td>      <td>37.37</td>      <td>34.07</td>      <td>56.87</td>      <td>38.37</td>      <td>53.75</td>      <td>57.02</td>      <td>30.42</td>      <td>82.06</td>      <td>58.14</td>      <td>33.32</td>      <td>53.96</td>    </tr>    <tr>      <td>Model || LSTM || Annot || S</td>      <td>97.2</td>      <td>90.84</td>      <td>74.16</td>      <td>90.4</td>      <td>86.09</td>      <td>72.93</td>      <td>93.9</td>      <td>90.06</td>      <td>69.09</td>      <td>94.73</td>      <td>93.3</td>      <td>75.27</td>      <td>94.27</td>      <td>92.35</td>      <td>90.84</td>      <td>93.22</td>      <td>90.95</td>      <td>69.48</td>    </tr>    <tr>      <td>Model || ELMO || Annot || S</td>      <td>97.32</td>      <td>91.88</td>      <td>86.55</td>      <td>91.03</td>      <td>87.95</td>      <td>77.51</td>      <td>94.07</td>      <td>91.15</td>      <td>77.36</td>      <td>94.63</td>      <td>94.27</td>      <td>88.45</td>      <td>94.27</td>      <td>93.32</td>      <td>93.99</td>      <td>93.66</td>      <td>92.25</td>      <td>76.04</td>    </tr>    <tr>      <td>Model || MFC || Annot || T</td>      <td>33.04</td>      <td>32.79</td>      <td>37.73</td>      <td>33.07</td>      <td>25.33</td>      <td>61.84</td>      <td>36.52</td>      <td>38.16</td>      <td>34.31</td>      <td>36.39</td>      <td>39.42</td>      <td>54.66</td>      <td>29.9</td>      <td>31.82</td>      <td>78.83</td>      <td>36.79</td>      <td>33.78</td>      <td>54.84</td>    </tr>    <tr>      <td>Model || LSTM || Annot || T</td>      <td>84.25</td>      <td>89.15</td>      <td>75.78</td>      <td>66.41</td>      <td>87.35</td>      <td>73.57</td>      <td>76.19</td>      <td>92.3</td>      <td>70.92</td>      <td>75.37</td>      <td>94.75</td>      <td>76.84</td>      <td>77.94</td>      <td>94.35</td>      <td>87.33</td>      <td>83.32</td>      <td>89.78</td>      <td>72.34</td>    </tr>    <tr>      <td>Model || ELMO || Annot || T</td>      <td>84.04</td>      <td>89.99</td>      <td>85.64</td>      <td>65.69</td>      <td>88.96</td>      <td>79.63</td>      <td>76.29</td>      <td>94.5</td>      <td>79.47</td>      <td>75.34</td>      <td>95.39</td>      <td>89.51</td>      <td>77.81</td>      <td>94.76</td>      <td>91.48</td>      <td>82.97</td>      <td>90.85</td>      <td>76.48</td>    </tr>  </tbody></table>",
        "table_name": "Table 7",
        "table_id": "table_7",
        "paper_id": "D19-1460",
        "page_no": 8,
        "dir": "emnlp2019",
        "valid": 1
    },
    {
        "table_id_paper": "D19-1477table_2",
        "caption": "Results for all the models on the three datasets in our experiment. Marked with \u2217 are the results which significantly improve over LING and LING+random (p < 0.05, also for the following results); (cid:5) indicates a significant improvement over LING+PV; \u2020 a significant improvement over LING+N2V.",
        "row_header_level": 2,
        "row_headers": [
            [
                "Model",
                "Frequency"
            ],
            [
                "Model",
                "LING"
            ],
            [
                "Model",
                "LING+random"
            ],
            [
                "Model",
                "LING+PV"
            ],
            [
                "Model",
                "LING+N2V"
            ],
            [
                "Model",
                "LING+GAT"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "Sentiment"
            ],
            [
                "Stance"
            ],
            [
                "Hate"
            ]
        ],
        "contents": [
            [
                "0.332",
                "0.397",
                "0.057"
            ],
            [
                "0.676",
                "0.569",
                "0.624"
            ],
            [
                "0.657",
                "0.571",
                "0.600"
            ],
            [
                "0.671",
                "0.601*",
                "0.667*"
            ],
            [
                "0.672",
                "0.629*",
                "0.656*"
            ],
            [
                "0.666",
                "0.640*",
                "0.674*"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "accuracy",
            "accuracy",
            "accuracy"
        ],
        "target_entity": [
            "LING+GAT"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Sentiment</th>      <th>Stance</th>      <th>Hate</th>    </tr>  </thead>  <tbody>    <tr>      <td>Model || Frequency</td>      <td>0.332</td>      <td>0.397</td>      <td>0.057</td>    </tr>    <tr>      <td>Model || LING</td>      <td>0.676</td>      <td>0.569</td>      <td>0.624</td>    </tr>    <tr>      <td>Model || LING+random</td>      <td>0.657</td>      <td>0.571</td>      <td>0.600</td>    </tr>    <tr>      <td>Model || LING+PV</td>      <td>0.671</td>      <td>0.601*</td>      <td>0.667*</td>    </tr>    <tr>      <td>Model || LING+N2V</td>      <td>0.672</td>      <td>0.629*</td>      <td>0.656*</td>    </tr>    <tr>      <td>Model || LING+GAT</td>      <td>0.666</td>      <td>0.640*</td>      <td>0.674*</td>    </tr>  </tbody></table>",
        "table_name": "Table 2",
        "table_id": "table_2",
        "paper_id": "D19-1477",
        "page_no": 6,
        "dir": "emnlp2019",
        "valid": 1
    },
    {
        "table_id_paper": "D19-1486table_3",
        "caption": "Results of zero-shot intent classification.",
        "row_header_level": 2,
        "row_headers": [
            [
                "Method",
                "DeViSE"
            ],
            [
                "Method",
                "CMT"
            ],
            [
                "Method",
                "CDSSM"
            ],
            [
                "Method",
                "Zero-shot DNN"
            ],
            [
                "Method",
                "IntentCapsNet"
            ],
            [
                "Method",
                "ReCapsNet-ZS-Dim"
            ],
            [
                "Method",
                "ReCapsNet-ZS-TM"
            ],
            [
                "Method",
                "ReCapsNet-ZS"
            ]
        ],
        "column_header_level": 2,
        "column_headers": [
            [
                "SNIPS-NLU",
                "Acc"
            ],
            [
                "SNIPS-NLU",
                "F1"
            ],
            [
                "SMP-2018",
                "Acc"
            ],
            [
                "SMP-2018",
                "F1"
            ]
        ],
        "contents": [
            [
                "0.7447",
                "0.7446",
                "0.5456",
                "0.3875"
            ],
            [
                "0.7396",
                "0.7206",
                "0.4452",
                "0.4245"
            ],
            [
                "0.7588",
                "0.758",
                "0.4308",
                "0.3765"
            ],
            [
                "0.7165",
                "0.7116",
                "0.4615",
                "0.3897"
            ],
            [
                "0.7752",
                "0.775",
                "0.4864",
                "0.4227"
            ],
            [
                "0.7868",
                "0.7859",
                "0.5005",
                "0.4501"
            ],
            [
                "0.786",
                "0.7837",
                "0.5315",
                "0.463"
            ],
            [
                "0.7996",
                "0.798",
                "0.5418",
                "0.4769"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "Acc",
            "F1",
            "Acc",
            "F1"
        ],
        "target_entity": [
            "ReCapsNet-ZS"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>SNIPS-NLU || Acc</th>      <th>SNIPS-NLU || F1</th>      <th>SMP-2018 || Acc</th>      <th>SMP-2018 || F1</th>    </tr>  </thead>  <tbody>    <tr>      <td>Method || DeViSE</td>      <td>0.7447</td>      <td>0.7446</td>      <td>0.5456</td>      <td>0.3875</td>    </tr>    <tr>      <td>Method || CMT</td>      <td>0.7396</td>      <td>0.7206</td>      <td>0.4452</td>      <td>0.4245</td>    </tr>    <tr>      <td>Method || CDSSM</td>      <td>0.7588</td>      <td>0.758</td>      <td>0.4308</td>      <td>0.3765</td>    </tr>    <tr>      <td>Method || Zero-shot DNN</td>      <td>0.7165</td>      <td>0.7116</td>      <td>0.4615</td>      <td>0.3897</td>    </tr>    <tr>      <td>Method || IntentCapsNet</td>      <td>0.7752</td>      <td>0.775</td>      <td>0.4864</td>      <td>0.4227</td>    </tr>    <tr>      <td>Method || ReCapsNet-ZS-Dim</td>      <td>0.7868</td>      <td>0.7859</td>      <td>0.5005</td>      <td>0.4501</td>    </tr>    <tr>      <td>Method || ReCapsNet-ZS-TM</td>      <td>0.786</td>      <td>0.7837</td>      <td>0.5315</td>      <td>0.463</td>    </tr>    <tr>      <td>Method || ReCapsNet-ZS</td>      <td>0.7996</td>      <td>0.798</td>      <td>0.5418</td>      <td>0.4769</td>    </tr>  </tbody></table>",
        "table_name": "Table 3",
        "table_id": "table_3",
        "paper_id": "D19-1486",
        "page_no": 10,
        "dir": "emnlp2019",
        "valid": 1
    },
    {
        "table_id_paper": "D19-1496table_7",
        "caption": "The performance of DISP using ground-truth and recovered tokens over different types of attacks in SST-2. Result are in accuracy. Note that DISPG denotes DISP using ground-truth tokens.",
        "row_header_level": 2,
        "row_headers": [
            [
                "Method",
                "DISP G"
            ],
            [
                "Method",
                "DISP"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "Insertion"
            ],
            [
                "Delete"
            ],
            [
                "Swap"
            ],
            [
                "Random"
            ],
            [
                "Embed"
            ],
            [
                "Overall"
            ]
        ],
        "contents": [
            [
                "0.8773",
                "0.8681",
                "0.8796",
                "0.797",
                "0.7924",
                "0.8429"
            ],
            [
                "0.8278",
                "0.8278",
                "0.8301",
                "0.7773",
                "0.7784",
                "0.8083"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "accuracy",
            "accuracy",
            "accuracy",
            "accuracy",
            "accuracy",
            "accuracy"
        ],
        "target_entity": [
            "DISP G"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Insertion</th>      <th>Delete</th>      <th>Swap</th>      <th>Random</th>      <th>Embed</th>      <th>Overall</th>    </tr>  </thead>  <tbody>    <tr>      <td>Method || DISP G</td>      <td>0.8773</td>      <td>0.8681</td>      <td>0.8796</td>      <td>0.797</td>      <td>0.7924</td>      <td>0.8429</td>    </tr>    <tr>      <td>Method || DISP</td>      <td>0.8278</td>      <td>0.8278</td>      <td>0.8301</td>      <td>0.7773</td>      <td>0.7784</td>      <td>0.8083</td>    </tr>  </tbody></table>",
        "table_name": "Table 7",
        "table_id": "table_7",
        "paper_id": "D19-1496",
        "page_no": 8,
        "dir": "emnlp2019",
        "valid": 1
    },
    {
        "table_id_paper": "D19-1498table_3",
        "caption": "Performance of EoG on the CDR test set with different pre-trained word embeddings.",
        "row_header_level": 2,
        "row_headers": [
            [
                "Embeddings",
                "EoG (PubMed)"
            ],
            [
                "Embeddings",
                "EoG (GloVe)"
            ],
            [
                "Embeddings",
                "EoG (random)"
            ]
        ],
        "column_header_level": 2,
        "column_headers": [
            [
                "F1 (%)",
                "Overall"
            ],
            [
                "F1 (%)",
                "Intra"
            ],
            [
                "F1 (%)",
                "Inter"
            ]
        ],
        "contents": [
            [
                "63.62",
                "68.25",
                "50.94"
            ],
            [
                "63.01",
                "67.52",
                "50.26"
            ],
            [
                "61.41",
                "66.8",
                "46.51"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "F1 (%)",
            "F1 (%)",
            "F1 (%)"
        ],
        "target_entity": [
            "Embeddings"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>F1 (%) || Overall</th>      <th>F1 (%) || Intra</th>      <th>F1 (%) || Inter</th>    </tr>  </thead>  <tbody>    <tr>      <td>Embeddings || EoG (PubMed)</td>      <td>63.62</td>      <td>68.25</td>      <td>50.94</td>    </tr>    <tr>      <td>Embeddings || EoG (GloVe)</td>      <td>63.01</td>      <td>67.52</td>      <td>50.26</td>    </tr>    <tr>      <td>Embeddings || EoG (random)</td>      <td>61.41</td>      <td>66.8</td>      <td>46.51</td>    </tr>  </tbody></table>",
        "table_name": "Table 3",
        "table_id": "table_3",
        "paper_id": "D19-1498",
        "page_no": 7,
        "dir": "emnlp2019",
        "valid": 1
    },
    {
        "table_id_paper": "D19-1511table_2",
        "caption": "Evaluation result of question generation.",
        "row_header_level": 2,
        "row_headers": [
            [
                "Models",
                "Seq2Seq"
            ],
            [
                "Models",
                "CVAE"
            ],
            [
                "Models",
                "STD"
            ],
            [
                "Models",
                "HTD"
            ],
            [
                "Models",
                "CVAE (qt)"
            ],
            [
                "Models",
                "A-CVAE"
            ],
            [
                "Models",
                "RL-CVAE"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "RubA"
            ],
            [
                "RubG"
            ],
            [
                "Dist2"
            ],
            [
                "PPL"
            ]
        ],
        "contents": [
            [
                "0.614",
                "0.574",
                "0.008",
                "63.02"
            ],
            [
                "0.682",
                "0.649",
                "0.112",
                "20.39"
            ],
            [
                "0.658",
                "0.613",
                "0.010",
                "28.75"
            ],
            [
                "0.689",
                "0.654",
                "0.114",
                "26.02"
            ],
            [
                "0.688",
                "0.652",
                "0.114",
                "20.03"
            ],
            [
                "0.715",
                "0.661",
                "0.123",
                "19.51"
            ],
            [
                "0.720",
                "0.668",
                "0.185",
                "16.93"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "RubA",
            "RubG",
            "Dist2",
            "PPL"
        ],
        "target_entity": [
            "A-CVAE",
            "RL-CVAE"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>RubA</th>      <th>RubG</th>      <th>Dist2</th>      <th>PPL</th>    </tr>  </thead>  <tbody>    <tr>      <td>Models || Seq2Seq</td>      <td>0.614</td>      <td>0.574</td>      <td>0.008</td>      <td>63.02</td>    </tr>    <tr>      <td>Models || CVAE</td>      <td>0.682</td>      <td>0.649</td>      <td>0.112</td>      <td>20.39</td>    </tr>    <tr>      <td>Models || STD</td>      <td>0.658</td>      <td>0.613</td>      <td>0.010</td>      <td>28.75</td>    </tr>    <tr>      <td>Models || HTD</td>      <td>0.689</td>      <td>0.654</td>      <td>0.114</td>      <td>26.02</td>    </tr>    <tr>      <td>Models || CVAE (qt)</td>      <td>0.688</td>      <td>0.652</td>      <td>0.114</td>      <td>20.03</td>    </tr>    <tr>      <td>Models || A-CVAE</td>      <td>0.715</td>      <td>0.661</td>      <td>0.123</td>      <td>19.51</td>    </tr>    <tr>      <td>Models || RL-CVAE</td>      <td>0.720</td>      <td>0.668</td>      <td>0.185</td>      <td>16.93</td>    </tr>  </tbody></table>",
        "table_name": "Table 2",
        "table_id": "table_2",
        "paper_id": "D19-1511",
        "page_no": 7,
        "dir": "emnlp2019",
        "valid": 1
    },
    {
        "table_id_paper": "D19-1515table_3",
        "caption": "Decoding algorithms\u2019 impact on performance.",
        "row_header_level": 2,
        "row_headers": [
            [
                "Decoding Algorithm",
                "Viterbi (MAP)"
            ],
            [
                "Decoding Algorithm",
                "Smoothing"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "HL-CCRF"
            ],
            [
                "SL-CCRF"
            ]
        ],
        "contents": [
            [
                "72.26",
                "74.69"
            ],
            [
                "72.30",
                "74.73"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "accuracy",
            "accuracy"
        ],
        "target_entity": [
            "Smoothing"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>HL-CCRF</th>      <th>SL-CCRF</th>    </tr>  </thead>  <tbody>    <tr>      <td>Decoding Algorithm || Viterbi (MAP)</td>      <td>72.26</td>      <td>74.69</td>    </tr>    <tr>      <td>Decoding Algorithm || Smoothing</td>      <td>72.30</td>      <td>74.73</td>    </tr>  </tbody></table>",
        "table_name": "Table 3",
        "table_id": "table_3",
        "paper_id": "D19-1515",
        "page_no": 8,
        "dir": "emnlp2019",
        "valid": 1
    },
    {
        "table_id_paper": "D19-1531table_1",
        "caption": "Analyses on Spanish and French monolingual embeddings before and after bias mitigation. Results show that the original Spanish and French embeddings exhibit strong bias and Hybrid Ori significantly reduces the bias in the embedding to to an insignificant level (p-value > 0.05).",
        "row_header_level": 4,
        "row_headers": [
            [
                "Lang.",
                "ES",
                "Metric",
                "MWEAT\u2013Diff"
            ],
            [
                "Lang.",
                "ES",
                "Metric",
                "MWEAT\u2013p-value"
            ],
            [
                "Lang.",
                "FR",
                "Metric",
                "MWEAT\u2013Diff"
            ],
            [
                "Lang.",
                "FR",
                "Metric",
                "MWEAT\u2013p-value"
            ],
            [
                "Lang.",
                "ES",
                "Metric",
                "Word Similarity"
            ],
            [
                "Lang.",
                "FR",
                "Metric",
                "Word Similarity"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "Original"
            ],
            [
                "Shift_Ori"
            ],
            [
                "Shift_EN"
            ],
            [
                "De-Align"
            ],
            [
                "Hybrid_Ori"
            ],
            [
                "Hybrid_EN"
            ]
        ],
        "contents": [
            [
                "3.6918",
                "0.3090",
                "0.3324",
                "3.5748",
                "0.3090",
                "2.2494"
            ],
            [
                "0.0000",
                "0.1130",
                "0.0010",
                "0.0010",
                "0.7330",
                "0.0020"
            ],
            [
                "2.3437",
                "0.2446",
                "0.3882",
                "2.3436",
                "0.2446",
                "1.1758"
            ],
            [
                "0.0000",
                "0.1470",
                "0.0010",
                "0.0020",
                "0.5290",
                "0.0910"
            ],
            [
                "0.7392",
                "0.7363",
                "0.7359",
                "0.7392",
                "0.7358",
                "0.7356"
            ],
            [
                "0.7294",
                "0.7218",
                "0.7218",
                "0.7156",
                "0.7218",
                "0.7218"
            ]
        ],
        "metrics_loc": "row",
        "metrics_type": [
            "MWEAT\u2013Diff",
            "MWEAT\u2013p-value",
            "MWEAT\u2013Diff",
            "MWEAT\u2013p-value",
            "Word Similarity",
            "Word Similarity"
        ],
        "target_entity": [
            "Hybrid_Ori"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Original</th>      <th>Shift_Ori</th>      <th>Shift_EN</th>      <th>De-Align</th>      <th>Hybrid_Ori</th>      <th>Hybrid_EN</th>    </tr>  </thead>  <tbody>    <tr>      <td>Lang. || ES || Metric || MWEAT\u2013Diff</td>      <td>3.6918</td>      <td>0.3090</td>      <td>0.3324</td>      <td>3.5748</td>      <td>0.3090</td>      <td>2.2494</td>    </tr>    <tr>      <td>Lang. || ES || Metric || MWEAT\u2013p-value</td>      <td>0.0000</td>      <td>0.1130</td>      <td>0.0010</td>      <td>0.0010</td>      <td>0.7330</td>      <td>0.0020</td>    </tr>    <tr>      <td>Lang. || FR || Metric || MWEAT\u2013Diff</td>      <td>2.3437</td>      <td>0.2446</td>      <td>0.3882</td>      <td>2.3436</td>      <td>0.2446</td>      <td>1.1758</td>    </tr>    <tr>      <td>Lang. || FR || Metric || MWEAT\u2013p-value</td>      <td>0.0000</td>      <td>0.1470</td>      <td>0.0010</td>      <td>0.0020</td>      <td>0.5290</td>      <td>0.0910</td>    </tr>    <tr>      <td>Lang. || ES || Metric || Word Similarity</td>      <td>0.7392</td>      <td>0.7363</td>      <td>0.7359</td>      <td>0.7392</td>      <td>0.7358</td>      <td>0.7356</td>    </tr>    <tr>      <td>Lang. || FR || Metric || Word Similarity</td>      <td>0.7294</td>      <td>0.7218</td>      <td>0.7218</td>      <td>0.7156</td>      <td>0.7218</td>      <td>0.7218</td>    </tr>  </tbody></table>",
        "table_name": "Table 1",
        "table_id": "table_1",
        "paper_id": "D19-1531",
        "page_no": 6,
        "dir": "emnlp2019",
        "valid": 1
    },
    {
        "table_id_paper": "D19-1535table_2",
        "caption": "Variant results on FollowUp dev set.",
        "row_header_level": 2,
        "row_headers": [
            [
                "Variant",
                "STAR"
            ],
            [
                "Variant",
                "\u2013 Phase I"
            ],
            [
                "Variant",
                "\u2013 Phase II"
            ],
            [
                "Variant",
                "\u2013 RL"
            ],
            [
                "Variant",
                "+ Basic Reward"
            ],
            [
                "Variant",
                "+ Oracle Reward"
            ],
            [
                "Variant",
                "+ Uniform Reward"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "SymAcc (%)"
            ],
            [
                "BLEU (%)"
            ]
        ],
        "contents": [
            [
                "55.38",
                "67.62"
            ],
            [
                "40.63",
                "61.82"
            ],
            [
                "23.12",
                "48.65"
            ],
            [
                "41.25",
                "60.19"
            ],
            [
                "43.13",
                "58.48"
            ],
            [
                "45.20",
                "63.04"
            ],
            [
                "53.40",
                "66.93"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "SymAcc (%)",
            "BLEU (%)"
        ],
        "target_entity": [
            "STAR"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>SymAcc (%)</th>      <th>BLEU (%)</th>    </tr>  </thead>  <tbody>    <tr>      <td>Variant || STAR</td>      <td>55.38</td>      <td>67.62</td>    </tr>    <tr>      <td>Variant || \u2013 Phase I</td>      <td>40.63</td>      <td>61.82</td>    </tr>    <tr>      <td>Variant || \u2013 Phase II</td>      <td>23.12</td>      <td>48.65</td>    </tr>    <tr>      <td>Variant || \u2013 RL</td>      <td>41.25</td>      <td>60.19</td>    </tr>    <tr>      <td>Variant || + Basic Reward</td>      <td>43.13</td>      <td>58.48</td>    </tr>    <tr>      <td>Variant || + Oracle Reward</td>      <td>45.20</td>      <td>63.04</td>    </tr>    <tr>      <td>Variant || + Uniform Reward</td>      <td>53.40</td>      <td>66.93</td>    </tr>  </tbody></table>",
        "table_name": "Table 2",
        "table_id": "table_2",
        "paper_id": "D19-1535",
        "page_no": 7,
        "dir": "emnlp2019",
        "valid": 1
    },
    {
        "table_id_paper": "D19-1630table_4",
        "caption": "Performance on the CB test set and the MultiNLI dev set.",
        "row_header_level": 1,
        "row_headers": [
            [
                "CBOW"
            ],
            [
                "MNLIB"
            ],
            [
                "Heuristics"
            ],
            [
                "CBB"
            ],
            [
                "MNLI+CBB"
            ],
            [
                "Human"
            ]
        ],
        "column_header_level": 2,
        "column_headers": [
            [
                "CB",
                "Acc."
            ],
            [
                "CB",
                "F1"
            ],
            [
                "MultiNLI",
                "Acc."
            ],
            [
                "MultiNLI",
                "F1"
            ]
        ],
        "contents": [
            [
                "69.2",
                "47.6",
                "71.2",
                "71.2"
            ],
            [
                "77.6",
                "66.7",
                "83.6",
                "83.6"
            ],
            [
                "81.2",
                "71.3",
                "-",
                "-"
            ],
            [
                "85.2",
                "81.2",
                "41.1",
                "30.6"
            ],
            [
                "91.2",
                "85.3",
                "72.3",
                "74.4"
            ],
            [
                "98.9",
                "95.8",
                "92.0/92.8",
                "-"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "Acc.",
            "F1",
            "Acc.",
            "F1"
        ],
        "target_entity": [
            "MNLI+CBB",
            "CBB",
            "MNLIB"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>CB || Acc.</th>      <th>CB || F1</th>      <th>MultiNLI || Acc.</th>      <th>MultiNLI || F1</th>    </tr>  </thead>  <tbody>    <tr>      <td>CBOW</td>      <td>69.2</td>      <td>47.6</td>      <td>71.2</td>      <td>71.2</td>    </tr>    <tr>      <td>MNLIB</td>      <td>77.6</td>      <td>66.7</td>      <td>83.6</td>      <td>83.6</td>    </tr>    <tr>      <td>Heuristics</td>      <td>81.2</td>      <td>71.3</td>      <td>-</td>      <td>-</td>    </tr>    <tr>      <td>CBB</td>      <td>85.2</td>      <td>81.2</td>      <td>41.1</td>      <td>30.6</td>    </tr>    <tr>      <td>MNLI+CBB</td>      <td>91.2</td>      <td>85.3</td>      <td>72.3</td>      <td>74.4</td>    </tr>    <tr>      <td>Human</td>      <td>98.9</td>      <td>95.8</td>      <td>92.0/92.8</td>      <td>-</td>    </tr>  </tbody></table>",
        "table_name": "Table 4",
        "table_id": "table_4",
        "paper_id": "D19-1630",
        "page_no": 4,
        "dir": "emnlp2019",
        "valid": 1
    },
    {
        "table_id_paper": "D19-1654table_3",
        "caption": "Experimental results on two MAMS datasets and SemEval-2014 Restaurant Review dataset for both ATSA and ACSA subtasks.",
        "row_header_level": 2,
        "row_headers": [
            [
                "Method",
                "TextCNN"
            ],
            [
                "Method",
                "LSTM"
            ],
            [
                "Method",
                "TD LSTM"
            ],
            [
                "Method",
                "AT LSTM"
            ],
            [
                "Method",
                "ATAE LSTM"
            ],
            [
                "Method",
                "BiLSTM+Attn"
            ],
            [
                "Method",
                "IAN"
            ],
            [
                "Method",
                "AOA LSTM"
            ],
            [
                "Method",
                "AEN"
            ],
            [
                "Method",
                "MemNet"
            ],
            [
                "Method",
                "GCAE"
            ],
            [
                "Method",
                "CapsNet"
            ],
            [
                "Method",
                "BERT"
            ],
            [
                "Method",
                "CapsNet-BERT"
            ],
            [
                "Method",
                "CapsNet-DR"
            ],
            [
                "Method",
                "CapsNet-BERT-DR"
            ]
        ],
        "column_header_level": 2,
        "column_headers": [
            [
                "ATSA",
                "MAMS"
            ],
            [
                "ATSA",
                "MAMS-small"
            ],
            [
                "ATSA",
                "Restaurant"
            ],
            [
                "ACSA",
                "MAMS"
            ],
            [
                "ACSA",
                "MAMS-small"
            ],
            [
                "ACSA",
                "Restaurant"
            ]
        ],
        "contents": [
            [
                "52.694",
                "51.736",
                "75.928",
                "48.856",
                "48.814",
                "81.418"
            ],
            [
                "52.486",
                "50.134",
                "75.552",
                "48.546",
                "48.346",
                "82.076"
            ],
            [
                "74.596",
                "73.582",
                "75.63",
                "-",
                "-",
                "-"
            ],
            [
                "77.558",
                "73.028",
                "76.2",
                "66.436",
                "65.128",
                "83.1"
            ],
            [
                "77.054",
                "71.708",
                "77.2",
                "70.634",
                "66.814",
                "84"
            ],
            [
                "76.166",
                "70.72",
                "77.356",
                "66.304",
                "66.262",
                "80.514"
            ],
            [
                "76.602",
                "71.168",
                "78.6",
                "-",
                "-",
                "-"
            ],
            [
                "77.26",
                "72.29",
                "81.2",
                "-",
                "-",
                "-"
            ],
            [
                "66.722",
                "61.706",
                "80.98",
                "-",
                "-",
                "-"
            ],
            [
                "64.568",
                "62.694",
                "80.95",
                "63.288",
                "62.818",
                "77.862"
            ],
            [
                "77.588",
                "73.246",
                "77.28",
                "72.098",
                "66.968",
                "79.35"
            ],
            [
                "79.776",
                "73.86",
                "80.786",
                "73.986",
                "67.128",
                "83.554"
            ],
            [
                "82.218",
                "79.44",
                "84.46",
                "78.292",
                "75.316",
                "90.442"
            ],
            [
                "83.391",
                "80.91",
                "85.934",
                "79.461",
                "76.366",
                "91.375"
            ],
            [
                "79.434",
                "71.398",
                "77.768",
                "69.036",
                "65.638",
                "81.904"
            ],
            [
                "82.97",
                "80.092",
                "84.646",
                "79.132",
                "75.634",
                "90.736"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "accuracy",
            "accuracy",
            "accuracy",
            "accuracy",
            "accuracy",
            "accuracy"
        ],
        "target_entity": null,
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>ATSA || MAMS</th>      <th>ATSA || MAMS-small</th>      <th>ATSA || Restaurant</th>      <th>ACSA || MAMS</th>      <th>ACSA || MAMS-small</th>      <th>ACSA || Restaurant</th>    </tr>  </thead>  <tbody>    <tr>      <td>Method || TextCNN</td>      <td>52.694</td>      <td>51.736</td>      <td>75.928</td>      <td>48.856</td>      <td>48.814</td>      <td>81.418</td>    </tr>    <tr>      <td>Method || LSTM</td>      <td>52.486</td>      <td>50.134</td>      <td>75.552</td>      <td>48.546</td>      <td>48.346</td>      <td>82.076</td>    </tr>    <tr>      <td>Method || TD LSTM</td>      <td>74.596</td>      <td>73.582</td>      <td>75.63</td>      <td>-</td>      <td>-</td>      <td>-</td>    </tr>    <tr>      <td>Method || AT LSTM</td>      <td>77.558</td>      <td>73.028</td>      <td>76.2</td>      <td>66.436</td>      <td>65.128</td>      <td>83.1</td>    </tr>    <tr>      <td>Method || ATAE LSTM</td>      <td>77.054</td>      <td>71.708</td>      <td>77.2</td>      <td>70.634</td>      <td>66.814</td>      <td>84</td>    </tr>    <tr>      <td>Method || BiLSTM+Attn</td>      <td>76.166</td>      <td>70.72</td>      <td>77.356</td>      <td>66.304</td>      <td>66.262</td>      <td>80.514</td>    </tr>    <tr>      <td>Method || IAN</td>      <td>76.602</td>      <td>71.168</td>      <td>78.6</td>      <td>-</td>      <td>-</td>      <td>-</td>    </tr>    <tr>      <td>Method || AOA LSTM</td>      <td>77.26</td>      <td>72.29</td>      <td>81.2</td>      <td>-</td>      <td>-</td>      <td>-</td>    </tr>    <tr>      <td>Method || AEN</td>      <td>66.722</td>      <td>61.706</td>      <td>80.98</td>      <td>-</td>      <td>-</td>      <td>-</td>    </tr>    <tr>      <td>Method || MemNet</td>      <td>64.568</td>      <td>62.694</td>      <td>80.95</td>      <td>63.288</td>      <td>62.818</td>      <td>77.862</td>    </tr>    <tr>      <td>Method || GCAE</td>      <td>77.588</td>      <td>73.246</td>      <td>77.28</td>      <td>72.098</td>      <td>66.968</td>      <td>79.35</td>    </tr>    <tr>      <td>Method || CapsNet</td>      <td>79.776</td>      <td>73.86</td>      <td>80.786</td>      <td>73.986</td>      <td>67.128</td>      <td>83.554</td>    </tr>    <tr>      <td>Method || BERT</td>      <td>82.218</td>      <td>79.44</td>      <td>84.46</td>      <td>78.292</td>      <td>75.316</td>      <td>90.442</td>    </tr>    <tr>      <td>Method || CapsNet-BERT</td>      <td>83.391</td>      <td>80.91</td>      <td>85.934</td>      <td>79.461</td>      <td>76.366</td>      <td>91.375</td>    </tr>    <tr>      <td>Method || CapsNet-DR</td>      <td>79.434</td>      <td>71.398</td>      <td>77.768</td>      <td>69.036</td>      <td>65.638</td>      <td>81.904</td>    </tr>    <tr>      <td>Method || CapsNet-BERT-DR</td>      <td>82.97</td>      <td>80.092</td>      <td>84.646</td>      <td>79.132</td>      <td>75.634</td>      <td>90.736</td>    </tr>  </tbody></table>",
        "table_name": "Table 3",
        "table_id": "table_3",
        "paper_id": "D19-1654",
        "page_no": 5,
        "dir": "emnlp2019",
        "valid": 1
    },
    {
        "table_id_paper": "P16-1113table_6",
        "caption": "Results by word category and role label.",
        "row_header_level": 2,
        "row_headers": [
            [
                "Predicate & Role Label",
                "verb / A0"
            ],
            [
                "Predicate & Role Label",
                "verb / A1"
            ],
            [
                "Predicate & Role Label",
                "verb / A2"
            ],
            [
                "Predicate & Role Label",
                "verb / AM"
            ],
            [
                "Predicate & Role Label",
                "noun / A0"
            ],
            [
                "Predicate & Role Label",
                "noun / A1"
            ],
            [
                "Predicate & Role Label",
                "noun / A2"
            ],
            [
                "Predicate & Role Label",
                "noun / AM"
            ]
        ],
        "column_header_level": 2,
        "column_headers": [
            [
                "PathLSTM",
                "P (%)"
            ],
            [
                "PathLSTM",
                "R (%)"
            ],
            [
                "POS Improvement over mate-tools",
                "P (%)"
            ],
            [
                "POS Improvement over mate-tools",
                "R (%)"
            ]
        ],
        "contents": [
            [
                "90.8",
                "89.2",
                "\u22120.4",
                "+1.8"
            ],
            [
                "91.0",
                "91.9",
                "+0.0",
                "+1.1"
            ],
            [
                "84.3",
                "76.9",
                "+1.5",
                "+0.0"
            ],
            [
                "82.2",
                "72.4",
                "+2.9",
                "\u22122.0"
            ],
            [
                "86.9",
                "78.2",
                "+0.8",
                "+3.3"
            ],
            [
                "87.5",
                "84.4",
                "+2.6",
                "+2.2"
            ],
            [
                "82.4",
                "76.8",
                "+1.0",
                "+2.1"
            ],
            [
                "79.5",
                "69.2",
                "+0.9",
                "\u22122.8"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "P (%)",
            "R (%)",
            "P (%)",
            "R (%)"
        ],
        "target_entity": [
            "Predicate & Role Label",
            "PathLSTM"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>PathLSTM || P (%)</th>      <th>PathLSTM || R (%)</th>      <th>POS Improvement over mate-tools || P (%)</th>      <th>POS Improvement over mate-tools || R (%)</th>    </tr>  </thead>  <tbody>    <tr>      <td>Predicate &amp; Role Label || verb / A0</td>      <td>90.8</td>      <td>89.2</td>      <td>\u22120.4</td>      <td>+1.8</td>    </tr>    <tr>      <td>Predicate &amp; Role Label || verb / A1</td>      <td>91.0</td>      <td>91.9</td>      <td>+0.0</td>      <td>+1.1</td>    </tr>    <tr>      <td>Predicate &amp; Role Label || verb / A2</td>      <td>84.3</td>      <td>76.9</td>      <td>+1.5</td>      <td>+0.0</td>    </tr>    <tr>      <td>Predicate &amp; Role Label || verb / AM</td>      <td>82.2</td>      <td>72.4</td>      <td>+2.9</td>      <td>\u22122.0</td>    </tr>    <tr>      <td>Predicate &amp; Role Label || noun / A0</td>      <td>86.9</td>      <td>78.2</td>      <td>+0.8</td>      <td>+3.3</td>    </tr>    <tr>      <td>Predicate &amp; Role Label || noun / A1</td>      <td>87.5</td>      <td>84.4</td>      <td>+2.6</td>      <td>+2.2</td>    </tr>    <tr>      <td>Predicate &amp; Role Label || noun / A2</td>      <td>82.4</td>      <td>76.8</td>      <td>+1.0</td>      <td>+2.1</td>    </tr>    <tr>      <td>Predicate &amp; Role Label || noun / AM</td>      <td>79.5</td>      <td>69.2</td>      <td>+0.9</td>      <td>\u22122.8</td>    </tr>  </tbody></table>",
        "table_name": "Table 6",
        "table_id": "table_6",
        "paper_id": "P16-1113",
        "page_no": 8,
        "dir": "acl2016",
        "valid": 1
    },
    {
        "table_id_paper": "P16-1136table_1",
        "caption": "KB completion results on NCI-PID test: comparison of our compositional learning approach (ALL-PATHS+NODES) with baseline systems. d is the embedding dimension; sampled paths occurring less than c times were pruned in PRUNED-PATHS.",
        "row_header_level": 2,
        "row_headers": [
            [
                "Model",
                "BILINEAR-DIAG (Guu et al., 2015) d=100"
            ],
            [
                "Model",
                "BILINEAR-DIAG d=100"
            ],
            [
                "Model",
                "BILINEAR-DIAG d=2000"
            ],
            [
                "Model",
                "+Guu et al. (2015) d=100 orig."
            ],
            [
                "Model",
                "+Guu et al. (2015) d=100 reimpl."
            ],
            [
                "Model",
                "PRUNED-PATHS d=100 c=1000"
            ],
            [
                "Model",
                "PRUNED-PATHS d=100 c=100"
            ],
            [
                "Model",
                "PRUNED-PATHS d=100 c=1"
            ],
            [
                "Model",
                "ALL-PATHS d=100"
            ],
            [
                "Model",
                "ALL-PATHS+NODES d=100"
            ]
        ],
        "column_header_level": 2,
        "column_headers": [
            [
                "KB",
                "MAP"
            ],
            [
                "KB",
                "HITS@10"
            ],
            [
                "KB and Text",
                "MAP"
            ],
            [
                "KB and Text",
                "HITS@10"
            ]
        ],
        "contents": [
            [
                "12.48",
                "19.66",
                "12.48",
                "19.66"
            ],
            [
                "28.56",
                "39.92",
                "28.56",
                "39.92"
            ],
            [
                "30.16",
                "42.51",
                "30.16",
                "42.51"
            ],
            [
                "23.2",
                "34.84",
                "23.2",
                "24.84"
            ],
            [
                "29.13",
                "40.59",
                "30.25",
                "41.45"
            ],
            [
                "32.31",
                "43.16",
                "36.42",
                "48.22"
            ],
            [
                "32.31",
                "43.16",
                "36.79",
                "48.27"
            ],
            [
                "32.31",
                "43.16",
                "37.03",
                "48.26"
            ],
            [
                "32.31",
                "43.16",
                "36.24",
                "48.6"
            ],
            [
                "33.92",
                "45.96",
                "39.31",
                "52.53"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "MAP",
            "HITS@10",
            "MAP",
            "HITS@10"
        ],
        "target_entity": [
            "ALL-PATHS+NODES d=100"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>KB || MAP</th>      <th>KB || HITS@10</th>      <th>KB and Text || MAP</th>      <th>KB and Text || HITS@10</th>    </tr>  </thead>  <tbody>    <tr>      <td>Model || BILINEAR-DIAG (Guu et al., 2015) d=100</td>      <td>12.48</td>      <td>19.66</td>      <td>12.48</td>      <td>19.66</td>    </tr>    <tr>      <td>Model || BILINEAR-DIAG d=100</td>      <td>28.56</td>      <td>39.92</td>      <td>28.56</td>      <td>39.92</td>    </tr>    <tr>      <td>Model || BILINEAR-DIAG d=2000</td>      <td>30.16</td>      <td>42.51</td>      <td>30.16</td>      <td>42.51</td>    </tr>    <tr>      <td>Model || +Guu et al. (2015) d=100 orig.</td>      <td>23.2</td>      <td>34.84</td>      <td>23.2</td>      <td>24.84</td>    </tr>    <tr>      <td>Model || +Guu et al. (2015) d=100 reimpl.</td>      <td>29.13</td>      <td>40.59</td>      <td>30.25</td>      <td>41.45</td>    </tr>    <tr>      <td>Model || PRUNED-PATHS d=100 c=1000</td>      <td>32.31</td>      <td>43.16</td>      <td>36.42</td>      <td>48.22</td>    </tr>    <tr>      <td>Model || PRUNED-PATHS d=100 c=100</td>      <td>32.31</td>      <td>43.16</td>      <td>36.79</td>      <td>48.27</td>    </tr>    <tr>      <td>Model || PRUNED-PATHS d=100 c=1</td>      <td>32.31</td>      <td>43.16</td>      <td>37.03</td>      <td>48.26</td>    </tr>    <tr>      <td>Model || ALL-PATHS d=100</td>      <td>32.31</td>      <td>43.16</td>      <td>36.24</td>      <td>48.6</td>    </tr>    <tr>      <td>Model || ALL-PATHS+NODES d=100</td>      <td>33.92</td>      <td>45.96</td>      <td>39.31</td>      <td>52.53</td>    </tr>  </tbody></table>",
        "table_name": "Table 1",
        "table_id": "table_1",
        "paper_id": "P16-1136",
        "page_no": 7,
        "dir": "acl2016",
        "valid": 1
    },
    {
        "table_id_paper": "P16-1159table_8",
        "caption": "Comparison with previous work on English-German translation. The BLEU scores are casesensitive.",
        "row_header_level": 6,
        "row_headers": [
            [
                "Existing end-to-end NMT systems",
                "Jean et al. (2015)",
                "Architecture",
                "gated RNN with search",
                "Training",
                "MLE"
            ],
            [
                "Existing end-to-end NMT systems",
                "Jean et al. (2015)",
                "Architecture",
                "gated RNN with search + PosUnk",
                "Training",
                "MLE"
            ],
            [
                "Existing end-to-end NMT systems",
                "Jean et al. (2015)",
                "Architecture",
                "gated RNN with search + LV + PosUnk",
                "Training",
                "MLE"
            ],
            [
                "Existing end-to-end NMT systems",
                "Luong et al. (2015a)",
                "Architecture",
                "LSTM with 4 layers + dropout + local att. + PosUnk",
                "Training",
                "MLE"
            ],
            [
                "Our end-to-end NMT systems",
                "this work",
                "Architecture",
                "gated RNN with search",
                "Training",
                "MLE"
            ],
            [
                "Our end-to-end NMT systems",
                "this work",
                "Architecture",
                "gated RNN with search",
                "Training",
                "MRT"
            ],
            [
                "Our end-to-end NMT systems",
                "this work",
                "Architecture",
                "gated RNN with search + PosUnk",
                "Training",
                "MRT"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "BLEU"
            ]
        ],
        "contents": [
            [
                "16.46"
            ],
            [
                "18.97"
            ],
            [
                "19.4"
            ],
            [
                "20.9"
            ],
            [
                "16.45"
            ],
            [
                "18.02"
            ],
            [
                "20.45"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "BLEU"
        ],
        "target_entity": [
            "gated RNN with search + PosUnk"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>BLEU</th>    </tr>  </thead>  <tbody>    <tr>      <td>Existing end-to-end NMT systems || Jean et al. (2015) || Architecture || gated RNN with search || Training || MLE</td>      <td>16.46</td>    </tr>    <tr>      <td>Existing end-to-end NMT systems || Jean et al. (2015) || Architecture || gated RNN with search + PosUnk || Training || MLE</td>      <td>18.97</td>    </tr>    <tr>      <td>Existing end-to-end NMT systems || Jean et al. (2015) || Architecture || gated RNN with search + LV + PosUnk || Training || MLE</td>      <td>19.4</td>    </tr>    <tr>      <td>Existing end-to-end NMT systems || Luong et al. (2015a) || Architecture || LSTM with 4 layers + dropout + local att. + PosUnk || Training || MLE</td>      <td>20.9</td>    </tr>    <tr>      <td>Our end-to-end NMT systems || this work || Architecture || gated RNN with search || Training || MLE</td>      <td>16.45</td>    </tr>    <tr>      <td>Our end-to-end NMT systems || this work || Architecture || gated RNN with search || Training || MRT</td>      <td>18.02</td>    </tr>    <tr>      <td>Our end-to-end NMT systems || this work || Architecture || gated RNN with search + PosUnk || Training || MRT</td>      <td>20.45</td>    </tr>  </tbody></table>",
        "table_name": "Table 8",
        "table_id": "table_8",
        "paper_id": "P16-1159",
        "page_no": 8,
        "dir": "acl2016",
        "valid": 1
    },
    {
        "table_id_paper": "P16-1181table_2",
        "caption": "Results (F1) for baselines for sentence boundary detection on dev sets.",
        "row_header_level": 1,
        "row_headers": [
            [
                "OPENNLP"
            ],
            [
                "CORENLP"
            ],
            [
                "MARMOT"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "WSJ"
            ],
            [
                "Switchboard"
            ]
        ],
        "contents": [
            [
                "98.09",
                "-"
            ],
            [
                "98.6",
                "-"
            ],
            [
                "98.21",
                "71.78"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "F1",
            "F1"
        ],
        "target_entity": [
            "MARMOT"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>WSJ</th>      <th>Switchboard</th>    </tr>  </thead>  <tbody>    <tr>      <td>OPENNLP</td>      <td>98.09</td>      <td>-</td>    </tr>    <tr>      <td>CORENLP</td>      <td>98.6</td>      <td>-</td>    </tr>    <tr>      <td>MARMOT</td>      <td>98.21</td>      <td>71.78</td>    </tr>  </tbody></table>",
        "table_name": "Table 2",
        "table_id": "table_2",
        "paper_id": "P16-1181",
        "page_no": 6,
        "dir": "acl2016",
        "valid": 1
    },
    {
        "table_id_paper": "P16-1195table_5",
        "caption": "MRR for the RET task. Dev set results in parentheses.",
        "row_header_level": 3,
        "row_headers": [
            [
                "C#",
                "Model",
                "RET-IR"
            ],
            [
                "C#",
                "Model",
                "CODE-NN"
            ],
            [
                "SQL",
                "Model",
                "RET-IR"
            ],
            [
                "SQL",
                "Model",
                "CODE-NN"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "MRR"
            ]
        ],
        "contents": [
            [
                "0.42 \u00b1 0.02 (0.44 \u00b1 0.01)"
            ],
            [
                "0.58 \u00b1 0.01 (0.66 \u00b1 0.02)"
            ],
            [
                "0.28 \u00b10.01(0.4 \u00b1 0.01)"
            ],
            [
                "0.44 \u00b1 0.01 (0.54 \u00b1 0.02)"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "MRR"
        ],
        "target_entity": [
            "CODE-NN"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>MRR</th>    </tr>  </thead>  <tbody>    <tr>      <td>C# || Model || RET-IR</td>      <td>0.42 \u00b1 0.02 (0.44 \u00b1 0.01)</td>    </tr>    <tr>      <td>C# || Model || CODE-NN</td>      <td>0.58 \u00b1 0.01 (0.66 \u00b1 0.02)</td>    </tr>    <tr>      <td>SQL || Model || RET-IR</td>      <td>0.28 \u00b10.01(0.4 \u00b1 0.01)</td>    </tr>    <tr>      <td>SQL || Model || CODE-NN</td>      <td>0.44 \u00b1 0.01 (0.54 \u00b1 0.02)</td>    </tr>  </tbody></table>",
        "table_name": "Table 5",
        "table_id": "table_5",
        "paper_id": "P16-1195",
        "page_no": 8,
        "dir": "acl2016",
        "valid": 1
    },
    {
        "table_id_paper": "P16-1203table_5",
        "caption": "Performance of J48 for different feature settings",
        "row_header_level": 1,
        "row_headers": [
            [
                "Without domain features"
            ],
            [
                "Only domain features"
            ],
            [
                "Only phonological features"
            ],
            [
                "Without poetic features"
            ],
            [
                "Without consonance feature"
            ],
            [
                "Without emotions features"
            ],
            [
                "Without phonological features"
            ],
            [
                "Without social features"
            ],
            [
                "All features"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "Rec."
            ],
            [
                "Prec."
            ],
            [
                "F-score"
            ]
        ],
        "contents": [
            [
                "0.803",
                "0.801",
                "0.802"
            ],
            [
                "0.725",
                "0.699",
                "0.667"
            ],
            [
                "0.790",
                "0.786",
                "0.787"
            ],
            [
                "0.836",
                "0.832",
                "0.833"
            ],
            [
                "0.823",
                "0.820",
                "0.821"
            ],
            [
                "0.814",
                "0.810",
                "0.811"
            ],
            [
                "0.798",
                "0.792",
                "0.793"
            ],
            [
                "0.807",
                "0.803",
                "0.804"
            ],
            [
                "0.824",
                "0.822",
                "0.823"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "Rec.",
            "Prec.",
            "F-score"
        ],
        "target_entity": [
            "Without phonological features",
            "Only phonological features"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Rec.</th>      <th>Prec.</th>      <th>F-score</th>    </tr>  </thead>  <tbody>    <tr>      <td>Without domain features</td>      <td>0.803</td>      <td>0.801</td>      <td>0.802</td>    </tr>    <tr>      <td>Only domain features</td>      <td>0.725</td>      <td>0.699</td>      <td>0.667</td>    </tr>    <tr>      <td>Only phonological features</td>      <td>0.790</td>      <td>0.786</td>      <td>0.787</td>    </tr>    <tr>      <td>Without poetic features</td>      <td>0.836</td>      <td>0.832</td>      <td>0.833</td>    </tr>    <tr>      <td>Without consonance feature</td>      <td>0.823</td>      <td>0.820</td>      <td>0.821</td>    </tr>    <tr>      <td>Without emotions features</td>      <td>0.814</td>      <td>0.810</td>      <td>0.811</td>    </tr>    <tr>      <td>Without phonological features</td>      <td>0.798</td>      <td>0.792</td>      <td>0.793</td>    </tr>    <tr>      <td>Without social features</td>      <td>0.807</td>      <td>0.803</td>      <td>0.804</td>    </tr>    <tr>      <td>All features</td>      <td>0.824</td>      <td>0.822</td>      <td>0.823</td>    </tr>  </tbody></table>",
        "table_name": "Table 5",
        "table_id": "table_5",
        "paper_id": "P16-1203",
        "page_no": 7,
        "dir": "acl2016",
        "valid": 1
    },
    {
        "table_id_paper": "P16-1209table_4",
        "caption": "Performance of various models using 50 dimensional WE features. A:Disease name recognition, B: Disease classification task",
        "row_header_level": 3,
        "row_headers": [
            [
                "Task A",
                "Model",
                "NN+WE"
            ],
            [
                "Task A",
                "Model",
                "Bi-RNN+WE"
            ],
            [
                "Task A",
                "Model",
                "Bi-GRU+WE"
            ],
            [
                "Task A",
                "Model",
                "Bi-LSTM+WE"
            ],
            [
                "Task B",
                "Model",
                "NN+WE"
            ],
            [
                "Task B",
                "Model",
                "Bi-RNN+WE"
            ],
            [
                "Task B",
                "Model",
                "Bi-GRU+WE"
            ],
            [
                "Task B",
                "Model",
                "Bi-LSTM+WE"
            ]
        ],
        "column_header_level": 2,
        "column_headers": [
            [
                "Validation Set",
                "Precision"
            ],
            [
                "Validation Set",
                "Recall"
            ],
            [
                "Validation Set",
                "F1 Score"
            ],
            [
                "Test Set",
                "Precision"
            ],
            [
                "Test Set",
                "Recall"
            ],
            [
                "Test Set",
                "F1 Score"
            ]
        ],
        "contents": [
            [
                "81.86",
                "76.82",
                "79.26",
                "80.32",
                "73.58",
                "76.81"
            ],
            [
                "84.14",
                "77.46",
                "80.67",
                "82.49",
                "73.58",
                "77.78"
            ],
            [
                "84.51",
                "78.23",
                "81.25",
                "82.32",
                "75.16",
                "78.58"
            ],
            [
                "85.13",
                "77.72",
                "81.26",
                "84.87",
                "74.11",
                "79.13"
            ],
            [
                "65.33",
                "56.43",
                "60.55",
                "64.23",
                "57.14",
                "60.48"
            ],
            [
                "63.62",
                "56.84",
                "60.04",
                "67.47",
                "57.50",
                "62.09"
            ],
            [
                "66.42",
                "57.41",
                "61.59",
                "68.25",
                "58.58",
                "63.05"
            ],
            [
                "67.48",
                "58.01",
                "62.39",
                "68.97",
                "58.25",
                "63.16"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "Precision",
            "Recall",
            "F1 Score",
            "Precision",
            "Recall",
            "F1 Score"
        ],
        "target_entity": [
            "Model"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Validation Set || Precision</th>      <th>Validation Set || Recall</th>      <th>Validation Set || F1 Score</th>      <th>Test Set || Precision</th>      <th>Test Set || Recall</th>      <th>Test Set || F1 Score</th>    </tr>  </thead>  <tbody>    <tr>      <td>Task A || Model || NN+WE</td>      <td>81.86</td>      <td>76.82</td>      <td>79.26</td>      <td>80.32</td>      <td>73.58</td>      <td>76.81</td>    </tr>    <tr>      <td>Task A || Model || Bi-RNN+WE</td>      <td>84.14</td>      <td>77.46</td>      <td>80.67</td>      <td>82.49</td>      <td>73.58</td>      <td>77.78</td>    </tr>    <tr>      <td>Task A || Model || Bi-GRU+WE</td>      <td>84.51</td>      <td>78.23</td>      <td>81.25</td>      <td>82.32</td>      <td>75.16</td>      <td>78.58</td>    </tr>    <tr>      <td>Task A || Model || Bi-LSTM+WE</td>      <td>85.13</td>      <td>77.72</td>      <td>81.26</td>      <td>84.87</td>      <td>74.11</td>      <td>79.13</td>    </tr>    <tr>      <td>Task B || Model || NN+WE</td>      <td>65.33</td>      <td>56.43</td>      <td>60.55</td>      <td>64.23</td>      <td>57.14</td>      <td>60.48</td>    </tr>    <tr>      <td>Task B || Model || Bi-RNN+WE</td>      <td>63.62</td>      <td>56.84</td>      <td>60.04</td>      <td>67.47</td>      <td>57.50</td>      <td>62.09</td>    </tr>    <tr>      <td>Task B || Model || Bi-GRU+WE</td>      <td>66.42</td>      <td>57.41</td>      <td>61.59</td>      <td>68.25</td>      <td>58.58</td>      <td>63.05</td>    </tr>    <tr>      <td>Task B || Model || Bi-LSTM+WE</td>      <td>67.48</td>      <td>58.01</td>      <td>62.39</td>      <td>68.97</td>      <td>58.25</td>      <td>63.16</td>    </tr>  </tbody></table>",
        "table_name": "Table 4",
        "table_id": "table_4",
        "paper_id": "P16-1209",
        "page_no": 7,
        "dir": "acl2016",
        "valid": 1
    },
    {
        "table_id_paper": "P16-1230table_1",
        "caption": "Subjective evaluation of the Obj=Subj, off-line RNN, Subj and on-line GP system during different stages of on-line policy learning. Subjective: user binary rating on dialogue success. Statistical significance was calculated using a twotailed Students t-test with p-value of 0.05.",
        "row_header_level": 4,
        "row_headers": [
            [
                "Dialogues",
                "400-500",
                "Reward Model",
                "Obj=Subj"
            ],
            [
                "Dialogues",
                "400-500",
                "Reward Model",
                "off-line RNN"
            ],
            [
                "Dialogues",
                "400-500",
                "Reward Model",
                "Subj"
            ],
            [
                "Dialogues",
                "400-500",
                "Reward Model",
                "on-line GP"
            ],
            [
                "Dialogues",
                "500-850",
                "Reward Model",
                "Subj"
            ],
            [
                "Dialogues",
                "500-850",
                "Reward Model",
                "on-line GP"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "Subjective (%)"
            ]
        ],
        "contents": [
            [
                "85.0 \u00b1 2.1"
            ],
            [
                "89.0 \u00b1 1.8"
            ],
            [
                "90.7 \u00b1 1.7"
            ],
            [
                "91.7 \u00b1 1.6"
            ],
            [
                "87.1 \u00b1 1.0"
            ],
            [
                "90.9 \u00b1 0.9*"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "Subjective (%)"
        ],
        "target_entity": [
            "on-line GP"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Subjective (%)</th>    </tr>  </thead>  <tbody>    <tr>      <td>Dialogues || 400-500 || Reward Model || Obj=Subj</td>      <td>85.0 \u00b1 2.1</td>    </tr>    <tr>      <td>Dialogues || 400-500 || Reward Model || off-line RNN</td>      <td>89.0 \u00b1 1.8</td>    </tr>    <tr>      <td>Dialogues || 400-500 || Reward Model || Subj</td>      <td>90.7 \u00b1 1.7</td>    </tr>    <tr>      <td>Dialogues || 400-500 || Reward Model || on-line GP</td>      <td>91.7 \u00b1 1.6</td>    </tr>    <tr>      <td>Dialogues || 500-850 || Reward Model || Subj</td>      <td>87.1 \u00b1 1.0</td>    </tr>    <tr>      <td>Dialogues || 500-850 || Reward Model || on-line GP</td>      <td>90.9 \u00b1 0.9*</td>    </tr>  </tbody></table>",
        "table_name": "Table 1",
        "table_id": "table_1",
        "paper_id": "P16-1230",
        "page_no": 9,
        "dir": "acl2016",
        "valid": 1
    },
    {
        "table_id_paper": "P16-2006table_4",
        "caption": "Development and test set results for shiftreduce dependency parser on Penn Chinese Treebank (CTB-5) using only (s1, s0, q0) position features (trained and tested with gold POS tags).",
        "row_header_level": 2,
        "row_headers": [
            [
                "Parser",
                "C & M 2014"
            ],
            [
                "Parser",
                "Dyer et al. 2015"
            ],
            [
                "Parser",
                "Bi-LSTM"
            ],
            [
                "Parser",
                "2-Layer Bi-LSTM"
            ]
        ],
        "column_header_level": 2,
        "column_headers": [
            [
                "Dev",
                "UAS"
            ],
            [
                "Dev",
                "LAS"
            ],
            [
                "Test",
                "UAS"
            ],
            [
                "Test",
                "LAS"
            ]
        ],
        "contents": [
            [
                "84.0",
                "82.4",
                "83.9",
                "82.4"
            ],
            [
                "87.2",
                "85.9",
                "87.2",
                "85.7"
            ],
            [
                "85.84",
                "85.24",
                "85.53",
                "84.89"
            ],
            [
                "86.13",
                "85.51",
                "86.35",
                "85.71"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "UAS",
            "LAS",
            "UAS",
            "LAS"
        ],
        "target_entity": [
            "Bi-LSTM",
            "2-Layer Bi-LSTM"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Dev || UAS</th>      <th>Dev || LAS</th>      <th>Test || UAS</th>      <th>Test || LAS</th>    </tr>  </thead>  <tbody>    <tr>      <td>Parser || C &amp; M 2014</td>      <td>84.0</td>      <td>82.4</td>      <td>83.9</td>      <td>82.4</td>    </tr>    <tr>      <td>Parser || Dyer et al. 2015</td>      <td>87.2</td>      <td>85.9</td>      <td>87.2</td>      <td>85.7</td>    </tr>    <tr>      <td>Parser || Bi-LSTM</td>      <td>85.84</td>      <td>85.24</td>      <td>85.53</td>      <td>84.89</td>    </tr>    <tr>      <td>Parser || 2-Layer Bi-LSTM</td>      <td>86.13</td>      <td>85.51</td>      <td>86.35</td>      <td>85.71</td>    </tr>  </tbody></table>",
        "table_name": "Table 4",
        "table_id": "table_4",
        "paper_id": "P16-2006",
        "page_no": 5,
        "dir": "acl2016",
        "valid": 1
    },
    {
        "table_id_paper": "P17-1171table_4",
        "caption": "Evaluation results on the SQuAD dataset (single model only). \u2020: Test results re\ufb02ect the SQuAD leaderboard (https://stanford-qa.com) as of Feb 6, 2017.",
        "row_header_level": 2,
        "row_headers": [
            [
                "Method",
                "Dynamic Coattention Networks (Xiong et al. 2016)"
            ],
            [
                "Method",
                "Multi-Perspective Matching (Wang et al. 2016)\u2020"
            ],
            [
                "Method",
                "BiDAF (Seo et al. 2016)"
            ],
            [
                "Method",
                "R-net\u2020"
            ],
            [
                "Method",
                "DrQA (Our model Document Reader Only)"
            ]
        ],
        "column_header_level": 2,
        "column_headers": [
            [
                "Dev",
                "EM"
            ],
            [
                "Dev",
                "F1"
            ],
            [
                "Test",
                "EM"
            ],
            [
                "Test",
                "F1"
            ]
        ],
        "contents": [
            [
                "65.4",
                "75.6",
                "66.2",
                "75.9"
            ],
            [
                "66.1",
                "75.8",
                "65.5",
                "75.1"
            ],
            [
                "67.7",
                "77.3",
                "68.0",
                "77.3"
            ],
            [
                "n/a",
                "n/a",
                "71.3",
                "79.7"
            ],
            [
                "69.5",
                "78.8",
                "70.0",
                "79.0"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "EM",
            "F1",
            "EM",
            "F1"
        ],
        "target_entity": [
            "DrQA (Our model Document Reader Only)"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Dev || EM</th>      <th>Dev || F1</th>      <th>Test || EM</th>      <th>Test || F1</th>    </tr>  </thead>  <tbody>    <tr>      <td>Method || Dynamic Coattention Networks (Xiong et al. 2016)</td>      <td>65.4</td>      <td>75.6</td>      <td>66.2</td>      <td>75.9</td>    </tr>    <tr>      <td>Method || Multi-Perspective Matching (Wang et al. 2016)\u2020</td>      <td>66.1</td>      <td>75.8</td>      <td>65.5</td>      <td>75.1</td>    </tr>    <tr>      <td>Method || BiDAF (Seo et al. 2016)</td>      <td>67.7</td>      <td>77.3</td>      <td>68.0</td>      <td>77.3</td>    </tr>    <tr>      <td>Method || R-net\u2020</td>      <td>n/a</td>      <td>n/a</td>      <td>71.3</td>      <td>79.7</td>    </tr>    <tr>      <td>Method || DrQA (Our model Document Reader Only)</td>      <td>69.5</td>      <td>78.8</td>      <td>70.0</td>      <td>79.0</td>    </tr>  </tbody></table>",
        "table_name": "Table 4",
        "table_id": "table_4",
        "paper_id": "P17-1171",
        "page_no": 8,
        "dir": "acl2017",
        "valid": 1
    },
    {
        "table_id_paper": "P17-2007table_2",
        "caption": "Multi-source parsing results in terms of average accuracy % over 3 runs. Best results are in bold.",
        "row_header_level": 2,
        "row_headers": [
            [
                "GEO",
                "en+de+el"
            ],
            [
                "GEO",
                "en+de+th"
            ],
            [
                "GEO",
                "en+el+th"
            ],
            [
                "GEO",
                "de+el+th"
            ],
            [
                "GEO",
                "en+de+el+th"
            ],
            [
                "ATIS",
                "en+id"
            ],
            [
                "ATIS",
                "en+zh"
            ],
            [
                "ATIS",
                "id+zh"
            ],
            [
                "ATIS",
                "en+id+zh"
            ]
        ],
        "column_header_level": 2,
        "column_headers": [
            [
                "RANKING",
                "-"
            ],
            [
                "MULTI",
                "word"
            ],
            [
                "MULTI",
                "sentence"
            ]
        ],
        "contents": [
            [
                "83.21",
                "85.48",
                "86.43"
            ],
            [
                "82.02",
                "86.19",
                "85.48"
            ],
            [
                "82.62",
                "85.60",
                "85.24"
            ],
            [
                "79.64",
                "72.14",
                "76.43"
            ],
            [
                "82.50",
                "85.48",
                "86.79"
            ],
            [
                "82.81",
                "83.93",
                "83.78"
            ],
            [
                "82.81",
                "82.96",
                "82.96"
            ],
            [
                "78.50",
                "76.79",
                "77.75"
            ],
            [
                "83.11",
                "82.22",
                "83.85"
            ]
        ],
        "metrics_loc": "row",
        "metrics_type": [
            "accuracy",
            "accuracy",
            "accuracy",
            "accuracy",
            "accuracy",
            "accuracy",
            "accuracy",
            "accuracy",
            "accuracy"
        ],
        "target_entity": [
            "MULTI"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>RANKING || -</th>      <th>MULTI || word</th>      <th>MULTI || sentence</th>    </tr>  </thead>  <tbody>    <tr>      <td>GEO || en+de+el</td>      <td>83.21</td>      <td>85.48</td>      <td>86.43</td>    </tr>    <tr>      <td>GEO || en+de+th</td>      <td>82.02</td>      <td>86.19</td>      <td>85.48</td>    </tr>    <tr>      <td>GEO || en+el+th</td>      <td>82.62</td>      <td>85.60</td>      <td>85.24</td>    </tr>    <tr>      <td>GEO || de+el+th</td>      <td>79.64</td>      <td>72.14</td>      <td>76.43</td>    </tr>    <tr>      <td>GEO || en+de+el+th</td>      <td>82.50</td>      <td>85.48</td>      <td>86.79</td>    </tr>    <tr>      <td>ATIS || en+id</td>      <td>82.81</td>      <td>83.93</td>      <td>83.78</td>    </tr>    <tr>      <td>ATIS || en+zh</td>      <td>82.81</td>      <td>82.96</td>      <td>82.96</td>    </tr>    <tr>      <td>ATIS || id+zh</td>      <td>78.50</td>      <td>76.79</td>      <td>77.75</td>    </tr>    <tr>      <td>ATIS || en+id+zh</td>      <td>83.11</td>      <td>82.22</td>      <td>83.85</td>    </tr>  </tbody></table>",
        "table_name": "Table 2",
        "table_id": "table_2",
        "paper_id": "P17-2007",
        "page_no": 4,
        "dir": "acl2017",
        "valid": 1
    },
    {
        "table_id_paper": "P17-2021table_1",
        "caption": "BLEU results for the WMT16 experiment",
        "row_header_level": 2,
        "row_headers": [
            [
                "system",
                "bpe2bpe"
            ],
            [
                "system",
                "bpe2tree"
            ],
            [
                "system",
                "bpe2bpe ens."
            ],
            [
                "system",
                "bpe2tree ens."
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "newstest2015"
            ],
            [
                "newstest2016"
            ]
        ],
        "contents": [
            [
                "27.33",
                "31.19"
            ],
            [
                "27.36",
                "32.13"
            ],
            [
                "28.62",
                "32.38"
            ],
            [
                "28.7",
                "33.24"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "BLEU",
            "BLEU"
        ],
        "target_entity": [
            "system"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>newstest2015</th>      <th>newstest2016</th>    </tr>  </thead>  <tbody>    <tr>      <td>system || bpe2bpe</td>      <td>27.33</td>      <td>31.19</td>    </tr>    <tr>      <td>system || bpe2tree</td>      <td>27.36</td>      <td>32.13</td>    </tr>    <tr>      <td>system || bpe2bpe ens.</td>      <td>28.62</td>      <td>32.38</td>    </tr>    <tr>      <td>system || bpe2tree ens.</td>      <td>28.7</td>      <td>33.24</td>    </tr>  </tbody></table>",
        "table_name": "Table 1",
        "table_id": "table_1",
        "paper_id": "P17-2021",
        "page_no": 3,
        "dir": "acl2017",
        "valid": 1
    },
    {
        "table_id_paper": "P17-2042table_3",
        "caption": "Results of using different word embeddings. We also list the Precision, Recall and F1 score for each relation.",
        "row_header_level": 3,
        "row_headers": [
            [
                "CDRR",
                "Temp",
                "P"
            ],
            [
                "CDRR",
                "Temp",
                "R"
            ],
            [
                "CDRR",
                "Temp",
                "F1"
            ],
            [
                "CDRR",
                "Comp",
                "P"
            ],
            [
                "CDRR",
                "Comp",
                "R"
            ],
            [
                "CDRR",
                "Comp",
                "F1"
            ],
            [
                "CDRR",
                "Cont",
                "P"
            ],
            [
                "CDRR",
                "Cont",
                "R"
            ],
            [
                "CDRR",
                "Cont",
                "F1"
            ],
            [
                "CDRR",
                "Expa",
                "P"
            ],
            [
                "CDRR",
                "Expa",
                "R"
            ],
            [
                "CDRR",
                "Expa",
                "F1"
            ],
            [
                "CDRR",
                "-",
                "Accuracy"
            ],
            [
                "CDRR",
                "-",
                "Macro F1"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "+GloVe"
            ],
            [
                "+word2vec"
            ],
            [
                "+DSWE"
            ]
        ],
        "contents": [
            [
                "36.00",
                "27.03",
                "31.58"
            ],
            [
                "16.36",
                "18.18",
                "21.82"
            ],
            [
                "22.50",
                "21.74",
                "25.81"
            ],
            [
                "53.97",
                "50.00",
                "43.00"
            ],
            [
                "23.45",
                "20.00",
                "29.66"
            ],
            [
                "32.69",
                "28.57",
                "35.10"
            ],
            [
                "44.90",
                "51.81",
                "55.29"
            ],
            [
                "40.29",
                "36.63",
                "42.12"
            ],
            [
                "42.47",
                "42.92",
                "47.82"
            ],
            [
                "60.47",
                "60.72",
                "63.91"
            ],
            [
                "76.21",
                "81.60",
                "79.00"
            ],
            [
                "67.43",
                "69.63",
                "70.66"
            ],
            [
                "55.68",
                "57.17",
                "58.85"
            ],
            [
                "41.27",
                "40.71",
                "44.84"
            ]
        ],
        "metrics_loc": "row",
        "metrics_type": [
            "P",
            "R",
            "F1",
            "P",
            "R",
            "F1",
            "P",
            "R",
            "F1",
            "P",
            "R",
            "F1",
            "Accuracy",
            "Macro F1"
        ],
        "target_entity": [
            "+DSWE"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>+GloVe</th>      <th>+word2vec</th>      <th>+DSWE</th>    </tr>  </thead>  <tbody>    <tr>      <td>CDRR || Temp || P</td>      <td>36.00</td>      <td>27.03</td>      <td>31.58</td>    </tr>    <tr>      <td>CDRR || Temp || R</td>      <td>16.36</td>      <td>18.18</td>      <td>21.82</td>    </tr>    <tr>      <td>CDRR || Temp || F1</td>      <td>22.50</td>      <td>21.74</td>      <td>25.81</td>    </tr>    <tr>      <td>CDRR || Comp || P</td>      <td>53.97</td>      <td>50.00</td>      <td>43.00</td>    </tr>    <tr>      <td>CDRR || Comp || R</td>      <td>23.45</td>      <td>20.00</td>      <td>29.66</td>    </tr>    <tr>      <td>CDRR || Comp || F1</td>      <td>32.69</td>      <td>28.57</td>      <td>35.10</td>    </tr>    <tr>      <td>CDRR || Cont || P</td>      <td>44.90</td>      <td>51.81</td>      <td>55.29</td>    </tr>    <tr>      <td>CDRR || Cont || R</td>      <td>40.29</td>      <td>36.63</td>      <td>42.12</td>    </tr>    <tr>      <td>CDRR || Cont || F1</td>      <td>42.47</td>      <td>42.92</td>      <td>47.82</td>    </tr>    <tr>      <td>CDRR || Expa || P</td>      <td>60.47</td>      <td>60.72</td>      <td>63.91</td>    </tr>    <tr>      <td>CDRR || Expa || R</td>      <td>76.21</td>      <td>81.60</td>      <td>79.00</td>    </tr>    <tr>      <td>CDRR || Expa || F1</td>      <td>67.43</td>      <td>69.63</td>      <td>70.66</td>    </tr>    <tr>      <td>CDRR || - || Accuracy</td>      <td>55.68</td>      <td>57.17</td>      <td>58.85</td>    </tr>    <tr>      <td>CDRR || - || Macro F1</td>      <td>41.27</td>      <td>40.71</td>      <td>44.84</td>    </tr>  </tbody></table>",
        "table_name": "Table 3",
        "table_id": "table_3",
        "paper_id": "P17-2042",
        "page_no": 4,
        "dir": "acl2017",
        "valid": 1
    },
    {
        "table_id_paper": "P17-2042table_4",
        "caption": "Comparison with recent systems.",
        "row_header_level": 2,
        "row_headers": [
            [
                "System",
                "R&X2015"
            ],
            [
                "System",
                "B&D2016"
            ],
            [
                "System",
                "Liu2016"
            ],
            [
                "System",
                "CDRR+DSWE"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "Accuracy"
            ],
            [
                "Macro F1"
            ]
        ],
        "contents": [
            [
                "57.10",
                "40.50"
            ],
            [
                "52.81",
                "42.27"
            ],
            [
                "57.27",
                "44.98"
            ],
            [
                "58.85",
                "44.84"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "Accuracy",
            "Macro F1"
        ],
        "target_entity": [
            "CDRR+DSWE"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Accuracy</th>      <th>Macro F1</th>    </tr>  </thead>  <tbody>    <tr>      <td>System || R&amp;X2015</td>      <td>57.10</td>      <td>40.50</td>    </tr>    <tr>      <td>System || B&amp;D2016</td>      <td>52.81</td>      <td>42.27</td>    </tr>    <tr>      <td>System || Liu2016</td>      <td>57.27</td>      <td>44.98</td>    </tr>    <tr>      <td>System || CDRR+DSWE</td>      <td>58.85</td>      <td>44.84</td>    </tr>  </tbody></table>",
        "table_name": "Table 4",
        "table_id": "table_4",
        "paper_id": "P17-2042",
        "page_no": 4,
        "dir": "acl2017",
        "valid": 1
    },
    {
        "table_id_paper": "P17-2079table_3",
        "caption": "Comparison with another chatbot.",
        "row_header_level": 1,
        "row_headers": [
            [
                "Number"
            ],
            [
                "Percentage"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "Win"
            ],
            [
                "Equal"
            ],
            [
                "Lose"
            ]
        ],
        "contents": [
            [
                "330",
                "382",
                "165"
            ],
            [
                "37.64%",
                "43.52%",
                "18.84%"
            ]
        ],
        "metrics_loc": "row",
        "metrics_type": [
            "Number",
            "Percentage"
        ],
        "target_entity": [
            "Win",
            "Equal",
            "Lose"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Win</th>      <th>Equal</th>      <th>Lose</th>    </tr>  </thead>  <tbody>    <tr>      <td>Number</td>      <td>330</td>      <td>382</td>      <td>165</td>    </tr>    <tr>      <td>Percentage</td>      <td>37.64%</td>      <td>43.52%</td>      <td>18.84%</td>    </tr>  </tbody></table>",
        "table_name": "Table 3",
        "table_id": "table_3",
        "paper_id": "P17-2079",
        "page_no": 4,
        "dir": "acl2017",
        "valid": 1
    },
    {
        "table_id_paper": "P18-1003table_2",
        "caption": "Results for the relation induction task using alternative word embedding models.",
        "row_header_level": 1,
        "row_headers": [
            [
                "Diff"
            ],
            [
                "Conc"
            ],
            [
                "Avg"
            ],
            [
                "R1ik"
            ],
            [
                "R2ik"
            ],
            [
                "R3ik"
            ],
            [
                "R4ik"
            ]
        ],
        "column_header_level": 3,
        "column_headers": [
            [
                "GloVe",
                "Google",
                "Acc"
            ],
            [
                "GloVe",
                "Google",
                "F1"
            ],
            [
                "GloVe",
                "DiffVec",
                "Acc"
            ],
            [
                "GloVe",
                "DiffVec",
                "F1"
            ],
            [
                "SkipGram",
                "Google",
                "Acc"
            ],
            [
                "SkipGram",
                "Google",
                "F1"
            ],
            [
                "SkipGram",
                "DiffVec",
                "Acc"
            ],
            [
                "SkipGram",
                "DiffVec",
                "F1"
            ],
            [
                "CBOW",
                "Google",
                "Acc"
            ],
            [
                "CBOW",
                "Google",
                "F1"
            ],
            [
                "CBOW",
                "DiffVec",
                "Acc"
            ],
            [
                "CBOW",
                "DiffVec",
                "F1"
            ]
        ],
        "contents": [
            [
                "90",
                "81.9",
                "21.2",
                "13.9",
                "89.8",
                "81.9",
                "21.7",
                "14.5",
                "89.9",
                "82.1",
                "17.4",
                "9.7"
            ],
            [
                "88.9",
                "80.4",
                "20.2",
                "11.9",
                "89.2",
                "81.6",
                "20.5",
                "12",
                "89.1",
                "81.1",
                "16.4",
                "7.7"
            ],
            [
                "89.8",
                "82.1",
                "21.4",
                "13.9",
                "90.2",
                "82.4",
                "21.8",
                "14.4",
                "89.8",
                "82.2",
                "17.5",
                "10"
            ],
            [
                "89.7",
                "81.7",
                "20.9",
                "12.5",
                "89.4",
                "81.2",
                "21.1",
                "12.3",
                "89.8",
                "81.9",
                "17.2",
                "9.2"
            ],
            [
                "90",
                "82.8",
                "21.2",
                "13.4",
                "89.1",
                "81.3",
                "21.1",
                "12.9",
                "90.2",
                "82.4",
                "17.7",
                "10"
            ],
            [
                "90",
                "82.3",
                "20",
                "11.2",
                "89.5",
                "81.1",
                "20.5",
                "12.3",
                "89.5",
                "81.1",
                "17.2",
                "9.6"
            ],
            [
                "90",
                "82.5",
                "20",
                "11.4",
                "88.9",
                "80.8",
                "20.6",
                "12.1",
                "90.5",
                "82.2",
                "17.1",
                "8.4"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "Acc",
            "F1",
            "Acc",
            "F1",
            "Acc",
            "F1",
            "Acc",
            "F1",
            "Acc",
            "F1",
            "Acc",
            "F1"
        ],
        "target_entity": [
            "R1ik",
            "R2ik",
            "R3ik",
            "R4ik"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>GloVe || Google || Acc</th>      <th>GloVe || Google || F1</th>      <th>GloVe || DiffVec || Acc</th>      <th>GloVe || DiffVec || F1</th>      <th>SkipGram || Google || Acc</th>      <th>SkipGram || Google || F1</th>      <th>SkipGram || DiffVec || Acc</th>      <th>SkipGram || DiffVec || F1</th>      <th>CBOW || Google || Acc</th>      <th>CBOW || Google || F1</th>      <th>CBOW || DiffVec || Acc</th>      <th>CBOW || DiffVec || F1</th>    </tr>  </thead>  <tbody>    <tr>      <td>Diff</td>      <td>90</td>      <td>81.9</td>      <td>21.2</td>      <td>13.9</td>      <td>89.8</td>      <td>81.9</td>      <td>21.7</td>      <td>14.5</td>      <td>89.9</td>      <td>82.1</td>      <td>17.4</td>      <td>9.7</td>    </tr>    <tr>      <td>Conc</td>      <td>88.9</td>      <td>80.4</td>      <td>20.2</td>      <td>11.9</td>      <td>89.2</td>      <td>81.6</td>      <td>20.5</td>      <td>12</td>      <td>89.1</td>      <td>81.1</td>      <td>16.4</td>      <td>7.7</td>    </tr>    <tr>      <td>Avg</td>      <td>89.8</td>      <td>82.1</td>      <td>21.4</td>      <td>13.9</td>      <td>90.2</td>      <td>82.4</td>      <td>21.8</td>      <td>14.4</td>      <td>89.8</td>      <td>82.2</td>      <td>17.5</td>      <td>10</td>    </tr>    <tr>      <td>R1ik</td>      <td>89.7</td>      <td>81.7</td>      <td>20.9</td>      <td>12.5</td>      <td>89.4</td>      <td>81.2</td>      <td>21.1</td>      <td>12.3</td>      <td>89.8</td>      <td>81.9</td>      <td>17.2</td>      <td>9.2</td>    </tr>    <tr>      <td>R2ik</td>      <td>90</td>      <td>82.8</td>      <td>21.2</td>      <td>13.4</td>      <td>89.1</td>      <td>81.3</td>      <td>21.1</td>      <td>12.9</td>      <td>90.2</td>      <td>82.4</td>      <td>17.7</td>      <td>10</td>    </tr>    <tr>      <td>R3ik</td>      <td>90</td>      <td>82.3</td>      <td>20</td>      <td>11.2</td>      <td>89.5</td>      <td>81.1</td>      <td>20.5</td>      <td>12.3</td>      <td>89.5</td>      <td>81.1</td>      <td>17.2</td>      <td>9.6</td>    </tr>    <tr>      <td>R4ik</td>      <td>90</td>      <td>82.5</td>      <td>20</td>      <td>11.4</td>      <td>88.9</td>      <td>80.8</td>      <td>20.6</td>      <td>12.1</td>      <td>90.5</td>      <td>82.2</td>      <td>17.1</td>      <td>8.4</td>    </tr>  </tbody></table>",
        "table_name": "Table 2",
        "table_id": "table_2",
        "paper_id": "P18-1003",
        "page_no": 7,
        "dir": "acl2018",
        "valid": 1
    },
    {
        "table_id_paper": "P18-1014table_1",
        "caption": "Performance on Daily-Mail test set using the limited length recall of Rouge at 75 bytes.",
        "row_header_level": 3,
        "row_headers": [
            [
                "baseline",
                "Models",
                "Lead-3"
            ],
            [
                "baseline",
                "Models",
                "NN"
            ],
            [
                "baseline",
                "Models",
                "SummaRuNNer-abs"
            ],
            [
                "baseline",
                "Models",
                "SummaRuNNer"
            ],
            [
                "-",
                "Models",
                "SWAP-NET"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "R1"
            ],
            [
                "R2"
            ],
            [
                "RL"
            ]
        ],
        "contents": [
            [
                "21.9",
                "7.2",
                "11.6"
            ],
            [
                "22.7",
                "8.5",
                "12.5"
            ],
            [
                "23.8",
                "9.6",
                "13.3"
            ],
            [
                "26.2",
                "10.8",
                "14.4"
            ],
            [
                "26.4",
                "10.7",
                "14.4"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "R1",
            "R2",
            "RL"
        ],
        "target_entity": [
            "SWAP-NET"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>R1</th>      <th>R2</th>      <th>RL</th>    </tr>  </thead>  <tbody>    <tr>      <td>baseline || Models || Lead-3</td>      <td>21.9</td>      <td>7.2</td>      <td>11.6</td>    </tr>    <tr>      <td>baseline || Models || NN</td>      <td>22.7</td>      <td>8.5</td>      <td>12.5</td>    </tr>    <tr>      <td>baseline || Models || SummaRuNNer-abs</td>      <td>23.8</td>      <td>9.6</td>      <td>13.3</td>    </tr>    <tr>      <td>baseline || Models || SummaRuNNer</td>      <td>26.2</td>      <td>10.8</td>      <td>14.4</td>    </tr>    <tr>      <td>- || Models || SWAP-NET</td>      <td>26.4</td>      <td>10.7</td>      <td>14.4</td>    </tr>  </tbody></table>",
        "table_name": "Table 1",
        "table_id": "table_1",
        "paper_id": "P18-1014",
        "page_no": 7,
        "dir": "acl2018",
        "valid": 1
    },
    {
        "table_id_paper": "P18-1044table_5",
        "caption": "The results of case analysis (Case) and zero anaphora resolution (Zero). We use F-measure as an evaluation measure. \u2021 denotes that the improvement is statistically significant at p < 0.05, compared with Gen using paired t-test.",
        "row_header_level": 1,
        "row_headers": [
            [
                "Ouchi+ 2015"
            ],
            [
                "Shibata+ 2016"
            ],
            [
                "Gen"
            ],
            [
                "Gen+Adv"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "Case"
            ],
            [
                "Zero"
            ]
        ],
        "contents": [
            [
                "76.5",
                "42.1"
            ],
            [
                "89.3",
                "53.4"
            ],
            [
                "91.5",
                "56.2"
            ],
            [
                "92.0\u0081\u00f6",
                "58.4\u0081\u00f6"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "F-measure",
            "F-measure"
        ],
        "target_entity": [
            "Gen+Adv"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Case</th>      <th>Zero</th>    </tr>  </thead>  <tbody>    <tr>      <td>Ouchi+ 2015</td>      <td>76.5</td>      <td>42.1</td>    </tr>    <tr>      <td>Shibata+ 2016</td>      <td>89.3</td>      <td>53.4</td>    </tr>    <tr>      <td>Gen</td>      <td>91.5</td>      <td>56.2</td>    </tr>    <tr>      <td>Gen+Adv</td>      <td>92.0\u0081\u00f6</td>      <td>58.4\u0081\u00f6</td>    </tr>  </tbody></table>",
        "table_name": "Table 5",
        "table_id": "table_5",
        "paper_id": "P18-1044",
        "page_no": 7,
        "dir": "acl2018",
        "valid": 1
    },
    {
        "table_id_paper": "P18-1045table_3",
        "caption": "Results for event coreference resolution systems on the KBP 2016 and 2017 corpus. Joint learning results correspond to the actual result files evaluated in (Lu and Ng, 2017). The file was obtained from the authors.",
        "row_header_level": 2,
        "row_headers": [
            [
                "Model",
                "Local classifier"
            ],
            [
                "Model",
                "Clustering"
            ],
            [
                "Model",
                "Basic ILP"
            ],
            [
                "Model",
                "Basic ILP + Topic structure"
            ],
            [
                "Model",
                "Basic ILP + Cross-chain"
            ],
            [
                "Model",
                "Basic ILP + Distribution"
            ],
            [
                "Model",
                "Basic ILP + Subevent"
            ],
            [
                "Model",
                "Joint learning"
            ]
        ],
        "column_header_level": 2,
        "column_headers": [
            [
                "KBP 2016",
                "B3"
            ],
            [
                "KBP 2016",
                "CEAFe"
            ],
            [
                "KBP 2016",
                "MUC"
            ],
            [
                "KBP 2016",
                "BLANC"
            ],
            [
                "KBP 2016",
                "AVG"
            ],
            [
                "KBP 2017",
                "B3"
            ],
            [
                "KBP 2017",
                "CEAFe"
            ],
            [
                "KBP 2017",
                "MUC"
            ],
            [
                "KBP 2017",
                "BLANC"
            ],
            [
                "KBP 2017",
                "AVG"
            ]
        ],
        "contents": [
            [
                "51.47",
                "47.96",
                "26.29",
                "30.82",
                "39.13",
                "50.24",
                "48.47",
                "30.81",
                "29.94",
                "39.87"
            ],
            [
                "46.97",
                "41.95",
                "18.79",
                "26.88",
                "33.65",
                "46.51",
                "40.21",
                "23.1",
                "25.08",
                "33.72"
            ],
            [
                "51.44",
                "47.77",
                "26.65",
                "30.95",
                "39.19",
                "50.4",
                "48.49",
                "31.33",
                "30.58",
                "40.2"
            ],
            [
                "51.44",
                "47.94",
                "28.86",
                "31.87",
                "40.03",
                "50.39",
                "48.23",
                "33.08",
                "31.26",
                "40.74"
            ],
            [
                "51.09",
                "47.53",
                "31.27",
                "33.07",
                "40.74",
                "50.39",
                "47.67",
                "35.15",
                "31.88",
                "41.27"
            ],
            [
                "51.06",
                "48.28",
                "33.53",
                "33.63",
                "41.62",
                "50.42",
                "48.67",
                "37.52",
                "32.08",
                "42.17"
            ],
            [
                "51.67",
                "49.1",
                "34.08",
                "34.08",
                "42.23",
                "50.35",
                "48.61",
                "37.24",
                "31.94",
                "42.04"
            ],
            [
                "50.16",
                "48.59",
                "32.41",
                "32.72",
                "40.97",
                "-",
                "-",
                "-",
                "-",
                "-"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "B3",
            "CEAFe",
            "MUC",
            "BLANC",
            "AVG",
            "B3",
            "CEAFe",
            "MUC",
            "BLANC",
            "AVG"
        ],
        "target_entity": [
            "Basic ILP"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>KBP 2016 || B3</th>      <th>KBP 2016 || CEAFe</th>      <th>KBP 2016 || MUC</th>      <th>KBP 2016 || BLANC</th>      <th>KBP 2016 || AVG</th>      <th>KBP 2017 || B3</th>      <th>KBP 2017 || CEAFe</th>      <th>KBP 2017 || MUC</th>      <th>KBP 2017 || BLANC</th>      <th>KBP 2017 || AVG</th>    </tr>  </thead>  <tbody>    <tr>      <td>Model || Local classifier</td>      <td>51.47</td>      <td>47.96</td>      <td>26.29</td>      <td>30.82</td>      <td>39.13</td>      <td>50.24</td>      <td>48.47</td>      <td>30.81</td>      <td>29.94</td>      <td>39.87</td>    </tr>    <tr>      <td>Model || Clustering</td>      <td>46.97</td>      <td>41.95</td>      <td>18.79</td>      <td>26.88</td>      <td>33.65</td>      <td>46.51</td>      <td>40.21</td>      <td>23.1</td>      <td>25.08</td>      <td>33.72</td>    </tr>    <tr>      <td>Model || Basic ILP</td>      <td>51.44</td>      <td>47.77</td>      <td>26.65</td>      <td>30.95</td>      <td>39.19</td>      <td>50.4</td>      <td>48.49</td>      <td>31.33</td>      <td>30.58</td>      <td>40.2</td>    </tr>    <tr>      <td>Model || Basic ILP + Topic structure</td>      <td>51.44</td>      <td>47.94</td>      <td>28.86</td>      <td>31.87</td>      <td>40.03</td>      <td>50.39</td>      <td>48.23</td>      <td>33.08</td>      <td>31.26</td>      <td>40.74</td>    </tr>    <tr>      <td>Model || Basic ILP + Cross-chain</td>      <td>51.09</td>      <td>47.53</td>      <td>31.27</td>      <td>33.07</td>      <td>40.74</td>      <td>50.39</td>      <td>47.67</td>      <td>35.15</td>      <td>31.88</td>      <td>41.27</td>    </tr>    <tr>      <td>Model || Basic ILP + Distribution</td>      <td>51.06</td>      <td>48.28</td>      <td>33.53</td>      <td>33.63</td>      <td>41.62</td>      <td>50.42</td>      <td>48.67</td>      <td>37.52</td>      <td>32.08</td>      <td>42.17</td>    </tr>    <tr>      <td>Model || Basic ILP + Subevent</td>      <td>51.67</td>      <td>49.1</td>      <td>34.08</td>      <td>34.08</td>      <td>42.23</td>      <td>50.35</td>      <td>48.61</td>      <td>37.24</td>      <td>31.94</td>      <td>42.04</td>    </tr>    <tr>      <td>Model || Joint learning</td>      <td>50.16</td>      <td>48.59</td>      <td>32.41</td>      <td>32.72</td>      <td>40.97</td>      <td>-</td>      <td>-</td>      <td>-</td>      <td>-</td>      <td>-</td>    </tr>  </tbody></table>",
        "table_name": "Table 3",
        "table_id": "table_3",
        "paper_id": "P18-1045",
        "page_no": 8,
        "dir": "acl2018",
        "valid": 1
    },
    {
        "table_id_paper": "P18-1054table_3",
        "caption": "Ablation study on the development set. The cells shaded gray represent they are not directly affected from the ablation, but from the counterpart analysis result.",
        "row_header_level": 1,
        "row_headers": [
            [
                "Our proposed model"
            ],
            [
                "CR - string match"
            ],
            [
                "CR - sentence distance"
            ],
            [
                "CR - synonym dictionary"
            ],
            [
                "PA - path embedding"
            ],
            [
                "PA - selectional preference"
            ],
            [
                "PA - sentence distance"
            ]
        ],
        "column_header_level": 3,
        "column_headers": [
            [
                "coreference resolution",
                "Web",
                "F1"
            ],
            [
                "coreference resolution",
                "Web",
                "delta"
            ],
            [
                "coreference resolution",
                "News",
                "F1"
            ],
            [
                "coreference resolution",
                "News",
                "delta"
            ],
            [
                "zero anaphora resolution (ZAR)",
                "Web",
                "F1"
            ],
            [
                "zero anaphora resolution (ZAR)",
                "Web",
                "delta"
            ],
            [
                "zero anaphora resolution (ZAR)",
                "News",
                "F1"
            ],
            [
                "zero anaphora resolution (ZAR)",
                "News",
                "delta"
            ]
        ],
        "contents": [
            [
                "0.633",
                "",
                "0.613",
                "",
                "0.512",
                "",
                "0.361",
                ""
            ],
            [
                "0.212",
                "-0.42",
                "0.184",
                "-0.429",
                "0.474",
                "-0.038",
                "0.348",
                "-0.013"
            ],
            [
                "0.643",
                "0.011",
                "0.588",
                "-0.025",
                "0.505",
                "-0.007",
                "0.343",
                "-0.018"
            ],
            [
                "0.643",
                "0.01",
                "0.613",
                "0",
                "0.51",
                "-0.002",
                "0.348",
                "-0.013"
            ],
            [
                "0.643",
                "0.01",
                "0.625",
                "0.012",
                "0.459",
                "-0.054",
                "0.268",
                "-0.093"
            ],
            [
                "0.638",
                "0.005",
                "0.316",
                "-0.297",
                "0.507",
                "-0.005",
                "0.173",
                "-0.188"
            ],
            [
                "0.647",
                "0.014",
                "0.606",
                "-0.007",
                "0.516",
                "0.004",
                "0.327",
                "-0.034"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "F1",
            "delta",
            "F1",
            "delta",
            "F1",
            "delta",
            "F1",
            "delta"
        ],
        "target_entity": [
            "delta"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>coreference resolution || Web || F1</th>      <th>coreference resolution || Web || delta</th>      <th>coreference resolution || News || F1</th>      <th>coreference resolution || News || delta</th>      <th>zero anaphora resolution (ZAR) || Web || F1</th>      <th>zero anaphora resolution (ZAR) || Web || delta</th>      <th>zero anaphora resolution (ZAR) || News || F1</th>      <th>zero anaphora resolution (ZAR) || News || delta</th>    </tr>  </thead>  <tbody>    <tr>      <td>Our proposed model</td>      <td>0.633</td>      <td></td>      <td>0.613</td>      <td></td>      <td>0.512</td>      <td></td>      <td>0.361</td>      <td></td>    </tr>    <tr>      <td>CR - string match</td>      <td>0.212</td>      <td>-0.42</td>      <td>0.184</td>      <td>-0.429</td>      <td>0.474</td>      <td>-0.038</td>      <td>0.348</td>      <td>-0.013</td>    </tr>    <tr>      <td>CR - sentence distance</td>      <td>0.643</td>      <td>0.011</td>      <td>0.588</td>      <td>-0.025</td>      <td>0.505</td>      <td>-0.007</td>      <td>0.343</td>      <td>-0.018</td>    </tr>    <tr>      <td>CR - synonym dictionary</td>      <td>0.643</td>      <td>0.01</td>      <td>0.613</td>      <td>0</td>      <td>0.51</td>      <td>-0.002</td>      <td>0.348</td>      <td>-0.013</td>    </tr>    <tr>      <td>PA - path embedding</td>      <td>0.643</td>      <td>0.01</td>      <td>0.625</td>      <td>0.012</td>      <td>0.459</td>      <td>-0.054</td>      <td>0.268</td>      <td>-0.093</td>    </tr>    <tr>      <td>PA - selectional preference</td>      <td>0.638</td>      <td>0.005</td>      <td>0.316</td>      <td>-0.297</td>      <td>0.507</td>      <td>-0.005</td>      <td>0.173</td>      <td>-0.188</td>    </tr>    <tr>      <td>PA - sentence distance</td>      <td>0.647</td>      <td>0.014</td>      <td>0.606</td>      <td>-0.007</td>      <td>0.516</td>      <td>0.004</td>      <td>0.327</td>      <td>-0.034</td>    </tr>  </tbody></table>",
        "table_name": "Table 3",
        "table_id": "table_3",
        "paper_id": "P18-1054",
        "page_no": 9,
        "dir": "acl2018",
        "valid": 1
    },
    {
        "table_id_paper": "P18-1097table_5",
        "caption": "Performance of systems on CoNLL-2014 dataset. The system with bold fonts are based on seq2seq models. (cid:63) denotes the system uses the non-public error-corrected data from Lang-8.com.",
        "row_header_level": 2,
        "row_headers": [
            [
                "System",
                "Spell check"
            ],
            [
                "System",
                "CAMB14"
            ],
            [
                "System",
                "CAMB16SMT"
            ],
            [
                "System",
                "CAMB16NMT"
            ],
            [
                "System",
                "CAMB17 (CAMB16SMT based)"
            ],
            [
                "System",
                "CAMB17 (AMU16 based)"
            ],
            [
                "System",
                "AMU14"
            ],
            [
                "System",
                "AMU16"
            ],
            [
                "System",
                "AMU16\u2605"
            ],
            [
                "System",
                "CUUI"
            ],
            [
                "System",
                "VT16\u2605"
            ],
            [
                "System",
                "NUS14"
            ],
            [
                "System",
                "NUS16"
            ],
            [
                "System",
                "NUS17"
            ],
            [
                "System",
                "Char-seq2seq"
            ],
            [
                "System",
                "Nested-seq2seq"
            ],
            [
                "System",
                "Adapt-seq2seq"
            ],
            [
                "System",
                "dual-boost (single)"
            ],
            [
                "System",
                "dual-boost (AMU16 based)"
            ],
            [
                "System",
                "dual-boost (single) *"
            ],
            [
                "System",
                "dual-boost (AMU16 based) *"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "P"
            ],
            [
                "R"
            ],
            [
                "F0.5"
            ]
        ],
        "contents": [
            [
                "53.01",
                "8.16",
                "25.25"
            ],
            [
                "39.71",
                "30.1",
                "37.33"
            ],
            [
                "45.39",
                "21.82",
                "37.33"
            ],
            [
                "-",
                "-",
                "39.9"
            ],
            [
                "51.09",
                "25.3",
                "42.44"
            ],
            [
                "59.88",
                "32.16",
                "51.08"
            ],
            [
                "41.62",
                "21.4",
                "35.01"
            ],
            [
                "61.27",
                "27.98",
                "49.49"
            ],
            [
                "63.52",
                "30.49",
                "52.21"
            ],
            [
                "41.78",
                "24.88",
                "36.79"
            ],
            [
                "60.17",
                "25.64",
                "47.4"
            ],
            [
                "53.55",
                "19.14",
                "39.39"
            ],
            [
                "-",
                "-",
                "44.27"
            ],
            [
                "62.74",
                "32.96",
                "53.14"
            ],
            [
                "49.24",
                "23.77",
                "40.56"
            ],
            [
                "-",
                "-",
                "45.15"
            ],
            [
                "-",
                "-",
                "41.37"
            ],
            [
                "62.7",
                "27.69",
                "50.04"
            ],
            [
                "60.57",
                "36.02",
                "53.3"
            ],
            [
                "64.47",
                "30.48",
                "52.72"
            ],
            [
                "61.24",
                "37.86",
                "54.51"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "P",
            "R",
            "F0.5"
        ],
        "target_entity": [
            "dual-boost (single) *",
            "dual-boost (AMU16 based) *"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>P</th>      <th>R</th>      <th>F0.5</th>    </tr>  </thead>  <tbody>    <tr>      <td>System || Spell check</td>      <td>53.01</td>      <td>8.16</td>      <td>25.25</td>    </tr>    <tr>      <td>System || CAMB14</td>      <td>39.71</td>      <td>30.1</td>      <td>37.33</td>    </tr>    <tr>      <td>System || CAMB16SMT</td>      <td>45.39</td>      <td>21.82</td>      <td>37.33</td>    </tr>    <tr>      <td>System || CAMB16NMT</td>      <td>-</td>      <td>-</td>      <td>39.9</td>    </tr>    <tr>      <td>System || CAMB17 (CAMB16SMT based)</td>      <td>51.09</td>      <td>25.3</td>      <td>42.44</td>    </tr>    <tr>      <td>System || CAMB17 (AMU16 based)</td>      <td>59.88</td>      <td>32.16</td>      <td>51.08</td>    </tr>    <tr>      <td>System || AMU14</td>      <td>41.62</td>      <td>21.4</td>      <td>35.01</td>    </tr>    <tr>      <td>System || AMU16</td>      <td>61.27</td>      <td>27.98</td>      <td>49.49</td>    </tr>    <tr>      <td>System || AMU16\u2605</td>      <td>63.52</td>      <td>30.49</td>      <td>52.21</td>    </tr>    <tr>      <td>System || CUUI</td>      <td>41.78</td>      <td>24.88</td>      <td>36.79</td>    </tr>    <tr>      <td>System || VT16\u2605</td>      <td>60.17</td>      <td>25.64</td>      <td>47.4</td>    </tr>    <tr>      <td>System || NUS14</td>      <td>53.55</td>      <td>19.14</td>      <td>39.39</td>    </tr>    <tr>      <td>System || NUS16</td>      <td>-</td>      <td>-</td>      <td>44.27</td>    </tr>    <tr>      <td>System || NUS17</td>      <td>62.74</td>      <td>32.96</td>      <td>53.14</td>    </tr>    <tr>      <td>System || Char-seq2seq</td>      <td>49.24</td>      <td>23.77</td>      <td>40.56</td>    </tr>    <tr>      <td>System || Nested-seq2seq</td>      <td>-</td>      <td>-</td>      <td>45.15</td>    </tr>    <tr>      <td>System || Adapt-seq2seq</td>      <td>-</td>      <td>-</td>      <td>41.37</td>    </tr>    <tr>      <td>System || dual-boost (single)</td>      <td>62.7</td>      <td>27.69</td>      <td>50.04</td>    </tr>    <tr>      <td>System || dual-boost (AMU16 based)</td>      <td>60.57</td>      <td>36.02</td>      <td>53.3</td>    </tr>    <tr>      <td>System || dual-boost (single) *</td>      <td>64.47</td>      <td>30.48</td>      <td>52.72</td>    </tr>    <tr>      <td>System || dual-boost (AMU16 based) *</td>      <td>61.24</td>      <td>37.86</td>      <td>54.51</td>    </tr>  </tbody></table>",
        "table_name": "Table 5",
        "table_id": "table_5",
        "paper_id": "P18-1097",
        "page_no": 7,
        "dir": "acl2018",
        "valid": 1
    },
    {
        "table_id_paper": "P18-1120table_3",
        "caption": "Scores for MRR and Top k results.",
        "row_header_level": 1,
        "row_headers": [
            [
                "EMBED"
            ],
            [
                "PMI"
            ],
            [
                "FREQ"
            ],
            [
                "AP"
            ],
            [
                "AP+AL"
            ],
            [
                "AP+AO"
            ],
            [
                "AP+AE"
            ],
            [
                "AP+AL+E"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "MRRE"
            ],
            [
                "MRRP"
            ],
            [
                "TOP1"
            ],
            [
                "TOP2"
            ],
            [
                "TOP3"
            ]
        ],
        "contents": [
            [
                "0.02",
                "0.09",
                "0.05",
                "0.08",
                "0.12"
            ],
            [
                "0.20",
                "0.33",
                "0.25",
                "0.36",
                "0.41"
            ],
            [
                "0.23",
                "0.34",
                "0.23",
                "0.32",
                "0.40"
            ],
            [
                "0.28",
                "0.38",
                "0.29",
                "0.41",
                "0.47"
            ],
            [
                "0.28",
                "0.40",
                "0.32",
                "0.44",
                "0.49"
            ],
            [
                "0.23",
                "0.33",
                "0.24",
                "0.35",
                "0.43"
            ],
            [
                "0.25",
                "0.36",
                "0.28",
                "0.40",
                "0.47"
            ],
            [
                "0.29",
                "0.42",
                "0.35",
                "0.44",
                "0.52"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "MRRE",
            "MRRP",
            "TOP1",
            "TOP2",
            "TOP3"
        ],
        "target_entity": [
            "AP+AL+E"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>MRRE</th>      <th>MRRP</th>      <th>TOP1</th>      <th>TOP2</th>      <th>TOP3</th>    </tr>  </thead>  <tbody>    <tr>      <td>EMBED</td>      <td>0.02</td>      <td>0.09</td>      <td>0.05</td>      <td>0.08</td>      <td>0.12</td>    </tr>    <tr>      <td>PMI</td>      <td>0.20</td>      <td>0.33</td>      <td>0.25</td>      <td>0.36</td>      <td>0.41</td>    </tr>    <tr>      <td>FREQ</td>      <td>0.23</td>      <td>0.34</td>      <td>0.23</td>      <td>0.32</td>      <td>0.40</td>    </tr>    <tr>      <td>AP</td>      <td>0.28</td>      <td>0.38</td>      <td>0.29</td>      <td>0.41</td>      <td>0.47</td>    </tr>    <tr>      <td>AP+AL</td>      <td>0.28</td>      <td>0.40</td>      <td>0.32</td>      <td>0.44</td>      <td>0.49</td>    </tr>    <tr>      <td>AP+AO</td>      <td>0.23</td>      <td>0.33</td>      <td>0.24</td>      <td>0.35</td>      <td>0.43</td>    </tr>    <tr>      <td>AP+AE</td>      <td>0.25</td>      <td>0.36</td>      <td>0.28</td>      <td>0.40</td>      <td>0.47</td>    </tr>    <tr>      <td>AP+AL+E</td>      <td>0.29</td>      <td>0.42</td>      <td>0.35</td>      <td>0.44</td>      <td>0.52</td>    </tr>  </tbody></table>",
        "table_name": "Table 3",
        "table_id": "table_3",
        "paper_id": "P18-1120",
        "page_no": 7,
        "dir": "acl2018",
        "valid": 1
    },
    {
        "table_id_paper": "P18-1126table_6",
        "caption": "Abridged SentEval and paraphrase evaluation results. Full results in supplementary material. AvgAcc is the average of all 10 SentEval classification tasks (see Table S1 in supplementary material), AvgSim averages all 7 similarity tasks (see Table S2). Hyand COstand for HyTER and COCO, respectively. \u201cH.\u201d is the number of attention heads. We give the out-of-vocabulary (OOV) rate and the perplexity of a 4-gram language model (LM) trained on the English side of the respective parallel corpus and evaluated on all available data for a given task.",
        "row_header_level": 6,
        "row_headers": [
            [
                "Name",
                "InferSent",
                "Size",
                "4096",
                "H.",
                "-"
            ],
            [
                "Name",
                "GloVe-BOW",
                "Size",
                "300",
                "H.",
                "-"
            ],
            [
                "Name",
                "cs-FINAL-CTX",
                "Size",
                "1000",
                "H.",
                "-"
            ],
            [
                "Name",
                "cs-ATTN-ATTN",
                "Size",
                "1000",
                "H.",
                "1"
            ],
            [
                "Name",
                "cs-FINAL",
                "Size",
                "1000",
                "H.",
                "-"
            ],
            [
                "Name",
                "cs-MAXPOOL",
                "Size",
                "1000",
                "H.",
                "-"
            ],
            [
                "Name",
                "cs-AVGPOOL",
                "Size",
                "1000",
                "H.",
                "-"
            ],
            [
                "Name",
                "cs-ATTN-CTX",
                "Size",
                "1000",
                "H.",
                "4"
            ],
            [
                "Name",
                "cs-ATTN-ATTN",
                "Size",
                "4000",
                "H.",
                "4"
            ],
            [
                "Name",
                "cs-ATTN-ATTN",
                "Size",
                "1000",
                "H.",
                "4"
            ],
            [
                "Name",
                "cs-ATTN-ATTN",
                "Size",
                "1000",
                "H.",
                "8"
            ],
            [
                "Name",
                "de-MAXPOOL-CTX",
                "Size",
                "600",
                "H.",
                "-"
            ],
            [
                "Name",
                "de-ATTN-CTX",
                "Size",
                "1200",
                "H.",
                "12"
            ],
            [
                "Name",
                "de-ATTN-CTX",
                "Size",
                "600",
                "H.",
                "8"
            ],
            [
                "Name",
                "de-AVGPOOL-CTX",
                "Size",
                "600",
                "H.",
                "-"
            ],
            [
                "Name",
                "de-ATTN-CTX",
                "Size",
                "600",
                "H.",
                "12"
            ],
            [
                "Name",
                "de-FINAL",
                "Size",
                "600",
                "H.",
                "-"
            ],
            [
                "Name",
                "de-ATTN-CTX",
                "Size",
                "600",
                "H.",
                "3"
            ],
            [
                "Name",
                "de-ATTN-ATTN",
                "Size",
                "600",
                "H.",
                "1"
            ],
            [
                "Name",
                "de-ATTN-ATTN",
                "Size",
                "600",
                "H.",
                "3"
            ],
            [
                "Name",
                "de-FINAL-CTX",
                "Size",
                "600",
                "H.",
                "-"
            ],
            [
                "Name",
                "de-ATTN-ATTN",
                "Size",
                "1200",
                "H.",
                "6"
            ],
            [
                "Name",
                "de-TRF-ATTN-ATTN",
                "Size",
                "600",
                "H.",
                "3"
            ],
            [
                "Name",
                "de-ATTN-ATTN",
                "Size",
                "1200",
                "H.",
                "12"
            ],
            [
                "Name",
                "de-ATTN-ATTN",
                "Size",
                "2400",
                "H.",
                "12"
            ],
            [
                "Name",
                "de-TRF-ATTN-ATTN",
                "Size",
                "2400",
                "H.",
                "12"
            ],
            [
                "Name",
                "de-ATTN-ATTN",
                "Size",
                "600",
                "H.",
                "6"
            ],
            [
                "Name",
                "de-ATTN-ATTN",
                "Size",
                "600",
                "H.",
                "8"
            ],
            [
                "Name",
                "de-TRF-ATTN-ATTN",
                "Size",
                "600",
                "H.",
                "6"
            ],
            [
                "Name",
                "de-ATTN-ATTN",
                "Size",
                "600",
                "H.",
                "12"
            ],
            [
                "Name",
                "de-TRF-ATTN-ATTN",
                "Size",
                "1200",
                "H.",
                "12"
            ],
            [
                "Name",
                "de-ATTN-CTX",
                "Size",
                "600",
                "H.",
                "6"
            ],
            [
                "Name",
                "LM perplexity (cs)",
                "Size",
                "-",
                "H.",
                "-"
            ],
            [
                "Name",
                "% OOV (cs)",
                "Size",
                "-",
                "H.",
                "-"
            ],
            [
                "Name",
                "LM perplexity (de)",
                "Size",
                "-",
                "H.",
                "-"
            ],
            [
                "Name",
                "% OOV (de)",
                "Size",
                "-",
                "H.",
                "-"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "SNLI"
            ],
            [
                "SICK-E"
            ],
            [
                "AvgAcc"
            ],
            [
                "AvgSim"
            ],
            [
                "Hy-Cl"
            ],
            [
                "Hy-NN"
            ],
            [
                "Hy-iDB"
            ],
            [
                "CO-Cl"
            ],
            [
                "CO-NN"
            ],
            [
                "CO-iDB"
            ]
        ],
        "contents": [
            [
                "83.7",
                "86.4",
                "81.7",
                ".70",
                "99.99",
                "100.0",
                "0.579",
                "31.58",
                "26.21",
                "0.367"
            ],
            [
                "66.0",
                "78.2",
                "75.8",
                ".59",
                "99.94",
                "100.0",
                "0.654",
                "34.28",
                "19.72",
                "0.352"
            ],
            [
                "70.2",
                "82.1",
                "74.4",
                ".60",
                "99.92",
                "100.0",
                "0.406",
                "23.20",
                "16.07",
                "0.346"
            ],
            [
                "69.3",
                "80.8",
                "73.4",
                ".54",
                "99.88",
                "99.91",
                "0.347",
                "21.54",
                "11.50",
                "0.331"
            ],
            [
                "69.2",
                "81.1",
                "73.2",
                ".60",
                "99.91",
                "100.0",
                "0.439",
                "22.40",
                "14.63",
                "0.340"
            ],
            [
                "68.5",
                "81.7",
                "73.0",
                ".60",
                "99.86",
                "100.0",
                "0.447",
                "21.76",
                "16.34",
                "0.348"
            ],
            [
                "67.8",
                "79.7",
                "72.4",
                ".50",
                "99.80",
                "99.99",
                "0.387",
                "17.90",
                "8.61",
                "0.311"
            ],
            [
                "66.0",
                "79.5",
                "72.2",
                ".45",
                "99.75",
                "99.74",
                "0.287",
                "14.60",
                "7.54",
                "0.318"
            ],
            [
                "65.2",
                "78.0",
                "71.2",
                ".39",
                "99.54",
                "98.98",
                "0.252",
                "11.52",
                "5.51",
                "0.303"
            ],
            [
                "64.6",
                "78.0",
                "70.8",
                ".39",
                "99.26",
                "98.93",
                "0.253",
                "10.84",
                "5.20",
                "0.299"
            ],
            [
                "63.2",
                "76.6",
                "70.0",
                ".36",
                "99.41",
                "98.09",
                "0.243",
                "10.24",
                "4.64",
                "0.287"
            ],
            [
                "68.0",
                "78.8",
                "67.1",
                ".50",
                "98.42",
                "99.90",
                "0.343",
                "21.54",
                "15.62",
                "0.341"
            ],
            [
                "65.0",
                "77.4",
                "66.7",
                ".52",
                "98.88",
                "99.91",
                "0.347",
                "20.06",
                "16.68",
                "0.348"
            ],
            [
                "64.0",
                "75.7",
                "65.8",
                ".51",
                "98.11",
                "99.90",
                "0.348",
                "21.64",
                "17.32",
                "0.349"
            ],
            [
                "65.2",
                "77.5",
                "65.6",
                ".48",
                "97.72",
                "99.60",
                "0.312",
                "20.04",
                "14.27",
                "0.337"
            ],
            [
                "61.9",
                "76.0",
                "65.5",
                ".50",
                "97.79",
                "99.89",
                "0.360",
                "20.22",
                "16.10",
                "0.344"
            ],
            [
                "64.7",
                "77.0",
                "65.3",
                ".47",
                "97.01",
                "99.30",
                "0.305",
                "19.88",
                "12.40",
                "0.328"
            ],
            [
                "63.3",
                "76.0",
                "65.3",
                ".50",
                "97.81",
                "99.87",
                "0.328",
                "19.74",
                "16.43",
                "0.343"
            ],
            [
                "63.8",
                "76.9",
                "64.8",
                ".50",
                "97.70",
                "99.73",
                "0.352",
                "19.74",
                "16.26",
                "0.340"
            ],
            [
                "61.5",
                "74.7",
                "64.5",
                ".47",
                "97.42",
                "99.75",
                "0.314",
                "17.36",
                "14.35",
                "0.333"
            ],
            [
                "62.6",
                "76.2",
                "64.5",
                ".48",
                "96.65",
                "99.70",
                "0.323",
                "17.22",
                "12.84",
                "0.333"
            ],
            [
                "59.6",
                "72.3",
                "64.3",
                ".41",
                "98.05",
                "99.80",
                "0.289",
                "11.90",
                "10.69",
                "0.327"
            ],
            [
                "61.4",
                "72.5",
                "63.9",
                ".49",
                "95.79",
                "99.64",
                "0.315",
                "15.76",
                "14.04",
                "0.340"
            ],
            [
                "58.2",
                "72.5",
                "63.4",
                ".43",
                "97.15",
                "99.65",
                "0.283",
                "12.18",
                "11.97",
                "0.330"
            ],
            [
                "59.8",
                "73.9",
                "63.2",
                ".41",
                "98.69",
                "99.77",
                "0.287",
                "10.26",
                "10.94",
                "0.326"
            ],
            [
                "59.0",
                "71.2",
                "63.0",
                ".46",
                "95.82",
                "99.03",
                "0.307",
                "5.66",
                "14.53",
                "0.339"
            ],
            [
                "57.5",
                "70.9",
                "62.6",
                ".40",
                "96.03",
                "99.71",
                "0.287",
                "12.22",
                "10.59",
                "0.323"
            ],
            [
                "55.6",
                "68.6",
                "62.1",
                ".39",
                "95.32",
                "99.73",
                "0.275",
                "10.22",
                "10.58",
                "0.325"
            ],
            [
                "59.5",
                "71.0",
                "61.9",
                ".45",
                "90.24",
                "98.44",
                "0.313",
                "9.06",
                "13.64",
                "0.332"
            ],
            [
                "55.2",
                "70.5",
                "61.5",
                ".40",
                "95.16",
                "99.64",
                "0.278",
                "9.62",
                "10.47",
                "0.323"
            ],
            [
                "58.2",
                "68.8",
                "61.1",
                ".46",
                "90.71",
                "98.22",
                "0.301",
                "7.06",
                "13.70",
                "0.333"
            ],
            [
                "62.9",
                "68.7",
                "61.0",
                ".43",
                "98.11",
                "99.86",
                "0.358",
                "20.44",
                "15.57",
                "0.342"
            ],
            [
                "190.6",
                "299.4",
                "1150.2",
                "1224.2",
                "",
                "668.5",
                "",
                "",
                "238.5",
                ""
            ],
            [
                "0.3",
                "0.2",
                "2.3",
                "2.6",
                "",
                "1.2",
                "",
                "",
                "0.1",
                ""
            ],
            [
                "38.8",
                "65.0",
                "3578.2",
                "2010.6",
                "",
                "3354.8",
                "",
                "",
                "86.3",
                ""
            ],
            [
                "1.5",
                "0.7",
                "17.8",
                "16.2",
                "",
                "19.3",
                "",
                "",
                "1.9",
                ""
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "accuracy",
            "accuracy",
            "accuracy",
            "accuracy",
            "accuracy",
            "accuracy",
            "accuracy",
            "accuracy",
            "accuracy",
            "accuracy"
        ],
        "target_entity": [
            "InferSent"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>SNLI</th>      <th>SICK-E</th>      <th>AvgAcc</th>      <th>AvgSim</th>      <th>Hy-Cl</th>      <th>Hy-NN</th>      <th>Hy-iDB</th>      <th>CO-Cl</th>      <th>CO-NN</th>      <th>CO-iDB</th>    </tr>  </thead>  <tbody>    <tr>      <td>Name || InferSent || Size || 4096 || H. || -</td>      <td>83.7</td>      <td>86.4</td>      <td>81.7</td>      <td>.70</td>      <td>99.99</td>      <td>100.0</td>      <td>0.579</td>      <td>31.58</td>      <td>26.21</td>      <td>0.367</td>    </tr>    <tr>      <td>Name || GloVe-BOW || Size || 300 || H. || -</td>      <td>66.0</td>      <td>78.2</td>      <td>75.8</td>      <td>.59</td>      <td>99.94</td>      <td>100.0</td>      <td>0.654</td>      <td>34.28</td>      <td>19.72</td>      <td>0.352</td>    </tr>    <tr>      <td>Name || cs-FINAL-CTX || Size || 1000 || H. || -</td>      <td>70.2</td>      <td>82.1</td>      <td>74.4</td>      <td>.60</td>      <td>99.92</td>      <td>100.0</td>      <td>0.406</td>      <td>23.20</td>      <td>16.07</td>      <td>0.346</td>    </tr>    <tr>      <td>Name || cs-ATTN-ATTN || Size || 1000 || H. || 1</td>      <td>69.3</td>      <td>80.8</td>      <td>73.4</td>      <td>.54</td>      <td>99.88</td>      <td>99.91</td>      <td>0.347</td>      <td>21.54</td>      <td>11.50</td>      <td>0.331</td>    </tr>    <tr>      <td>Name || cs-FINAL || Size || 1000 || H. || -</td>      <td>69.2</td>      <td>81.1</td>      <td>73.2</td>      <td>.60</td>      <td>99.91</td>      <td>100.0</td>      <td>0.439</td>      <td>22.40</td>      <td>14.63</td>      <td>0.340</td>    </tr>    <tr>      <td>Name || cs-MAXPOOL || Size || 1000 || H. || -</td>      <td>68.5</td>      <td>81.7</td>      <td>73.0</td>      <td>.60</td>      <td>99.86</td>      <td>100.0</td>      <td>0.447</td>      <td>21.76</td>      <td>16.34</td>      <td>0.348</td>    </tr>    <tr>      <td>Name || cs-AVGPOOL || Size || 1000 || H. || -</td>      <td>67.8</td>      <td>79.7</td>      <td>72.4</td>      <td>.50</td>      <td>99.80</td>      <td>99.99</td>      <td>0.387</td>      <td>17.90</td>      <td>8.61</td>      <td>0.311</td>    </tr>    <tr>      <td>Name || cs-ATTN-CTX || Size || 1000 || H. || 4</td>      <td>66.0</td>      <td>79.5</td>      <td>72.2</td>      <td>.45</td>      <td>99.75</td>      <td>99.74</td>      <td>0.287</td>      <td>14.60</td>      <td>7.54</td>      <td>0.318</td>    </tr>    <tr>      <td>Name || cs-ATTN-ATTN || Size || 4000 || H. || 4</td>      <td>65.2</td>      <td>78.0</td>      <td>71.2</td>      <td>.39</td>      <td>99.54</td>      <td>98.98</td>      <td>0.252</td>      <td>11.52</td>      <td>5.51</td>      <td>0.303</td>    </tr>    <tr>      <td>Name || cs-ATTN-ATTN || Size || 1000 || H. || 4</td>      <td>64.6</td>      <td>78.0</td>      <td>70.8</td>      <td>.39</td>      <td>99.26</td>      <td>98.93</td>      <td>0.253</td>      <td>10.84</td>      <td>5.20</td>      <td>0.299</td>    </tr>    <tr>      <td>Name || cs-ATTN-ATTN || Size || 1000 || H. || 8</td>      <td>63.2</td>      <td>76.6</td>      <td>70.0</td>      <td>.36</td>      <td>99.41</td>      <td>98.09</td>      <td>0.243</td>      <td>10.24</td>      <td>4.64</td>      <td>0.287</td>    </tr>    <tr>      <td>Name || de-MAXPOOL-CTX || Size || 600 || H. || -</td>      <td>68.0</td>      <td>78.8</td>      <td>67.1</td>      <td>.50</td>      <td>98.42</td>      <td>99.90</td>      <td>0.343</td>      <td>21.54</td>      <td>15.62</td>      <td>0.341</td>    </tr>    <tr>      <td>Name || de-ATTN-CTX || Size || 1200 || H. || 12</td>      <td>65.0</td>      <td>77.4</td>      <td>66.7</td>      <td>.52</td>      <td>98.88</td>      <td>99.91</td>      <td>0.347</td>      <td>20.06</td>      <td>16.68</td>      <td>0.348</td>    </tr>    <tr>      <td>Name || de-ATTN-CTX || Size || 600 || H. || 8</td>      <td>64.0</td>      <td>75.7</td>      <td>65.8</td>      <td>.51</td>      <td>98.11</td>      <td>99.90</td>      <td>0.348</td>      <td>21.64</td>      <td>17.32</td>      <td>0.349</td>    </tr>    <tr>      <td>Name || de-AVGPOOL-CTX || Size || 600 || H. || -</td>      <td>65.2</td>      <td>77.5</td>      <td>65.6</td>      <td>.48</td>      <td>97.72</td>      <td>99.60</td>      <td>0.312</td>      <td>20.04</td>      <td>14.27</td>      <td>0.337</td>    </tr>    <tr>      <td>Name || de-ATTN-CTX || Size || 600 || H. || 12</td>      <td>61.9</td>      <td>76.0</td>      <td>65.5</td>      <td>.50</td>      <td>97.79</td>      <td>99.89</td>      <td>0.360</td>      <td>20.22</td>      <td>16.10</td>      <td>0.344</td>    </tr>    <tr>      <td>Name || de-FINAL || Size || 600 || H. || -</td>      <td>64.7</td>      <td>77.0</td>      <td>65.3</td>      <td>.47</td>      <td>97.01</td>      <td>99.30</td>      <td>0.305</td>      <td>19.88</td>      <td>12.40</td>      <td>0.328</td>    </tr>    <tr>      <td>Name || de-ATTN-CTX || Size || 600 || H. || 3</td>      <td>63.3</td>      <td>76.0</td>      <td>65.3</td>      <td>.50</td>      <td>97.81</td>      <td>99.87</td>      <td>0.328</td>      <td>19.74</td>      <td>16.43</td>      <td>0.343</td>    </tr>    <tr>      <td>Name || de-ATTN-ATTN || Size || 600 || H. || 1</td>      <td>63.8</td>      <td>76.9</td>      <td>64.8</td>      <td>.50</td>      <td>97.70</td>      <td>99.73</td>      <td>0.352</td>      <td>19.74</td>      <td>16.26</td>      <td>0.340</td>    </tr>    <tr>      <td>Name || de-ATTN-ATTN || Size || 600 || H. || 3</td>      <td>61.5</td>      <td>74.7</td>      <td>64.5</td>      <td>.47</td>      <td>97.42</td>      <td>99.75</td>      <td>0.314</td>      <td>17.36</td>      <td>14.35</td>      <td>0.333</td>    </tr>    <tr>      <td>Name || de-FINAL-CTX || Size || 600 || H. || -</td>      <td>62.6</td>      <td>76.2</td>      <td>64.5</td>      <td>.48</td>      <td>96.65</td>      <td>99.70</td>      <td>0.323</td>      <td>17.22</td>      <td>12.84</td>      <td>0.333</td>    </tr>    <tr>      <td>Name || de-ATTN-ATTN || Size || 1200 || H. || 6</td>      <td>59.6</td>      <td>72.3</td>      <td>64.3</td>      <td>.41</td>      <td>98.05</td>      <td>99.80</td>      <td>0.289</td>      <td>11.90</td>      <td>10.69</td>      <td>0.327</td>    </tr>    <tr>      <td>Name || de-TRF-ATTN-ATTN || Size || 600 || H. || 3</td>      <td>61.4</td>      <td>72.5</td>      <td>63.9</td>      <td>.49</td>      <td>95.79</td>      <td>99.64</td>      <td>0.315</td>      <td>15.76</td>      <td>14.04</td>      <td>0.340</td>    </tr>    <tr>      <td>Name || de-ATTN-ATTN || Size || 1200 || H. || 12</td>      <td>58.2</td>      <td>72.5</td>      <td>63.4</td>      <td>.43</td>      <td>97.15</td>      <td>99.65</td>      <td>0.283</td>      <td>12.18</td>      <td>11.97</td>      <td>0.330</td>    </tr>    <tr>      <td>Name || de-ATTN-ATTN || Size || 2400 || H. || 12</td>      <td>59.8</td>      <td>73.9</td>      <td>63.2</td>      <td>.41</td>      <td>98.69</td>      <td>99.77</td>      <td>0.287</td>      <td>10.26</td>      <td>10.94</td>      <td>0.326</td>    </tr>    <tr>      <td>Name || de-TRF-ATTN-ATTN || Size || 2400 || H. || 12</td>      <td>59.0</td>      <td>71.2</td>      <td>63.0</td>      <td>.46</td>      <td>95.82</td>      <td>99.03</td>      <td>0.307</td>      <td>5.66</td>      <td>14.53</td>      <td>0.339</td>    </tr>    <tr>      <td>Name || de-ATTN-ATTN || Size || 600 || H. || 6</td>      <td>57.5</td>      <td>70.9</td>      <td>62.6</td>      <td>.40</td>      <td>96.03</td>      <td>99.71</td>      <td>0.287</td>      <td>12.22</td>      <td>10.59</td>      <td>0.323</td>    </tr>    <tr>      <td>Name || de-ATTN-ATTN || Size || 600 || H. || 8</td>      <td>55.6</td>      <td>68.6</td>      <td>62.1</td>      <td>.39</td>      <td>95.32</td>      <td>99.73</td>      <td>0.275</td>      <td>10.22</td>      <td>10.58</td>      <td>0.325</td>    </tr>    <tr>      <td>Name || de-TRF-ATTN-ATTN || Size || 600 || H. || 6</td>      <td>59.5</td>      <td>71.0</td>      <td>61.9</td>      <td>.45</td>      <td>90.24</td>      <td>98.44</td>      <td>0.313</td>      <td>9.06</td>      <td>13.64</td>      <td>0.332</td>    </tr>    <tr>      <td>Name || de-ATTN-ATTN || Size || 600 || H. || 12</td>      <td>55.2</td>      <td>70.5</td>      <td>61.5</td>      <td>.40</td>      <td>95.16</td>      <td>99.64</td>      <td>0.278</td>      <td>9.62</td>      <td>10.47</td>      <td>0.323</td>    </tr>    <tr>      <td>Name || de-TRF-ATTN-ATTN || Size || 1200 || H. || 12</td>      <td>58.2</td>      <td>68.8</td>      <td>61.1</td>      <td>.46</td>      <td>90.71</td>      <td>98.22</td>      <td>0.301</td>      <td>7.06</td>      <td>13.70</td>      <td>0.333</td>    </tr>    <tr>      <td>Name || de-ATTN-CTX || Size || 600 || H. || 6</td>      <td>62.9</td>      <td>68.7</td>      <td>61.0</td>      <td>.43</td>      <td>98.11</td>      <td>99.86</td>      <td>0.358</td>      <td>20.44</td>      <td>15.57</td>      <td>0.342</td>    </tr>    <tr>      <td>Name || LM perplexity (cs) || Size || - || H. || -</td>      <td>190.6</td>      <td>299.4</td>      <td>1150.2</td>      <td>1224.2</td>      <td></td>      <td>668.5</td>      <td></td>      <td></td>      <td>238.5</td>      <td></td>    </tr>    <tr>      <td>Name || % OOV (cs) || Size || - || H. || -</td>      <td>0.3</td>      <td>0.2</td>      <td>2.3</td>      <td>2.6</td>      <td></td>      <td>1.2</td>      <td></td>      <td></td>      <td>0.1</td>      <td></td>    </tr>    <tr>      <td>Name || LM perplexity (de) || Size || - || H. || -</td>      <td>38.8</td>      <td>65.0</td>      <td>3578.2</td>      <td>2010.6</td>      <td></td>      <td>3354.8</td>      <td></td>      <td></td>      <td>86.3</td>      <td></td>    </tr>    <tr>      <td>Name || % OOV (de) || Size || - || H. || -</td>      <td>1.5</td>      <td>0.7</td>      <td>17.8</td>      <td>16.2</td>      <td></td>      <td>19.3</td>      <td></td>      <td></td>      <td>1.9</td>      <td></td>    </tr>  </tbody></table>",
        "table_name": "Table 6",
        "table_id": "table_6",
        "paper_id": "P18-1126",
        "page_no": 7,
        "dir": "acl2018",
        "valid": 1
    },
    {
        "table_id_paper": "P18-1131table_4",
        "caption": "Recall by relation type under UDPipe\u2019s Morpho-Tagger and ARK Tagger settings (+synthetic+embeddings; (3) and (6) from Table 3; \u00a75.3). Reduction is the reduction in performance gap from the Morpho-Tagger setting to the ARK Tagger setting; bolded numbers indicate a gap reduction of \u2265 10.0.",
        "row_header_level": 2,
        "row_headers": [
            [
                "Relation",
                "compound"
            ],
            [
                "Relation",
                "obl:tmod"
            ],
            [
                "Relation",
                "nmod"
            ],
            [
                "Relation",
                "cop"
            ],
            [
                "Relation",
                "obl"
            ],
            [
                "Relation",
                "cc"
            ],
            [
                "Relation",
                "ccomp"
            ],
            [
                "Relation",
                "obj"
            ],
            [
                "Relation",
                "case"
            ],
            [
                "Relation",
                "det"
            ],
            [
                "Relation",
                "advmod"
            ],
            [
                "Relation",
                "advcl"
            ],
            [
                "Relation",
                "root"
            ],
            [
                "Relation",
                "xcomp"
            ],
            [
                "Relation",
                "discourse"
            ]
        ],
        "column_header_level": 2,
        "column_headers": [
            [
                "Morpho-Tagger",
                "AA Recall"
            ],
            [
                "Morpho-Tagger",
                "WH Recall"
            ],
            [
                "Morpho-Tagger",
                "Gap (WH - AA)"
            ],
            [
                "ARK Tagger",
                "AA Recall"
            ],
            [
                "ARK Tagger",
                "WH Recall"
            ],
            [
                "ARK Tagger",
                "Gap (WH - AA)"
            ],
            [
                "-",
                "Reduction"
            ]
        ],
        "contents": [
            [
                "36.4",
                "71.2",
                "34.8",
                "42.4",
                "72.9",
                "30.5",
                "4.4"
            ],
            [
                "25.0",
                "51.7",
                "26.7",
                "43.8",
                "55.2",
                "11.4",
                "15.3"
            ],
            [
                "28.6",
                "54.4",
                "25.8",
                "45.7",
                "51.5",
                "5.8",
                "20.1"
            ],
            [
                "56.5",
                "82.1",
                "25.6",
                "65.2",
                "79.1",
                "13.9",
                "11.7"
            ],
            [
                "41.4",
                "65.4",
                "24.0",
                "56.8",
                "62.5",
                "5.7",
                "18.3"
            ],
            [
                "56.9",
                "79.0",
                "22.1",
                "78.5",
                "82.7",
                "4.3",
                "17.8"
            ],
            [
                "33.3",
                "54.2",
                "20.8",
                "40.5",
                "54.2",
                "13.7",
                "7.1"
            ],
            [
                "61.3",
                "81.5",
                "20.2",
                "72.8",
                "83.5",
                "10.7",
                "9.5"
            ],
            [
                "60.5",
                "79.8",
                "19.3",
                "75.2",
                "83.4",
                "8.2",
                "11.1"
            ],
            [
                "73.1",
                "90.7",
                "17.5",
                "83.4",
                "92.2",
                "8.8",
                "8.7"
            ],
            [
                "53.8",
                "71.2",
                "17.3",
                "62.9",
                "72.1",
                "9.1",
                "8.2"
            ],
            [
                "31.5",
                "46.8",
                "15.3",
                "25.9",
                "46.8",
                "20.9",
                "-5.6"
            ],
            [
                "56.4",
                "71.6",
                "15.2",
                "62.8",
                "74.0",
                "11.2",
                "4.0"
            ],
            [
                "40.0",
                "54.9",
                "14.9",
                "51.2",
                "50.0",
                "1.2",
                "13.7"
            ],
            [
                "30.7",
                "44.9",
                "14.2",
                "46",
                "51.4",
                "5.4",
                "8.8"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "accuracy",
            "accuracy",
            "accuracy",
            "accuracy",
            "accuracy",
            "accuracy",
            "accuracy"
        ],
        "target_entity": [
            "Morpho-Tagger",
            "ARK Tagger"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Morpho-Tagger || AA Recall</th>      <th>Morpho-Tagger || WH Recall</th>      <th>Morpho-Tagger || Gap (WH - AA)</th>      <th>ARK Tagger || AA Recall</th>      <th>ARK Tagger || WH Recall</th>      <th>ARK Tagger || Gap (WH - AA)</th>      <th>- || Reduction</th>    </tr>  </thead>  <tbody>    <tr>      <td>Relation || compound</td>      <td>36.4</td>      <td>71.2</td>      <td>34.8</td>      <td>42.4</td>      <td>72.9</td>      <td>30.5</td>      <td>4.4</td>    </tr>    <tr>      <td>Relation || obl:tmod</td>      <td>25.0</td>      <td>51.7</td>      <td>26.7</td>      <td>43.8</td>      <td>55.2</td>      <td>11.4</td>      <td>15.3</td>    </tr>    <tr>      <td>Relation || nmod</td>      <td>28.6</td>      <td>54.4</td>      <td>25.8</td>      <td>45.7</td>      <td>51.5</td>      <td>5.8</td>      <td>20.1</td>    </tr>    <tr>      <td>Relation || cop</td>      <td>56.5</td>      <td>82.1</td>      <td>25.6</td>      <td>65.2</td>      <td>79.1</td>      <td>13.9</td>      <td>11.7</td>    </tr>    <tr>      <td>Relation || obl</td>      <td>41.4</td>      <td>65.4</td>      <td>24.0</td>      <td>56.8</td>      <td>62.5</td>      <td>5.7</td>      <td>18.3</td>    </tr>    <tr>      <td>Relation || cc</td>      <td>56.9</td>      <td>79.0</td>      <td>22.1</td>      <td>78.5</td>      <td>82.7</td>      <td>4.3</td>      <td>17.8</td>    </tr>    <tr>      <td>Relation || ccomp</td>      <td>33.3</td>      <td>54.2</td>      <td>20.8</td>      <td>40.5</td>      <td>54.2</td>      <td>13.7</td>      <td>7.1</td>    </tr>    <tr>      <td>Relation || obj</td>      <td>61.3</td>      <td>81.5</td>      <td>20.2</td>      <td>72.8</td>      <td>83.5</td>      <td>10.7</td>      <td>9.5</td>    </tr>    <tr>      <td>Relation || case</td>      <td>60.5</td>      <td>79.8</td>      <td>19.3</td>      <td>75.2</td>      <td>83.4</td>      <td>8.2</td>      <td>11.1</td>    </tr>    <tr>      <td>Relation || det</td>      <td>73.1</td>      <td>90.7</td>      <td>17.5</td>      <td>83.4</td>      <td>92.2</td>      <td>8.8</td>      <td>8.7</td>    </tr>    <tr>      <td>Relation || advmod</td>      <td>53.8</td>      <td>71.2</td>      <td>17.3</td>      <td>62.9</td>      <td>72.1</td>      <td>9.1</td>      <td>8.2</td>    </tr>    <tr>      <td>Relation || advcl</td>      <td>31.5</td>      <td>46.8</td>      <td>15.3</td>      <td>25.9</td>      <td>46.8</td>      <td>20.9</td>      <td>-5.6</td>    </tr>    <tr>      <td>Relation || root</td>      <td>56.4</td>      <td>71.6</td>      <td>15.2</td>      <td>62.8</td>      <td>74.0</td>      <td>11.2</td>      <td>4.0</td>    </tr>    <tr>      <td>Relation || xcomp</td>      <td>40.0</td>      <td>54.9</td>      <td>14.9</td>      <td>51.2</td>      <td>50.0</td>      <td>1.2</td>      <td>13.7</td>    </tr>    <tr>      <td>Relation || discourse</td>      <td>30.7</td>      <td>44.9</td>      <td>14.2</td>      <td>46</td>      <td>51.4</td>      <td>5.4</td>      <td>8.8</td>    </tr>  </tbody></table>",
        "table_name": "Table 4",
        "table_id": "table_4",
        "paper_id": "P18-1131",
        "page_no": 8,
        "dir": "acl2018",
        "valid": 1
    },
    {
        "table_id_paper": "P18-1185table_3",
        "caption": "Results of our models on noisy social media data.",
        "row_header_level": 2,
        "row_headers": [
            [
                "Model",
                "BLSTM-CRF"
            ],
            [
                "Model",
                "BLSTM-CRF + Global Image Vector"
            ],
            [
                "Model",
                "BLSTM-CRF + Visual attention"
            ],
            [
                "Model",
                "BLSTM-CRF + Visual attention + Gate"
            ]
        ],
        "column_header_level": 2,
        "column_headers": [
            [
                "Snap Captions",
                "Precision"
            ],
            [
                "Snap Captions",
                "Recall"
            ],
            [
                "Snap Captions",
                "F1"
            ],
            [
                "Twitter",
                "Precision"
            ],
            [
                "Twitter",
                "Recall"
            ],
            [
                "Twitter",
                "F1"
            ]
        ],
        "contents": [
            [
                "57.71",
                "58.65",
                "58.18",
                "78.88",
                "77.47",
                "78.17"
            ],
            [
                "61.49",
                "57.84",
                "59.61",
                "79.75",
                "77.32",
                "78.51"
            ],
            [
                "65.53",
                "57.03",
                "60.98",
                "80.81",
                "77.36",
                "79.05"
            ],
            [
                "66.67",
                "57.84",
                "61.94",
                "81.62",
                "79.90",
                "80.75"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "Precision",
            "Recall",
            "F1",
            "Precision",
            "Recall",
            "F1"
        ],
        "target_entity": [
            "BLSTM-CRF + Visual attention + Gate"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Snap Captions || Precision</th>      <th>Snap Captions || Recall</th>      <th>Snap Captions || F1</th>      <th>Twitter || Precision</th>      <th>Twitter || Recall</th>      <th>Twitter || F1</th>    </tr>  </thead>  <tbody>    <tr>      <td>Model || BLSTM-CRF</td>      <td>57.71</td>      <td>58.65</td>      <td>58.18</td>      <td>78.88</td>      <td>77.47</td>      <td>78.17</td>    </tr>    <tr>      <td>Model || BLSTM-CRF + Global Image Vector</td>      <td>61.49</td>      <td>57.84</td>      <td>59.61</td>      <td>79.75</td>      <td>77.32</td>      <td>78.51</td>    </tr>    <tr>      <td>Model || BLSTM-CRF + Visual attention</td>      <td>65.53</td>      <td>57.03</td>      <td>60.98</td>      <td>80.81</td>      <td>77.36</td>      <td>79.05</td>    </tr>    <tr>      <td>Model || BLSTM-CRF + Visual attention + Gate</td>      <td>66.67</td>      <td>57.84</td>      <td>61.94</td>      <td>81.62</td>      <td>79.90</td>      <td>80.75</td>    </tr>  </tbody></table>",
        "table_name": "Table 3",
        "table_id": "table_3",
        "paper_id": "P18-1185",
        "page_no": 7,
        "dir": "acl2018",
        "valid": 1
    },
    {
        "table_id_paper": "P18-1193table_4",
        "caption": "Development results, including model ablations. We also report mean \u00b5 and standard deviation \u03c3 for all metrics for our approach across five experiments. We bold the best performing variations of our model.",
        "row_header_level": 2,
        "row_headers": [
            [
                "System",
                "SUPERVISED"
            ],
            [
                "System",
                "POLICYGRADIENT"
            ],
            [
                "System",
                "CONTEXTUALBANDIT"
            ],
            [
                "System",
                "Our approach"
            ],
            [
                "System",
                "Our approach -previous instructions"
            ],
            [
                "System",
                "Our approach -current and initial state"
            ],
            [
                "System",
                "Our approach -current state"
            ],
            [
                "System",
                "Our approach -initial state"
            ],
            [
                "System",
                "Our approach (mean \u00b1 stdev)"
            ]
        ],
        "column_header_level": 2,
        "column_headers": [
            [
                "ALCHEMY",
                "Inst"
            ],
            [
                "ALCHEMY",
                "3utts"
            ],
            [
                "ALCHEMY",
                "5utts"
            ],
            [
                "SCENE",
                "Inst"
            ],
            [
                "SCENE",
                "3utts"
            ],
            [
                "SCENE",
                "5utts"
            ],
            [
                "TANGRAMS",
                "Inst"
            ],
            [
                "TANGRAMS",
                "3utts"
            ],
            [
                "TANGRAMS",
                "5utts"
            ]
        ],
        "contents": [
            [
                "92.0",
                "83.3",
                "71.4",
                "85.3",
                "72.7",
                "60.6",
                "86.1",
                "81.9",
                "58.3"
            ],
            [
                "0.0",
                "0.0",
                "0.0",
                "0.9",
                "1.0",
                "0.5",
                "85.2",
                "74.9",
                "52.3"
            ],
            [
                "58.8",
                "6.9",
                "5.7",
                "12.0",
                "0.5",
                "1.5",
                "85.6",
                "78.4",
                "52.6"
            ],
            [
                "92.1",
                "82.9",
                "71.8",
                "83.9",
                "68.7",
                "56.1",
                "88.5",
                "82.4",
                "60.3"
            ],
            [
                "90.1",
                "77.1",
                "66.1",
                "79.3",
                "60.6",
                "45.5",
                "76.4",
                "55.8",
                "27.6"
            ],
            [
                "25.7",
                "4.5",
                "3.3",
                "17.5",
                "0.0",
                "0.0",
                "45.4",
                "15.1",
                "3.5"
            ],
            [
                "89.8",
                "78.0",
                "62.9",
                "83.0",
                "68.7",
                "54.0",
                "87.6",
                "78.4",
                "60.8"
            ],
            [
                "81.1",
                "68.6",
                "42.9",
                "82.7",
                "67.7",
                "57.1",
                "88.6",
                "82.9",
                "63.3"
            ],
            [
                "91.5 \u00b11.4",
                "80.4 \u00b12.6",
                "69.5 \u00b15.0",
                "62.9 \u00b117.7",
                "37.8 \u00b123.5",
                "29.0 \u00b121.1",
                "88.2 \u00b10.6",
                "80.8 \u00b12.8",
                "59.2 \u00b12.3"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "accuracy",
            "accuracy",
            "accuracy",
            "accuracy",
            "accuracy",
            "accuracy",
            "accuracy",
            "accuracy",
            "accuracy"
        ],
        "target_entity": [
            "Our approach"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>ALCHEMY || Inst</th>      <th>ALCHEMY || 3utts</th>      <th>ALCHEMY || 5utts</th>      <th>SCENE || Inst</th>      <th>SCENE || 3utts</th>      <th>SCENE || 5utts</th>      <th>TANGRAMS || Inst</th>      <th>TANGRAMS || 3utts</th>      <th>TANGRAMS || 5utts</th>    </tr>  </thead>  <tbody>    <tr>      <td>System || SUPERVISED</td>      <td>92.0</td>      <td>83.3</td>      <td>71.4</td>      <td>85.3</td>      <td>72.7</td>      <td>60.6</td>      <td>86.1</td>      <td>81.9</td>      <td>58.3</td>    </tr>    <tr>      <td>System || POLICYGRADIENT</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.9</td>      <td>1.0</td>      <td>0.5</td>      <td>85.2</td>      <td>74.9</td>      <td>52.3</td>    </tr>    <tr>      <td>System || CONTEXTUALBANDIT</td>      <td>58.8</td>      <td>6.9</td>      <td>5.7</td>      <td>12.0</td>      <td>0.5</td>      <td>1.5</td>      <td>85.6</td>      <td>78.4</td>      <td>52.6</td>    </tr>    <tr>      <td>System || Our approach</td>      <td>92.1</td>      <td>82.9</td>      <td>71.8</td>      <td>83.9</td>      <td>68.7</td>      <td>56.1</td>      <td>88.5</td>      <td>82.4</td>      <td>60.3</td>    </tr>    <tr>      <td>System || Our approach -previous instructions</td>      <td>90.1</td>      <td>77.1</td>      <td>66.1</td>      <td>79.3</td>      <td>60.6</td>      <td>45.5</td>      <td>76.4</td>      <td>55.8</td>      <td>27.6</td>    </tr>    <tr>      <td>System || Our approach -current and initial state</td>      <td>25.7</td>      <td>4.5</td>      <td>3.3</td>      <td>17.5</td>      <td>0.0</td>      <td>0.0</td>      <td>45.4</td>      <td>15.1</td>      <td>3.5</td>    </tr>    <tr>      <td>System || Our approach -current state</td>      <td>89.8</td>      <td>78.0</td>      <td>62.9</td>      <td>83.0</td>      <td>68.7</td>      <td>54.0</td>      <td>87.6</td>      <td>78.4</td>      <td>60.8</td>    </tr>    <tr>      <td>System || Our approach -initial state</td>      <td>81.1</td>      <td>68.6</td>      <td>42.9</td>      <td>82.7</td>      <td>67.7</td>      <td>57.1</td>      <td>88.6</td>      <td>82.9</td>      <td>63.3</td>    </tr>    <tr>      <td>System || Our approach (mean \u00b1 stdev)</td>      <td>91.5 \u00b11.4</td>      <td>80.4 \u00b12.6</td>      <td>69.5 \u00b15.0</td>      <td>62.9 \u00b117.7</td>      <td>37.8 \u00b123.5</td>      <td>29.0 \u00b121.1</td>      <td>88.2 \u00b10.6</td>      <td>80.8 \u00b12.8</td>      <td>59.2 \u00b12.3</td>    </tr>  </tbody></table>",
        "table_name": "Table 4",
        "table_id": "table_4",
        "paper_id": "P18-1193",
        "page_no": 9,
        "dir": "acl2018",
        "valid": 1
    },
    {
        "table_id_paper": "P18-1212table_4",
        "caption": "Comparison between the proposed method and existing ones, in terms of both temporal and causal performances. See Sec. 4.2.1 for description of our new dataset. Per the McNemar\u2019s test, the joint system is significantly better than both baselines with p<0.05. Lines 4-5 provide the best possible performance the joint system could achieve if gold temporal/causal relations were given.",
        "row_header_level": 2,
        "row_headers": [
            [
                "-",
                "1. Temporal Only"
            ],
            [
                "-",
                "2. Causal Only"
            ],
            [
                "-",
                "3. Joint System"
            ],
            [
                "Enforcing Gold Relations in Joint System",
                "4. Gold Temporal"
            ],
            [
                "Enforcing Gold Relations in Joint System",
                "5. Gold Causal"
            ]
        ],
        "column_header_level": 2,
        "column_headers": [
            [
                "Temporal",
                "P"
            ],
            [
                "Temporal",
                "R"
            ],
            [
                "Temporal",
                "F1"
            ],
            [
                "Causal",
                "Accuracy"
            ]
        ],
        "contents": [
            [
                "67.2",
                "72.3",
                "69.7",
                "-"
            ],
            [
                "-",
                "-",
                "-",
                "70.5"
            ],
            [
                "68.6",
                "73.8",
                "71.1",
                "77.3"
            ],
            [
                "100",
                "100",
                "100",
                "91.9"
            ],
            [
                "69.3",
                "74.4",
                "71.8",
                "100"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "P",
            "R",
            "F1",
            "Accuracy"
        ],
        "target_entity": [
            "3. Joint System"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Temporal || P</th>      <th>Temporal || R</th>      <th>Temporal || F1</th>      <th>Causal || Accuracy</th>    </tr>  </thead>  <tbody>    <tr>      <td>- || 1. Temporal Only</td>      <td>67.2</td>      <td>72.3</td>      <td>69.7</td>      <td>-</td>    </tr>    <tr>      <td>- || 2. Causal Only</td>      <td>-</td>      <td>-</td>      <td>-</td>      <td>70.5</td>    </tr>    <tr>      <td>- || 3. Joint System</td>      <td>68.6</td>      <td>73.8</td>      <td>71.1</td>      <td>77.3</td>    </tr>    <tr>      <td>Enforcing Gold Relations in Joint System || 4. Gold Temporal</td>      <td>100</td>      <td>100</td>      <td>100</td>      <td>91.9</td>    </tr>    <tr>      <td>Enforcing Gold Relations in Joint System || 5. Gold Causal</td>      <td>69.3</td>      <td>74.4</td>      <td>71.8</td>      <td>100</td>    </tr>  </tbody></table>",
        "table_name": "Table 4",
        "table_id": "table_4",
        "paper_id": "P18-1212",
        "page_no": 8,
        "dir": "acl2018",
        "valid": 1
    },
    {
        "table_id_paper": "P18-1228table_3",
        "caption": "Results of analogy tests, comparing 20M sample texts from Reddit vs. Google 100B News.",
        "row_header_level": 2,
        "row_headers": [
            [
                "Category",
                "World"
            ],
            [
                "Category",
                "family"
            ],
            [
                "Category",
                "Gram1-9"
            ],
            [
                "-",
                "Total"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "Reddit20M"
            ],
            [
                "Google300D"
            ]
        ],
        "contents": [
            [
                "28.34",
                "70.2"
            ],
            [
                "94.58",
                "90.06"
            ],
            [
                "70.21",
                "73.4"
            ],
            [
                "67.88",
                "77.08"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "accuracy",
            "accuracy"
        ],
        "target_entity": [
            "Reddit20M"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Reddit20M</th>      <th>Google300D</th>    </tr>  </thead>  <tbody>    <tr>      <td>Category || World</td>      <td>28.34</td>      <td>70.2</td>    </tr>    <tr>      <td>Category || family</td>      <td>94.58</td>      <td>90.06</td>    </tr>    <tr>      <td>Category || Gram1-9</td>      <td>70.21</td>      <td>73.4</td>    </tr>    <tr>      <td>- || Total</td>      <td>67.88</td>      <td>77.08</td>    </tr>  </tbody></table>",
        "table_name": "Table 3",
        "table_id": "table_3",
        "paper_id": "P18-1228",
        "page_no": 6,
        "dir": "acl2018",
        "valid": 1
    },
    {
        "table_id_paper": "P18-1244table_3",
        "caption": "Evaluation of unmixed speech without multi-speaker training.",
        "row_header_level": 2,
        "row_headers": [
            [
                "TASK",
                "WSJ"
            ],
            [
                "TASK",
                "CSJ"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "AVG."
            ]
        ],
        "contents": [
            [
                "2.6"
            ],
            [
                "7.8"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "AVG."
        ],
        "target_entity": [
            "WSJ",
            "CSJ"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>AVG.</th>    </tr>  </thead>  <tbody>    <tr>      <td>TASK || WSJ</td>      <td>2.6</td>    </tr>    <tr>      <td>TASK || CSJ</td>      <td>7.8</td>    </tr>  </tbody></table>",
        "table_name": "Table 3",
        "table_id": "table_3",
        "paper_id": "P18-1244",
        "page_no": 7,
        "dir": "acl2018",
        "valid": 1
    },
    {
        "table_id_paper": "P18-1246table_4",
        "caption": "Results for morphological features. The column CoNLL Winner shows the top system of the ST 17, the DQM Reimpl. shows our reimplementation of Dozat et al. (2017), the column ours shows our system with a sentence-based character model; RRIE gives the relative reduction in error between the Reimpl. DQM and sentencebased character system. Our system outperforms the CoNLL Winner by 48 out of 54 treebanks and the reimplementation of DQM, by 43 of 54 treebanks, with 6 ties.",
        "row_header_level": 2,
        "row_headers": [
            [
                "lang.",
                "cs_cac"
            ],
            [
                "lang.",
                "ru_syn."
            ],
            [
                "lang.",
                "cs"
            ],
            [
                "lang.",
                "la_ittb"
            ],
            [
                "lang.",
                "sl"
            ],
            [
                "lang.",
                "ca"
            ],
            [
                "lang.",
                "fi_ftb"
            ],
            [
                "lang.",
                "no_bok."
            ],
            [
                "lang.",
                "grc_proiel"
            ],
            [
                "lang.",
                "fr_sequoia"
            ],
            [
                "lang.",
                "la_proiel"
            ],
            [
                "lang.",
                "es_ancora"
            ],
            [
                "lang.",
                "da"
            ],
            [
                "lang.",
                "fi"
            ],
            [
                "lang.",
                "sv"
            ],
            [
                "lang.",
                "pt"
            ],
            [
                "lang.",
                "grc"
            ],
            [
                "lang.",
                "no_nyn."
            ],
            [
                "lang.",
                "de"
            ],
            [
                "lang.",
                "ru"
            ],
            [
                "lang.",
                "hi"
            ],
            [
                "lang.",
                "cu"
            ],
            [
                "lang.",
                "fa"
            ],
            [
                "lang.",
                "tr"
            ],
            [
                "lang.",
                "en_partut"
            ],
            [
                "lang.",
                "sk"
            ],
            [
                "lang.",
                "eu"
            ],
            [
                "lang.",
                "pt_br"
            ],
            [
                "lang.",
                "es"
            ],
            [
                "lang.",
                "ko"
            ],
            [
                "lang.",
                "ar"
            ],
            [
                "lang.",
                "it"
            ],
            [
                "lang.",
                "nl_lassy"
            ],
            [
                "lang.",
                "nl"
            ],
            [
                "lang.",
                "pl"
            ],
            [
                "lang.",
                "ur"
            ],
            [
                "lang.",
                "bg"
            ],
            [
                "lang.",
                "hr"
            ],
            [
                "lang.",
                "he"
            ],
            [
                "lang.",
                "et"
            ],
            [
                "lang.",
                "zh"
            ],
            [
                "lang.",
                "vi"
            ],
            [
                "lang.",
                "ja"
            ],
            [
                "lang.",
                "en_lines"
            ],
            [
                "lang.",
                "fr"
            ],
            [
                "lang.",
                "gl"
            ],
            [
                "lang.",
                "id"
            ],
            [
                "lang.",
                "ro"
            ],
            [
                "lang.",
                "sv_lines"
            ],
            [
                "lang.",
                "cs_cltt"
            ],
            [
                "lang.",
                "lv"
            ],
            [
                "lang.",
                "el"
            ],
            [
                "lang.",
                "hu"
            ],
            [
                "lang.",
                "en"
            ],
            [
                "lang.",
                "macro-avg"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "CONLL Winner"
            ],
            [
                "DQM Reimpl."
            ],
            [
                "ours"
            ]
        ],
        "contents": [
            [
                "90.72",
                "94.66",
                "96.41"
            ],
            [
                "94.55",
                "96.70",
                "97.53"
            ],
            [
                "93.14",
                "96.32",
                "97.14"
            ],
            [
                "94.28",
                "96.45",
                "97.12"
            ],
            [
                "90.08",
                "95.26",
                "96.03"
            ],
            [
                "97.23",
                "97.85",
                "98.13"
            ],
            [
                "93.43",
                "95.96",
                "96.42"
            ],
            [
                "95.56",
                "96.95",
                "97.26"
            ],
            [
                "90.24",
                "91.35",
                "92.22"
            ],
            [
                "96.10",
                "96.62",
                "97.62"
            ],
            [
                "89.22",
                "91.52",
                "92.35"
            ],
            [
                "97.72",
                "98.15",
                "98.32"
            ],
            [
                "94.83",
                "96.62",
                "96.94"
            ],
            [
                "92.43",
                "94.29",
                "94.83"
            ],
            [
                "95.15",
                "96.52",
                "96.84"
            ],
            [
                "94.62",
                "95.89",
                "96.27"
            ],
            [
                "88.00",
                "90.39",
                "91.13"
            ],
            [
                "95.25",
                "96.79",
                "97.08"
            ],
            [
                "93.11",
                "89.78",
                "90.70"
            ],
            [
                "87.27",
                "91.99",
                "92.69"
            ],
            [
                "91.03",
                "90.72",
                "91.78"
            ],
            [
                "88.90",
                "88.93",
                "89.82"
            ],
            [
                "96.34",
                "97.23",
                "97.45"
            ],
            [
                "87.03",
                "89.39",
                "90.21"
            ],
            [
                "92.69",
                "93.93",
                "94.40"
            ],
            [
                "81.23",
                "87.54",
                "88.48"
            ],
            [
                "89.57",
                "92.48",
                "83.04"
            ],
            [
                "99.73",
                "99.73",
                "99.75"
            ],
            [
                "96.34",
                "96.42",
                "96.68"
            ],
            [
                "99.41",
                "99.44",
                "99.48"
            ],
            [
                "87.15",
                "85.45",
                "88.29"
            ],
            [
                "97.37",
                "97.72",
                "97.86"
            ],
            [
                "97.55",
                "98.04",
                "98.15"
            ],
            [
                "90.04",
                "92.06",
                "92.47"
            ],
            [
                "86.53",
                "91.71",
                "92.14"
            ],
            [
                "81.03",
                "83.16",
                "84.02"
            ],
            [
                "96.47",
                "97.71",
                "97.82"
            ],
            [
                "85.82",
                "90.64",
                "91.50"
            ],
            [
                "85.06",
                "79.34",
                "79.76"
            ],
            [
                "84.62",
                "88.18",
                "88.25"
            ],
            [
                "92.90",
                "87.67",
                "87.74"
            ],
            [
                "86.92",
                "82.23",
                "82.30"
            ],
            [
                "96.84",
                "89.65",
                "89.66"
            ],
            [
                "99.96",
                "99.99",
                "99.99"
            ],
            [
                "96.12",
                "95.98",
                "95.98"
            ],
            [
                "99.78",
                "99.72",
                "99.72"
            ],
            [
                "99.55",
                "99.50",
                "99.50"
            ],
            [
                "96.24",
                "97.26",
                "97.26"
            ],
            [
                "99.98",
                "99.98",
                "99.98"
            ],
            [
                "87.88",
                "90.41",
                "90.36"
            ],
            [
                "84.14",
                "87.00",
                "86.92"
            ],
            [
                "91.37",
                "94.00",
                "93.92"
            ],
            [
                "72.61",
                "82.67",
                "82.44"
            ],
            [
                "94.49",
                "95.93",
                "95.71"
            ],
            [
                "91.51",
                "92.89",
                "93.31"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "accuracy",
            "accuracy",
            "accuracy"
        ],
        "target_entity": [
            "ours"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>CONLL Winner</th>      <th>DQM Reimpl.</th>      <th>ours</th>      <th>RRIE</th>    </tr>  </thead>  <tbody>    <tr>      <td>lang. || cs_cac</td>      <td>90.72</td>      <td>94.66</td>      <td>96.41</td>      <td>27.9</td>    </tr>    <tr>      <td>lang. || ru_syn.</td>      <td>94.55</td>      <td>96.70</td>      <td>97.53</td>      <td>23.1</td>    </tr>    <tr>      <td>lang. || cs</td>      <td>93.14</td>      <td>96.32</td>      <td>97.14</td>      <td>22.3</td>    </tr>    <tr>      <td>lang. || la_ittb</td>      <td>94.28</td>      <td>96.45</td>      <td>97.12</td>      <td>18.9</td>    </tr>    <tr>      <td>lang. || sl</td>      <td>90.08</td>      <td>95.26</td>      <td>96.03</td>      <td>16.2</td>    </tr>    <tr>      <td>lang. || ca</td>      <td>97.23</td>      <td>97.85</td>      <td>98.13</td>      <td>13.0</td>    </tr>    <tr>      <td>lang. || fi_ftb</td>      <td>93.43</td>      <td>95.96</td>      <td>96.42</td>      <td>11.4</td>    </tr>    <tr>      <td>lang. || no_bok.</td>      <td>95.56</td>      <td>96.95</td>      <td>97.26</td>      <td>10.2</td>    </tr>    <tr>      <td>lang. || grc_proiel</td>      <td>90.24</td>      <td>91.35</td>      <td>92.22</td>      <td>10.1</td>    </tr>    <tr>      <td>lang. || fr_sequoia</td>      <td>96.10</td>      <td>96.62</td>      <td>97.62</td>      <td>10.1</td>    </tr>    <tr>      <td>lang. || la_proiel</td>      <td>89.22</td>      <td>91.52</td>      <td>92.35</td>      <td>9.8</td>    </tr>    <tr>      <td>lang. || es_ancora</td>      <td>97.72</td>      <td>98.15</td>      <td>98.32</td>      <td>9.7</td>    </tr>    <tr>      <td>lang. || da</td>      <td>94.83</td>      <td>96.62</td>      <td>96.94</td>      <td>9.5</td>    </tr>    <tr>      <td>lang. || fi</td>      <td>92.43</td>      <td>94.29</td>      <td>94.83</td>      <td>9.5</td>    </tr>    <tr>      <td>lang. || sv</td>      <td>95.15</td>      <td>96.52</td>      <td>96.84</td>      <td>9.2</td>    </tr>    <tr>      <td>lang. || pt</td>      <td>94.62</td>      <td>95.89</td>      <td>96.27</td>      <td>9.2</td>    </tr>    <tr>      <td>lang. || grc</td>      <td>88.00</td>      <td>90.39</td>      <td>91.13</td>      <td>9.0</td>    </tr>    <tr>      <td>lang. || no_nyn.</td>      <td>95.25</td>      <td>96.79</td>      <td>97.08</td>      <td>9.0</td>    </tr>    <tr>      <td>lang. || de</td>      <td>93.11</td>      <td>89.78</td>      <td>90.70</td>      <td>9.0</td>    </tr>    <tr>      <td>lang. || ru</td>      <td>87.27</td>      <td>91.99</td>      <td>92.69</td>      <td>8.7</td>    </tr>    <tr>      <td>lang. || hi</td>      <td>91.03</td>      <td>90.72</td>      <td>91.78</td>      <td>8.1</td>    </tr>    <tr>      <td>lang. || cu</td>      <td>88.90</td>      <td>88.93</td>      <td>89.82</td>      <td>8.0</td>    </tr>    <tr>      <td>lang. || fa</td>      <td>96.34</td>      <td>97.23</td>      <td>97.45</td>      <td>7.9</td>    </tr>    <tr>      <td>lang. || tr</td>      <td>87.03</td>      <td>89.39</td>      <td>90.21</td>      <td>7.7</td>    </tr>    <tr>      <td>lang. || en_partut</td>      <td>92.69</td>      <td>93.93</td>      <td>94.40</td>      <td>7.7</td>    </tr>    <tr>      <td>lang. || sk</td>      <td>81.23</td>      <td>87.54</td>      <td>88.48</td>      <td>7.5</td>    </tr>    <tr>      <td>lang. || eu</td>      <td>89.57</td>      <td>92.48</td>      <td>83.04</td>      <td>7.4</td>    </tr>    <tr>      <td>lang. || pt_br</td>      <td>99.73</td>      <td>99.73</td>      <td>99.75</td>      <td>7.4</td>    </tr>    <tr>      <td>lang. || es</td>      <td>96.34</td>      <td>96.42</td>      <td>96.68</td>      <td>7.3</td>    </tr>    <tr>      <td>lang. || ko</td>      <td>99.41</td>      <td>99.44</td>      <td>99.48</td>      <td>7.1</td>    </tr>    <tr>      <td>lang. || ar</td>      <td>87.15</td>      <td>85.45</td>      <td>88.29</td>      <td>6.7</td>    </tr>    <tr>      <td>lang. || it</td>      <td>97.37</td>      <td>97.72</td>      <td>97.86</td>      <td>6.1</td>    </tr>    <tr>      <td>lang. || nl_lassy</td>      <td>97.55</td>      <td>98.04</td>      <td>98.15</td>      <td>5.2</td>    </tr>    <tr>      <td>lang. || nl</td>      <td>90.04</td>      <td>92.06</td>      <td>92.47</td>      <td>5.2</td>    </tr>    <tr>      <td>lang. || pl</td>      <td>86.53</td>      <td>91.71</td>      <td>92.14</td>      <td>5.2</td>    </tr>    <tr>      <td>lang. || ur</td>      <td>81.03</td>      <td>83.16</td>      <td>84.02</td>      <td>5.1</td>    </tr>    <tr>      <td>lang. || bg</td>      <td>96.47</td>      <td>97.71</td>      <td>97.82</td>      <td>4.8</td>    </tr>    <tr>      <td>lang. || hr</td>      <td>85.82</td>      <td>90.64</td>      <td>91.50</td>      <td>3.8</td>    </tr>    <tr>      <td>lang. || he</td>      <td>85.06</td>      <td>79.34</td>      <td>79.76</td>      <td>2.0</td>    </tr>    <tr>      <td>lang. || et</td>      <td>84.62</td>      <td>88.18</td>      <td>88.25</td>      <td>0.6</td>    </tr>    <tr>      <td>lang. || zh</td>      <td>92.90</td>      <td>87.67</td>      <td>87.74</td>      <td>0.6</td>    </tr>    <tr>      <td>lang. || vi</td>      <td>86.92</td>      <td>82.23</td>      <td>82.30</td>      <td>0.4</td>    </tr>    <tr>      <td>lang. || ja</td>      <td>96.84</td>      <td>89.65</td>      <td>89.66</td>      <td>0.1</td>    </tr>    <tr>      <td>lang. || en_lines</td>      <td>99.96</td>      <td>99.99</td>      <td>99.99</td>      <td>0.0</td>    </tr>    <tr>      <td>lang. || fr</td>      <td>96.12</td>      <td>95.98</td>      <td>95.98</td>      <td>0.0</td>    </tr>    <tr>      <td>lang. || gl</td>      <td>99.78</td>      <td>99.72</td>      <td>99.72</td>      <td>0.0</td>    </tr>    <tr>      <td>lang. || id</td>      <td>99.55</td>      <td>99.50</td>      <td>99.50</td>      <td>0.0</td>    </tr>    <tr>      <td>lang. || ro</td>      <td>96.24</td>      <td>97.26</td>      <td>97.26</td>      <td>0.0</td>    </tr>    <tr>      <td>lang. || sv_lines</td>      <td>99.98</td>      <td>99.98</td>      <td>99.98</td>      <td>0.0</td>    </tr>    <tr>      <td>lang. || cs_cltt</td>      <td>87.88</td>      <td>90.41</td>      <td>90.36</td>      <td>-0.5</td>    </tr>    <tr>      <td>lang. || lv</td>      <td>84.14</td>      <td>87.00</td>      <td>86.92</td>      <td>-0.6</td>    </tr>    <tr>      <td>lang. || el</td>      <td>91.37</td>      <td>94.00</td>      <td>93.92</td>      <td>-1.3</td>    </tr>    <tr>      <td>lang. || hu</td>      <td>72.61</td>      <td>82.67</td>      <td>82.44</td>      <td>-1.3</td>    </tr>    <tr>      <td>lang. || en</td>      <td>94.49</td>      <td>95.93</td>      <td>95.71</td>      <td>-5.4</td>    </tr>    <tr>      <td>lang. || macro-avg</td>      <td>91.51</td>      <td>92.89</td>      <td>93.31</td>      <td>-</td>    </tr>  </tbody></table>",
        "table_name": "Table 4",
        "table_id": "table_4",
        "paper_id": "P18-1246",
        "page_no": 7,
        "dir": "acl2018",
        "valid": 1
    },
    {
        "table_id_paper": "P18-1256table_2",
        "caption": "Performance of various models, including our weighted-pooled LSTM (WP). MFC refers to the most-frequent-class baseline, LogReg is the logistic regression baseline. LSTM and CNN correspond to strong neural network baselines. Note that we bold the performance numbers for the best performing model for each of the \u201c+ POS\u201d case and the \u201cPOS\u201d case.",
        "row_header_level": 4,
        "row_headers": [
            [
                "Models",
                "MFC",
                "Variants",
                "-"
            ],
            [
                "Models",
                "LogReg",
                "Variants",
                "+ POS"
            ],
            [
                "Models",
                "LogReg",
                "Variants",
                "- POS"
            ],
            [
                "Models",
                "CNN",
                "Variants",
                "+ POS"
            ],
            [
                "Models",
                "CNN",
                "Variants",
                "- POS"
            ],
            [
                "Models",
                "LSTM",
                "Variants",
                "+ POS"
            ],
            [
                "Models",
                "LSTM",
                "Variants",
                "- POS"
            ],
            [
                "Models",
                "WP",
                "Variants",
                "+ POS"
            ],
            [
                "Models",
                "WP",
                "Variants",
                "- POS"
            ]
        ],
        "column_header_level": 3,
        "column_headers": [
            [
                "Accuracy",
                "WSJ",
                "All adverbs"
            ],
            [
                "Accuracy",
                "Gigaword",
                "All adverbs"
            ],
            [
                "Accuracy",
                "Gigaword",
                "Also"
            ],
            [
                "Accuracy",
                "Gigaword",
                "Still"
            ],
            [
                "Accuracy",
                "Gigaword",
                "Again"
            ],
            [
                "Accuracy",
                "Gigaword",
                "Too"
            ],
            [
                "Accuracy",
                "Gigaword",
                "Yet"
            ]
        ],
        "contents": [
            [
                "51.66",
                "50.24",
                "50.32",
                "50.29",
                "50.25",
                "65.06",
                "50.19"
            ],
            [
                "52.81",
                "53.65",
                "52.00",
                "56.36",
                "59.49",
                "69.77",
                "61.05"
            ],
            [
                "54.47",
                "52.86",
                "56.07",
                "55.29",
                "58.60",
                "67.60",
                "58.60"
            ],
            [
                "58.84",
                "59.12",
                "61.53",
                "59.54",
                "60.26",
                "67.53",
                "59.69"
            ],
            [
                "62.16",
                "57.21",
                "59.76",
                "56.95",
                "57.28",
                "67.84",
                "56.53"
            ],
            [
                "74.23",
                "60.58",
                "81.48",
                "60.72",
                "61.81",
                "69.70",
                "59.13"
            ],
            [
                "73.18",
                "58.86",
                "81.16",
                "58.97",
                "59.93",
                "68.32",
                "55.71"
            ],
            [
                "76.09",
                "60.62",
                "82.42",
                "61.00",
                "61.59",
                "69.38",
                "57.68"
            ],
            [
                "74.84",
                "58.87",
                "81.64",
                "59.03",
                "58.49",
                "68.37",
                "56.68"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "Accuracy",
            "Accuracy",
            "Accuracy",
            "Accuracy",
            "Accuracy",
            "Accuracy",
            "Accuracy"
        ],
        "target_entity": [
            "WP"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Accuracy || WSJ || All adverbs</th>      <th>Accuracy || Gigaword || All adverbs</th>      <th>Accuracy || Gigaword || Also</th>      <th>Accuracy || Gigaword || Still</th>      <th>Accuracy || Gigaword || Again</th>      <th>Accuracy || Gigaword || Too</th>      <th>Accuracy || Gigaword || Yet</th>    </tr>  </thead>  <tbody>    <tr>      <td>Models || MFC || Variants || -</td>      <td>51.66</td>      <td>50.24</td>      <td>50.32</td>      <td>50.29</td>      <td>50.25</td>      <td>65.06</td>      <td>50.19</td>    </tr>    <tr>      <td>Models || LogReg || Variants || + POS</td>      <td>52.81</td>      <td>53.65</td>      <td>52.00</td>      <td>56.36</td>      <td>59.49</td>      <td>69.77</td>      <td>61.05</td>    </tr>    <tr>      <td>Models || LogReg || Variants || - POS</td>      <td>54.47</td>      <td>52.86</td>      <td>56.07</td>      <td>55.29</td>      <td>58.60</td>      <td>67.60</td>      <td>58.60</td>    </tr>    <tr>      <td>Models || CNN || Variants || + POS</td>      <td>58.84</td>      <td>59.12</td>      <td>61.53</td>      <td>59.54</td>      <td>60.26</td>      <td>67.53</td>      <td>59.69</td>    </tr>    <tr>      <td>Models || CNN || Variants || - POS</td>      <td>62.16</td>      <td>57.21</td>      <td>59.76</td>      <td>56.95</td>      <td>57.28</td>      <td>67.84</td>      <td>56.53</td>    </tr>    <tr>      <td>Models || LSTM || Variants || + POS</td>      <td>74.23</td>      <td>60.58</td>      <td>81.48</td>      <td>60.72</td>      <td>61.81</td>      <td>69.70</td>      <td>59.13</td>    </tr>    <tr>      <td>Models || LSTM || Variants || - POS</td>      <td>73.18</td>      <td>58.86</td>      <td>81.16</td>      <td>58.97</td>      <td>59.93</td>      <td>68.32</td>      <td>55.71</td>    </tr>    <tr>      <td>Models || WP || Variants || + POS</td>      <td>76.09</td>      <td>60.62</td>      <td>82.42</td>      <td>61.00</td>      <td>61.59</td>      <td>69.38</td>      <td>57.68</td>    </tr>    <tr>      <td>Models || WP || Variants || - POS</td>      <td>74.84</td>      <td>58.87</td>      <td>81.64</td>      <td>59.03</td>      <td>58.49</td>      <td>68.37</td>      <td>56.68</td>    </tr>  </tbody></table>",
        "table_name": "Table 2",
        "table_id": "table_2",
        "paper_id": "P18-1256",
        "page_no": 7,
        "dir": "acl2018",
        "valid": 1
    },
    {
        "table_id_paper": "P18-2042table_2",
        "caption": "Method Comparison (%).",
        "row_header_level": 2,
        "row_headers": [
            [
                "Method",
                "LSTM-LM"
            ],
            [
                "Method",
                "Seq2seq"
            ],
            [
                "Method",
                "ED(1)"
            ],
            [
                "Method",
                "ED(2)"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "METEOR"
            ],
            [
                "ROUGE-L"
            ],
            [
                "PREFERENCE"
            ]
        ],
        "contents": [
            [
                "8.7",
                "15.1",
                "0"
            ],
            [
                "13.5",
                "19.2",
                "22"
            ],
            [
                "13.3",
                "20.3",
                "30"
            ],
            [
                "14.0",
                "19.8",
                "48"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "METEOR",
            "ROUGE-L",
            "PREFERENCE"
        ],
        "target_entity": [
            "ED(2)"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>METEOR</th>      <th>ROUGE-L</th>      <th>PREFERENCE</th>    </tr>  </thead>  <tbody>    <tr>      <td>Method || LSTM-LM</td>      <td>8.7</td>      <td>15.1</td>      <td>0</td>    </tr>    <tr>      <td>Method || Seq2seq</td>      <td>13.5</td>      <td>19.2</td>      <td>22</td>    </tr>    <tr>      <td>Method || ED(1)</td>      <td>13.3</td>      <td>20.3</td>      <td>30</td>    </tr>    <tr>      <td>Method || ED(2)</td>      <td>14.0</td>      <td>19.8</td>      <td>48</td>    </tr>  </tbody></table>",
        "table_name": "Table 2",
        "table_id": "table_2",
        "paper_id": "P18-2042",
        "page_no": 3,
        "dir": "acl2018",
        "valid": 1
    },
    {
        "table_id_paper": "P19-1002table_1",
        "caption": "Automatic evaluation and manual evaluation results for baselines and our proposed models.",
        "row_header_level": 2,
        "row_headers": [
            [
                "Model",
                "Seq2Seq without knowledge"
            ],
            [
                "Model",
                "HRED without knowledge"
            ],
            [
                "Model",
                "Transformer without knowledge"
            ],
            [
                "Model",
                "Seq2Seq (+knowledge)"
            ],
            [
                "Model",
                "HRED (+knowledge)"
            ],
            [
                "Model",
                "Wizard Transformer"
            ],
            [
                "Model",
                "ITE+DD (ours)"
            ],
            [
                "Model",
                "ITE+CKAD (ours)"
            ],
            [
                "Model",
                "KAT (ours)"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "PPL"
            ],
            [
                "BLEU(%)"
            ],
            [
                "Fluency"
            ],
            [
                "Knowledge Relevance"
            ],
            [
                "Context Coherence"
            ]
        ],
        "contents": [
            [
                "80.93",
                "0.38",
                "1.62",
                "0.18",
                "0.54"
            ],
            [
                "80.84",
                "0.43",
                "1.25",
                "0.18",
                "0.3"
            ],
            [
                "87.32",
                "0.36",
                "1.6",
                "0.29",
                "0.67"
            ],
            [
                "78.47",
                "0.39",
                "1.5",
                "0.22",
                "0.61"
            ],
            [
                "79.12",
                "0.77",
                "1.56",
                "0.35",
                "0.47"
            ],
            [
                "70.3",
                "0.66",
                "1.62",
                "0.47",
                "0.56"
            ],
            [
                "15.11",
                "0.95",
                "1.67",
                "0.56",
                "0.9"
            ],
            [
                "64.97",
                "0.86",
                "1.68",
                "0.5",
                "0.82"
            ],
            [
                "65.36",
                "0.58",
                "1.58",
                "0.33",
                "0.78"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "PPL",
            "BLEU(%)",
            "Fluency",
            "Knowledge Relevance",
            "Context Coherence"
        ],
        "target_entity": [
            "ITE+DD (ours)",
            "ITE+CKAD (ours)",
            "KAT (ours)"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>PPL</th>      <th>BLEU(%)</th>      <th>Fluency</th>      <th>Knowledge Relevance</th>      <th>Context Coherence</th>    </tr>  </thead>  <tbody>    <tr>      <td>Model || Seq2Seq without knowledge</td>      <td>80.93</td>      <td>0.38</td>      <td>1.62</td>      <td>0.18</td>      <td>0.54</td>    </tr>    <tr>      <td>Model || HRED without knowledge</td>      <td>80.84</td>      <td>0.43</td>      <td>1.25</td>      <td>0.18</td>      <td>0.3</td>    </tr>    <tr>      <td>Model || Transformer without knowledge</td>      <td>87.32</td>      <td>0.36</td>      <td>1.6</td>      <td>0.29</td>      <td>0.67</td>    </tr>    <tr>      <td>Model || Seq2Seq (+knowledge)</td>      <td>78.47</td>      <td>0.39</td>      <td>1.5</td>      <td>0.22</td>      <td>0.61</td>    </tr>    <tr>      <td>Model || HRED (+knowledge)</td>      <td>79.12</td>      <td>0.77</td>      <td>1.56</td>      <td>0.35</td>      <td>0.47</td>    </tr>    <tr>      <td>Model || Wizard Transformer</td>      <td>70.3</td>      <td>0.66</td>      <td>1.62</td>      <td>0.47</td>      <td>0.56</td>    </tr>    <tr>      <td>Model || ITE+DD (ours)</td>      <td>15.11</td>      <td>0.95</td>      <td>1.67</td>      <td>0.56</td>      <td>0.9</td>    </tr>    <tr>      <td>Model || ITE+CKAD (ours)</td>      <td>64.97</td>      <td>0.86</td>      <td>1.68</td>      <td>0.5</td>      <td>0.82</td>    </tr>    <tr>      <td>Model || KAT (ours)</td>      <td>65.36</td>      <td>0.58</td>      <td>1.58</td>      <td>0.33</td>      <td>0.78</td>    </tr>  </tbody></table>",
        "table_name": "Table 1",
        "table_id": "table_1",
        "paper_id": "P19-1002",
        "page_no": 6,
        "dir": "acl2019",
        "valid": 1
    },
    {
        "table_id_paper": "P19-1012table_1",
        "caption": "Average (from six runs) parsing results (LAS) on test sets. \u2020 marks statistical significance (p-value < 0.05). Corresponding standard deviations are provided in Table 3 in Appendix A.",
        "row_header_level": 1,
        "row_headers": [
            [
                "TBMIN"
            ],
            [
                "TBEXT"
            ],
            [
                "GBMIN"
            ],
            [
                "GBSIBL"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "avg."
            ],
            [
                "en-ptb"
            ],
            [
                "ar"
            ],
            [
                "en"
            ],
            [
                "fi"
            ],
            [
                "grc"
            ],
            [
                "he"
            ],
            [
                "ko"
            ],
            [
                "ru"
            ],
            [
                "sv"
            ],
            [
                "zh"
            ]
        ],
        "contents": [
            [
                "76.43",
                "90.25",
                "76.22",
                "81.85\u2020",
                "72.51\u2020",
                "71.92\u2020",
                "79.41\u2020",
                "64.39",
                "74.35\u2020",
                "80.11\u2020",
                "73.28\u2020"
            ],
            [
                "75.56",
                "90.25",
                "75.77",
                "80.5",
                "71.47",
                "70.32",
                "78.62",
                "63.88",
                "73.82",
                "78.8",
                "72.17"
            ],
            [
                "77.74",
                "91.4",
                "77.25",
                "82.53",
                "74.37",
                "73.48",
                "80.83",
                "65.47",
                "76.43",
                "81.22",
                "74.47"
            ],
            [
                "77.89",
                "91.59",
                "77.21",
                "82.65",
                "74.44",
                "73.2",
                "81.03",
                "65.61",
                "76.79\u2020",
                "81.42",
                "74.95\u2020"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "accuracy",
            "accuracy",
            "accuracy",
            "accuracy",
            "accuracy",
            "accuracy",
            "accuracy",
            "accuracy",
            "accuracy",
            "accuracy",
            "accuracy"
        ],
        "target_entity": [
            "TBMIN",
            "TBEXT",
            "GBMIN",
            "GBSIBL"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>avg.</th>      <th>en-ptb</th>      <th>ar</th>      <th>en</th>      <th>fi</th>      <th>grc</th>      <th>he</th>      <th>ko</th>      <th>ru</th>      <th>sv</th>      <th>zh</th>    </tr>  </thead>  <tbody>    <tr>      <td>TBMIN</td>      <td>76.43</td>      <td>90.25</td>      <td>76.22</td>      <td>81.85\u2020</td>      <td>72.51\u2020</td>      <td>71.92\u2020</td>      <td>79.41\u2020</td>      <td>64.39</td>      <td>74.35\u2020</td>      <td>80.11\u2020</td>      <td>73.28\u2020</td>    </tr>    <tr>      <td>TBEXT</td>      <td>75.56</td>      <td>90.25</td>      <td>75.77</td>      <td>80.5</td>      <td>71.47</td>      <td>70.32</td>      <td>78.62</td>      <td>63.88</td>      <td>73.82</td>      <td>78.8</td>      <td>72.17</td>    </tr>    <tr>      <td>GBMIN</td>      <td>77.74</td>      <td>91.4</td>      <td>77.25</td>      <td>82.53</td>      <td>74.37</td>      <td>73.48</td>      <td>80.83</td>      <td>65.47</td>      <td>76.43</td>      <td>81.22</td>      <td>74.47</td>    </tr>    <tr>      <td>GBSIBL</td>      <td>77.89</td>      <td>91.59</td>      <td>77.21</td>      <td>82.65</td>      <td>74.44</td>      <td>73.2</td>      <td>81.03</td>      <td>65.61</td>      <td>76.79\u2020</td>      <td>81.42</td>      <td>74.95\u2020</td>    </tr>  </tbody></table>",
        "table_name": "Table 1",
        "table_id": "table_1",
        "paper_id": "P19-1012",
        "page_no": 5,
        "dir": "acl2019",
        "valid": 1
    },
    {
        "table_id_paper": "P19-1048table_3",
        "caption": "Model comparison. Average results over 5 runs with random initialization are reported. \u2217 indicates the proposed method is significantly better than the other baselines (p < 0.05) based on one-tailed unpaired t-test.",
        "row_header_level": 2,
        "row_headers": [
            [
                "D1",
                "F1-a"
            ],
            [
                "D1",
                "F1-o"
            ],
            [
                "D1",
                "acc-s"
            ],
            [
                "D1",
                "F1-s"
            ],
            [
                "D1",
                "F1-I"
            ],
            [
                "D2",
                "F1-a"
            ],
            [
                "D2",
                "F1-o"
            ],
            [
                "D2",
                "acc-s"
            ],
            [
                "D2",
                "F1-s"
            ],
            [
                "D2",
                "F1-I"
            ],
            [
                "D3",
                "F1-a"
            ],
            [
                "D3",
                "F1-o"
            ],
            [
                "D3",
                "acc-s"
            ],
            [
                "D3",
                "F1-s"
            ],
            [
                "D3",
                "F1-I"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "CMLA-ALSTM"
            ],
            [
                "CMLA-dTrans"
            ],
            [
                "DECNN-ALSTM"
            ],
            [
                "DECNN-dTrans"
            ],
            [
                "PIPELINE"
            ],
            [
                "MNN"
            ],
            [
                "INABSA"
            ],
            [
                "IMN -d wo DE"
            ],
            [
                "IMN -d"
            ],
            [
                "IMN wo DE"
            ],
            [
                "IMN"
            ]
        ],
        "contents": [
            [
                "82.45",
                "82.45",
                "83.94",
                "83.94",
                "83.94",
                "83.05",
                "83.92",
                "83.95",
                "84.01",
                "83.5",
                "83.33"
            ],
            [
                "82.67",
                "82.67",
                "85.6",
                "85.6",
                "85.6",
                "84.55",
                "84.97",
                "85.21",
                "85.64",
                "84.62",
                "85.61"
            ],
            [
                "77.46",
                "79.58",
                "77.79",
                "80.04",
                "79.56",
                "77.17",
                "79.68",
                "79.65",
                "81.56",
                "83.17",
                "83.89"
            ],
            [
                "68.7",
                "72.23",
                "68.5",
                "73.31",
                "69.59",
                "68.45",
                "68.38",
                "69.32",
                "71.9",
                "73.44",
                "75.66"
            ],
            [
                "63.87",
                "65.34",
                "65.26",
                "67.25",
                "66.53",
                "63.87",
                "66.6",
                "66.96",
                "68.32",
                "69.11",
                "69.54"
            ],
            [
                "76.8",
                "76.8",
                "78.38",
                "78.38",
                "78.38",
                "76.94",
                "77.34",
                "76.96",
                "78.46",
                "76.87",
                "77.96"
            ],
            [
                "77.33",
                "77.33",
                "78.81",
                "78.81",
                "78.81",
                "77.77",
                "76.62",
                "76.85",
                "78.14",
                "77.04",
                "77.51"
            ],
            [
                "70.25",
                "72.38",
                "70.46",
                "73.1",
                "72.29",
                "70.4",
                "72.3",
                "72.89",
                "73.21",
                "74.31",
                "75.36"
            ],
            [
                "66.67",
                "69.52",
                "66.78",
                "70.63",
                "68.12",
                "65.98",
                "68.24",
                "67.26",
                "69.92",
                "70.76",
                "72.02"
            ],
            [
                "53.68",
                "55.56",
                "55.05",
                "56.6",
                "56.02",
                "53.8",
                "55.88",
                "56.25",
                "57.66",
                "57.04",
                "58.37"
            ],
            [
                "68.55",
                "68.55",
                "68.32",
                "68.32",
                "68.32",
                "70.24",
                "69.4",
                "69.23",
                "69.8",
                "68.23",
                "70.04"
            ],
            [
                "71.07",
                "71.07",
                "71.22",
                "71.22",
                "71.22",
                "69.38",
                "71.43",
                "68.39",
                "72.11",
                "70.09",
                "71.94"
            ],
            [
                "81.03",
                "82.27",
                "80.32",
                "82.65",
                "82.27",
                "80.79",
                "82.56",
                "81.64",
                "83.38",
                "85.9",
                "85.64"
            ],
            [
                "58.91",
                "66.45",
                "57.25",
                "69.58",
                "59.53",
                "57.9",
                "58.81",
                "57.51",
                "60.65",
                "71.67",
                "71.76"
            ],
            [
                "54.79",
                "56.09",
                "55.1",
                "56.28",
                "55.96",
                "56.57",
                "57.38",
                "56.8",
                "57.91",
                "58.82",
                "59.18"
            ]
        ],
        "metrics_loc": "row",
        "metrics_type": [
            "F1-a",
            "F1-o",
            "acc-s",
            "F1-s",
            "F1-i",
            "F1-a",
            "F1-o",
            "acc-s",
            "F1-s",
            "F1-i",
            "F1-a",
            "F1-o",
            "acc-s",
            "F1-s",
            "F1-i"
        ],
        "target_entity": [
            "IMN -d",
            "IMN wo DE",
            "IMN"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>CMLA-ALSTM</th>      <th>CMLA-dTrans</th>      <th>DECNN-ALSTM</th>      <th>DECNN-dTrans</th>      <th>PIPELINE</th>      <th>MNN</th>      <th>INABSA</th>      <th>IMN -d wo DE</th>      <th>IMN -d</th>      <th>IMN wo DE</th>      <th>IMN</th>    </tr>  </thead>  <tbody>    <tr>      <td>D1 || F1-a</td>      <td>82.45</td>      <td>82.45</td>      <td>83.94</td>      <td>83.94</td>      <td>83.94</td>      <td>83.05</td>      <td>83.92</td>      <td>83.95</td>      <td>84.01</td>      <td>83.5</td>      <td>83.33</td>    </tr>    <tr>      <td>D1 || F1-o</td>      <td>82.67</td>      <td>82.67</td>      <td>85.6</td>      <td>85.6</td>      <td>85.6</td>      <td>84.55</td>      <td>84.97</td>      <td>85.21</td>      <td>85.64</td>      <td>84.62</td>      <td>85.61</td>    </tr>    <tr>      <td>D1 || acc-s</td>      <td>77.46</td>      <td>79.58</td>      <td>77.79</td>      <td>80.04</td>      <td>79.56</td>      <td>77.17</td>      <td>79.68</td>      <td>79.65</td>      <td>81.56</td>      <td>83.17</td>      <td>83.89</td>    </tr>    <tr>      <td>D1 || F1-s</td>      <td>68.7</td>      <td>72.23</td>      <td>68.5</td>      <td>73.31</td>      <td>69.59</td>      <td>68.45</td>      <td>68.38</td>      <td>69.32</td>      <td>71.9</td>      <td>73.44</td>      <td>75.66</td>    </tr>    <tr>      <td>D1 || F1-I</td>      <td>63.87</td>      <td>65.34</td>      <td>65.26</td>      <td>67.25</td>      <td>66.53</td>      <td>63.87</td>      <td>66.6</td>      <td>66.96</td>      <td>68.32</td>      <td>69.11</td>      <td>69.54</td>    </tr>    <tr>      <td>D2 || F1-a</td>      <td>76.8</td>      <td>76.8</td>      <td>78.38</td>      <td>78.38</td>      <td>78.38</td>      <td>76.94</td>      <td>77.34</td>      <td>76.96</td>      <td>78.46</td>      <td>76.87</td>      <td>77.96</td>    </tr>    <tr>      <td>D2 || F1-o</td>      <td>77.33</td>      <td>77.33</td>      <td>78.81</td>      <td>78.81</td>      <td>78.81</td>      <td>77.77</td>      <td>76.62</td>      <td>76.85</td>      <td>78.14</td>      <td>77.04</td>      <td>77.51</td>    </tr>    <tr>      <td>D2 || acc-s</td>      <td>70.25</td>      <td>72.38</td>      <td>70.46</td>      <td>73.1</td>      <td>72.29</td>      <td>70.4</td>      <td>72.3</td>      <td>72.89</td>      <td>73.21</td>      <td>74.31</td>      <td>75.36</td>    </tr>    <tr>      <td>D2 || F1-s</td>      <td>66.67</td>      <td>69.52</td>      <td>66.78</td>      <td>70.63</td>      <td>68.12</td>      <td>65.98</td>      <td>68.24</td>      <td>67.26</td>      <td>69.92</td>      <td>70.76</td>      <td>72.02</td>    </tr>    <tr>      <td>D2 || F1-I</td>      <td>53.68</td>      <td>55.56</td>      <td>55.05</td>      <td>56.6</td>      <td>56.02</td>      <td>53.8</td>      <td>55.88</td>      <td>56.25</td>      <td>57.66</td>      <td>57.04</td>      <td>58.37</td>    </tr>    <tr>      <td>D3 || F1-a</td>      <td>68.55</td>      <td>68.55</td>      <td>68.32</td>      <td>68.32</td>      <td>68.32</td>      <td>70.24</td>      <td>69.4</td>      <td>69.23</td>      <td>69.8</td>      <td>68.23</td>      <td>70.04</td>    </tr>    <tr>      <td>D3 || F1-o</td>      <td>71.07</td>      <td>71.07</td>      <td>71.22</td>      <td>71.22</td>      <td>71.22</td>      <td>69.38</td>      <td>71.43</td>      <td>68.39</td>      <td>72.11</td>      <td>70.09</td>      <td>71.94</td>    </tr>    <tr>      <td>D3 || acc-s</td>      <td>81.03</td>      <td>82.27</td>      <td>80.32</td>      <td>82.65</td>      <td>82.27</td>      <td>80.79</td>      <td>82.56</td>      <td>81.64</td>      <td>83.38</td>      <td>85.9</td>      <td>85.64</td>    </tr>    <tr>      <td>D3 || F1-s</td>      <td>58.91</td>      <td>66.45</td>      <td>57.25</td>      <td>69.58</td>      <td>59.53</td>      <td>57.9</td>      <td>58.81</td>      <td>57.51</td>      <td>60.65</td>      <td>71.67</td>      <td>71.76</td>    </tr>    <tr>      <td>D3 || F1-I</td>      <td>54.79</td>      <td>56.09</td>      <td>55.1</td>      <td>56.28</td>      <td>55.96</td>      <td>56.57</td>      <td>57.38</td>      <td>56.8</td>      <td>57.91</td>      <td>58.82</td>      <td>59.18</td>    </tr>  </tbody></table>",
        "table_name": "Table 3",
        "table_id": "table_3",
        "paper_id": "P19-1048",
        "page_no": 8,
        "dir": "acl2019",
        "valid": 1
    },
    {
        "table_id_paper": "P19-1085table_3",
        "caption": "Document retrieval evaluation on dev set (%). (\u2019-\u2019 denotes a missing value)",
        "row_header_level": 2,
        "row_headers": [
            [
                "Model",
                "Athene"
            ],
            [
                "Model",
                "UCL MRG"
            ],
            [
                "Model",
                "UNC NLP"
            ],
            [
                "Model",
                "Our Model"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "OFEVER"
            ]
        ],
        "contents": [
            [
                "93.55"
            ],
            [
                "-"
            ],
            [
                "92.82"
            ],
            [
                "93.33"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "OFEVER"
        ],
        "target_entity": [
            "Our Model"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>OFEVER</th>    </tr>  </thead>  <tbody>    <tr>      <td>Model || Athene</td>      <td>93.55</td>    </tr>    <tr>      <td>Model || UCL MRG</td>      <td>-</td>    </tr>    <tr>      <td>Model || UNC NLP</td>      <td>92.82</td>    </tr>    <tr>      <td>Model || Our Model</td>      <td>93.33</td>    </tr>  </tbody></table>",
        "table_name": "Table 3",
        "table_id": "table_3",
        "paper_id": "P19-1085",
        "page_no": 6,
        "dir": "acl2019",
        "valid": 1
    },
    {
        "table_id_paper": "P19-1198table_2",
        "caption": "Comparison of evaluation metrics for proposed systems (UNTS), unsupervised baseline (UNMT,USMT, and ST) and existing supervised and the unsupervised lexical simplification system LIGHTLS.",
        "row_header_level": 2,
        "row_headers": [
            [
                "System",
                "UNTS+10K"
            ],
            [
                "System",
                "UNTS"
            ],
            [
                "System",
                "UNMT"
            ],
            [
                "System",
                "USMT"
            ],
            [
                "System",
                "ST"
            ],
            [
                "System",
                "NTS"
            ],
            [
                "System",
                "SBMT"
            ],
            [
                "System",
                "PBSMT"
            ],
            [
                "System",
                "LIGHTLS"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "FE-diff"
            ],
            [
                "SARI"
            ],
            [
                "BLEU"
            ],
            [
                "Word-diff"
            ]
        ],
        "contents": [
            [
                "10.45",
                "35.29",
                "76.13",
                "2.38"
            ],
            [
                "11.15",
                "33.8",
                "74.24",
                "3.55"
            ],
            [
                "6.6",
                "33.72",
                "70.84",
                "0.74"
            ],
            [
                "13.84",
                "32.11",
                "87.36",
                "-0.01"
            ],
            [
                "54.38",
                "14.97",
                "0.73",
                "5.61"
            ],
            [
                "5.37",
                "36.1",
                "79.38",
                "2.73"
            ],
            [
                "17.68",
                "38.59",
                "73.62",
                "-0.84"
            ],
            [
                "9.14",
                "34.07",
                "67.79",
                "2.26"
            ],
            [
                "3.01",
                "34.96",
                "83.54",
                "-0.02"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "FE-diff",
            "SARI",
            "BLEU",
            "Word-diff"
        ],
        "target_entity": [
            "LIGHTLS"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>FE-diff</th>      <th>SARI</th>      <th>BLEU</th>      <th>Word-diff</th>    </tr>  </thead>  <tbody>    <tr>      <td>System || UNTS+10K</td>      <td>10.45</td>      <td>35.29</td>      <td>76.13</td>      <td>2.38</td>    </tr>    <tr>      <td>System || UNTS</td>      <td>11.15</td>      <td>33.8</td>      <td>74.24</td>      <td>3.55</td>    </tr>    <tr>      <td>System || UNMT</td>      <td>6.6</td>      <td>33.72</td>      <td>70.84</td>      <td>0.74</td>    </tr>    <tr>      <td>System || USMT</td>      <td>13.84</td>      <td>32.11</td>      <td>87.36</td>      <td>-0.01</td>    </tr>    <tr>      <td>System || ST</td>      <td>54.38</td>      <td>14.97</td>      <td>0.73</td>      <td>5.61</td>    </tr>    <tr>      <td>System || NTS</td>      <td>5.37</td>      <td>36.1</td>      <td>79.38</td>      <td>2.73</td>    </tr>    <tr>      <td>System || SBMT</td>      <td>17.68</td>      <td>38.59</td>      <td>73.62</td>      <td>-0.84</td>    </tr>    <tr>      <td>System || PBSMT</td>      <td>9.14</td>      <td>34.07</td>      <td>67.79</td>      <td>2.26</td>    </tr>    <tr>      <td>System || LIGHTLS</td>      <td>3.01</td>      <td>34.96</td>      <td>83.54</td>      <td>-0.02</td>    </tr>  </tbody></table>",
        "table_name": "Table 2",
        "table_id": "table_2",
        "paper_id": "P19-1198",
        "page_no": 8,
        "dir": "acl2019",
        "valid": 1
    },
    {
        "table_id_paper": "P19-1228table_1",
        "caption": "Unlabeled sentence-level F1 scores on PTB and CTB test sets. Top shows results from previous work while the rest of the results are from this paper. Mean/Max scores are obtained from 4 runs of each model with different random seeds. Oracle is the maximum score obtainable with binarized trees, since we compare against the non-binarized gold trees per convention. Results with \u2020 are trained on a version of PTB with punctuation, and hence not strictly comparable to the present work. For URNNG/DIORA, we take the parsed test set provided by the authors from their best runs and evaluate F1 with our evaluation setup. obtained from 4 different runs. We find that PRPN is particularly consistent across multiple runs. We also observe that different models are better at identifying different constituent labels, as measured by label recall (Table 2, bottom). While left as future work, this naturally suggests an ensemble approach wherein the empirical probabilities of constituents (obtained by averaging the predicted binary constituent labels from the different models) are used either to supervise another model or directly as potentials in a CRF constituency parser. Finally, all models seemed to have some difficulty in identifying SBAR/VP constituents which typically span more words than NP constituents. Induced Trees for Downstream Tasks While the compound PCFG has fewer independence assumptions than the neural PCFG, it is still a more constrained model of language than standard neural language models (NLM) and thus not competitive in terms of perplexity: the compound PCFG obtains a perplexity of 196.3 while an LSTM language model (LM) obtains 86.2 (Table 3).12 In contrast, both PRPN and ON perform as well as an",
        "row_header_level": 2,
        "row_headers": [
            [
                "Model",
                "PRPN (Shen et al., 2018)"
            ],
            [
                "Model",
                "(Shen et al., 2019)"
            ],
            [
                "Model",
                "URNNG\u00a0 (Kim et al., 2019)"
            ],
            [
                "Model",
                "(Drozdov et al., 2019)"
            ],
            [
                "Model",
                "Left Branching"
            ],
            [
                "Model",
                "Right Branching"
            ],
            [
                "Model",
                "Random Trees"
            ],
            [
                "Model",
                "PRPN (tuned)"
            ],
            [
                "Model",
                "ON (tuned)"
            ],
            [
                "Model",
                "Neural PCFG"
            ],
            [
                "Model",
                "Compound PCFG"
            ],
            [
                "Model",
                "Oracle Trees"
            ]
        ],
        "column_header_level": 2,
        "column_headers": [
            [
                "PTB",
                "Mean"
            ],
            [
                "PTB",
                "Max"
            ],
            [
                "CTB",
                "Mean"
            ],
            [
                "CTB",
                "Max"
            ]
        ],
        "contents": [
            [
                "37.4",
                "38.1",
                "-",
                "-"
            ],
            [
                "47.7",
                "49.4",
                "-",
                "-"
            ],
            [
                "-",
                "4540.00%",
                "-",
                "-"
            ],
            [
                "-",
                "5890.00%",
                "-",
                "-"
            ],
            [
                "8.7",
                "8.7",
                "9.7",
                "9.7"
            ],
            [
                "39.5",
                "39.5",
                "20",
                "20"
            ],
            [
                "19.2",
                "19.5",
                "1570.00%",
                "1600.00%"
            ],
            [
                "47.3",
                "47.9",
                "30.4",
                "31.5"
            ],
            [
                "48.1",
                "50",
                "25.4",
                "25.7"
            ],
            [
                "50.8",
                "52.6",
                "25.7",
                "29.5"
            ],
            [
                "55.2",
                "60.1",
                "36",
                "39.8"
            ],
            [
                "84.3",
                "84.3",
                "81.1",
                "81.1"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "F1",
            "F1",
            "F1",
            "F1"
        ],
        "target_entity": [
            "Neural PCFG",
            "Compound PCFG"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>PTB || Mean</th>      <th>PTB || Max</th>      <th>CTB || Mean</th>      <th>CTB || Max</th>    </tr>  </thead>  <tbody>    <tr>      <td>Model || PRPN (Shen et al., 2018)</td>      <td>37.4</td>      <td>38.1</td>      <td>-</td>      <td>-</td>    </tr>    <tr>      <td>Model || (Shen et al., 2019)</td>      <td>47.7</td>      <td>49.4</td>      <td>-</td>      <td>-</td>    </tr>    <tr>      <td>Model || URNNG\u00a0 (Kim et al., 2019)</td>      <td>-</td>      <td>4540.00%</td>      <td>-</td>      <td>-</td>    </tr>    <tr>      <td>Model || (Drozdov et al., 2019)</td>      <td>-</td>      <td>5890.00%</td>      <td>-</td>      <td>-</td>    </tr>    <tr>      <td>Model || Left Branching</td>      <td>8.7</td>      <td>8.7</td>      <td>9.7</td>      <td>9.7</td>    </tr>    <tr>      <td>Model || Right Branching</td>      <td>39.5</td>      <td>39.5</td>      <td>20</td>      <td>20</td>    </tr>    <tr>      <td>Model || Random Trees</td>      <td>19.2</td>      <td>19.5</td>      <td>1570.00%</td>      <td>1600.00%</td>    </tr>    <tr>      <td>Model || PRPN (tuned)</td>      <td>47.3</td>      <td>47.9</td>      <td>30.4</td>      <td>31.5</td>    </tr>    <tr>      <td>Model || ON (tuned)</td>      <td>48.1</td>      <td>50</td>      <td>25.4</td>      <td>25.7</td>    </tr>    <tr>      <td>Model || Neural PCFG</td>      <td>50.8</td>      <td>52.6</td>      <td>25.7</td>      <td>29.5</td>    </tr>    <tr>      <td>Model || Compound PCFG</td>      <td>55.2</td>      <td>60.1</td>      <td>36</td>      <td>39.8</td>    </tr>    <tr>      <td>Model || Oracle Trees</td>      <td>84.3</td>      <td>84.3</td>      <td>81.1</td>      <td>81.1</td>    </tr>  </tbody></table>",
        "table_name": "Table 1",
        "table_id": "table_1",
        "paper_id": "P19-1228",
        "page_no": 6,
        "dir": "acl2019",
        "valid": 1
    },
    {
        "table_id_paper": "P19-1291table_2",
        "caption": "Translation results on NIST Mandarin-English test sets",
        "row_header_level": 2,
        "row_headers": [
            [
                "Models",
                "Transformer-base"
            ],
            [
                "Models",
                "beta = 0.2"
            ],
            [
                "Models",
                "beta = 0.4"
            ],
            [
                "Models",
                "beta = 0.6"
            ],
            [
                "Models",
                "beta = 0.8"
            ],
            [
                "Models",
                "beta = 0.95"
            ],
            [
                "Models",
                "beta = 1.0"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "NIST06 (Dev Set)"
            ],
            [
                "NIST02"
            ],
            [
                "NIST03"
            ],
            [
                "NIST04"
            ],
            [
                "NIST08"
            ]
        ],
        "contents": [
            [
                "45.97",
                "47.4",
                "46.01",
                "47.25",
                "41.71"
            ],
            [
                "47.14",
                "48.63",
                "47.82",
                "48.63",
                "43.77"
            ],
            [
                "48.56",
                "49.41",
                "48.73",
                "50.53",
                "45.16"
            ],
            [
                "48.32",
                "48.83",
                "48.82",
                "49.86",
                "44.17"
            ],
            [
                "48.15",
                "49.42",
                "49.44",
                "49.98",
                "44.86"
            ],
            [
                "48.91",
                "49.33",
                "50.46",
                "50.57",
                "44.83"
            ],
            [
                "45.6",
                "47.04",
                "46.42",
                "47.65",
                "40.27"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "BLEU",
            "BLEU",
            "BLEU",
            "BLEU",
            "BLEU"
        ],
        "target_entity": [
            "Models"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>NIST06 (Dev Set)</th>      <th>NIST02</th>      <th>NIST03</th>      <th>NIST04</th>      <th>NIST08</th>    </tr>  </thead>  <tbody>    <tr>      <td>Models || Transformer-base</td>      <td>45.97</td>      <td>47.4</td>      <td>46.01</td>      <td>47.25</td>      <td>41.71</td>    </tr>    <tr>      <td>Models || beta = 0.2</td>      <td>47.14</td>      <td>48.63</td>      <td>47.82</td>      <td>48.63</td>      <td>43.77</td>    </tr>    <tr>      <td>Models || beta = 0.4</td>      <td>48.56</td>      <td>49.41</td>      <td>48.73</td>      <td>50.53</td>      <td>45.16</td>    </tr>    <tr>      <td>Models || beta = 0.6</td>      <td>48.32</td>      <td>48.83</td>      <td>48.82</td>      <td>49.86</td>      <td>44.17</td>    </tr>    <tr>      <td>Models || beta = 0.8</td>      <td>48.15</td>      <td>49.42</td>      <td>49.44</td>      <td>49.98</td>      <td>44.86</td>    </tr>    <tr>      <td>Models || beta = 0.95</td>      <td>48.91</td>      <td>49.33</td>      <td>50.46</td>      <td>50.57</td>      <td>44.83</td>    </tr>    <tr>      <td>Models || beta = 1.0</td>      <td>45.6</td>      <td>47.04</td>      <td>46.42</td>      <td>47.65</td>      <td>40.27</td>    </tr>  </tbody></table>",
        "table_name": "Table 2",
        "table_id": "table_2",
        "paper_id": "P19-1291",
        "page_no": 4,
        "dir": "acl2019",
        "valid": 1
    },
    {
        "table_id_paper": "P19-1329table_4",
        "caption": "Performance (% accuracy) of various (retrained) embedding models on magnitude and numeration tests.",
        "row_header_level": 1,
        "row_headers": [
            [
                "random"
            ],
            [
                "GloVe-Num"
            ],
            [
                "GloVe-All"
            ],
            [
                "FastText-Num"
            ],
            [
                "FastText-All"
            ],
            [
                "Word2Vec-Num"
            ],
            [
                "Word2Vec-All"
            ]
        ],
        "column_header_level": 3,
        "column_headers": [
            [
                "Model",
                "Magnitude",
                "OVA-MAG"
            ],
            [
                "Model",
                "Magnitude",
                "SC-MAG"
            ],
            [
                "Model",
                "Magnitude",
                "BC-MAG"
            ],
            [
                "Model",
                "Numeration",
                "OVA-NUM"
            ],
            [
                "Model",
                "Numeration",
                "SC-NUM"
            ],
            [
                "Model",
                "Numeration",
                "BC-NUM"
            ]
        ],
        "contents": [
            [
                "0",
                "49.62",
                "49.71",
                "2.31",
                "47.69",
                "53.68"
            ],
            [
                "0.01",
                "49.47",
                "72.76",
                "0",
                "50",
                "19.85"
            ],
            [
                "0.01",
                "49.08",
                "74.02",
                "0",
                "46.15",
                "19.85"
            ],
            [
                "0.09",
                "51.05",
                "96.69",
                "1.54",
                "54.62",
                "58.09"
            ],
            [
                "0.09",
                "51.16",
                "97.9",
                "0",
                "46.92",
                "61.03"
            ],
            [
                "0.02",
                "50.12",
                "93.55",
                "0.77",
                "44.62",
                "33.82"
            ],
            [
                "0.02",
                "49.37",
                "94.2",
                "0",
                "54.62",
                "34.56"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "accuracy",
            "accuracy",
            "accuracy",
            "accuracy",
            "accuracy",
            "accuracy"
        ],
        "target_entity": [
            "FastText-Num",
            "FastText-All"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Model || Magnitude || OVA-MAG</th>      <th>Model || Magnitude || SC-MAG</th>      <th>Model || Magnitude || BC-MAG</th>      <th>Model || Numeration || OVA-NUM</th>      <th>Model || Numeration || SC-NUM</th>      <th>Model || Numeration || BC-NUM</th>    </tr>  </thead>  <tbody>    <tr>      <td>random</td>      <td>0</td>      <td>49.62</td>      <td>49.71</td>      <td>2.31</td>      <td>47.69</td>      <td>53.68</td>    </tr>    <tr>      <td>GloVe-Num</td>      <td>0.01</td>      <td>49.47</td>      <td>72.76</td>      <td>0</td>      <td>50</td>      <td>19.85</td>    </tr>    <tr>      <td>GloVe-All</td>      <td>0.01</td>      <td>49.08</td>      <td>74.02</td>      <td>0</td>      <td>46.15</td>      <td>19.85</td>    </tr>    <tr>      <td>FastText-Num</td>      <td>0.09</td>      <td>51.05</td>      <td>96.69</td>      <td>1.54</td>      <td>54.62</td>      <td>58.09</td>    </tr>    <tr>      <td>FastText-All</td>      <td>0.09</td>      <td>51.16</td>      <td>97.9</td>      <td>0</td>      <td>46.92</td>      <td>61.03</td>    </tr>    <tr>      <td>Word2Vec-Num</td>      <td>0.02</td>      <td>50.12</td>      <td>93.55</td>      <td>0.77</td>      <td>44.62</td>      <td>33.82</td>    </tr>    <tr>      <td>Word2Vec-All</td>      <td>0.02</td>      <td>49.37</td>      <td>94.2</td>      <td>0</td>      <td>54.62</td>      <td>34.56</td>    </tr>  </tbody></table>",
        "table_name": "Table 4",
        "table_id": "table_4",
        "paper_id": "P19-1329",
        "page_no": 4,
        "dir": "acl2019",
        "valid": 1
    },
    {
        "table_id_paper": "P19-1343table_6",
        "caption": "Hate speech results (3-fold cross val.). In most cells we show performance without thresholding and stratification (within bracket with thresholding and stratification). Green: Best performance in each column.",
        "row_header_level": 1,
        "row_headers": [
            [
                "Only synthetic"
            ],
            [
                "Synthetic +Gold"
            ],
            [
                "Gold"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "Prec"
            ],
            [
                "Recall"
            ],
            [
                "F-score"
            ]
        ],
        "contents": [
            [
                "0.58 (0.63)",
                "0.60 (0.63)",
                "0.51 (0.52)"
            ],
            [
                "0.59 (0.60)",
                "0.63 (0.63)",
                "0.53 (0.54)"
            ],
            [
                "0.4",
                "0.62",
                "0.48"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "Prec",
            "Recall",
            "F-score"
        ],
        "target_entity": [
            "Only synthetic",
            "Synthetic +Gold",
            "Gold"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Prec</th>      <th>Recall</th>      <th>F-score</th>    </tr>  </thead>  <tbody>    <tr>      <td>Only synthetic</td>      <td>0.58 (0.63)</td>      <td>0.60 (0.63)</td>      <td>0.51 (0.52)</td>    </tr>    <tr>      <td>Synthetic +Gold</td>      <td>0.59 (0.60)</td>      <td>0.63 (0.63)</td>      <td>0.53 (0.54)</td>    </tr>    <tr>      <td>Gold</td>      <td>0.4</td>      <td>0.62</td>      <td>0.48</td>    </tr>  </tbody></table>",
        "table_name": "Table 6",
        "table_id": "table_6",
        "paper_id": "P19-1343",
        "page_no": 8,
        "dir": "acl2019",
        "valid": 1
    },
    {
        "table_id_paper": "P19-1345table_3",
        "caption": "Performances of all the approaches to two sub-tasks, i.e., Term-level and Category-level ASC-QA. In each sub-task, all approaches are evaluated in three different domains, i.e., Bags, Cosmetics and Electronics. approach without using question-to-answer attention. 10) RBAN w/o A2Q. Our RBAN approach without using answer-to-question attention.",
        "row_header_level": 2,
        "row_headers": [
            [
                "Approaches",
                "LSTM (Wang et al.,2016)"
            ],
            [
                "Approaches",
                "RAM (Chen et al.,2017)"
            ],
            [
                "Approaches",
                "GCAE (Xue and Li, 2018)"
            ],
            [
                "Approaches",
                "S-LSTM (Wang and Lu, 2018)"
            ],
            [
                "Approaches",
                "BIDAF (Seo et al., 2016)"
            ],
            [
                "Approaches",
                "HMN (Shen et al., 2018a)"
            ],
            [
                "Approaches",
                "MAMC (Yin et al., 2017)"
            ],
            [
                "Approaches",
                "RBAN w/o RAWS"
            ],
            [
                "Approaches",
                "RBAN w/o Q2A"
            ],
            [
                "Approaches",
                "RBAN w/o A2Q"
            ],
            [
                "Approaches",
                "RBAN"
            ]
        ],
        "column_header_level": 3,
        "column_headers": [
            [
                "Term-level ASC-QA",
                "Bags",
                "F1"
            ],
            [
                "Term-level ASC-QA",
                "Bags",
                "Acc."
            ],
            [
                "Term-level ASC-QA",
                "Cosmetics",
                "F1"
            ],
            [
                "Term-level ASC-QA",
                "Cosmetics",
                "Acc."
            ],
            [
                "Term-level ASC-QA",
                "Electronics",
                "F1"
            ],
            [
                "Term-level ASC-QA",
                "Electronics",
                "Acc."
            ],
            [
                "Category-level ASC-QA",
                "Bags",
                "F1"
            ],
            [
                "Category-level ASC-QA",
                "Bags",
                "Acc."
            ],
            [
                "Category-level ASC-QA",
                "Cosmetics",
                "F1"
            ],
            [
                "Category-level ASC-QA",
                "Cosmetics",
                "Acc."
            ],
            [
                "Category-level ASC-QA",
                "Electronics",
                "F1"
            ],
            [
                "Category-level ASC-QA",
                "Electronics",
                "Acc."
            ]
        ],
        "contents": [
            [
                "0.571",
                "0.757",
                "0.582",
                "0.771",
                "0.534",
                "0.756",
                "0.528",
                "0.773",
                "0.493",
                "0.739",
                "0.522",
                "0.752"
            ],
            [
                "0.605",
                "0.782",
                "0.614",
                "0.805",
                "0.557",
                "0.788",
                "0.561",
                "0.795",
                "0.519",
                "0.762",
                "0.579",
                "0.792"
            ],
            [
                "0.617",
                "0.779",
                "0.623",
                "0.819",
                "0.57",
                "0.781",
                "0.59",
                "0.787",
                "0.514",
                "0.791",
                "0.576",
                "0.788"
            ],
            [
                "0.615",
                "0.824",
                "0.623",
                "0.821",
                "0.569",
                "0.794",
                "0.587",
                "0.828",
                "0.522",
                "0.788",
                "0.581",
                "0.801"
            ],
            [
                "0.613",
                "0.815",
                "0.618",
                "0.813",
                "0.558",
                "0.809",
                "0.592",
                "0.83",
                "0.515",
                "0.788",
                "0.571",
                "0.787"
            ],
            [
                "0.607",
                "0.817",
                "0.615",
                "0.821",
                "0.561",
                "0.802",
                "0.606",
                "0.827",
                "0.512",
                "0.798",
                "0.579",
                "0.804"
            ],
            [
                "0.621",
                "0.825",
                "0.629",
                "0.823",
                "0.562",
                "0.815",
                "0.612",
                "0.837",
                "0.524",
                "0.794",
                "0.582",
                "0.805"
            ],
            [
                "0.623",
                "0.826",
                "0.633",
                "0.827",
                "0.578",
                "0.817",
                "0.616",
                "0.839",
                "0.532",
                "0.804",
                "0.591",
                "0.813"
            ],
            [
                "0.595",
                "0.788",
                "0.614",
                "0.817",
                "0.569",
                "0.779",
                "0.578",
                "0.814",
                "0.514",
                "0.788",
                "0.569",
                "0.782"
            ],
            [
                "0.623",
                "0.837",
                "0.639",
                "0.834",
                "0.588",
                "0.821",
                "0.617",
                "0.845",
                "0.536",
                "0.815",
                "0.603",
                "0.826"
            ],
            [
                "0.648",
                "0.856",
                "0.662",
                "0.855",
                "0.616",
                "0.833",
                "0.634",
                "0.869",
                "0.557",
                "0.833",
                "0.625",
                "0.839"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "F1",
            "Acc.",
            "F1",
            "Acc.",
            "F1",
            "Acc.",
            "F1",
            "Acc.",
            "F1",
            "Acc.",
            "F1",
            "Acc."
        ],
        "target_entity": [
            "RBAN",
            "RBAN w/o RAWS",
            "RBAN w/o A2Q",
            "RBAN w/o Q2A"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Term-level ASC-QA || Bags || F1</th>      <th>Term-level ASC-QA || Bags || Acc.</th>      <th>Term-level ASC-QA || Cosmetics || F1</th>      <th>Term-level ASC-QA || Cosmetics || Acc.</th>      <th>Term-level ASC-QA || Electronics || F1</th>      <th>Term-level ASC-QA || Electronics || Acc.</th>      <th>Category-level ASC-QA || Bags || F1</th>      <th>Category-level ASC-QA || Bags || Acc.</th>      <th>Category-level ASC-QA || Cosmetics || F1</th>      <th>Category-level ASC-QA || Cosmetics || Acc.</th>      <th>Category-level ASC-QA || Electronics || F1</th>      <th>Category-level ASC-QA || Electronics || Acc.</th>    </tr>  </thead>  <tbody>    <tr>      <td>Approaches || LSTM (Wang et al.,2016)</td>      <td>0.571</td>      <td>0.757</td>      <td>0.582</td>      <td>0.771</td>      <td>0.534</td>      <td>0.756</td>      <td>0.528</td>      <td>0.773</td>      <td>0.493</td>      <td>0.739</td>      <td>0.522</td>      <td>0.752</td>    </tr>    <tr>      <td>Approaches || RAM (Chen et al.,2017)</td>      <td>0.605</td>      <td>0.782</td>      <td>0.614</td>      <td>0.805</td>      <td>0.557</td>      <td>0.788</td>      <td>0.561</td>      <td>0.795</td>      <td>0.519</td>      <td>0.762</td>      <td>0.579</td>      <td>0.792</td>    </tr>    <tr>      <td>Approaches || GCAE (Xue and Li, 2018)</td>      <td>0.617</td>      <td>0.779</td>      <td>0.623</td>      <td>0.819</td>      <td>0.57</td>      <td>0.781</td>      <td>0.59</td>      <td>0.787</td>      <td>0.514</td>      <td>0.791</td>      <td>0.576</td>      <td>0.788</td>    </tr>    <tr>      <td>Approaches || S-LSTM (Wang and Lu, 2018)</td>      <td>0.615</td>      <td>0.824</td>      <td>0.623</td>      <td>0.821</td>      <td>0.569</td>      <td>0.794</td>      <td>0.587</td>      <td>0.828</td>      <td>0.522</td>      <td>0.788</td>      <td>0.581</td>      <td>0.801</td>    </tr>    <tr>      <td>Approaches || BIDAF (Seo et al., 2016)</td>      <td>0.613</td>      <td>0.815</td>      <td>0.618</td>      <td>0.813</td>      <td>0.558</td>      <td>0.809</td>      <td>0.592</td>      <td>0.83</td>      <td>0.515</td>      <td>0.788</td>      <td>0.571</td>      <td>0.787</td>    </tr>    <tr>      <td>Approaches || HMN (Shen et al., 2018a)</td>      <td>0.607</td>      <td>0.817</td>      <td>0.615</td>      <td>0.821</td>      <td>0.561</td>      <td>0.802</td>      <td>0.606</td>      <td>0.827</td>      <td>0.512</td>      <td>0.798</td>      <td>0.579</td>      <td>0.804</td>    </tr>    <tr>      <td>Approaches || MAMC (Yin et al., 2017)</td>      <td>0.621</td>      <td>0.825</td>      <td>0.629</td>      <td>0.823</td>      <td>0.562</td>      <td>0.815</td>      <td>0.612</td>      <td>0.837</td>      <td>0.524</td>      <td>0.794</td>      <td>0.582</td>      <td>0.805</td>    </tr>    <tr>      <td>Approaches || RBAN w/o RAWS</td>      <td>0.623</td>      <td>0.826</td>      <td>0.633</td>      <td>0.827</td>      <td>0.578</td>      <td>0.817</td>      <td>0.616</td>      <td>0.839</td>      <td>0.532</td>      <td>0.804</td>      <td>0.591</td>      <td>0.813</td>    </tr>    <tr>      <td>Approaches || RBAN w/o Q2A</td>      <td>0.595</td>      <td>0.788</td>      <td>0.614</td>      <td>0.817</td>      <td>0.569</td>      <td>0.779</td>      <td>0.578</td>      <td>0.814</td>      <td>0.514</td>      <td>0.788</td>      <td>0.569</td>      <td>0.782</td>    </tr>    <tr>      <td>Approaches || RBAN w/o A2Q</td>      <td>0.623</td>      <td>0.837</td>      <td>0.639</td>      <td>0.834</td>      <td>0.588</td>      <td>0.821</td>      <td>0.617</td>      <td>0.845</td>      <td>0.536</td>      <td>0.815</td>      <td>0.603</td>      <td>0.826</td>    </tr>    <tr>      <td>Approaches || RBAN</td>      <td>0.648</td>      <td>0.856</td>      <td>0.662</td>      <td>0.855</td>      <td>0.616</td>      <td>0.833</td>      <td>0.634</td>      <td>0.869</td>      <td>0.557</td>      <td>0.833</td>      <td>0.625</td>      <td>0.839</td>    </tr>  </tbody></table>",
        "table_name": "Table 3",
        "table_id": "table_3",
        "paper_id": "P19-1345",
        "page_no": 7,
        "dir": "acl2019",
        "valid": 1
    },
    {
        "table_id_paper": "P19-1407table_2",
        "caption": "Methods allowing the model to keep track of past attention (Coverage, Scratchpad) significantly improve performance when combined with a copy mechanism. The Scratchpad Encoder achieves the best performance.",
        "row_header_level": 3,
        "row_headers": [
            [
                "Model",
                "WebQSP",
                "Baseline"
            ],
            [
                "Model",
                "WebQSP",
                "Copynet"
            ],
            [
                "Model",
                "WebQSP",
                "Copy + Coverage"
            ],
            [
                "Model",
                "WebQSP",
                "Copy + Scratchpad"
            ],
            [
                "Model",
                "WikiSQL",
                "Baseline"
            ],
            [
                "Model",
                "WikiSQL",
                "Copynet"
            ],
            [
                "Model",
                "WikiSQL",
                "Copy + Coverage"
            ],
            [
                "Model",
                "WikiSQL",
                "Copy + Scratchpad"
            ]
        ],
        "column_header_level": 2,
        "column_headers": [
            [
                "Per-Sentence",
                "Bleu"
            ],
            [
                "Per-Sentence",
                "Meteor"
            ],
            [
                "Per-Sentence",
                "Rouge-L"
            ],
            [
                "Corpus-Level",
                "Bleu"
            ],
            [
                "Corpus-Level",
                "Meteor"
            ],
            [
                "Corpus-Level",
                "Rouge-L"
            ]
        ],
        "contents": [
            [
                "7.51",
                "23.9",
                "47.1",
                "17.96",
                "22.9",
                "47.13"
            ],
            [
                "6.89",
                "27.1",
                "52.5",
                "17.42",
                "26.03",
                "52.56"
            ],
            [
                "14.55",
                "33.7",
                "58.9",
                "26.78",
                "30.86",
                "58.91"
            ],
            [
                "15.29",
                "34.7",
                "59.5",
                "27.64",
                "31.49",
                "59.44"
            ],
            [
                "9.94",
                "26.71",
                "47.96",
                "17.34",
                "25.34",
                "47.96"
            ],
            [
                "8.04",
                "24.66",
                "46.82",
                "15.11",
                "23.53",
                "46.82"
            ],
            [
                "15.76",
                "34.04",
                "54.94",
                "25.01",
                "32.38",
                "54.94"
            ],
            [
                "16.89",
                "34.47",
                "55.69",
                "26.1",
                "32.76",
                "55.69"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "Bleu",
            "Meteor",
            "Rouge-L",
            "Bleu",
            "Meteor",
            "Rouge-L"
        ],
        "target_entity": [
            "Copy + Scratchpad"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Per-Sentence || Bleu</th>      <th>Per-Sentence || Meteor</th>      <th>Per-Sentence || Rouge-L</th>      <th>Corpus-Level || Bleu</th>      <th>Corpus-Level || Meteor</th>      <th>Corpus-Level || Rouge-L</th>    </tr>  </thead>  <tbody>    <tr>      <td>Model || WebQSP || Baseline</td>      <td>7.51</td>      <td>23.9</td>      <td>47.1</td>      <td>17.96</td>      <td>22.9</td>      <td>47.13</td>    </tr>    <tr>      <td>Model || WebQSP || Copynet</td>      <td>6.89</td>      <td>27.1</td>      <td>52.5</td>      <td>17.42</td>      <td>26.03</td>      <td>52.56</td>    </tr>    <tr>      <td>Model || WebQSP || Copy + Coverage</td>      <td>14.55</td>      <td>33.7</td>      <td>58.9</td>      <td>26.78</td>      <td>30.86</td>      <td>58.91</td>    </tr>    <tr>      <td>Model || WebQSP || Copy + Scratchpad</td>      <td>15.29</td>      <td>34.7</td>      <td>59.5</td>      <td>27.64</td>      <td>31.49</td>      <td>59.44</td>    </tr>    <tr>      <td>Model || WikiSQL || Baseline</td>      <td>9.94</td>      <td>26.71</td>      <td>47.96</td>      <td>17.34</td>      <td>25.34</td>      <td>47.96</td>    </tr>    <tr>      <td>Model || WikiSQL || Copynet</td>      <td>8.04</td>      <td>24.66</td>      <td>46.82</td>      <td>15.11</td>      <td>23.53</td>      <td>46.82</td>    </tr>    <tr>      <td>Model || WikiSQL || Copy + Coverage</td>      <td>15.76</td>      <td>34.04</td>      <td>54.94</td>      <td>25.01</td>      <td>32.38</td>      <td>54.94</td>    </tr>    <tr>      <td>Model || WikiSQL || Copy + Scratchpad</td>      <td>16.89</td>      <td>34.47</td>      <td>55.69</td>      <td>26.1</td>      <td>32.76</td>      <td>55.69</td>    </tr>  </tbody></table>",
        "table_name": "Table 2",
        "table_id": "table_2",
        "paper_id": "P19-1407",
        "page_no": 4,
        "dir": "acl2019",
        "valid": 1
    },
    {
        "table_id_paper": "P19-1428table_1",
        "caption": "Comparison of approaches in the eHealth-KD challenge. Only researchers that participated in Scenario 1 are considered.",
        "row_header_level": 2,
        "row_headers": [
            [
                "Approach",
                "Zavala et al. (2018)"
            ],
            [
                "Approach",
                "Lopez-Ubeda et al. (2018)"
            ],
            [
                "Approach",
                "Palatresi and Hontoria (2018)"
            ],
            [
                "Approach",
                "Suarez-Paniagua et al. (2018)"
            ],
            [
                "Approach",
                "Our Proposal"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "F 1"
            ]
        ],
        "contents": [
            [
                "0.744"
            ],
            [
                "0.71"
            ],
            [
                "0.681"
            ],
            [
                "0.31"
            ],
            [
                "0.754"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "F 1"
        ],
        "target_entity": [
            "Our Proposal"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>F 1 (Scenario 1)</th>    </tr>  </thead>  <tbody>    <tr>      <td>Approach || Zavala et al. (2018)</td>      <td>0.744</td>    </tr>    <tr>      <td>Approach || Lopez-Ubeda et al. (2018)</td>      <td>0.71</td>    </tr>    <tr>      <td>Approach || Palatresi and Hontoria (2018)</td>      <td>0.681</td>    </tr>    <tr>      <td>Approach || Suarez-Paniagua et al. (2018)</td>      <td>0.31</td>    </tr>    <tr>      <td>Approach || Our Proposal</td>      <td>0.754</td>    </tr>  </tbody></table>",
        "table_name": "Table 1",
        "table_id": "table_1",
        "paper_id": "P19-1428",
        "page_no": 6,
        "dir": "acl2019",
        "valid": 1
    },
    {
        "table_id_paper": "P19-1513table_7",
        "caption": "Results of TDMS-IE for ten leaderboards on ARC-PDN.",
        "row_header_level": 2,
        "row_headers": [
            [
                "Task:Dataset:Metric",
                "Dependency parsing:Penn Treebank:UAS"
            ],
            [
                "Task:Dataset:Metric",
                "Summarization:DUC 2004 Task 1:ROUGE-2"
            ],
            [
                "Task:Dataset:Metric",
                "Word sense disambiguation:Senseval 2:F1"
            ],
            [
                "Task:Dataset:Metric",
                "Word sense disambiguation:SemEval 2007:F1"
            ],
            [
                "Task:Dataset:Metric",
                "Word segmentation:Chinese Treebank 6:F1"
            ],
            [
                "Task:Dataset:Metric",
                "Word Segmentation:MSRA:F1"
            ],
            [
                "Task:Dataset:Metric",
                "Sentiment analysis:SST-2:Accuracy"
            ],
            [
                "Task:Dataset:Metric",
                "AMR parsing:LDC2014T12:F1 on All"
            ],
            [
                "Task:Dataset:Metric",
                "CCG supertagging:CCGBank:Accuracy"
            ],
            [
                "Task:Dataset:Metric",
                "Machine translation:WMT 2014 EN-FR:BLEU"
            ],
            [
                "Task:Dataset:Metric",
                "Macro-average"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "P@1"
            ],
            [
                "P@3"
            ],
            [
                "P@5"
            ],
            [
                "P@10"
            ],
            [
                "#Correct Score"
            ],
            [
                "#Wrong Task"
            ]
        ],
        "contents": [
            [
                "1",
                "1",
                "0.8",
                "0.9",
                "2",
                "0"
            ],
            [
                "0",
                "0.67",
                "0.8",
                "0.7",
                "0",
                "0"
            ],
            [
                "0",
                "0",
                "0.1",
                "0.1",
                "0",
                "0"
            ],
            [
                "1",
                "1",
                "0.8",
                "0.7",
                "1",
                "0"
            ],
            [
                "1",
                "0.67",
                "0.4",
                "0.2",
                "0",
                "2"
            ],
            [
                "1",
                "0.67",
                "0.6",
                "0.7",
                "2",
                "3"
            ],
            [
                "1",
                "0.67",
                "0.6",
                "0.3",
                "0",
                "3"
            ],
            [
                "0",
                "0.67",
                "0.4",
                "0.2",
                "0",
                "5"
            ],
            [
                "1",
                "1",
                "1",
                "0.8",
                "0",
                "1"
            ],
            [
                "1",
                "0.33",
                "0.2",
                "0.1",
                "0",
                "0"
            ],
            [
                "0.7",
                "0.67",
                "0.57",
                "0.46",
                "-",
                "-"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "P@1",
            "P@3",
            "P@5",
            "P@10",
            "#Correct Score",
            "#Wrong Task"
        ],
        "target_entity": [
            "Macro-average"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>P@1</th>      <th>P@3</th>      <th>P@5</th>      <th>P@10</th>      <th>#Correct Score</th>      <th>#Wrong Task</th>    </tr>  </thead>  <tbody>    <tr>      <td>Task:Dataset:Metric || Dependency parsing:Penn Treebank:UAS</td>      <td>1</td>      <td>1</td>      <td>0.8</td>      <td>0.9</td>      <td>2</td>      <td>0</td>    </tr>    <tr>      <td>Task:Dataset:Metric || Summarization:DUC 2004 Task 1:ROUGE-2</td>      <td>0</td>      <td>0.67</td>      <td>0.8</td>      <td>0.7</td>      <td>0</td>      <td>0</td>    </tr>    <tr>      <td>Task:Dataset:Metric || Word sense disambiguation:Senseval 2:F1</td>      <td>0</td>      <td>0</td>      <td>0.1</td>      <td>0.1</td>      <td>0</td>      <td>0</td>    </tr>    <tr>      <td>Task:Dataset:Metric || Word sense disambiguation:SemEval 2007:F1</td>      <td>1</td>      <td>1</td>      <td>0.8</td>      <td>0.7</td>      <td>1</td>      <td>0</td>    </tr>    <tr>      <td>Task:Dataset:Metric || Word segmentation:Chinese Treebank 6:F1</td>      <td>1</td>      <td>0.67</td>      <td>0.4</td>      <td>0.2</td>      <td>0</td>      <td>2</td>    </tr>    <tr>      <td>Task:Dataset:Metric || Word Segmentation:MSRA:F1</td>      <td>1</td>      <td>0.67</td>      <td>0.6</td>      <td>0.7</td>      <td>2</td>      <td>3</td>    </tr>    <tr>      <td>Task:Dataset:Metric || Sentiment analysis:SST-2:Accuracy</td>      <td>1</td>      <td>0.67</td>      <td>0.6</td>      <td>0.3</td>      <td>0</td>      <td>3</td>    </tr>    <tr>      <td>Task:Dataset:Metric || AMR parsing:LDC2014T12:F1 on All</td>      <td>0</td>      <td>0.67</td>      <td>0.4</td>      <td>0.2</td>      <td>0</td>      <td>5</td>    </tr>    <tr>      <td>Task:Dataset:Metric || CCG supertagging:CCGBank:Accuracy</td>      <td>1</td>      <td>1</td>      <td>1</td>      <td>0.8</td>      <td>0</td>      <td>1</td>    </tr>    <tr>      <td>Task:Dataset:Metric || Machine translation:WMT 2014 EN-FR:BLEU</td>      <td>1</td>      <td>0.33</td>      <td>0.2</td>      <td>0.1</td>      <td>0</td>      <td>0</td>    </tr>    <tr>      <td>Task:Dataset:Metric || Macro-average</td>      <td>0.7</td>      <td>0.67</td>      <td>0.57</td>      <td>0.46</td>      <td>-</td>      <td>-</td>    </tr>  </tbody></table>",
        "table_name": "Table 7",
        "table_id": "table_7",
        "paper_id": "P19-1513",
        "page_no": 9,
        "dir": "acl2019",
        "valid": 1
    },
    {
        "table_id_paper": "P19-1557table_3",
        "caption": "The results of our system on the Hate Speech and Kaggle datasets. With one exception, in all cases longer class description leads to better performance. The results of the Kaggle dataset are only reported in AUC to be comparable with other systems in the multilabel category.",
        "row_header_level": 2,
        "row_headers": [
            [
                "Hate Speech dataset",
                "(Davidson et al., 2017)"
            ],
            [
                "Hate Speech dataset",
                "(Founta et al., 2018)"
            ],
            [
                "Hate Speech dataset",
                "This work + chisquare50 "
            ],
            [
                "Hate Speech dataset",
                "This work + chisuare100 "
            ],
            [
                "Hate Speech dataset",
                "This work + ANOVA50 "
            ],
            [
                "Hate Speech dataset",
                "This work + ANOVA100 "
            ],
            [
                "Kaggle dataset",
                "Leader-board  "
            ],
            [
                "Kaggle dataset",
                "This work + chisquare50 "
            ],
            [
                "Kaggle dataset",
                "This work + chisquare100 "
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "P (%)"
            ],
            [
                "R (%)"
            ],
            [
                "F1 (%)"
            ],
            [
                "AUC (%)"
            ]
        ],
        "contents": [
            [
                "91",
                "90",
                "90",
                "87"
            ],
            [
                "89",
                "89",
                "89",
                "92"
            ],
            [
                "89.7",
                "90.4",
                "90",
                "92.9"
            ],
            [
                "90.3",
                "92.5",
                "91.3",
                "93.7"
            ],
            [
                "89.2",
                "89.6",
                "89.3",
                "92.1"
            ],
            [
                "89.8",
                "89.2",
                "89.4",
                "92.4"
            ],
            [
                "-",
                "-",
                "-",
                "98.82"
            ],
            [
                "-",
                "-",
                "-",
                "98.05"
            ],
            [
                "-",
                "-",
                "-",
                "98.24"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "P (%)",
            "R (%)",
            "F1 (%)",
            "AUC (%)"
        ],
        "target_entity": [
            "This work + chisquare50 ",
            "This work + chisuare100 ",
            "This work + ANOVA50 ",
            "This work + ANOVA100 ",
            "This work + chisquare100 "
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>P (%)</th>      <th>R (%)</th>      <th>F1 (%)</th>      <th>AUC (%)</th>    </tr>  </thead>  <tbody>    <tr>      <td>Hate Speech dataset || (Davidson et al., 2017)</td>      <td>91</td>      <td>90</td>      <td>90</td>      <td>87</td>    </tr>    <tr>      <td>Hate Speech dataset || (Founta et al., 2018)</td>      <td>89</td>      <td>89</td>      <td>89</td>      <td>92</td>    </tr>    <tr>      <td>Hate Speech dataset || This work + chisquare50</td>      <td>89.7</td>      <td>90.4</td>      <td>90</td>      <td>92.9</td>    </tr>    <tr>      <td>Hate Speech dataset || This work + chisuare100</td>      <td>90.3</td>      <td>92.5</td>      <td>91.3</td>      <td>93.7</td>    </tr>    <tr>      <td>Hate Speech dataset || This work + ANOVA50</td>      <td>89.2</td>      <td>89.6</td>      <td>89.3</td>      <td>92.1</td>    </tr>    <tr>      <td>Hate Speech dataset || This work + ANOVA100</td>      <td>89.8</td>      <td>89.2</td>      <td>89.4</td>      <td>92.4</td>    </tr>    <tr>      <td>Kaggle dataset || Leader-board</td>      <td>-</td>      <td>-</td>      <td>-</td>      <td>98.82</td>    </tr>    <tr>      <td>Kaggle dataset || This work + chisquare50</td>      <td>-</td>      <td>-</td>      <td>-</td>      <td>98.05</td>    </tr>    <tr>      <td>Kaggle dataset || This work + chisquare100</td>      <td>-</td>      <td>-</td>      <td>-</td>      <td>98.24</td>    </tr>  </tbody></table>",
        "table_name": "Table 3",
        "table_id": "table_3",
        "paper_id": "P19-1557",
        "page_no": 5,
        "dir": "acl2019",
        "valid": 1
    },
    {
        "table_id_paper": "P19-1570table_3",
        "caption": "Comparison of embeddings on word entailment. The number reported for (Baroni et al., 2012) has been taken from original paper and uses the balAPinc metric. For W ord2GM, we were able to reproduce results in the original paper; we report results using both Cosine and KL divergence metrics. For W ord2Sense , we use KL divergence.",
        "row_header_level": 2,
        "row_headers": [
            [
                "Method",
                "(Baroni et al., 2012)"
            ],
            [
                "Method",
                "Word2GM (10)-Cos"
            ],
            [
                "Method",
                "Word2GM (10)-KL"
            ],
            [
                "Method",
                "Word2Sense"
            ],
            [
                "Method",
                "Word2Sense -full"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "Best AP"
            ],
            [
                "Best F1"
            ]
        ],
        "contents": [
            [
                "0.751",
                "-"
            ],
            [
                "0.729",
                "0.757"
            ],
            [
                "0.747",
                "0.763"
            ],
            [
                "0.751",
                "0.761"
            ],
            [
                "0.791",
                "0.798"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "Best AP",
            "Best F1"
        ],
        "target_entity": [
            "Word2Sense -full"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Best AP</th>      <th>Best F1</th>    </tr>  </thead>  <tbody>    <tr>      <td>Method || (Baroni et al., 2012)</td>      <td>0.751</td>      <td>-</td>    </tr>    <tr>      <td>Method || Word2GM (10)-Cos</td>      <td>0.729</td>      <td>0.757</td>    </tr>    <tr>      <td>Method || Word2GM (10)-KL</td>      <td>0.747</td>      <td>0.763</td>    </tr>    <tr>      <td>Method || Word2Sense</td>      <td>0.751</td>      <td>0.761</td>    </tr>    <tr>      <td>Method || Word2Sense -full</td>      <td>0.791</td>      <td>0.798</td>    </tr>  </tbody></table>",
        "table_name": "Table 3",
        "table_id": "table_3",
        "paper_id": "P19-1570",
        "page_no": 6,
        "dir": "acl2019",
        "valid": 1
    },
    {
        "table_id_paper": "P19-1570table_5",
        "caption": "Comparison of embeddings on for Word Intrusion tasks. The second column indicates the inter annotator agreement \u2013 the first number is the fraction of questions for which at least 2 annotators agreed and the second indicates the fraction on which all three agreed. The last column is the precision of the majority vote. 6.1 Qualitative evaluation We show the effectiveness of our embeddings at capturing multiple senses of a polysemous word in Table 1. For e.g. \u201dtie\u201d can be used as a verb to mean tying a rope, or drawing a match, or as a noun to mean clothing material. These three senses are captured in the top 3 dimensions of W ord2Sense embedding for \u201dtie\u201d. Similarly, the embedding for \u201dcell\u201d captures the 5 senses discussed in section 1 within the top 15 dimensions of the embedding. The remaining top senses capture fine grained senses such as different kinds of biological cells \u2013 e.g. bone marrow cell, liver cell, neuron \u2013 that a subject expert might relate to. 7 W ordCtx2Sense embeddings A word with several senses in the training corpus, when used in a context, would have a narrower set of senses. It is therefore important to be able to refine the representation of a word according to its usage in a context. Note that W ord2vec and W ord2GM models do not have such a mechanism. Here, we present an algorithm that generates an embedding for a target word \u02c6w in a short context T = {w1, .., wN} that re\ufb02ects the sense in which the target word was used in the context. For this, we suppose that the senses of the word \u02c6w in context T are an intersection of the senses of \u02c6w and T . We therefore infer the sense distribution of T by restricting the support of the distribution to those senses \u02c6w can take. 7.1 Methodology We suppose that the words in the context T were picked from a mixture of a small number of senses. Let Sk = {\u03c8 = (\u03c81, \u03c82, ..., \u03c8k) : \u03c8z \u2265 z \u03c8z = 1} be the unit positive simplex. The generative model is as follows. Pick a \u03c8 \u2208 Sk, and let P = \u03b2\u03c8, where \u03b2 is the collection of sense probability distributions recovered by LDA from",
        "row_header_level": 2,
        "row_headers": [
            [
                "Method",
                "Word2vec"
            ],
            [
                "Method",
                "SPOWV"
            ],
            [
                "Method",
                "SPINE"
            ],
            [
                "Method",
                "Word2Sense"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "Agreement"
            ],
            [
                "Precision"
            ]
        ],
        "contents": [
            [
                "0.77/0.18",
                "0.261"
            ],
            [
                "0.79/0.28",
                "0.418"
            ],
            [
                "0.91/0.48",
                "0.748"
            ],
            [
                "0.891/0.589",
                "0.753"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "Agreement",
            "Precision"
        ],
        "target_entity": [
            "Word2Sense"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Agreement</th>      <th>Precision</th>    </tr>  </thead>  <tbody>    <tr>      <td>Method || Word2vec</td>      <td>0.77/0.18</td>      <td>0.261</td>    </tr>    <tr>      <td>Method || SPOWV</td>      <td>0.79/0.28</td>      <td>0.418</td>    </tr>    <tr>      <td>Method || SPINE</td>      <td>0.91/0.48</td>      <td>0.748</td>    </tr>    <tr>      <td>Method || Word2Sense</td>      <td>0.891/0.589</td>      <td>0.753</td>    </tr>  </tbody></table>",
        "table_name": "Table 5",
        "table_id": "table_5",
        "paper_id": "P19-1570",
        "page_no": 7,
        "dir": "acl2019",
        "valid": 1
    },
    {
        "table_id_paper": "P19-1586table_6",
        "caption": "Low-resource performance (300 labeled examples) of different sampling strategies (DBLP-ACM).",
        "row_header_level": 2,
        "row_headers": [
            [
                "Sampling Method",
                "High-Confidence"
            ],
            [
                "Sampling Method",
                "Partition"
            ],
            [
                "Sampling Method",
                "High-Conf.+Part."
            ],
            [
                "Sampling Method",
                "Top K Entrop"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "Prec"
            ],
            [
                "Recall"
            ],
            [
                "F1"
            ]
        ],
        "contents": [
            [
                "93.32",
                "97.21",
                "95.19\u00b12.21"
            ],
            [
                "96.14",
                "97.12",
                "96.61\u00b10.57"
            ],
            [
                "97.63",
                "97.84",
                "97.73\u00b10.43"
            ],
            [
                "96.16",
                "89.64",
                "92.07\u00b19.73"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "Prec",
            "Recall",
            "F1"
        ],
        "target_entity": [
            "High-Conf.+Part."
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Prec</th>      <th>Recall</th>      <th>F1</th>    </tr>  </thead>  <tbody>    <tr>      <td>Sampling Method || High-Confidence</td>      <td>93.32</td>      <td>97.21</td>      <td>95.19\u00b12.21</td>    </tr>    <tr>      <td>Sampling Method || Partition</td>      <td>96.14</td>      <td>97.12</td>      <td>96.61\u00b10.57</td>    </tr>    <tr>      <td>Sampling Method || High-Conf.+Part.</td>      <td>97.63</td>      <td>97.84</td>      <td>97.73\u00b10.43</td>    </tr>    <tr>      <td>Sampling Method || Top K Entrop</td>      <td>96.16</td>      <td>89.64</td>      <td>92.07\u00b19.73</td>    </tr>  </tbody></table>",
        "table_name": "Table 6",
        "table_id": "table_6",
        "paper_id": "P19-1586",
        "page_no": 9,
        "dir": "acl2019",
        "valid": 1
    },
    {
        "table_id_paper": "P19-1596table_6",
        "caption": "Automatic semantic evaluation (higher is better for all but SER).",
        "row_header_level": 1,
        "row_headers": [
            [
                "BLEU"
            ],
            [
                "METEOR"
            ],
            [
                "CIDEr"
            ],
            [
                "NIST"
            ],
            [
                "Avg SER"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "BASE"
            ],
            [
                " +ADI"
            ],
            [
                " +SENT"
            ],
            [
                " +STYLE"
            ]
        ],
        "contents": [
            [
                "0.126",
                "0.164",
                "0.166",
                "0.173"
            ],
            [
                "0.206",
                "0.233",
                "0.234",
                "0.235"
            ],
            [
                "1.3",
                "1.686",
                "1.692",
                "1.838"
            ],
            [
                "3.84",
                "4.547",
                "4.477",
                "5.537"
            ],
            [
                "0.053",
                "0.063",
                "0.064",
                "0.09"
            ]
        ],
        "metrics_loc": "row",
        "metrics_type": [
            "BLEU",
            "METEOR",
            "CIDEr",
            "NIST",
            "Avg SER"
        ],
        "target_entity": [
            "Avg SER"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>BASE</th>      <th>+ADI</th>      <th>+SENT</th>      <th>+STYLE</th>    </tr>  </thead>  <tbody>    <tr>      <td>BLEU</td>      <td>0.126</td>      <td>0.164</td>      <td>0.166</td>      <td>0.173</td>    </tr>    <tr>      <td>METEOR</td>      <td>0.206</td>      <td>0.233</td>      <td>0.234</td>      <td>0.235</td>    </tr>    <tr>      <td>CIDEr</td>      <td>1.3</td>      <td>1.686</td>      <td>1.692</td>      <td>1.838</td>    </tr>    <tr>      <td>NIST</td>      <td>3.84</td>      <td>4.547</td>      <td>4.477</td>      <td>5.537</td>    </tr>    <tr>      <td>Avg SER</td>      <td>0.053</td>      <td>0.063</td>      <td>0.064</td>      <td>0.09</td>    </tr>  </tbody></table>",
        "table_name": "Table 6",
        "table_id": "table_6",
        "paper_id": "P19-1596",
        "page_no": 7,
        "dir": "acl2019",
        "valid": 1
    },
    {
        "table_id_paper": "P19-1630table_1",
        "caption": "Quantitative comparison (Rouge 1, 2 and L) of models on aspect-specific summarization.",
        "row_header_level": 1,
        "row_headers": [
            [
                "lead-3"
            ],
            [
                "PG-net"
            ],
            [
                "enc-attn"
            ],
            [
                "dec-attn"
            ],
            [
                "sf"
            ],
            [
                "enc-attn-extract"
            ],
            [
                "dec-attn-extract"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "Rouge 1"
            ],
            [
                "Rouge 2"
            ],
            [
                "Rouge L"
            ]
        ],
        "contents": [
            [
                "0.2150",
                "0.0690",
                "0.1410"
            ],
            [
                "0.1757",
                "0.0472",
                "0.1594"
            ],
            [
                "0.2750",
                "0.1027",
                "0.2502"
            ],
            [
                "0.2734",
                "0.1005",
                "0.2509"
            ],
            [
                "0.2802",
                "0.1046",
                "0.2536"
            ],
            [
                "0.3033",
                "0.1092",
                "0.2732"
            ],
            [
                "0.3326",
                "0.1379",
                "0.3026"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "Rouge 1",
            "Rouge 2",
            "Rouge L"
        ],
        "target_entity": [
            "enc-attn-extract",
            "dec-attn-extract"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Rouge 1</th>      <th>Rouge 2</th>      <th>Rouge L</th>    </tr>  </thead>  <tbody>    <tr>      <td>lead-3</td>      <td>0.2150</td>      <td>0.0690</td>      <td>0.1410</td>    </tr>    <tr>      <td>PG-net</td>      <td>0.1757</td>      <td>0.0472</td>      <td>0.1594</td>    </tr>    <tr>      <td>enc-attn</td>      <td>0.2750</td>      <td>0.1027</td>      <td>0.2502</td>    </tr>    <tr>      <td>dec-attn</td>      <td>0.2734</td>      <td>0.1005</td>      <td>0.2509</td>    </tr>    <tr>      <td>sf</td>      <td>0.2802</td>      <td>0.1046</td>      <td>0.2536</td>    </tr>    <tr>      <td>enc-attn-extract</td>      <td>0.3033</td>      <td>0.1092</td>      <td>0.2732</td>    </tr>    <tr>      <td>dec-attn-extract</td>      <td>0.3326</td>      <td>0.1379</td>      <td>0.3026</td>    </tr>  </tbody></table>",
        "table_name": "Table 1",
        "table_id": "table_1",
        "paper_id": "P19-1630",
        "page_no": 6,
        "dir": "acl2019",
        "valid": 1
    },
    {
        "table_id_paper": "P19-1635table_4",
        "caption": "Experimental results.",
        "row_header_level": 2,
        "row_headers": [
            [
                "Model",
                "LR"
            ],
            [
                "Model",
                "CNN"
            ],
            [
                "Model",
                "GRU"
            ],
            [
                "Model",
                "BiGRU"
            ],
            [
                "Model",
                "CRNN"
            ],
            [
                "Model",
                "CNN-capsule"
            ],
            [
                "Model",
                "GRU-capsule"
            ],
            [
                "Model",
                "BiGRU-capsule"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "Micro-F1"
            ],
            [
                "Macro-F1"
            ]
        ],
        "contents": [
            [
                "71.25%",
                "60.80%"
            ],
            [
                "77.17%",
                "58.49%"
            ],
            [
                "78.25%",
                "58.08%"
            ],
            [
                "80.16%",
                "62.74%"
            ],
            [
                "78.00%",
                "64.62%"
            ],
            [
                "75.89%",
                "59.22%"
            ],
            [
                "77.36%",
                "64.71%"
            ],
            [
                "77.97%",
                "64.34%"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "Micro-F1",
            "Macro-F1"
        ],
        "target_entity": [
            "BiGRU"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Micro-F1</th>      <th>Macro-F1</th>    </tr>  </thead>  <tbody>    <tr>      <td>Model || LR</td>      <td>71.25%</td>      <td>60.80%</td>    </tr>    <tr>      <td>Model || CNN</td>      <td>77.17%</td>      <td>58.49%</td>    </tr>    <tr>      <td>Model || GRU</td>      <td>78.25%</td>      <td>58.08%</td>    </tr>    <tr>      <td>Model || BiGRU</td>      <td>80.16%</td>      <td>62.74%</td>    </tr>    <tr>      <td>Model || CRNN</td>      <td>78.00%</td>      <td>64.62%</td>    </tr>    <tr>      <td>Model || CNN-capsule</td>      <td>75.89%</td>      <td>59.22%</td>    </tr>    <tr>      <td>Model || GRU-capsule</td>      <td>77.36%</td>      <td>64.71%</td>    </tr>    <tr>      <td>Model || BiGRU-capsule</td>      <td>77.97%</td>      <td>64.34%</td>    </tr>  </tbody></table>",
        "table_name": "Table 4",
        "table_id": "table_4",
        "paper_id": "P19-1635",
        "page_no": 3,
        "dir": "acl2019",
        "valid": 1
    },
    {
        "table_id_paper": "P19-1638table_3",
        "caption": " Yelp test accuracy (without fine-tuning).CNN-SC significantly improves over CNN-R.",
        "row_header_level": 2,
        "row_headers": [
            [
                "Pre-training",
                "On Yelp"
            ],
            [
                "Pre-training",
                "On Wikipedia"
            ],
            [
                "Pre-training",
                "Wall-clock speedup"
            ]
        ],
        "column_header_level": 2,
        "column_headers": [
            [
                "Model",
                "CNN-R"
            ],
            [
                "Model",
                "CNN-SC"
            ]
        ],
        "contents": [
            [
                "67.4",
                "90"
            ],
            [
                "61.4",
                "65.7"
            ],
            [
                "1x",
                "4x"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "accuracy",
            "accuracy"
        ],
        "target_entity": [
            "CNN-SC"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>Model || CNN-R</th>      <th>Model || CNN-SC</th>    </tr>  </thead>  <tbody>    <tr>      <td>Pre-training || On Yelp</td>      <td>67.4</td>      <td>90</td>    </tr>    <tr>      <td>Pre-training || On Wikipedia</td>      <td>61.4</td>      <td>65.7</td>    </tr>    <tr>      <td>Pre-training || Wall-clock speedup</td>      <td>1x</td>      <td>4x</td>    </tr>  </tbody></table>",
        "table_name": "Table 3",
        "table_id": "table_3",
        "paper_id": "P19-1638",
        "page_no": 4,
        "dir": "acl2019",
        "valid": 1
    },
    {
        "table_id_paper": "P19-1648table_4",
        "caption": "Comparison of ReDAN to state-of-the-art visual dialog models on the blind test-std v1.0 set, as reported by (\u2020) taken from https://evalai.cloudcv.org/web/challenges/challenge-page/161/ the test server. (\u2021) taken from https://evalai.cloudcv.org/web/challenges/challenge-page/ leaderboard/483. 103/leaderboard/298.",
        "row_header_level": 2,
        "row_headers": [
            [
                "Model",
                "ReDAN+ (Diverse Ens.)"
            ],
            [
                "Model",
                "ReDAN (1 Dis. + 1 Gen.)"
            ],
            [
                "Model",
                "DAN (Kang et al., 2019)"
            ],
            [
                "Model",
                "NMN (Kottur et al., 2018)"
            ],
            [
                "Model",
                "Sync (Guo et al., 2019)"
            ],
            [
                "Model",
                "HACAN (Yang et al., 2019)"
            ],
            [
                "Model",
                "FGA\u2020"
            ],
            [
                "Model",
                "USTC-YTH\u2021"
            ],
            [
                "Model",
                "RvA (Niu et al., 2018)"
            ],
            [
                "Model",
                "MS ConvAI\u2021"
            ],
            [
                "Model",
                "CorefNMN (Kottur et al., 2018)"
            ],
            [
                "Model",
                "FGA (Schwartz et al., 2019)"
            ],
            [
                "Model",
                "GNN (Zheng et al., 2019)"
            ],
            [
                "Model",
                "LF-Att w/ bottom-up\u2020"
            ],
            [
                "Model",
                "LF-Att\u2021"
            ],
            [
                "Model",
                "MN-Att\u2021"
            ],
            [
                "Model",
                "MN\u2021"
            ],
            [
                "Model",
                "HRE\u2021"
            ],
            [
                "Model",
                "LF\u2021"
            ]
        ],
        "column_header_level": 1,
        "column_headers": [
            [
                "NDCG"
            ],
            [
                "MRR"
            ],
            [
                "R@1"
            ],
            [
                "R@5"
            ],
            [
                "R@10"
            ],
            [
                "Mean"
            ]
        ],
        "contents": [
            [
                "64.47",
                "53.73",
                "42.45",
                "64.68",
                "75.68",
                "6.63"
            ],
            [
                "61.86",
                "53.13",
                "41.38",
                "66.07",
                "74.5",
                "8.91"
            ],
            [
                "59.36",
                "64.92",
                "51.28",
                "81.6",
                "90.88",
                "3.92"
            ],
            [
                "58.1",
                "58.8",
                "44.15",
                "76.88",
                "86.88",
                "4.81"
            ],
            [
                "57.88",
                "63.42",
                "49.3",
                "80.77",
                "90.68",
                "3.97"
            ],
            [
                "57.17",
                "64.22",
                "50.88",
                "80.63",
                "89.45",
                "4.2"
            ],
            [
                "57.13",
                "69.25",
                "55.65",
                "86.73",
                "94.05",
                "3.14"
            ],
            [
                "56.47",
                "61.44",
                "47.65",
                "78.13",
                "87.88",
                "4.65"
            ],
            [
                "55.59",
                "63.03",
                "49.03",
                "80.4",
                "89.83",
                "4.18"
            ],
            [
                "55.35",
                "63.27",
                "49.53",
                "80.4",
                "89.6",
                "4.15"
            ],
            [
                "54.7",
                "61.5",
                "47.55",
                "78.1",
                "88.8",
                "4.4"
            ],
            [
                "54.46",
                "67.25",
                "53.4",
                "85.28",
                "92.7",
                "3.54"
            ],
            [
                "52.82",
                "61.37",
                "47.33",
                "77.98",
                "87.83",
                "4.57"
            ],
            [
                "51.63",
                "60.41",
                "46.18",
                "77.8",
                "87.3",
                "4.75"
            ],
            [
                "49.76",
                "57.07",
                "42.08",
                "74.83",
                "85.05",
                "5.41"
            ],
            [
                "49.58",
                "56.9",
                "42.43",
                "74",
                "84.35",
                "5.59"
            ],
            [
                "47.5",
                "55.49",
                "40.98",
                "72.3",
                "83.3",
                "5.92"
            ],
            [
                "45.46",
                "54.16",
                "39.93",
                "70.45",
                "81.5",
                "6.41"
            ],
            [
                "45.31",
                "55.42",
                "40.95",
                "72.45",
                "82.83",
                "5.95"
            ]
        ],
        "metrics_loc": "column",
        "metrics_type": [
            "NDCG",
            "MRR",
            "R@1",
            "R@5",
            "R@10",
            "Mean"
        ],
        "target_entity": [
            "ReDAN+ (Diverse Ens.)"
        ],
        "table_html_clean": "<table border='1' class='dataframe'>  <thead>    <tr style='text-align: right;'>      <th></th>      <th>NDCG</th>      <th>MRR</th>      <th>R@1</th>      <th>R@5</th>      <th>R@10</th>      <th>Mean</th>    </tr>  </thead>  <tbody>    <tr>      <td>Model || ReDAN+ (Diverse Ens.)</td>      <td>64.47</td>      <td>53.73</td>      <td>42.45</td>      <td>64.68</td>      <td>75.68</td>      <td>6.63</td>    </tr>    <tr>      <td>Model || ReDAN (1 Dis. + 1 Gen.)</td>      <td>61.86</td>      <td>53.13</td>      <td>41.38</td>      <td>66.07</td>      <td>74.5</td>      <td>8.91</td>    </tr>    <tr>      <td>Model || DAN (Kang et al., 2019)</td>      <td>59.36</td>      <td>64.92</td>      <td>51.28</td>      <td>81.6</td>      <td>90.88</td>      <td>3.92</td>    </tr>    <tr>      <td>Model || NMN (Kottur et al., 2018)</td>      <td>58.1</td>      <td>58.8</td>      <td>44.15</td>      <td>76.88</td>      <td>86.88</td>      <td>4.81</td>    </tr>    <tr>      <td>Model || Sync (Guo et al., 2019)</td>      <td>57.88</td>      <td>63.42</td>      <td>49.3</td>      <td>80.77</td>      <td>90.68</td>      <td>3.97</td>    </tr>    <tr>      <td>Model || HACAN (Yang et al., 2019)</td>      <td>57.17</td>      <td>64.22</td>      <td>50.88</td>      <td>80.63</td>      <td>89.45</td>      <td>4.2</td>    </tr>    <tr>      <td>Model || FGA\u2020</td>      <td>57.13</td>      <td>69.25</td>      <td>55.65</td>      <td>86.73</td>      <td>94.05</td>      <td>3.14</td>    </tr>    <tr>      <td>Model || USTC-YTH\u2021</td>      <td>56.47</td>      <td>61.44</td>      <td>47.65</td>      <td>78.13</td>      <td>87.88</td>      <td>4.65</td>    </tr>    <tr>      <td>Model || RvA (Niu et al., 2018)</td>      <td>55.59</td>      <td>63.03</td>      <td>49.03</td>      <td>80.4</td>      <td>89.83</td>      <td>4.18</td>    </tr>    <tr>      <td>Model || MS ConvAI\u2021</td>      <td>55.35</td>      <td>63.27</td>      <td>49.53</td>      <td>80.4</td>      <td>89.6</td>      <td>4.15</td>    </tr>    <tr>      <td>Model || CorefNMN (Kottur et al., 2018)</td>      <td>54.7</td>      <td>61.5</td>      <td>47.55</td>      <td>78.1</td>      <td>88.8</td>      <td>4.4</td>    </tr>    <tr>      <td>Model || FGA (Schwartz et al., 2019)</td>      <td>54.46</td>      <td>67.25</td>      <td>53.4</td>      <td>85.28</td>      <td>92.7</td>      <td>3.54</td>    </tr>    <tr>      <td>Model || GNN (Zheng et al., 2019)</td>      <td>52.82</td>      <td>61.37</td>      <td>47.33</td>      <td>77.98</td>      <td>87.83</td>      <td>4.57</td>    </tr>    <tr>      <td>Model || LF-Att w/ bottom-up\u2020</td>      <td>51.63</td>      <td>60.41</td>      <td>46.18</td>      <td>77.8</td>      <td>87.3</td>      <td>4.75</td>    </tr>    <tr>      <td>Model || LF-Att\u2021</td>      <td>49.76</td>      <td>57.07</td>      <td>42.08</td>      <td>74.83</td>      <td>85.05</td>      <td>5.41</td>    </tr>    <tr>      <td>Model || MN-Att\u2021</td>      <td>49.58</td>      <td>56.9</td>      <td>42.43</td>      <td>74</td>      <td>84.35</td>      <td>5.59</td>    </tr>    <tr>      <td>Model || MN\u2021</td>      <td>47.5</td>      <td>55.49</td>      <td>40.98</td>      <td>72.3</td>      <td>83.3</td>      <td>5.92</td>    </tr>    <tr>      <td>Model || HRE\u2021</td>      <td>45.46</td>      <td>54.16</td>      <td>39.93</td>      <td>70.45</td>      <td>81.5</td>      <td>6.41</td>    </tr>    <tr>      <td>Model || LF\u2021</td>      <td>45.31</td>      <td>55.42</td>      <td>40.95</td>      <td>72.45</td>      <td>82.83</td>      <td>5.95</td>    </tr>  </tbody></table>",
        "table_name": "Table 4",
        "table_id": "table_4",
        "paper_id": "P19-1648",
        "page_no": 9,
        "dir": "acl2019",
        "valid": 1
    }
]